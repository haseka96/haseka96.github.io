<!DOCTYPE html><html lang="en" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>PETR代码详解 | 在发之泽</title><meta name="author" content="haseka"><meta name="copyright" content="haseka"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="PETR 代码详解 小记 看了很久的PETR源代码，后续磕盐工作以此文章为基础在上面更改，期望能顺利毕业。 本来很早就想边看边记录，但是一直以为博客的源文件没有迁移到主力本上，突然才发现上一篇4090时都迁过来了，感觉自己最近有些不在状态了，还是得开启学习记录，保持状态。 整体的代码流程  配置文件 使用了mmdet框架的代码结构，这里从头到尾把配置文件部分讲清楚，其中一些细节会同步放出定义源码讲">
<meta property="og:type" content="article">
<meta property="og:title" content="PETR代码详解">
<meta property="og:url" content="https://github.com/haseka96.github.io/2023/11/23/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/index.html">
<meta property="og:site_name" content="在发之泽">
<meta property="og:description" content="PETR 代码详解 小记 看了很久的PETR源代码，后续磕盐工作以此文章为基础在上面更改，期望能顺利毕业。 本来很早就想边看边记录，但是一直以为博客的源文件没有迁移到主力本上，突然才发现上一篇4090时都迁过来了，感觉自己最近有些不在状态了，还是得开启学习记录，保持状态。 整体的代码流程  配置文件 使用了mmdet框架的代码结构，这里从头到尾把配置文件部分讲清楚，其中一些细节会同步放出定义源码讲">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png">
<meta property="article:published_time" content="2023-11-23T08:41:06.000Z">
<meta property="article:modified_time" content="2023-11-23T08:43:49.724Z">
<meta property="article:author" content="haseka">
<meta property="article:tag" content="PETR">
<meta property="article:tag" content="code">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://github.com/haseka96.github.io/2023/11/23/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: undefined,
  copy: {
    success: 'Copy Successful',
    error: 'Copy Error',
    noSupport: 'Browser Not Supported'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: 'Just now',
    min: 'minutes ago',
    hour: 'hours ago',
    day: 'days ago',
    month: 'months ago'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: 'Load More'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'PETR代码详解',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2023-11-23 16:43:49'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiperstyle.css" media="print" onload="this.media='all'"><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">32</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">33</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a href="/" title="在发之泽"><span class="site-name">在发之泽</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">PETR代码详解</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">Created</span><time class="post-meta-date-created" datetime="2023-11-23T08:41:06.000Z" title="Created 2023-11-23 16:41:06">2023-11-23</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">Updated</span><time class="post-meta-date-updated" datetime="2023-11-23T08:43:49.724Z" title="Updated 2023-11-23 16:43:49">2023-11-23</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="PETR代码详解"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">Post Views:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="petr-代码详解">PETR 代码详解</h1>
<h2 id="小记">小记</h2>
<p>看了很久的PETR源代码，后续磕盐工作以此文章为基础在上面更改，期望能顺利毕业。</p>
<p>本来很早就想边看边记录，但是一直以为博客的源文件没有迁移到主力本上，突然才发现上一篇4090时都迁过来了，感觉自己最近有些不在状态了，还是得开启学习记录，保持状态。</p>
<p>整体的代码流程</p>
<p><a
target="_blank" rel="noopener" href="https://goodxue.github.io/images/PETR代码详解/liucheng.png"><img
src="https://goodxue.github.io/images/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/liucheng.png"
alt="img" /></a></p>
<h2 id="配置文件">配置文件</h2>
<p>使用了mmdet框架的代码结构，这里从头到尾把配置文件部分讲清楚，其中一些细节会同步放出定义源码讲解。</p>
<p>使用 <em>petr_r50dcn_gridmask_p4.py</em>
做解释。首先是配置加载和预先定义。</p>
<pre><code>_base_ = [
    &#39;../../../mmdetection3d/configs/_base_/datasets/nus-3d.py&#39;,
    &#39;../../../mmdetection3d/configs/_base_/default_runtime.py&#39;
]
# 这里引用了nus-3d的nuscenes数据集，所以包含了在mm3d中的配置，default_runtime是基本的runtime设置。
backbone_norm_cfg = dict(type=&#39;LN&#39;, requires_grad=True)
# LayerNorm 层归一化，设置了backbone中使用到的归一化参数
plugin=True
plugin_dir=&#39;projects/mmdet3d_plugin/&#39;
# 给出了当前工程路径

# If point cloud range is changed, the models should also change their point
# cloud range accordingly
point_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
voxel_size = [0.2, 0.2, 8]
img_norm_cfg = dict(
    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)
# For nuScenes we usually do 10-class detection
class_names = [
    &#39;car&#39;, &#39;truck&#39;, &#39;construction_vehicle&#39;, &#39;bus&#39;, &#39;trailer&#39;, &#39;barrier&#39;,
    &#39;motorcycle&#39;, &#39;bicycle&#39;, &#39;pedestrian&#39;, &#39;traffic_cone&#39;
]
# 十个类别
input_modality = dict(
    use_lidar=False,
    use_camera=True,
    use_radar=False,
    use_map=False,
    use_external=False)
# 输入数据的模态，只使用相机图像数据</code></pre>
<p>模型定义部分，这一部分是重点关注部分。</p>
<pre><code>model = dict(
    type=&#39;Petr3D&#39;, # 首先最顶层的网络定义就是PETR，定义在PETR3d.py中，它需要多个输入参数，包括了backbone，neck，petr_head等等，属于模型的最上层定义。
    use_grid_mask=True, # 一种数据增强的方法
    img_backbone=dict(
        type=&#39;ResNet&#39;,
        depth=50,
        num_stages=4,
        out_indices=(2, 3,), # 输出第3，4层的中间特征，维度为1024，2048，对应FPN网络
        frozen_stages=-1, # -1表示不进行frozen
        norm_cfg=dict(type=&#39;BN2d&#39;, requires_grad=False),
        norm_eval=True,
        style=&#39;caffe&#39;,
        with_cp=True,
        dcn=dict(type=&#39;DCNv2&#39;, deform_groups=1, fallback_on_stride=False), #加入DCNv2模块
        stage_with_dcn=(False, False, True, True),
        pretrained = &#39;ckpts/resnet50_msra-5891d200.pth&#39;,
        ),
    # 首先是backbone，是一个resnet50，输入数据维度（B，N，3，H，W），查看源码后发现如果是5维的tensor，会将BN相乘后转换到4维输入。</code></pre>
<p>在模型的定义，最上层模型文件中
<em>petr3d.py</em>，提取特征时对输入进行了处理。</p>
<pre><code>def extract_img_feat(self, img, img_metas):
        &quot;&quot;&quot;Extract features of images.&quot;&quot;&quot;
        # print(img[0].size())
        if isinstance(img, list):
            img = torch.stack(img, dim=0)

        B = img.size(0)
        if img is not None:
            input_shape = img.shape[-2:]
            # update real input shape of each single img
            for img_meta in img_metas:
                img_meta.update(input_shape=input_shape)
            if img.dim() == 5:
                if img.size(0) == 1 and img.size(1) != 1:
                    img.squeeze_()
                else:
                    B, N, C, H, W = img.size()
                    img = img.view(B * N, C, H, W) # 这里将维度降维到4维
            if self.use_grid_mask:
                img = self.grid_mask(img)
            img_feats = self.img_backbone(img) # 送入backbone，输出的是BN，Cout，Hout，Wout维度，list里是设置输出的层数
            if isinstance(img_feats, dict):
                img_feats = list(img_feats.values())
        else:
            return None
        if self.with_img_neck:
            img_feats = self.img_neck(img_feats) # 送到FPN中提取多层特征
        img_feats_reshaped = []
        for img_feat in img_feats:
            BN, C, H, W = img_feat.size()
            img_feats_reshaped.append(img_feat.view(B, int(BN / B), C, H, W)) # 将每个特征图的维度重新包装成B，N，C，H，W
        return img_feats_reshaped</code></pre>
<p>neck是FPN，不必多说。petr_head定义了decoder的结构，与DETR基本类似，主要不同就是PETR_head里面前向forward过程中的变化，这里先略过，先熟悉整体代码流程。</p>
<pre><code>img_neck=dict(
    type=&#39;CPFPN&#39;,
    in_channels=[1024, 2048],
    out_channels=256, # FPN输出256个通道
    num_outs=2),    
pts_bbox_head=dict(
    type=&#39;PETRHead&#39;,
    num_classes=10,
    in_channels=256, # 输入通道数为256
    num_query=900, # 设置了900个query初始化
    LID=True,
    with_position=True,
    with_multiview=True,
    position_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
    normedlinear=False,
    transformer=dict( # 使用的Transformer定义
        type=&#39;PETRTransformer&#39;,
        decoder=dict(
            type=&#39;PETRTransformerDecoder&#39;,
            return_intermediate=True,
            num_layers=6,
            transformerlayers=dict(
                type=&#39;PETRTransformerDecoderLayer&#39;,
                attn_cfgs=[
                    dict(
                        type=&#39;MultiheadAttention&#39;,
                        embed_dims=256,
                        num_heads=8,
                        dropout=0.1),
                    dict(
                        type=&#39;PETRMultiheadAttention&#39;,
                        embed_dims=256,
                        num_heads=8,
                        dropout=0.1),
                    ],
                feedforward_channels=2048,
                ffn_dropout=0.1,
                with_cp=True,
                operation_order=(&#39;self_attn&#39;, &#39;norm&#39;, &#39;cross_attn&#39;, &#39;norm&#39;,
                                 &#39;ffn&#39;, &#39;norm&#39;)),
        )),
    bbox_coder=dict(
        type=&#39;NMSFreeCoder&#39;,
        # type=&#39;NMSFreeClsCoder&#39;,
        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],
        pc_range=point_cloud_range,
        max_num=300,
        voxel_size=voxel_size,
        num_classes=10), 
    positional_encoding=dict(
        type=&#39;SinePositionalEncoding3D&#39;, num_feats=128, normalize=True),</code></pre>
<p>到这里模型的定义基本完成，具体petr_head的细节在后面解释。positional_encoding是DETR中的位置编码，不是PETR的positional_embedding，positional_embedding的定义是在<em>petr_head.py</em>当中作为一个函数加进去的，后面会说。</p>
<pre><code>    loss_cls=dict(
        type=&#39;FocalLoss&#39;,
        use_sigmoid=True,
        gamma=2.0,
        alpha=0.25,
        loss_weight=2.0),
    loss_bbox=dict(type=&#39;L1Loss&#39;, loss_weight=0.25),
    loss_iou=dict(type=&#39;GIoULoss&#39;, loss_weight=0.0)),
# model training and testing settings
train_cfg=dict(pts=dict(
    grid_size=[512, 512, 1],
    voxel_size=voxel_size,
    point_cloud_range=point_cloud_range,
    out_size_factor=4,
    assigner=dict(
        type=&#39;HungarianAssigner3D&#39;,
        cls_cost=dict(type=&#39;FocalLossCost&#39;, weight=2.0),
        reg_cost=dict(type=&#39;BBox3DL1Cost&#39;, weight=0.25),
        iou_cost=dict(type=&#39;IoUCost&#39;, weight=0.0), # Fake cost. This is just to make it compatible with DETR head. 
        pc_range=point_cloud_range))))</code></pre>
<p>这里是损失函数的定义使用的都是mmdet中自带的损失定义，Focalloss作为分类损失，L1和GIoU作为回归损失，匈牙利损失为Transformer的分类匹配损失。</p>
<p>下面是训练流程的配置，这里以前没有搞明白是做什么的，其实这里才是数据加载的重要过程，数据集的最终load进内存后进行预处理的过程是在这个pipeline当中完成的，要想知道输入给模型的数据是什么格式，是什么样的组织结构需要对这个地方有了解。</p>
<pre><code>train_pipeline = [
    dict(type=&#39;LoadMultiViewImageFromFiles&#39;, to_float32=True),
    dict(type=&#39;LoadAnnotations3D&#39;, with_bbox_3d=True, with_label_3d=True, with_attr_label=False),
    dict(type=&#39;ObjectRangeFilter&#39;, point_cloud_range=point_cloud_range),
    dict(type=&#39;ObjectNameFilter&#39;, classes=class_names),
    dict(type=&#39;ResizeCropFlipImage&#39;, data_aug_conf = ida_aug_conf, training=True),
    dict(type=&#39;GlobalRotScaleTransImage&#39;,
            rot_range=[-0.3925, 0.3925],
            translation_std=[0, 0, 0],
            scale_ratio_range=[0.95, 1.05],
            reverse_angle=True,
            training=True
            ),
    dict(type=&#39;NormalizeMultiviewImage&#39;, **img_norm_cfg),
    dict(type=&#39;PadMultiViewImage&#39;, size_divisor=32),
    dict(type=&#39;DefaultFormatBundle3D&#39;, class_names=class_names),
    dict(type=&#39;Collect3D&#39;, keys=[&#39;gt_bboxes_3d&#39;, &#39;gt_labels_3d&#39;, &#39;img&#39;])
]</code></pre>
<p>需要关注一下“LoadMultiViewImageFromFiles”这个过程</p>
<p>首先先来看一下数据集是如何定义的，在 <em>nuscenes_dataset.py</em>
中：</p>
<pre><code>class CustomNuScenesDataset(NuScenesDataset):
    ...
    def get_data_info(self, index):
        ...
        if self.modality[&#39;use_camera&#39;]:
            image_paths = []
            for cam_type, cam_info in info[&#39;cams&#39;].items():
                img_timestamp.append(cam_info[&#39;timestamp&#39;] / 1e6)
                image_paths.append(cam_info[&#39;data_path&#39;])
                ...
            input_dict.update(
                dict(
                    img_timestamp=img_timestamp,
                    img_filename=image_paths, # dict 前面的key:img_filename直接转化为“img_filename”：image_path字符串
                    lidar2img=lidar2img_rts,
                    intrinsics=intrinsics,
                    extrinsics=extrinsics 
                ))
        return input_dict</code></pre>
<p>可以看到输出的data信息只有图像的文件路径，并没有加载进内存。</p>
<p>在 <em>loading.py</em>中</p>
<pre><code>class LoadMultiViewImageFromFiles(object):
    def __call__(self, results):
        &quot;&quot;&quot;Call function to load multi-view image from files.

        Args:
            results (dict): Result dict containing multi-view image filenames.

        Returns:
            dict: The result dict containing the multi-view image data. \
                Added keys and values are described below.

                - filename (str): Multi-view image filenames.
                - img (np.ndarray): Multi-view image arrays.
                - img_shape (tuple[int]): Shape of multi-view image arrays.
                - ori_shape (tuple[int]): Shape of original image arrays.
                - pad_shape (tuple[int]): Shape of padded image arrays.
                - scale_factor (float): Scale factor.
                - img_norm_cfg (dict): Normalization configuration of images.
        &quot;&quot;&quot;
        filename = results[&#39;img_filename&#39;]
        # img is of shape (h, w, c, num_views)
        # 这里根据数据集的输出，将图像地址找到加载起来，每一个img_filename内是一个时刻下6个相机的图像地址，将其堆叠起来
        img = np.stack(
            [mmcv.imread(name, self.color_type) for name in filename], axis=-1)
        if self.to_float32:
            img = img.astype(np.float32)
        results[&#39;filename&#39;] = filename
        # unravel to list, see `DefaultFormatBundle` in formating.py
        # which will transpose each image separately and then stack into array
        results[&#39;img&#39;] = [img[..., i] for i in range(img.shape[-1])]
        # 转为列表形式，维数为 N，C，H，W。
        results[&#39;img_shape&#39;] = img.shape
        results[&#39;ori_shape&#39;] = img.shape
        # Set initial values for default meta_keys
        results[&#39;pad_shape&#39;] = img.shape
        results[&#39;scale_factor&#39;] = 1.0
        num_channels = 1 if len(img.shape) &lt; 3 else img.shape[2]
        results[&#39;img_norm_cfg&#39;] = dict(
            mean=np.zeros(num_channels, dtype=np.float32),
            std=np.ones(num_channels, dtype=np.float32),
            to_rgb=False)
        return results</code></pre>
<p>这一部分看明白后，就可以知道送入<span
class="math inline">\(\color{Red}
{backbone}\)</span>的数据为什么是（B，N，C，H，W）的维数了。backbone通过一次直接处理BN张（C，H，W）的图像数据，一次性的可以提取N个视角下的多目图像特征，在后续的encoder-decoder模块内可以学习到多个图像特征间的关联，实现特征融合。</p>
<p>最后的<span class="math inline">\(\color{Red}
{Collect3D}\)</span>步骤是将key内的元素提取出来。于是训练阶段的输入数据就包括了[‘gt_bboxes_3d’,
‘gt_labels_3d’, ‘img’]这三个内容。</p>
<p>数据集的配置部分，这里只是配置了数据集的一些基本情况，重点部分还是上面流水线与数据集的接口部分比较重要。</p>
<pre><code>dataset_type = &#39;CustomNuScenesDataset&#39;
data_root = &#39;./data/nuscenes/&#39;
data = dict(
    samples_per_gpu=4, # 这里是batch size，一般来说越大越好，我用的4090有24gb显存，只能开到4.
    workers_per_gpu=4, # 多进程加载数据，这里用了4个进程。
    train=dict(
        type=dataset_type, # 数据集的定义
        data_root=data_root, # 数据集的路径
        ann_file=data_root + &#39;nuscenes_infos_train.pkl&#39;,
        pipeline=train_pipeline,
        classes=class_names,
        modality=input_modality,
        test_mode=False,
        use_valid_flag=True,
        # we use box_type_3d=&#39;LiDAR&#39; in kitti and nuscenes dataset
        # and box_type_3d=&#39;Depth&#39; in sunrgbd and scannet dataset.
        box_type_3d=&#39;LiDAR&#39;),
    val=dict(type=dataset_type, pipeline=test_pipeline, classes=class_names, modality=input_modality),
    test=dict(type=dataset_type, pipeline=test_pipeline, classes=class_names, modality=input_modality))</code></pre>
<p>剩下的部分就比较容易理解了，配置优化器和学习率等等，属于不需要较多改动的部分。</p>
<pre><code>optimizer = dict(
    type=&#39;AdamW&#39;, 
    lr=2e-4,
    paramwise_cfg=dict(
        custom_keys=&#123;
            &#39;img_backbone&#39;: dict(lr_mult=0.1),
        &#125;),
    weight_decay=0.01)

optimizer_config = dict(type=&#39;Fp16OptimizerHook&#39;, loss_scale=512., grad_clip=dict(max_norm=35, norm_type=2))
# learning policy
lr_config = dict(
    policy=&#39;CosineAnnealing&#39;,
    warmup=&#39;linear&#39;,
    warmup_iters=500,
    warmup_ratio=1.0 / 3,
    min_lr_ratio=1e-3,
    # by_epoch=False
    )
total_epochs = 24
evaluation = dict(interval=24, pipeline=test_pipeline)
find_unused_parameters = False

runner = dict(type=&#39;EpochBasedRunner&#39;, max_epochs=total_epochs)
load_from=None
resume_from=&#39;work_dirs/petr_r50dcn_gridmask_p4/latest.pth&#39;</code></pre>
<h2 id="petr-head">PETR HEAD</h2>
<p>我们先从最上层的PETR模型开始</p>
<p><em>petr.py</em></p>
<pre><code>@DETECTORS.register_module()
class Petr3D(MVXTwoStageDetector):
    ...
    def forward_train(...):
        img_feats = self.extract_feat(img=img, img_metas=img_metas)
        losses = dict()
        losses_pts = self.forward_pts_train(img_feats, gt_bboxes_3d,
                                            gt_labels_3d, img_metas,
                                            gt_bboxes_ignore)
        losses.update(losses_pts)
        return losses

    def forward_pts_train(...):
        outs = self.pts_bbox_head(pts_feats, img_metas)
        loss_inputs = [gt_bboxes_3d, gt_labels_3d, outs]
        losses = self.pts_bbox_head.loss(*loss_inputs)

        return losses</code></pre>
<p>通过 <em>backbone</em>
提取特征后送入petr_head得到输出，和真值计算损失后输出一个训练损失，即为一个训练。</p>
<p>petr_head.py
这个文件中就完成了PETR对于DETR的改进部分和自己的创新点。理解PETR文章即为理解这一部分代码。</p>
<pre><code>@HEADS.register_module()
class PETRHead(AnchorFreeHead):
    def forward(self, mlvl_feats, img_metas):
        x = mlvl_feats[0] # 首先x为深层的特征图，即fpn输出的256维的tensor
        batch_size, num_cams = x.size(0), x.size(1)
        input_img_h, input_img_w, _ = img_metas[0][&#39;pad_shape&#39;][0]
        masks = x.new_ones(
            (batch_size, num_cams, input_img_h, input_img_w)) # 新生成与原始输入大小相同的mask
        for img_id in range(batch_size):
            for cam_id in range(num_cams):
                img_h, img_w, _ = img_metas[img_id][&#39;img_shape&#39;][cam_id]
                masks[img_id, cam_id, :img_h, :img_w] = 0
        # 图像像素对齐操作
        x = self.input_proj(x.flatten(0,1)) # self.input_proj = Conv2d(self.in_channels, self.embed_dims, kernel_size=1) 先经过一层卷积降维 self.embed_dims = 256
        x = x.view(batch_size, num_cams, *x.shape[-3:]) # BNCHW
        # interpolate masks to have the same spatial shape with x
        masks = F.interpolate(
            masks, size=x.shape[-2:]).to(torch.bool)

        if self.with_position:
            coords_position_embeding, _ = self.position_embeding(mlvl_feats, img_metas, masks) # 这里是PE的部分，PE的具体原理在下一部分说明
            pos_embed = coords_position_embeding
            if self.with_multiview:
                sin_embed = self.positional_encoding(masks) # DETR的positional encoding，作用是图像的位置编码
                sin_embed = self.adapt_pos3d(sin_embed.flatten(0, 1)).view(x.size())
                pos_embed = pos_embed + sin_embed # 两部分相加作为transformer的positional encoding

                # self.adapt_pos3d = nn.Sequential(
                #     nn.Conv2d(self.embed_dims*3//2, self.embed_dims*4, kernel_size=1, stride=1, padding=0),
                #     nn.ReLU(),
                #     nn.Conv2d(self.embed_dims*4, self.embed_dims, kernel_size=1, stride=1, padding=0),
                # )
            else:
                pos_embeds = []
                for i in range(num_cams):
                    xy_embed = self.positional_encoding(masks[:, i, :, :])
                    pos_embeds.append(xy_embed.unsqueeze(1))
                sin_embed = torch.cat(pos_embeds, 1)
                sin_embed = self.adapt_pos3d(sin_embed.flatten(0, 1)).view(x.size())
                pos_embed = pos_embed + sin_embed
        else:
            if self.with_multiview:
                pos_embed = self.positional_encoding(masks)
                pos_embed = self.adapt_pos3d(pos_embed.flatten(0, 1)).view(x.size())
            else:
                pos_embeds = []
                for i in range(num_cams):
                    pos_embed = self.positional_encoding(masks[:, i, :, :])
                    pos_embeds.append(pos_embed.unsqueeze(1))
                pos_embed = torch.cat(pos_embeds, 1)

        reference_points = self.reference_points.weight # shape(num_query,3) 应该是每个query初始化一个point 这里的num_query=100
        # self.reference_points = nn.Embedding(self.num_query, 3) 使用了里面的可学习参数作为querry，因此querry是通过学习不断改变的
        query_embeds = self.query_embedding(pos2posemb3d(reference_points)) # querry后续操作
        # self.query_embedding = nn.Sequential(
        #     nn.Linear(self.embed_dims*3//2, self.embed_dims),
        #     nn.ReLU(),
        #     nn.Linear(self.embed_dims, self.embed_dims),
        # )
        reference_points = reference_points.unsqueeze(0).repeat(batch_size, 1, 1) #.sigmoid()

        outs_dec, _ = self.transformer(x, masks, query_embeds, pos_embed, self.reg_branches) # transformer操作
        outs_dec = torch.nan_to_num(outs_dec)
        outputs_classes = []
        outputs_coords = []
        # outs_dec 输出的每一项表示一个视角的检测目标。这里的操作是将深度信息与之前的坐标系对齐（即加上参考点的位置）
        for lvl in range(outs_dec.shape[0]):
            reference = inverse_sigmoid(reference_points.clone())
            assert reference.shape[-1] == 3
            outputs_class = self.cls_branches[lvl](outs_dec[lvl])
            tmp = self.reg_branches[lvl](outs_dec[lvl])
            # 因为输出的格式是(cx, cy, w, l, cz, h, theta, vx, vy)
            # 将输出的偏移量相加后再归一化，即网络计算的是位置的偏移量
            tmp[..., 0:2] += reference[..., 0:2]
            tmp[..., 0:2] = tmp[..., 0:2].sigmoid()
            tmp[..., 4:5] += reference[..., 2:3] # 因为reference是(num_querry,3) 第三维是z，所以这里是2:3
            tmp[..., 4:5] = tmp[..., 4:5].sigmoid()

            outputs_coord = tmp
            outputs_classes.append(outputs_class)
            outputs_coords.append(outputs_coord)

        all_cls_scores = torch.stack(outputs_classes)
        all_bbox_preds = torch.stack(outputs_coords)
        # 筛选出处于检测范围内的目标
        all_bbox_preds[..., 0:1] = (all_bbox_preds[..., 0:1] * (self.pc_range[3] - self.pc_range[0]) + self.pc_range[0])
        all_bbox_preds[..., 1:2] = (all_bbox_preds[..., 1:2] * (self.pc_range[4] - self.pc_range[1]) + self.pc_range[1])
        all_bbox_preds[..., 4:5] = (all_bbox_preds[..., 4:5] * (self.pc_range[5] - self.pc_range[2]) + self.pc_range[2])

        outs = &#123;
            &#39;all_cls_scores&#39;: all_cls_scores,
            &#39;all_bbox_preds&#39;: all_bbox_preds,
            &#39;enc_cls_scores&#39;: None,
            &#39;enc_bbox_preds&#39;: None, 
        &#125;
        return outs</code></pre>
<p>这里输出了所有检测到的目标。 position_embedding部分</p>
<pre><code>def position_embeding(self, img_feats, img_metas, masks=None):
    eps = 1e-5
    pad_h, pad_w, _ = img_metas[0][&#39;pad_shape&#39;][0]
    B, N, C, H, W = img_feats[self.position_level].shape
    coords_h = torch.arange(H, device=img_feats[0].device).float() * pad_h / H # 生成像素平面内的网格
    coords_w = torch.arange(W, device=img_feats[0].device).float() * pad_w / W

    if self.LID: # 线性分划网络
        index  = torch.arange(start=0, end=self.depth_num, step=1, device=img_feats[0].device).float() # 深度范围内的网格
        index_1 = index + 1
        bin_size = (self.position_range[3] - self.depth_start) / (self.depth_num * (1 + self.depth_num))
        coords_d = self.depth_start + bin_size * index * index_1
    else:
        index  = torch.arange(start=0, end=self.depth_num, step=1, device=img_feats[0].device).float()
        bin_size = (self.position_range[3] - self.depth_start) / self.depth_num
        coords_d = self.depth_start + bin_size * index

    D = coords_d.shape[0]
    coords = torch.stack(torch.meshgrid([coords_w, coords_h, coords_d])).permute(1, 2, 3, 0) # W, H, D, 3 # meshgrid就是生成体素网格
    coords = torch.cat((coords, torch.ones_like(coords[..., :1])), -1) #增加一维，与内参矩阵对应
    coords[..., :2] = coords[..., :2] * torch.maximum(coords[..., 2:3], torch.ones_like(coords[..., 2:3])*eps)

    img2lidars = []
    for img_meta in img_metas:
        img2lidar = []
        for i in range(len(img_meta[&#39;lidar2img&#39;])):
            img2lidar.append(np.linalg.inv(img_meta[&#39;lidar2img&#39;][i])) #乘内参矩阵的逆将相机坐标系转换到世界坐标系
        img2lidars.append(np.asarray(img2lidar))
    img2lidars = np.asarray(img2lidars)
    img2lidars = coords.new_tensor(img2lidars) # (B, N, 4, 4)

    coords = coords.view(1, 1, W, H, D, 4, 1).repeat(B, N, 1, 1, 1, 1, 1)
    img2lidars = img2lidars.view(B, N, 1, 1, 1, 4, 4).repeat(1, 1, W, H, D, 1, 1)
    coords3d = torch.matmul(img2lidars, coords).squeeze(-1)[..., :3] # 划定范围
    coords3d[..., 0:1] = (coords3d[..., 0:1] - self.position_range[0]) / (self.position_range[3] - self.position_range[0])
    coords3d[..., 1:2] = (coords3d[..., 1:2] - self.position_range[1]) / (self.position_range[4] - self.position_range[1])
    coords3d[..., 2:3] = (coords3d[..., 2:3] - self.position_range[2]) / (self.position_range[5] - self.position_range[2])

    coords_mask = (coords3d &gt; 1.0) | (coords3d &lt; 0.0) # 不在范围内的元素将被mask遮住
    coords_mask = coords_mask.flatten(-2).sum(-1) &gt; (D * 0.5)
    coords_mask = masks | coords_mask.permute(0, 1, 3, 2)
    coords3d = coords3d.permute(0, 1, 4, 5, 3, 2).contiguous().view(B*N, -1, H, W)
    coords3d = inverse_sigmoid(coords3d) # 归一化
    coords_position_embeding = self.position_encoder(coords3d) # 送入几层卷积网络中，进一步加深编码信息
    
    return coords_position_embeding.view(B, N, self.embed_dims, H, W), coords_mask</code></pre>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>Author: </span><span class="post-copyright-info"><a href="https://github.com/haseka96.github.io">haseka</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>Link: </span><span class="post-copyright-info"><a href="https://github.com/haseka96.github.io/2023/11/23/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/">https://github.com/haseka96.github.io/2023/11/23/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>Copyright Notice: </span><span class="post-copyright-info">All articles in this blog are licensed under <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> unless stating additionally.</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/PETR/">PETR</a><a class="post-meta__tags" href="/tags/code/">code</a></div><div class="post_share"><div class="social-share" data-image="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2023/11/24/MMD3D%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%8B%E8%AF%95%E7%BE%A4%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/" title="MMD3D模型训练测试群流程解析"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Previous</div><div class="prev_info">MMD3D模型训练测试群流程解析</div></div></a></div><div class="next-post pull-right"><a href="/2023/11/23/Hook%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97/" title="Hook食用指南"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">Next</div><div class="next_info">Hook食用指南</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>Related Articles</span></div><div class="relatedPosts-list"><div><a href="/2023/11/27/MMD-PETR-train-detector%E5%AF%BC%E5%9B%BE/" title="MMD-PETR_train-detector导图"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-11-27</div><div class="title">MMD-PETR_train-detector导图</div></div></a></div><div><a href="/2023/12/05/Petr-3D%E5%9D%90%E6%A0%87%E7%94%9F%E6%88%90/" title="Petr_3D坐标生成"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2023-12-05</div><div class="title">Petr_3D坐标生成</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://i.loli.net/2021/02/24/5O1day2nriDzjSu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">haseka</div><div class="author-info__description">这是我的博客</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">Articles</div><div class="length-num">32</div></a><a href="/tags/"><div class="headline">Tags</div><div class="length-num">33</div></a><a href="/categories/"><div class="headline">Categories</div><div class="length-num">2</div></a></div><a id="card-info-btn" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>Announcement</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>Contents</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#petr-%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="toc-number">1.</span> <span class="toc-text">PETR 代码详解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%8F%E8%AE%B0"><span class="toc-number">1.1.</span> <span class="toc-text">小记</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6"><span class="toc-number">1.2.</span> <span class="toc-text">配置文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#petr-head"><span class="toc-number">1.3.</span> <span class="toc-text">PETR HEAD</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>Recent Post</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/12/07/embedding/" title="embedding">embedding</a><time datetime="2023-12-07T06:09:42.000Z" title="Created 2023-12-07 14:09:42">2023-12-07</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/12/05/Petr-3D%E5%9D%90%E6%A0%87%E7%94%9F%E6%88%90/" title="Petr_3D坐标生成">Petr_3D坐标生成</a><time datetime="2023-12-05T06:16:49.000Z" title="Created 2023-12-05 14:16:49">2023-12-05</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/29/FPN/" title="FPN">FPN</a><time datetime="2023-11-29T01:50:54.000Z" title="Created 2023-11-29 09:50:54">2023-11-29</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/27/pytorch-nn-module-call/" title="pytorch_nn_module__call__">pytorch_nn_module__call__</a><time datetime="2023-11-27T05:54:09.000Z" title="Created 2023-11-27 13:54:09">2023-11-27</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2023/11/27/MMD-PETR-train-detector%E5%AF%BC%E5%9B%BE/" title="MMD-PETR_train-detector导图">MMD-PETR_train-detector导图</a><time datetime="2023-11-27T00:37:42.000Z" title="Created 2023-11-27 08:37:42">2023-11-27</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2023 By haseka</div><div class="framework-info"><span>Framework </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>Theme </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="Read Mode"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="Toggle Between Light And Dark Mode"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="Toggle between Single-column and Double-column"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="Setting"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="Table Of Contents"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="Back To Top"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/metingjs/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener
  btf.removeGlobalFnEvent('pjax')
  btf.removeGlobalFnEvent('themeChange')

  document.getElementById('rightside').classList.remove('rightside-show')
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

  typeof disqusjs === 'object' && disqusjs.destroy()
})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()
})

document.addEventListener('pjax:error', e => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><!-- hexo injector body_end start --><script data-pjax>
  function butterfly_swiper_injector_config(){
    var parent_div_git = document.getElementById('recent-posts');
    var item_html = '<div class="recent-post-item" style="height: auto;width: 100%"><div class="blog-slider swiper-container-fade swiper-container-horizontal" id="swiper_container"><div class="blog-slider__wrp swiper-wrapper" style="transition-duration: 0ms;"></div><div class="blog-slider__pagination swiper-pagination-clickable swiper-pagination-bullets"></div></div></div>';
    console.log('已挂载butterfly_swiper')
    parent_div_git.insertAdjacentHTML("afterbegin",item_html)
    }
  var elist = 'undefined'.split(',');
  var cpage = location.pathname;
  var epage = 'all';
  var flag = 0;

  for (var i=0;i<elist.length;i++){
    if (cpage.includes(elist[i])){
      flag++;
    }
  }

  if ((epage ==='all')&&(flag == 0)){
    butterfly_swiper_injector_config();
  }
  else if (epage === cpage){
    butterfly_swiper_injector_config();
  }
  </script><script defer src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper.min.js"></script><script defer data-pjax src="https://npm.elemecdn.com/hexo-butterfly-swiper/lib/swiper_init.js"></script><!-- hexo injector body_end end --></body></html>