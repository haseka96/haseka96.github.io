<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>embedding</title>
      <link href="/2023/12/07/embedding/"/>
      <url>/2023/12/07/embedding/</url>
      
        <content type="html"><![CDATA[<h1 id="Input-Embedding"><a href="#Input-Embedding" class="headerlink" title="Input Embedding"></a>Input Embedding</h1><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>本文将针对 Transformer 关于输入部分的操作进行解析与总结，会结合代码来讲，只有结合了代码才比较“务实”，不然我总感觉很空洞、不踏实。</p><h2 id="One-Hot-Encoding"><a href="#One-Hot-Encoding" class="headerlink" title="One-Hot Encoding"></a>One-Hot Encoding</h2><p>在 CV 中，我们通常将输入图片转换为4维（batch, channel, height, weight）张量来表示；而在 NLP 中，可以将输入单词用 <strong>One-Hot</strong> 形式编码成<strong>序列向量。</strong>向量长度是预定义的词汇表中拥有的单词量，向量在这一维中的值只有一个位置是1，其余都是0，1对应的位置就是词汇表中表示这个单词的地方。</p><p>例如词汇表中有5个词，第3个词表示“你好”这个词，那么该词对应的 one-hot 编码即为 00<strong>1</strong>00（<strong>第3个位置为1，其余为0</strong>）</p><p><img src="https://pic1.zhimg.com/80/v2-f401c3cdfcfa062ecda0db24b5094c30_720w.webp" alt=""></p><p>代码实现起来也比较简单：</p><p><img src="https://pic4.zhimg.com/v2-784ad940c6dcd78983a242414712dfff_r.jpg" alt=""></p><h2 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h2><p>One-Hot 的形式看上去很简洁，也挺美，但劣势在于它很<strong>稀疏</strong>，而且还可能很<strong>长</strong>。比如词汇表如果有 10k 个词，那么一个词向量的长度就需要达到 10k，而其中却仅有一个位置是1，其余全是0，太“浪费”！</p><p>更重要的是，这种方式无法体现出<strong>词与词之间的关系。</strong>比如 “爱” 和 “喜欢” 这两个词，它们的意思是相近的，但基于 one-hot 编码后的结果取决于它们在词汇表中的位置，无法体现出它们之间的关系。</p><p>因此，我们需要另一种词的表示方法，能够体现词与词之间的关系，使得<strong>意思相近的词有相近的表示结果</strong>，这种方法即 <strong>Word Embedding。</strong></p><p>那么应该如何设计这种方法呢？最方便的途径是设计一个<strong>可学习的权重矩阵 W，</strong>将词向量与这个矩阵进行点乘，即得到新的表示结果。</p><p>嗯？就这么简单吗？CW 告诉你：是的。为何能work？举个例子来看吧！</p><p>假设 “爱” 和 “喜欢” 这两个词经过 one-hot 后分别表示为 10000 和 00001，权重矩阵设计如下：</p><pre><code class="lang-python">[ w00, w01, w02  w10, w11, w12  w20, w21, w22  w30, w31, w32  w40, w41, w42 ]</code></pre><p>那么两个词点乘后的结果分别是 [w00, w01, w02] 和 [w40, w41,  w42]，在网络学习过程中（这两个词后面通常都是接主语，如“你”，“他”等，或者在翻译场景，它们被翻译的目标意思也相近，它们要学习的目标一致或相近），权重矩阵的参数会不断进行更新，从而使得 [w00, w01, w02] 和 [w40, w41, w42] 的值越来越接近。</p><p>另一方面，对于以上这个例子，我们还把向量的维度从5维压缩到了3维。因此，word embedding 还可以起到<strong>降维</strong>的效果。</p><p>其实，可以将这种方式看作是一个 <strong>lookup table</strong>：对于每个 word，进行 word embedding 就相当于一个lookup操作，在表中查出一个对应结果。</p><p>在 Pytorch 框架下，可以使用 <em>torch.nn.Embedding</em>来实现 word embedding：</p><pre><code class="lang-python">class Embeddings(nn.Module):    def __init__(self, d_model, vocab):        super(Embeddings, self).__init__()        self.lut = nn.Embedding(vocab, d_model)        self.d_model = d_model    def forward(self, x):        return self.lut(x) * math.sqrt(self.d_model)</code></pre><p>其中，<em>vocab</em> 代表词汇表中的单词量，one-hot 编码后词向量的长度就是这个值；<em>d_model</em>代表权重矩阵的列数，通常为512，就是要将词向量的维度从 <em>vocab 编码</em>到 <em>d_model</em>。</p><h2 id="Position-Embedding"><a href="#Position-Embedding" class="headerlink" title="Position Embedding"></a>Position Embedding</h2><p>经过 word embedding，我们获得了词与词之间关系的表达形式，但是<strong>词在句子中的位置关系</strong>还无法体现。</p><p>由于 Transformer 是并行地处理句子中的所有词，因此需要加入词在句子中的位置信息，结合了这种方式的词嵌入就是 <strong>Position Embedding</strong> 了。</p><p>那么具体该怎么做？我们通常容易想到两种方式：</p><p>1、通过网络来学习；</p><p>2、预定义一个函数，通过函数计算出位置信息；</p><p>Transformer 的作者对以上两种方式都做了探究，发现最终效果相当，于是采用了第2种方式，从而减少模型参数量，同时还能适应即使在训练集中没有出现过的句子长度。</p><p>计算位置信息的函数计算公式如下：</p><p><img src="https://pic4.zhimg.com/80/v2-4b722868b2a7a6d5a2f669617e807ab7_720w.webp" alt=""></p><p><em>pos</em> 代表的是词在句子中的位置，<em>d</em> 是词向量的维度（通常经过 word embedding 后是512），<em>2i</em>  代表的是 <em>d</em> 中的偶数维度，(<em>2i + 1)</em> 则代表的是奇数维度，这种计算方式使得每一维都对应一个正弦曲线。</p><p><strong>为何使用三角函数呢？</strong></p><p>由于三角函数的性质： sin(a+b) = sin(a)cos(b) + cos(a)sin(b)、 cos(a+b) = cos(a)cos(b) -  sin(a)sin(b)，于是，对于位置 pos+k 处的信息，可以由 pos 位置计算得到，作者认为这样可以让模型更容易地学习到位置信息。</p><p><strong>为何使用这种方式编码能够代表不同位置信息呢？</strong></p><p>由公式可知，<strong>每一维</strong> i<strong>都对应不同周期的正余弦曲线</strong>: i=0时是周期为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.421ex" height="1.532ex" role="img" focusable="false" viewBox="0 -666 1070 677"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g></g></g></svg></mjx-container>的sin函数，i=1时是周期为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.421ex" height="1.532ex" role="img" focusable="false" viewBox="0 -666 1070 677"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D70B" d="M132 -11Q98 -11 98 22V33L111 61Q186 219 220 334L228 358H196Q158 358 142 355T103 336Q92 329 81 318T62 297T53 285Q51 284 38 284Q19 284 19 294Q19 300 38 329T93 391T164 429Q171 431 389 431Q549 431 553 430Q573 423 573 402Q573 371 541 360Q535 358 472 358H408L405 341Q393 269 393 222Q393 170 402 129T421 65T431 37Q431 20 417 5T381 -10Q370 -10 363 -7T347 17T331 77Q330 86 330 121Q330 170 339 226T357 318T367 358H269L268 354Q268 351 249 275T206 114T175 17Q164 -11 132 -11Z"></path></g></g></g></svg></mjx-container>的 函数..对于不同的两个位置pos1和pos2，若它们在某一维i上有相同的编码值，则说明这两个位置的差值等于该维所在曲线的周期，即 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.564ex;" xmlns="http://www.w3.org/2000/svg" width="17.957ex" height="2.26ex" role="img" focusable="false" viewBox="0 -749.5 7937 999"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mrow"><g data-mml-node="mo" transform="translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(278,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(781,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1266,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mn" transform="translate(1735,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(2457.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mi" transform="translate(3457.4,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(3960.4,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(4445.4,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mn" transform="translate(4914.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(5414.4,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g></g><g data-mml-node="mo" transform="translate(5970.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(7026,0)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>。而对于另一个维度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="8.126ex" height="2.363ex" role="img" focusable="false" viewBox="0 -750 3591.8 1044.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(1236.1,0)"><path data-c="2260" d="M166 -215T159 -215T147 -212T141 -204T139 -197Q139 -190 144 -183L306 133H70Q56 140 56 153Q56 168 72 173H327L406 327H72Q56 332 56 347Q56 360 70 367H426Q597 702 602 707Q605 716 618 716Q625 716 630 712T636 703T638 696Q638 692 471 367H707Q722 359 722 347Q722 336 708 328L451 327L371 173H708Q722 163 722 153Q722 140 707 133H351Q175 -210 170 -212Q166 -215 159 -215Z"></path></g><g data-mml-node="msub" transform="translate(2291.9,0)"><g data-mml-node="mi"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z"></path></g><g data-mml-node="mi" transform="translate(617,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(3202.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>，由于<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="7.422ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 3280.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(801,0)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(1490.8,0)"><path data-c="2260" d="M166 -215T159 -215T147 -212T141 -204T139 -197Q139 -190 144 -183L306 133H70Q56 140 56 153Q56 168 72 173H327L406 327H72Q56 332 56 347Q56 360 70 367H426Q597 702 602 707Q605 716 618 716Q625 716 630 712T636 703T638 696Q638 692 471 367H707Q722 359 722 347Q722 336 708 328L451 327L371 173H708Q722 163 722 153Q722 140 707 133H351Q175 -210 170 -212Q166 -215 159 -215Z"></path></g><g data-mml-node="mi" transform="translate(2546.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2891.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>，因此 pos1和pos2在这个维度 j上的编码值就不会相等，对于其它任意<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.486ex;" xmlns="http://www.w3.org/2000/svg" width="25.447ex" height="2.106ex" role="img" focusable="false" viewBox="0 -716 11247.6 931"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(798.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1743.6,0)"><g data-mml-node="mn"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g><g data-mml-node="mo" transform="translate(500,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(944.7,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1444.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(1889.3,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(2389.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(2834,0)"><path data-c="2026" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60ZM525 60Q525 84 542 102T585 120Q609 120 627 104T646 61Q646 36 629 18T586 0T543 17T525 60ZM972 60Q972 84 989 102T1032 120Q1056 120 1074 104T1093 61Q1093 36 1076 18T1033 0T990 17T972 60Z"></path></g><g data-mml-node="mo" transform="translate(4172.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4617.3,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(5359.6,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(6359.8,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g><g data-mml-node="mo" transform="translate(8603.3,0)"><path data-c="3B" d="M78 370Q78 394 95 412T138 430Q162 430 180 414T199 371Q199 346 182 328T139 310T96 327T78 370ZM78 60Q78 85 94 103T137 121Q202 121 202 8Q202 -44 183 -94T144 -169T118 -194Q115 -194 106 -186T95 -174Q94 -171 107 -155T137 -107T160 -38Q161 -32 162 -22T165 -4T165 4Q165 5 161 4T142 0Q110 0 94 18T78 60Z"></path></g><g data-mml-node="mi" transform="translate(9048,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g><g data-mml-node="mo" transform="translate(9846.8,0)"><path data-c="2260" d="M166 -215T159 -215T147 -212T141 -204T139 -197Q139 -190 144 -183L306 133H70Q56 140 56 153Q56 168 72 173H327L406 327H72Q56 332 56 347Q56 360 70 367H426Q597 702 602 707Q605 716 618 716Q625 716 630 712T636 703T638 696Q638 692 471 367H707Q722 359 722 347Q722 336 708 328L451 327L371 173H708Q722 163 722 153Q722 140 707 133H351Q175 -210 170 -212Q166 -215 159 -215Z"></path></g><g data-mml-node="mi" transform="translate(10902.6,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></svg></mjx-container>也是如此。</p><p>综上可知，这种编码方式保证了<strong>不同位置在所有维度上不会被编码到完全一样的值</strong>，从而使每个位置都获得独一无二的编码。</p><p>Pytorch 代码实现如下：</p><pre><code class="lang-python">class PositionalEncoding(nn.Module):    def __init__(self, d_model, dropout, max_len=5000):        super(PositionalEncoding, self).__init__()        self.dropout = nn.Dropout(p=dropout)          pe = torch.zeros(max_len, d_model)  # max_len代表句子中最多有几个词        position = torch.arange(0, max_len).unsqueeze(1)        div_term = torch.exp(torch.arange(0, d_model, 2) *  -(math.log(10000.0) / d_model))  # d_model即公式中的d        pe[:, 0::2] = torch.sin(position * div_term)        pe[:, 1::2] = torch.cos(position * div_term)        pe = pe.unsqueeze(0)        self.register_buffer('pe', pe)    def forward(self, x):        x = x + self.pe[:, :x.size(1)]  # 原向量加上计算出的位置信息才是最终的embedding        return self.dropout(x)</code></pre><p>实现过程中需要注意的一个细节是 —— <strong><em>self.register_buffer(‘pe’, pe)\</em></strong> 这句，它的作用是将pe 变量注册到模型的 <em>buffers()</em> 属性中，这代表该变量对应的是一个“<strong>持久态”，不会有梯度传播给它，但是能被模型的 state_dict 记录下来。</strong></p><p>注意，<strong>没有保存到模型的 *buffers()* 或 *parameters()* 属性中的参数是不会被记录到state_dict 中的，在 *buffers()* 中的参数默认不会有梯度，*parameters()* 中的则相反。</strong></p><p>通过代码可以看到，position encoding 是直接加在输入 <em>x</em> 上的，那么<strong>为何是相加而非拼接(concat)呢？</strong>拼接不是更能独立体现出位置信息吗？而相加的话都把位置信息混入到原输入中了，貌似“摸不着也看不清”..</p><p>这是因为 <strong>Transformer 通常会对原始输入做一个嵌入(embedding)，从而映射到需要的维度，可采用一个变换矩阵做矩阵乘积的方式来实现，上述代码中的输入 *x* 其实就是已经变换后的表示，而非原输入</strong>。</p><p>OK，了解这一点后，我们开始尝试使用 concat 的方式在原始输入中加入位置编码：</p><p>给每一个位置<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex;" xmlns="http://www.w3.org/2000/svg" width="10.026ex" height="2.112ex" role="img" focusable="false" viewBox="0 -893.3 4431.5 933.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1176.7,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2121.5,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(909,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(1187,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(1687,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></g></svg></mjx-container>concat上一个代表位置信息的 one-hot 向量<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="10.459ex" height="2.46ex" role="img" focusable="false" viewBox="0 -893.3 4622.7 1087.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,363) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1107.7,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2052.5,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(1277,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(1555,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(2055,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></g></svg></mjx-container>N代表共有N个位置）形成 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.869ex;" xmlns="http://www.w3.org/2000/svg" width="12.976ex" height="2.89ex" role="img" focusable="false" viewBox="0 -893.3 5735.4 1277.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(605,363) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(605,-247) scale(0.707)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g></g><g data-mml-node="mo" transform="translate(1288.5,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2233.2,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(909,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1187,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(1707,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mi" transform="translate(2485,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(3373,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></g></svg></mjx-container>,d就是需要嵌入到的维度（这里为了简便，直接假设原输入的维度与嵌入维度一致，都是d），它也可以表示为 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="9.639ex" height="2.48ex" role="img" focusable="false" viewBox="0 -846 4260.5 1096"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="msup" transform="translate(278,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g></g><g data-mml-node="mo" transform="translate(1820.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(2265.2,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g></g><g data-mml-node="mo" transform="translate(3982.5,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container>  ，其中 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="25.018ex" height="2.46ex" role="img" focusable="false" viewBox="0 -893.3 11058 1087.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D43C" d="M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z"></path></g></g><g data-mml-node="mo" transform="translate(1820.4,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2765.1,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(909,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1187,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(1707,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g><g data-mml-node="mo" transform="translate(5089.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(5533.9,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g></g><g data-mml-node="mo" transform="translate(7528.9,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(8473.7,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(909,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(1187,0)"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z"></path></g><g data-mml-node="mo" transform="translate(2075,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></g></svg></mjx-container>。现在进行变换：</p><script type="math/tex; mode=display">W \cdot x^i_p = [W^I,W^P] \cdot [[x^i]^T,[x^p]^T]^T = W^I \cdot x^i + W^P \cdot x^p = embed^i + pos^i</script><p>由变换结果可知，<strong>在原输入上 concat 一个代表位置信息的向量在经过线性变换后 等同于 将原输入经线性变换后直接加上位置编码信息。</strong></p><p>最后举个例子，Transformer 对输入的操作概括为如下：</p><p><img src="https://pic2.zhimg.com/v2-6a9d327e407881091a699280743cf735_r.jpg" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> embedding </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Petr_3D坐标生成</title>
      <link href="/2023/12/05/Petr-3D%E5%9D%90%E6%A0%87%E7%94%9F%E6%88%90/"/>
      <url>/2023/12/05/Petr-3D%E5%9D%90%E6%A0%87%E7%94%9F%E6%88%90/</url>
      
        <content type="html"><![CDATA[<h1 id="Petr-3D坐标生成"><a href="#Petr-3D坐标生成" class="headerlink" title="Petr_3D坐标生成"></a>Petr_3D坐标生成</h1><h3 id="1-DGSN的视锥空间离散化及其转换"><a href="#1-DGSN的视锥空间离散化及其转换" class="headerlink" title="1.DGSN的视锥空间离散化及其转换"></a>1.DGSN的视锥空间离散化及其转换</h3><p>为了学习3D空间中的3D卷积特征，先通过将PSV变换到3D空间来建立3DGV。</p><p>PSV的坐标由(u,v,d)表示，其中（u,v）为像素坐标，d是深度，将其所在空间称为grid camera frustum space。深度坐标d按照预定的3D网络间距vd（深度单位）进行均匀采样，串联的信息能够使网络学习用来目标识别的语义特征</p><h4 id="3D-Geometric-Volume："><a href="#3D-Geometric-Volume：" class="headerlink" title="3D Geometric Volume："></a>3D Geometric Volume：</h4><p>使用已知的相机内参，利用反向3D投影，在计算匹配损失前，将PSV最后的特征图从相机空间（u,v,d）到3D空间（x,y,z）：</p><p><img src="https://img-blog.csdnimg.cn/20200531173227708.png" alt=""></p><p>fx，fy为水平和垂直的焦距长度。</p><p>下图展示了转化过程，当物体识别在3D空间被学习，在相机frustum中施加了像素相关性约束（红虚线），在这两个表达中明显不同：</p><p><img src="https://img-blog.csdnimg.cn/20200531173605739.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyNTE4OTU2,size_16,color_FFFFFF,t_70" alt=""></p><p>图3：volume变换：图像被成像平面采集（红实线），PSV在左侧camera frustum中将图像以等深度（蓝色虚线）投影，如世界空间（左图）和camera frustum space（中间）。相机空间中，车是失真的，由K的逆矩阵进行转换后，PSV被转换到3DGV，重新储存了车辆。</p><p>PSV中最后的特征图，low cost voxel（u,v,d）表示物体存在于光心与像素点（u,v）延长线的深度d的高概率。随着3D空间中的转换，low cost的特征表示这个voxle在场景前面，能够作为3D几何结构的特征为后面的3D网络所学习。</p><h3 id="2-meshgrid-coordinates-和3D-world-space理解"><a href="#2-meshgrid-coordinates-和3D-world-space理解" class="headerlink" title="2.meshgrid coordinates 和3D world space理解"></a>2.meshgrid coordinates 和3D world space理解</h3><ul><li><p>meshgrid coordinates：</p><p>类似于DGSN，首先对相机的视锥空间进行离散化，生成大小为<script type="math/tex">(W^F,H^F,D)</script>的网格。网格中的每个点可以表示为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.987ex;" xmlns="http://www.w3.org/2000/svg" width="27.344ex" height="2.684ex" role="img" focusable="false" viewBox="0 -750 12085.9 1186.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msubsup"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,363) scale(0.707)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(536,-292.2) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(1484.6,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(2540.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(2929.4,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(4097.9,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msub" transform="translate(5098.2,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(5992.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(6437.2,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(518,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(7518.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="msub" transform="translate(8518.9,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(9413.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(9857.9,0)"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(10752.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mn" transform="translate(11196.9,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(11696.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>,这里的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="6.851ex" height="2.363ex" role="img" focusable="false" viewBox="0 -750 3028.3 1044.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(605,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(1335.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1780,0)"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g><g data-mml-node="mi" transform="translate(518,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g><g data-mml-node="mo" transform="translate(2639.3,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>是图像中的相机坐标，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.666ex;" xmlns="http://www.w3.org/2000/svg" width="2.023ex" height="2.236ex" role="img" focusable="false" viewBox="0 -694 894.3 988.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(553,-150) scale(0.707)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></svg></mjx-container>是沿与像平面正交的轴的深度值。例如，使用（50，30，64）大小的网络空间，如果有6个相机，那么grid meshgrid空间大小为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="24.01ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 10612.2 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(2944.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(3944.9,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(5167.1,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(6167.3,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7389.6,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8389.8,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(9112,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(10112.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>.</p></li><li><p>3D coordinates</p><p>由于网络可以被不同的视图相机同时可视，对应的3D坐标空间中的3D点$p^{3d}<em>{i,j} = (x</em>{i,j},y<em>{i,j},z</em>{i,j},1)^T<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="36.941ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 16328 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">可</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">以</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">通</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">过</text></g><g data-mml-node="mn" transform="translate(4000,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mi" transform="translate(4500,0)"><path data-c="1D437" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path></g><g data-mml-node="mi" transform="translate(5328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">投</text></g><g data-mml-node="mi" transform="translate(6328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">影</text></g><g data-mml-node="mi" transform="translate(7328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(8328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">逆</text></g><g data-mml-node="mi" transform="translate(9328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">变</text></g><g data-mml-node="mi" transform="translate(10328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">换</text></g><g data-mml-node="mi" transform="translate(11328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">进</text></g><g data-mml-node="mi" transform="translate(12328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">行</text></g><g data-mml-node="mi" transform="translate(13328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">计</text></g><g data-mml-node="mi" transform="translate(14328,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">算</text></g><g data-mml-node="mi" transform="translate(15328,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">：</text></g></g></g></svg></mjx-container>p^{3d}_{i,j} = K^{-1}_i p^m_j<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="7.793ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 3444.7 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">这</text></g><g data-mml-node="mi" transform="translate(1444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">里</text></g><g data-mml-node="mi" transform="translate(2444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g></g></g></svg></mjx-container>K_i \in R^{4 \times 4}$是第i个相机的内参矩阵，可以将3D空间点变换到相机视锥空间。</p><p>将内参矩阵<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.09ex;" xmlns="http://www.w3.org/2000/svg" width="16.052ex" height="1.977ex" role="img" focusable="false" viewBox="0 -833.9 7095.1 873.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="TeXAtom" transform="translate(974,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mo"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(778,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="mo" transform="translate(2205.5,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mn" transform="translate(3150.2,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></g><g data-mml-node="mo" transform="translate(3872.5,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(4872.7,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(5594.9,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(6595.1,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g></g></g></svg></mjx-container>拓展到meshgrid空间的维度<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="24.01ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 10612.2 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(2944.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(3944.9,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(5167.1,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(6167.3,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7389.6,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8389.8,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(9112,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(10112.2,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g></g></g></svg></mjx-container>。然后做meshgrid分支和内参分支相乘，这样得到3D空间维度为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="24.01ex" height="1.581ex" role="img" focusable="false" viewBox="0 -677 10612.2 699"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(2944.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(3944.9,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(5167.1,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(6167.3,0)"><path data-c="36" d="M42 313Q42 476 123 571T303 666Q372 666 402 630T432 550Q432 525 418 510T379 495Q356 495 341 509T326 548Q326 592 373 601Q351 623 311 626Q240 626 194 566Q147 500 147 364L148 360Q153 366 156 373Q197 433 263 433H267Q313 433 348 414Q372 400 396 374T435 317Q456 268 456 210V192Q456 169 451 149Q440 90 387 34T253 -22Q225 -22 199 -14T143 16T92 75T56 172T42 313ZM257 397Q227 397 205 380T171 335T154 278T148 216Q148 133 160 97T198 39Q222 21 251 21Q302 21 329 59Q342 77 347 104T352 209Q352 289 347 316T329 361Q302 397 257 397Z"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(500,0)"></path></g><g data-mml-node="mo" transform="translate(7389.6,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(8389.8,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mo" transform="translate(9112,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mn" transform="translate(10112.2,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></svg></mjx-container>。</p></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> PETR </tag>
            
            <tag> coordinate </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>FPN</title>
      <link href="/2023/11/29/FPN/"/>
      <url>/2023/11/29/FPN/</url>
      
        <content type="html"><![CDATA[<h1 id="FPN介绍"><a href="#FPN介绍" class="headerlink" title="FPN介绍"></a>FPN介绍</h1><p>FPN网络可以说是一个非常经典的组件，twostage网络中一般都会加上去，能够有效的提升对小目标的检测能力，cascade_rcnn/faster_rcnn+big backbone+fpn+dcn的经典组合经久不衰。</p><p>这篇博客就结合mmdetection的fpn模块来简单介绍一下FPN网络：</p><p><img src="https://img-blog.csdnimg.cn/20201117004400880.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1enpfNDk4MTAwMjA4,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p><img src="https://img-blog.csdnimg.cn/20201117004414116.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1enpfNDk4MTAwMjA4,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>这个是目标检测常用结构，输入一张图像，经过backbone提取特征，最后输出一张featuremap,以fasterrcnn举例，featuremap直接输入rpn得到proposals，proposals在featuremap上提取proposal feature然后进行box的分类和位置的回归。</p><p>为了增加多尺度能力，在上面结构上有很多变种，第一个就是下图的特征图像金字塔（Featurized image pyramid ），每一层做预测，缺点是计算量太大。</p><p><img src="https://img-blog.csdnimg.cn/20201117004434674.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1enpfNDk4MTAwMjA4,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>本文提出的FPN：</p><p><img src="https://img-blog.csdnimg.cn/20201117004620721.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1enpfNDk4MTAwMjA4,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p> 接下来我会从mmdetection的fpn模块实现具体介绍：</p><p><img src="https://img-blog.csdnimg.cn/20201117004649109.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1enpfNDk4MTAwMjA4,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>注意在mmdection的backbone中，输出是一个list，list里面是每个block的结果。这样的好处是方便FPN计算</p><p>接下来我们再看FPN是如何实现的：<br> 在mmdection中，我们以twostage为例：<br> 在</p><pre><code>class TwoStageDetector(BaseDetector)</code></pre><p>中:</p><p>Backbone输出的结果直接进入neck中，这里的neck就可以是fpn。</p><pre><code>def extract_feat(self, img):    &quot;&quot;&quot;Directly extract features from the backbone+neck.&quot;&quot;&quot;    x = self.backbone(img)    if self.with_neck:        x = self.neck(x)  #注意，这个neck就是FPN    return x</code></pre><p>我们再看FPN具体是怎么做的：</p><p>在necks/fpn,py中可以直接找到class FPN(nn.Module)</p><p>在介绍FPN代码之前我还是先贴一下FPN的结构图，这个是我在这里找到的灵魂绘图，非常的形象。对于backbone来说，已经完成了down-top过程，FPN要做的其实就是top-down。<br><img src="https://img-blog.csdnimg.cn/20201117004826467.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1enpfNDk4MTAwMjA4,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p> 首先是FPN的init阶段</p><pre><code>for i in range(self.start_level, self.backbone_end_level):    l_conv = ConvModule(        in_channels[i],        out_channels,        1,        conv_cfg=conv_cfg,        norm_cfg=norm_cfg if not self.no_norm_on_lateral else None,        act_cfg=act_cfg,        inplace=False)    fpn_conv = ConvModule(        out_channels,        out_channels,        3,        padding=1,        conv_cfg=conv_cfg,        norm_cfg=norm_cfg,        act_cfg=act_cfg,        inplace=False)    self.lateral_convs.append(l_conv)    self.fpn_convs.append(fpn_conv)</code></pre><p>在FPN的init阶段，注意这里的lateral_convs就是一个list，list里面存的就是1x1的卷积，对应的就是配图里这里，同理fpn_convs也是一个list，存的是最后的3x3卷积</p><p><img src="https://img-blog.csdnimg.cn/20201117010118591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3h1enpfNDk4MTAwMjA4,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>完了以后我们来看FPN的前向部分</p><pre><code>def forward(self, inputs):    &quot;&quot;&quot;Forward function.&quot;&quot;&quot;    assert len(inputs) == len(self.in_channels)    # build laterals    laterals = [        lateral_conv(inputs[i + self.start_level])        for i, lateral_conv in enumerate(self.lateral_convs)    ]    # build top-down path    used_backbone_levels = len(laterals)    for i in range(used_backbone_levels - 1, 0, -1):        # In some cases, fixing `scale factor` (e.g. 2) is preferred, but        #  it cannot co-exist with `size` in `F.interpolate`.        if &#39;scale_factor&#39; in self.upsample_cfg:            laterals[i - 1] += F.interpolate(laterals[i],                                             **self.upsample_cfg)        else:            prev_shape = laterals[i - 1].shape[2:]            laterals[i - 1] += F.interpolate(                laterals[i], size=prev_shape, **self.upsample_cfg)    # build outputs    # part 1: from original levels    outs = [        self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)    ]    # part 2: add extra levels    if self.num_outs &gt; len(outs):        # use max pool to get more levels on top of outputs        # (e.g., Faster R-CNN, Mask R-CNN)        if not self.add_extra_convs:            for i in range(self.num_outs - used_backbone_levels):                outs.append(F.max_pool2d(outs[-1], 1, stride=2))        # add conv layers on top of original feature maps (RetinaNet)        else:            if self.add_extra_convs == &#39;on_input&#39;:                extra_source = inputs[self.backbone_end_level - 1]            elif self.add_extra_convs == &#39;on_lateral&#39;:                extra_source = laterals[-1]            elif self.add_extra_convs == &#39;on_output&#39;:                extra_source = outs[-1]            else:                raise NotImplementedError            outs.append(self.fpn_convs[used_backbone_levels](extra_source))            for i in range(used_backbone_levels + 1, self.num_outs):                if self.relu_before_extra_convs:                    outs.append(self.fpn_convs[i](F.relu(outs[-1])))                else:                    outs.append(self.fpn_convs[i](outs[-1]))    return tuple(outs)</code></pre><p>其实这个前向就干了一件事情：完成top-down过程，如果原理图画的一样：</p><p><img src="https://img-blog.csdnimg.cn/20201117005028955.png#pic_center" alt=""></p><p>在backbone阶段每个block输出的featuremap经过1x1的卷积（说实话我还是很欣赏mmdetection的代码风格的，除了相比facebook的maskrcnn部署麻烦一点之外，整个结构会清爽很多）</p><pre><code>laterals = [    lateral_conv(inputs[i + self.start_level])    for i, lateral_conv in enumerate(self.lateral_convs)]</code></pre><p>然后与下一个block输出进行插值后相加</p><pre><code>prev_shape = laterals[i - 1].shape[2:]laterals[i - 1] += F.interpolate(    laterals[i], size=prev_shape, **self.upsample_cfg)</code></pre><p>最后过3x3的卷积：</p><pre><code>outs = [    self.fpn_convs[i](laterals[i]) for i in range(used_backbone_levels)]</code></pre><p>然后输出outs，这里的outs同样也是一个list，最后进入RPN。至此FPN阶段结束。</p>]]></content>
      
      
      
        <tags>
            
            <tag> FPN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>pytorch_nn_module__call__</title>
      <link href="/2023/11/27/pytorch-nn-module-call/"/>
      <url>/2023/11/27/pytorch-nn-module-call/</url>
      
        <content type="html"><![CDATA[<h1 id="PyTorch中nn-Module类中call方法介绍"><a href="#PyTorch中nn-Module类中call方法介绍" class="headerlink" title="PyTorch中nn.Module类中call方法介绍"></a>PyTorch中nn.Module类中<strong>call</strong>方法介绍</h1><p>在PyTorch源码的torch/nn/modules/module.py文件中，有一条<strong>call</strong>语句和一条forward语句，如下：</p><pre><code>__call__ : Callable[…, Any] = _call_implforward: Callable[…, Any] = _forward_unimplemented</code></pre><p> 在PyTorch中nn.Module类是所有神经网络模块的基类，你的网络也应该继承这个类，需要重载<strong>init</strong>和forward函数。以下是仿照PyTorch中Module和AlexNet类实现写的假的实现的测试代码：</p><pre><code>from typing import Callable, Any, Listdef _forward_unimplemented(self, *input: Any) -&gt; None:    &quot;Should be overridden by all subclasses&quot;    print(&quot;_forward_unimplemented&quot;)    raise NotImplementedErrorclass Module:    def __init__(self):        print(&quot;Module.__init__&quot;)    forward: Callable[..., Any] = _forward_unimplemented    def _call_impl(self, *input, **kwargs):        print(&quot;Module._call_impl&quot;)        result = self.forward(*input, **kwargs)        return result    __call__: Callable[..., Any] = _call_impl    def cpu(self):        print(&quot;Module.cpu&quot;)class AlexNet(Module):    def __init__(self):        print(&quot;AlexNet.__init__&quot;)        super(AlexNet, self).__init__()    def forward(self, x):        print(&quot;AlexNet.forward&quot;)        return xmodel = AlexNet()x: List[int] = [1, 2, 3, 4]print(&quot;result:&quot;, model(x))model.cpu()print(&quot;test finish&quot;)</code></pre><p>执行model(x)语句时，会调用AlexNet的forward函数，是因为AlexNet的父类Module中的<strong>call</strong>函数：首先Module中有<strong>call</strong>方法，因此model(x)这条语句可以正常执行。Module中并没有直接给出<strong>call</strong>的实现体，而是<strong>call</strong>后紧跟冒号，此冒号表示类型注解；后面的Callable和Any是typing模块中的，Callable表示可调用类型，即等号右边应该是一个可调用类型，此处指的是<em>call<em>impl；Any是一种特殊的类型，它与所有类型兼容；Callable[…, Any]表示<em>call<em>impl可接受任意数量的参数并返回Any。这里__call</em></em>实际指向了_call_impl函数，因此调用__call</em></em>实际是调用_call_impl。</p><pre><code>  typing模块的介绍参考：https://blog.csdn.net/fengbingchun/article/details/122288737  _call_impl函数体内会调用forward，Module中的forward的实现方式与__call__相同，但是_forward_unimplemented函数并没有实现体，调用它会触发Error即NotImplementedError。因此在子类AlexNet中一定要给出forward的具体实现，否则调用的将是_forward_unimplemented。</code></pre><p>   测试代码执行结果如下：</p><p><img src="https://img-blog.csdnimg.cn/4061cf753fc648ce8a3ab773c54efe0e.png" alt=""></p><p>forward，则执行结果如下：</p><p><img src="https://img-blog.csdnimg.cn/0289ae16e87c4e1299098278ffbfe69f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAZmVuZ2JpbmdjaHVu,size_20,color_FFFFFF,t_70,g_se,x_16" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> __call__ </tag>
            
            <tag> pytorch </tag>
            
            <tag> nn.Module </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMD-PETR_train-detector导图</title>
      <link href="/2023/11/27/MMD-PETR-train-detector%E5%AF%BC%E5%9B%BE/"/>
      <url>/2023/11/27/MMD-PETR-train-detector%E5%AF%BC%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<h1 id="md-petr_train-detector导图">MD-PETR_train-detector导图</h1><p><imgsrc="/home/haseka/Pictures/mmd_petr_train_detector_pig.png" /></p>]]></content>
      
      
      
        <tags>
            
            <tag> MMD </tag>
            
            <tag> PETR </tag>
            
            <tag> xmind </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDataParallel</title>
      <link href="/2023/11/24/MMDataParallel/"/>
      <url>/2023/11/24/MMDataParallel/</url>
      
        <content type="html"><![CDATA[<h1 id="mmdetectionmmdataparallel">mmdetection：MMDataParallel</h1><h3 id="前言">1.前言</h3><p>mmdetection为了利用多GPU，在mmcv中实现了MMDataParallel和MMDistributedDataParallel。有没有发现这两者的命名和pytorch中的DataParallel和DistributedDataParallel命名方式很相似。没错，mmcv中的dataparallel就是继承了pytorch中的dataparallel。</p><p>下面简单讲一下，DataParallel和DistributedDataParallel两者的区别，<strong>DataParallel实现的是单进程多线程，DistributedDataParallel实现的是多进程</strong>。总而言之，DistributedDataParallel<strong>实现了真正的分布式并发计算</strong>，很好地利用多进程，并且GPU间通信开销更小。关于他们的详细区别，可见<ahref="https://zhuanlan.zhihu.com/p/343951042">PyTorch 源码解读之 DP&amp; DDP</a>。写的非常详细，好文要顶。</p><p>对于计算密集任务，python的多进程要比多线程更好，熟悉python并发编程，肯定听说过python的GIL锁机制，导致多线程无法利用多核cpu。</p><hr /><h3 id="mmdataparallel简介">2.MMDataParallel简介</h3><p>本文将介绍MMDataParallel，建议先了解一下pytorch的DataParallel。这里就简单介绍一下pytorch的DataParallel。</p><p><code>torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)</code>功能：包装模型，利用多线程实现分发并行机制。可以把数据平均分发到各个 GPU上，每个 GPU实际的数据量为batch/gpu_num，实现并行计算。具体流程如下：</p><ol type="1"><li>各GPU卡分别计算损失和梯度</li><li>所有梯度整合到 device[0]（即主GPU）</li><li>device[0] 进行参数更新，其他卡拉取 device[0] 的参数进行更新</li></ol><p>构造参数：</p><ul><li>module：需要包装分发的模型</li><li>device_ids：可分发的 GPU，为None则默认分发到所有可见的GPU（即CUDA_VISIBLE_DEVICES）。其中<strong>主GPU为device_ids[0]</strong>，所以当为device_ids=None时，即为所有可见GPU的第一个。</li></ul><p><strong>注意！：使用DataParallel时，要把数据和模型放在主GPU上，主GPU负责分发数据</strong></p><p>MMDataParallel继承于DataParallel，主要做了两个变化：</p><ul><li>重写scatter方法（这步很重要，不仅要支持对DataContainer的解封装，还要将数据放到对应的GPU上）</li><li>实现train_step和val_step两个api接口，供mmcv.runner调用</li></ul><p>注意：MMDataParallel的train_step和val_step方法只支持单GPU，forward方法是可以支持多GPU。train_step和val_step会在训练时被runner调用，forward会在test、inference时被调用。</p><pre class="python3"><code>from itertools import chain。from torch.nn.parallel import DataParallelfrom .scatter_gather import scatter_kwargsclass MMDataParallel(DataParallel): # 继承于pytorch.DataParallel    def __init__(self, *args, dim=0, **kwargs):        # 构造函数和pytorch的DataParallel一致        super(MMDataParallel, self).__init__(*args, dim=dim, **kwargs)        self.dim = dim    def forward(self, *inputs, **kwargs):        # 在api/test.py和api/inference.py中调用model(return_loss=False, rescale=True, **data_batch)        # 所以实际上，这里参数只使用了kwargs，inputs为空tuple()        if not self.device_ids:             # 在cpu下            # 因为pytorch的Dataparallel.forward不会对cpu进行scatter，所以这里要判断一下            inputs, kwargs = self.scatter(inputs, kwargs, [-1])            return self.module(*inputs[0], **kwargs[0])        else:            return super().forward(*inputs, **kwargs)             # pytorch的forward，实现了把数据平均分发到各个 GPU 上，每个 GPU 实际的数据量为batch/gpu_num    def scatter(self, inputs, kwargs, device_ids): # 非常重要        return scatter_kwargs(inputs, kwargs, device_ids, dim=self.dim)     def train_step(self, *inputs, **kwargs):        # 参数就使用了inputs，为(data_loader[i])        # kwargs为空字典&#123;&#125;        if not self.device_ids:            inputs, kwargs = self.scatter(inputs, kwargs, [-1])            return self.module.train_step(*inputs[0], **kwargs[0]) # 调用真正的module        # 需要注意的是MMDataParallel只支持单GPU，MMDistributedDataParallel才支持多GPU        assert len(self.device_ids) == 1, \            (&#39;MMDataParallel only supports single GPU training, if you need to&#39;             &#39; train with multiple GPUs, please use MMDistributedDataParallel&#39;             &#39; instead.&#39;)        for t in chain(self.module.parameters(), self.module.buffers()):             # 遍历parameter和buffer，parameter记录需要BP更新的参数，buffer记录不需要BP更新的参数            # 还记得吗，使用 DataParallel时，要把数据和模型放在主GPU上。这里就是判断模型是不是在主GPU上            if t.device != self.src_device_obj:                raise RuntimeError(                    &#39;module must have its parameters and buffers &#39;                    f&#39;on device &#123;self.src_device_obj&#125; (device_ids[0]) but &#39;                    f&#39;found one of them on device: &#123;t.device&#125;&#39;)        inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)        return self.module.train_step(*inputs[0], **kwargs[0])    def val_step(self, *inputs, **kwargs):        # 参数就使用了inputs，为(data_loader[i])        # kwargs为空字典&#123;&#125;        if not self.device_ids:            inputs, kwargs = self.scatter(inputs, kwargs, [-1])            return self.module.val_step(*inputs[0], **kwargs[0])        # 需要注意的是MMDataParallel只支持单GPU，MMDistributedDataParallel才支持多GPU        assert len(self.device_ids) == 1, \            (&#39;MMDataParallel only supports single GPU training, if you need to&#39;             &#39; train with multiple GPUs, please use MMDistributedDataParallel&#39;             &#39; instead.&#39;)        for t in chain(self.module.parameters(), self.module.buffers()):            if t.device != self.src_device_obj:                raise RuntimeError(                    &#39;module must have its parameters and buffers &#39;                    f&#39;on device &#123;self.src_device_obj&#125; (device_ids[0]) but &#39;                    f&#39;found one of them on device: &#123;t.device&#125;&#39;)        inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)        return self.module.val_step(*inputs[0], **kwargs[0]) # 调用真正的module</code></pre><p><strong>MMDataParallel的关键点在于重写了self.scatter这个方法，不仅要支持对DataContainer的解封装，还要将数据放到对应的GPU上</strong>。</p><p><strong>MMDataParallel的输入就是dataloader的输出</strong>，先回忆一下<ahref="https://zhuanlan.zhihu.com/p/445147385">mmdetection源码阅读笔记：数据分发</a>文章中介绍的dataloder的输出：以训练时为例</p><pre class="python3"><code># num_gpus就是分布式训练时的gpu数量，默认为1dataloader[i] = dict(&#39;img&#39;:DC(list[ num_gpus * tensor(Batch,C,H,W) ],stacked=True,cpu_only=False),     &#39;img_metas&#39;:DC(list[ num_gpus * list[Batch*dict(&#39;flip&#39;,&#39;ori_shape&#39;……)] ],stacked=False,cpu_only=True),      &#39;gt_bboxes&#39;:DC(list[ num_gpus * list[Batch*tensor] ],stacked=Fasle,cpu_only=False),      &#39;gt_labels&#39;:DC(list[ num_gpus * list[Batch*tensor] ],stacked=False,cpu_only=False)    )</code></pre><p>scatter就是要对上述进行解封装，下面正式介绍重写后的scatter的具体实现：</p><pre class="python3"><code>import torchfrom torch.nn.parallel._functions import Scatter as OrigScatterfrom ._functions import Scatterfrom .data_container import DataContainerdef scatter(inputs, target_gpus, dim=0):    # 主要就是通过递归调用scatter_map来进行解封装    def scatter_map(obj):        if isinstance(obj, torch.Tensor):            if target_gpus != [-1]:                return OrigScatter.apply(target_gpus, None, dim, obj) # gpu下，调用pytorch的scatter            else:                return Scatter.forward(target_gpus, obj) # cpu下，只是加了一层tuple，可以直接替换为return (obj,)！        if isinstance(obj, DataContainer):            if obj.cpu_only:                return obj.data            else:                return Scatter.forward(target_gpus, obj.data) # 这一步是把将数据放到对应的GPU上！！        if isinstance(obj, tuple) and len(obj) &gt; 0:            return list(zip(*map(scatter_map, obj)))        if isinstance(obj, list) and len(obj) &gt; 0:            out = list(map(list, zip(*map(scatter_map, obj))))            return out        if isinstance(obj, dict) and len(obj) &gt; 0:            out = list(map(type(obj), zip(*map(scatter_map, obj.items()))))            return out        return [obj for targets in target_gpus] # 其他类型    try:        return scatter_map(inputs)    finally:        # 这步操作是为了避免，递归调用闭包函数引起的循环引用，进而导致内存泄漏        # 嘶，不是很懂，为什么会循环引用，请大佬指教！        scatter_map = Nonedef scatter_kwargs(inputs, kwargs, target_gpus, dim=0):    inputs = scatter(inputs, target_gpus, dim) if inputs else []    kwargs = scatter(kwargs, target_gpus, dim) if kwargs else []    # 保持数量一致    if len(inputs) &lt; len(kwargs):        inputs.extend([() for _ in range(len(kwargs) - len(inputs))])    elif len(kwargs) &lt; len(inputs):        kwargs.extend([&#123;&#125; for _ in range(len(inputs) - len(kwargs))])    inputs = tuple(inputs)    kwargs = tuple(kwargs)    return inputs, kwargs</code></pre><p>训练时，dataloader[i]经过解封装后，变为：</p><pre class="python3"><code># num_gpus就是分布式训练时的gpu数量，默认为1tuple(num_gpus *         dict(&#39;img&#39;: tensor(Batch,C,H,W) ,             &#39;img_metas&#39;: list[Batch*dict(&#39;flip&#39;,&#39;ori_shape&#39;……)],             &#39;gt_bboxes&#39;: list[Batch*tensor],             &#39;gt_labels&#39;: list[Batch*tensor]            )      )</code></pre><p>同样的，采用MultiScaleFlipAug时，解封装后，变为：</p><pre class="python3"><code># num_augs就是一张图片经过数据增强后的数据数量tuple(num_gpus *          dict(&#39;img&#39;: list[ num_augs * tensor(Batch,C,H,W) ],              &#39;img_metas&#39;: list[ num_augs * list[Batch*dict(&#39;flip&#39;,&#39;ori_shape&#39;……)] ],              &#39;gt_bboxes&#39;: list[ num_augs * list[Batch*tensor] ],              &#39;gt_labels&#39;: list[ num_augs * list[Batch*tensor] ],              &#39;return_loss&#39;:False,              &#39;rescale&#39;:True,              )     )# 需要注意的是，num_augs大于1时，batch必须为1，num_augs等于1时，batch可以大于1。</code></pre><p>解封装的过程告一段落，下面就剩下Scatter.forward实现将数据放到对应GPU上了。</p><p>Scatter.forward定义在_function.py中：</p><p>在这里主要有一个小技巧，当需要大量把数据从内存放到显存上的操作时，是件耗时的事情，我们应该用异步操作，即kernel会被发射到device的某个Stream上排队，CPU继续异步执行。这一切都通过cuda的stream进行封装，但网上讲这个cuda.Stream的使用太少，我觉得不用再深入了解。</p><pre class="python3"><code>import torchfrom torch.nn.parallel._functions import _get_streamdef scatter(input, devices, streams=None):    if streams is None:        streams = [None] * len(devices)    if isinstance(input, list):        chunk_size = (len(input) - 1) // len(devices) + 1        outputs = [ # 这里是关键，就是在做分配，把数据分配到相应GPU上            scatter(input[i], [devices[i // chunk_size]],                    [streams[i // chunk_size]]) for i in range(len(input))        ]        return outputs    elif isinstance(input, torch.Tensor):        output = input.contiguous()        # TODO: copy to a pinned buffer first (if copying from CPU)        stream = streams[0] if output.numel() &gt; 0 else None        if devices != [-1]:            with torch.cuda.device(devices[0]), torch.cuda.stream(stream): # 开启stream流                output = output.cuda(devices[0], non_blocking=True)        return output    else:        raise Exception(f&#39;Unknown type &#123;type(input)&#125;.&#39;)def synchronize_stream(output, devices, streams): # 同步    if isinstance(output, list):        chunk_size = len(output) // len(devices)        for i in range(len(devices)):            for j in range(chunk_size):                synchronize_stream(output[i * chunk_size + j], [devices[i]],[streams[i]])    elif isinstance(output, torch.Tensor):        if output.numel() != 0:            with torch.cuda.device(devices[0]):                main_stream = torch.cuda.current_stream()                main_stream.wait_stream(streams[0])                output.record_stream(main_stream)    else:        raise Exception(f&#39;Unknown type &#123;type(output)&#125;.&#39;)def get_input_device(input):    if isinstance(input, list):        for item in input:            input_device = get_input_device(item)            if input_device != -1:                return input_device        return -1    elif isinstance(input, torch.Tensor):        return input.get_device() if input.is_cuda else -1    else:        raise Exception(f&#39;Unknown type &#123;type(input)&#125;.&#39;)class Scatter:    @staticmethod    def forward(target_gpus, input):        input_device = get_input_device(input)         streams = None        if input_device == -1 and target_gpus != [-1]:            streams = [_get_stream(device) for device in target_gpus] # CPU到GPU的stream流        outputs = scatter(input, target_gpus, streams)        if streams is not None:            synchronize_stream(outputs, target_gpus, streams) # 同步stream流        return tuple(outputs) if isinstance(outputs,list) else (outputs,)        # 注意！如果outputs是tensor，那么tuple(outputs)会降维，应该改为(outputs,)</code></pre><p>pytorch的_get_stream具体实现为：</p><pre class="python3"><code># 维护全局的Stream流_streams = Nonedef _get_stream(device: int):    &quot;&quot;&quot;Gets a background stream for copying between CPU and GPU&quot;&quot;&quot;    global _streams    if device == -1:        return None    if _streams is None:        _streams = [None] * torch.cuda.device_count()    if _streams[device] is None:        _streams[device] = torch.cuda.Stream(device) # 创建cpu到device的Stream    return _streams[device]</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> MMD3D </tag>
            
            <tag> MMDataParallel </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMD3D模型训练测试群流程解析</title>
      <link href="/2023/11/24/MMD3D%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%8B%E8%AF%95%E7%BE%A4%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/"/>
      <url>/2023/11/24/MMD3D%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%B5%8B%E8%AF%95%E7%BE%A4%E6%B5%81%E7%A8%8B%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="mmd3d模型训练测试全流程解析">MMD3D模型训练测试全流程解析</h1><p>[TOC]</p><h3 id="训练与验证流程"><strong>训练与验证流程</strong></h3><p>在训练开始之前，我们需要编写配置文件。MMClassification 在<code>configs</code>文件夹中提供了各种模型常用的样例配置文件，可以直接使用或是稍作修改以用于自己的任务。</p><p>完成配置文件的编写之后，我们就可以使用入口脚本<code>tools/train.py</code>进行训练和验证。该脚本会进行数据集、模型相关的初始化，并调用高阶 API<code>train_model</code>来搭建执行器（Runner），模型的训练和验证步骤均由执行器进行调度。</p><p>更完整的配置文件教程可见：https://mmclassification.readthedocs.io/zh_CN/latest/tutorials/config.html</p><p>这里我们仅以 MMClassification为基准，介绍从训练入口开始，我们是如何让模型训练起来的，避免大家在OpenMMLab 架构中迷路，那么让我们出发~</p><h3 id="第一站-toolstrain.py"><strong>第一站</strong>tools/train.py</h3><p>正如上文所说，这里是训练和验证的入口脚本。它主要执行的工作是解析命令行参数、环境信息，把这些信息动态更新到配置文件中，做一些诸如打印环境信息、创建工作目录之类的外围操作。除此之外，它还完成了模型和训练数据集的构建。</p><p>之后调用高阶 API——<code>train_model</code> 继续我们的训练任务：</p><pre><code>def main():    # 读取命令行参数    args = parse_args()      # 读取配置文件    cfg = Config.fromfile(args.config)    # 合并 `--cfg-options` 至配置文件    if args.cfg_options is not None:        cfg.merge_from_dict(args.cfg_options)      # 收集并配置运行设备、工作目录、随机种子等信息    ...      # 构建模型并初始化权重    model = build_classifier(cfg.model)    model.init_weights()      # 构建数据集    datasets = [build_dataset(cfg.data.train)]    ...        # 调用高阶 API train_model 进行模型训练    train_model(        model,        datasets,        cfg,        distributed=distributed,        validate=(not args.no_validate),        timestamp=timestamp,        device=args.device,        meta=meta)</code></pre><h3 id="第二站-train_model"><strong>第二站</strong> train_model</h3><p>该函数的主要任务是搭建并执行训练执行器，这里我们通过一份流程图来了解它所做的工作：</p><p><imgsrc="https://img-blog.csdnimg.cn/img_convert/6bdcaea13cb3bee36ff7d93dfd4f7876.png" /></p><p>在函数的最后，我们使用 <code>runner.run</code>启动了执行器，由执行器来进行具体的训练。需要额外注意的是：<strong>模型的验证并没有使用相同的方式，而是作为执行器的一个钩子，利用Hook 技术实现模型的验证</strong>。</p><h3 id="第三站runner.run">第三站runner.run</h3><p>从这里开始，程序代码转入了MMCV，许多小伙伴在查阅源码时就会有些困惑，不知道接下来该去哪里跟踪源码，执行器到底调用了模型的哪个接口呢？我想要debug 该去哪里加断点呢？其实这里并不复杂，让我们一步一步跟踪执行器。</p><p>这里我们以分类任务最常用的 <code>EpochBasedRunner</code>为例进行说明。</p><p>以下提到的 <code>runner</code> 也均指<code>EpochBasedRunner</code></p><p>相关代码可以在https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/epoch_based_runner.py中找到</p><p>如下图所示，<code>runner.run</code> 方法会逐 epoch 地去调用<code>runner.train</code> 方法，而 <code>runner.train</code> 又会逐iteration 地去调用 <code>runner.run_iter</code> 方法。</p><p><imgsrc="https://img-blog.csdnimg.cn/img_convert/5647a1535c08d88f46b8e38a8ad5b39f.png" /></p><p>很多人在翻阅执行器源码时会被 <code>run</code>方法较为复杂的逻辑搞乱，其实其中核心的语句为如下几行：</p><pre><code>def run(self, data_loaders, workflow, max_epochs=None, **kwargs):        ...        while self.epoch &lt; self._max_epochs:            for i, flow in enumerate(workflow):                mode, epochs = flow                if isinstance(mode, str):  # self.train()                    if not hasattr(self, mode):                        raise ValueError(                            f&#39;runner has no method named &quot;&#123;mode&#125;&quot; to run an &#39;                            &#39;epoch&#39;)                    epoch_runner = getattr(self, mode)                else:                    raise TypeError(                        &#39;mode in workflow must be a str, but got &#123;&#125;&#39;.format(                            type(mode)))                  for _ in range(epochs):                    if mode == &#39;train&#39; and self.epoch &gt;= self._max_epochs:                        break                    epoch_runner(data_loaders[i], **kwargs)</code></pre><p>那么，代码在哪里调用了 <code>runner.train</code>方法？这还要追溯到我们的配置文件中，在默认的配置文件中都会有这么一行：</p><pre><code>workflow = [(&#39;train&#39;, 1)]</code></pre><p>其中第一个元素是 <code>'train'</code> ，对应着代码中的<code>mode</code>，代码中使用 <code>getattr(self, mode)</code>的方式取出了执行器的 <code>train</code> 方法。至于相关的 workflow设计，感兴趣的小伙伴可以看一下 MMCV 核心组件分析(七):Runner，这里我们就不多做介绍，通常也不推荐大家在没有特殊需求的情况下，在分类任务中修改workflow。</p><p>总之，我们终于接近了终点，要从执行器中跳回 MMClassification 了。在<code>runner.run_iter</code> 中，执行器调用了模型的<code>train_step</code> 方法如下：</p><div class="sourceCode" id="cb4"><preclass="sourceCode php"><code class="sourceCode php"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>outputs <span class="op">=</span> <span class="kw">self</span><span class="op">.</span>model<span class="op">.</span>train_step(data_batch<span class="ot">,</span> <span class="kw">self</span><span class="op">.</span>optimizer<span class="ot">,</span> <span class="op">**</span>kwargs)</span></code></pre></div><h3 id="第四站-model.train_step"><strong>第四站</strong>model.train_step</h3><p>首先一个问题是，执行器中的 <code>self.model</code>是哪个类？严谨地说，通常情况下它是 <code>MMDataParallel</code>（MMDP）或者 <code>MMDistributedDataParallel</code>（MMDDP），因为<code>train_model</code>函数对模型进行了封装。但这对于我们理解训练流程并不重要，因为 MMDP 或者MMDDP 只是一层封装，它们还是会调用所封装模型的 <code>train_step</code>方法。</p><p>那么这个被封装的模型是哪个类呢？其实很简单，在配置文件中，我们的<code>model</code> 字段通常定义如下，其中<code>type='ImageClassifier'</code>，因此我们主模型是<code>ImageClassifier</code> 类。</p><pre><code>model = dict(    type=&#39;ImageClassifier&#39;,    backbone=...,    neck=...,    head=...,    ))</code></pre><p>通常，主模型和算法本身的架构相关。如检测任务中，根据算法的不同，主模型可以是<code>RetinaNet</code>、<code>YOLOX</code>这样的算法。但在分类任务中，由于 MMClassification目前还仅支持单标签和多标签的监督学习，这些算法基本都遵循着“主干网络+可选的 GAP +分类头” 的总体结构，因而我们只有<code>ImageClassifier</code> 这么一个主模型，期待将来 MMClassficiation支持更多的任务吧~</p><p>在进入 <code>ImageClassfier.``train_step</code>（该方法定义在基类<code>BaseClassifier</code> 中） 之后，我们发现，<code>train_step</code>依然是一个“中间商”，它调用了模型的 <code>forward</code> 方法，并指定<code>return_loss=True</code>，进而调用模型的 <code>forward_train</code>方法。</p><pre><code>def train_step(self, data, optimizer=None, **kwargs):        &quot;&quot;&quot;mmcls/models/classifiers/base.py&quot;&quot;&quot;        losses = self(**data)   # --&gt; forward        loss, log_vars = self._parse_losses(losses)          outputs = dict(            loss=loss, log_vars=log_vars, num_samples=len(data[&#39;img&#39;].data))          return outputs            def forward(self, img, return_loss=True, **kwargs):        &quot;&quot;&quot;mmcls/models/classifiers/base.py&quot;&quot;&quot;        if return_loss:            return self.forward_train(img, **kwargs)        else:            return self.forward_test(img, **kwargs)                def forward_train(self, img, gt_label, **kwargs):        &quot;&quot;&quot;mmcls/models/classifiers/image.py&quot;&quot;&quot;        if self.augments is not None:            img, gt_label = self.augments(img, gt_label)          # 调用 backbone 和 neck 的 forward        x = self.extract_feat(img)          losses = dict()        # 在 head 中计算 loss        loss = self.head.forward_train(x, gt_label)          losses.update(loss)          return losses</code></pre><p>是否有些混乱了？其实简单来说，因为我们将损失函数定义在了分类头中，在训练时我们希望分类头返回损失函数，在验证或测试时我们希望分类头返回各类得分，因此通过<code>forward</code> 方法和 <code>return_loss</code>参数来做中间的分发，实际在训练中走的是模型的 <code>forward_train</code>方法，在这里，数据终于历尽千辛万苦，进入了主干网络、分类头等模型结构中。</p><h3 id="测试流程"><strong>测试流程</strong></h3><p>相较于训练流程，模型的测试流程就简单很多了。这里没有再使用执行器，而是直接在高级API <code>single_gpu_test</code> 或是 <code>multi_gpu_test</code>中调用模型进行测试。具体流程如下：</p><ol type="1"><li>在入口脚本 <code>tools/test.py</code>中，我们完成了<strong>命令参数的解析、数据集及 data loader的构建、模型的构建及封装，并调用</strong><code>**single_gpu_test**</code> <strong>或是</strong><code>**multi_gpu_test**</code> <strong>获取测试结果</strong>。</li><li>在 <code>single_gpu_test</code> 或是 <code>multi_gpu_test</code>中，我们遍历整个 data loader 中的数据，调用模型的 <code>forward</code>方法，并传入参数<code>return_loss=False</code>。在上一节中我们已经提到了，模型的<code>forward</code> 方法会根据 <code>return_loss</code>参数执行模型的不同分支，当 <code>return_loss=False</code>时，会<strong>调用模型的</strong> <code>**forward_test**</code><strong>函数</strong>，去获得模型预测结果，而不是损失函数。</li><li><code>forward_test</code> 函数的源码如下。虽然目前 MMClassification还不支持 TTA（Test-Time Augmentation），但为了保持 OpenMMLab各算法库风格统一，这里对输入参数 <code>imgs</code>做了许多额外的判断。在目前 MMClassification的测试流程中，<code>imgs</code> 参数只会是一个 batch的图像，即一个形状为 <code>(N, C, H, W)</code> 的Tensor。因此目前我们可以简单地认为 <code>**forward_test**</code><strong>进一步调用了模型的</strong> <code>**simple_test**</code><strong>方法</strong>。</li></ol><pre><code>def forward_test(self, imgs, **kwargs):        &quot;&quot;&quot;        Args:            imgs (Tensor | List[Tensor]): the outer list indicates test-time                augmentations and inner Tensor should have a shape NxCxHxW,                which contains all images in the batch.        &quot;&quot;&quot;        if isinstance(imgs, torch.Tensor):            imgs = [imgs]        for var, name in [(imgs, &#39;imgs&#39;)]:            if not isinstance(var, list):                raise TypeError(f&#39;&#123;name&#125; must be a list, but got &#123;type(var)&#125;&#39;)          if len(imgs) == 1:            return self.simple_test(imgs[0], **kwargs)        else:            raise NotImplementedError(&#39;aug_test has not been implemented&#39;)</code></pre><p>终于，我们获得模型在整个数据集中的推理结果，返回到了<code>tools/test.py</code> 中。之后，我们会<strong>调用数据集的</strong><code>**evalutate**</code><strong>方法</strong>，将数据集的推理结果传递进去，由<code>evaluate</code> 方法来处理各种评价指标的计算</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMD3D </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PETR代码详解</title>
      <link href="/2023/11/23/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/"/>
      <url>/2023/11/23/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/</url>
      
        <content type="html"><![CDATA[<h1 id="petr-代码详解">PETR 代码详解</h1><h2 id="小记">小记</h2><p>看了很久的PETR源代码，后续磕盐工作以此文章为基础在上面更改，期望能顺利毕业。</p><p>本来很早就想边看边记录，但是一直以为博客的源文件没有迁移到主力本上，突然才发现上一篇4090时都迁过来了，感觉自己最近有些不在状态了，还是得开启学习记录，保持状态。</p><p>整体的代码流程</p><p><ahref="https://goodxue.github.io/images/PETR代码详解/liucheng.png"><imgsrc="https://goodxue.github.io/images/PETR%E4%BB%A3%E7%A0%81%E8%AF%A6%E8%A7%A3/liucheng.png"alt="img" /></a></p><h2 id="配置文件">配置文件</h2><p>使用了mmdet框架的代码结构，这里从头到尾把配置文件部分讲清楚，其中一些细节会同步放出定义源码讲解。</p><p>使用 <em>petr_r50dcn_gridmask_p4.py</em>做解释。首先是配置加载和预先定义。</p><pre><code>_base_ = [    &#39;../../../mmdetection3d/configs/_base_/datasets/nus-3d.py&#39;,    &#39;../../../mmdetection3d/configs/_base_/default_runtime.py&#39;]# 这里引用了nus-3d的nuscenes数据集，所以包含了在mm3d中的配置，default_runtime是基本的runtime设置。backbone_norm_cfg = dict(type=&#39;LN&#39;, requires_grad=True)# LayerNorm 层归一化，设置了backbone中使用到的归一化参数plugin=Trueplugin_dir=&#39;projects/mmdet3d_plugin/&#39;# 给出了当前工程路径# If point cloud range is changed, the models should also change their point# cloud range accordinglypoint_cloud_range = [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]voxel_size = [0.2, 0.2, 8]img_norm_cfg = dict(    mean=[103.530, 116.280, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)# For nuScenes we usually do 10-class detectionclass_names = [    &#39;car&#39;, &#39;truck&#39;, &#39;construction_vehicle&#39;, &#39;bus&#39;, &#39;trailer&#39;, &#39;barrier&#39;,    &#39;motorcycle&#39;, &#39;bicycle&#39;, &#39;pedestrian&#39;, &#39;traffic_cone&#39;]# 十个类别input_modality = dict(    use_lidar=False,    use_camera=True,    use_radar=False,    use_map=False,    use_external=False)# 输入数据的模态，只使用相机图像数据</code></pre><p>模型定义部分，这一部分是重点关注部分。</p><pre><code>model = dict(    type=&#39;Petr3D&#39;, # 首先最顶层的网络定义就是PETR，定义在PETR3d.py中，它需要多个输入参数，包括了backbone，neck，petr_head等等，属于模型的最上层定义。    use_grid_mask=True, # 一种数据增强的方法    img_backbone=dict(        type=&#39;ResNet&#39;,        depth=50,        num_stages=4,        out_indices=(2, 3,), # 输出第3，4层的中间特征，维度为1024，2048，对应FPN网络        frozen_stages=-1, # -1表示不进行frozen        norm_cfg=dict(type=&#39;BN2d&#39;, requires_grad=False),        norm_eval=True,        style=&#39;caffe&#39;,        with_cp=True,        dcn=dict(type=&#39;DCNv2&#39;, deform_groups=1, fallback_on_stride=False), #加入DCNv2模块        stage_with_dcn=(False, False, True, True),        pretrained = &#39;ckpts/resnet50_msra-5891d200.pth&#39;,        ),    # 首先是backbone，是一个resnet50，输入数据维度（B，N，3，H，W），查看源码后发现如果是5维的tensor，会将BN相乘后转换到4维输入。</code></pre><p>在模型的定义，最上层模型文件中<em>petr3d.py</em>，提取特征时对输入进行了处理。</p><pre><code>def extract_img_feat(self, img, img_metas):        &quot;&quot;&quot;Extract features of images.&quot;&quot;&quot;        # print(img[0].size())        if isinstance(img, list):            img = torch.stack(img, dim=0)        B = img.size(0)        if img is not None:            input_shape = img.shape[-2:]            # update real input shape of each single img            for img_meta in img_metas:                img_meta.update(input_shape=input_shape)            if img.dim() == 5:                if img.size(0) == 1 and img.size(1) != 1:                    img.squeeze_()                else:                    B, N, C, H, W = img.size()                    img = img.view(B * N, C, H, W) # 这里将维度降维到4维            if self.use_grid_mask:                img = self.grid_mask(img)            img_feats = self.img_backbone(img) # 送入backbone，输出的是BN，Cout，Hout，Wout维度，list里是设置输出的层数            if isinstance(img_feats, dict):                img_feats = list(img_feats.values())        else:            return None        if self.with_img_neck:            img_feats = self.img_neck(img_feats) # 送到FPN中提取多层特征        img_feats_reshaped = []        for img_feat in img_feats:            BN, C, H, W = img_feat.size()            img_feats_reshaped.append(img_feat.view(B, int(BN / B), C, H, W)) # 将每个特征图的维度重新包装成B，N，C，H，W        return img_feats_reshaped</code></pre><p>neck是FPN，不必多说。petr_head定义了decoder的结构，与DETR基本类似，主要不同就是PETR_head里面前向forward过程中的变化，这里先略过，先熟悉整体代码流程。</p><pre><code>img_neck=dict(    type=&#39;CPFPN&#39;,    in_channels=[1024, 2048],    out_channels=256, # FPN输出256个通道    num_outs=2),    pts_bbox_head=dict(    type=&#39;PETRHead&#39;,    num_classes=10,    in_channels=256, # 输入通道数为256    num_query=900, # 设置了900个query初始化    LID=True,    with_position=True,    with_multiview=True,    position_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],    normedlinear=False,    transformer=dict( # 使用的Transformer定义        type=&#39;PETRTransformer&#39;,        decoder=dict(            type=&#39;PETRTransformerDecoder&#39;,            return_intermediate=True,            num_layers=6,            transformerlayers=dict(                type=&#39;PETRTransformerDecoderLayer&#39;,                attn_cfgs=[                    dict(                        type=&#39;MultiheadAttention&#39;,                        embed_dims=256,                        num_heads=8,                        dropout=0.1),                    dict(                        type=&#39;PETRMultiheadAttention&#39;,                        embed_dims=256,                        num_heads=8,                        dropout=0.1),                    ],                feedforward_channels=2048,                ffn_dropout=0.1,                with_cp=True,                operation_order=(&#39;self_attn&#39;, &#39;norm&#39;, &#39;cross_attn&#39;, &#39;norm&#39;,                                 &#39;ffn&#39;, &#39;norm&#39;)),        )),    bbox_coder=dict(        type=&#39;NMSFreeCoder&#39;,        # type=&#39;NMSFreeClsCoder&#39;,        post_center_range=[-61.2, -61.2, -10.0, 61.2, 61.2, 10.0],        pc_range=point_cloud_range,        max_num=300,        voxel_size=voxel_size,        num_classes=10),     positional_encoding=dict(        type=&#39;SinePositionalEncoding3D&#39;, num_feats=128, normalize=True),</code></pre><p>到这里模型的定义基本完成，具体petr_head的细节在后面解释。positional_encoding是DETR中的位置编码，不是PETR的positional_embedding，positional_embedding的定义是在<em>petr_head.py</em>当中作为一个函数加进去的，后面会说。</p><pre><code>    loss_cls=dict(        type=&#39;FocalLoss&#39;,        use_sigmoid=True,        gamma=2.0,        alpha=0.25,        loss_weight=2.0),    loss_bbox=dict(type=&#39;L1Loss&#39;, loss_weight=0.25),    loss_iou=dict(type=&#39;GIoULoss&#39;, loss_weight=0.0)),# model training and testing settingstrain_cfg=dict(pts=dict(    grid_size=[512, 512, 1],    voxel_size=voxel_size,    point_cloud_range=point_cloud_range,    out_size_factor=4,    assigner=dict(        type=&#39;HungarianAssigner3D&#39;,        cls_cost=dict(type=&#39;FocalLossCost&#39;, weight=2.0),        reg_cost=dict(type=&#39;BBox3DL1Cost&#39;, weight=0.25),        iou_cost=dict(type=&#39;IoUCost&#39;, weight=0.0), # Fake cost. This is just to make it compatible with DETR head.         pc_range=point_cloud_range))))</code></pre><p>这里是损失函数的定义使用的都是mmdet中自带的损失定义，Focalloss作为分类损失，L1和GIoU作为回归损失，匈牙利损失为Transformer的分类匹配损失。</p><p>下面是训练流程的配置，这里以前没有搞明白是做什么的，其实这里才是数据加载的重要过程，数据集的最终load进内存后进行预处理的过程是在这个pipeline当中完成的，要想知道输入给模型的数据是什么格式，是什么样的组织结构需要对这个地方有了解。</p><pre><code>train_pipeline = [    dict(type=&#39;LoadMultiViewImageFromFiles&#39;, to_float32=True),    dict(type=&#39;LoadAnnotations3D&#39;, with_bbox_3d=True, with_label_3d=True, with_attr_label=False),    dict(type=&#39;ObjectRangeFilter&#39;, point_cloud_range=point_cloud_range),    dict(type=&#39;ObjectNameFilter&#39;, classes=class_names),    dict(type=&#39;ResizeCropFlipImage&#39;, data_aug_conf = ida_aug_conf, training=True),    dict(type=&#39;GlobalRotScaleTransImage&#39;,            rot_range=[-0.3925, 0.3925],            translation_std=[0, 0, 0],            scale_ratio_range=[0.95, 1.05],            reverse_angle=True,            training=True            ),    dict(type=&#39;NormalizeMultiviewImage&#39;, **img_norm_cfg),    dict(type=&#39;PadMultiViewImage&#39;, size_divisor=32),    dict(type=&#39;DefaultFormatBundle3D&#39;, class_names=class_names),    dict(type=&#39;Collect3D&#39;, keys=[&#39;gt_bboxes_3d&#39;, &#39;gt_labels_3d&#39;, &#39;img&#39;])]</code></pre><p>需要关注一下“LoadMultiViewImageFromFiles”这个过程</p><p>首先先来看一下数据集是如何定义的，在 <em>nuscenes_dataset.py</em>中：</p><pre><code>class CustomNuScenesDataset(NuScenesDataset):    ...    def get_data_info(self, index):        ...        if self.modality[&#39;use_camera&#39;]:            image_paths = []            for cam_type, cam_info in info[&#39;cams&#39;].items():                img_timestamp.append(cam_info[&#39;timestamp&#39;] / 1e6)                image_paths.append(cam_info[&#39;data_path&#39;])                ...            input_dict.update(                dict(                    img_timestamp=img_timestamp,                    img_filename=image_paths, # dict 前面的key:img_filename直接转化为“img_filename”：image_path字符串                    lidar2img=lidar2img_rts,                    intrinsics=intrinsics,                    extrinsics=extrinsics                 ))        return input_dict</code></pre><p>可以看到输出的data信息只有图像的文件路径，并没有加载进内存。</p><p>在 <em>loading.py</em>中</p><pre><code>class LoadMultiViewImageFromFiles(object):    def __call__(self, results):        &quot;&quot;&quot;Call function to load multi-view image from files.        Args:            results (dict): Result dict containing multi-view image filenames.        Returns:            dict: The result dict containing the multi-view image data. \                Added keys and values are described below.                - filename (str): Multi-view image filenames.                - img (np.ndarray): Multi-view image arrays.                - img_shape (tuple[int]): Shape of multi-view image arrays.                - ori_shape (tuple[int]): Shape of original image arrays.                - pad_shape (tuple[int]): Shape of padded image arrays.                - scale_factor (float): Scale factor.                - img_norm_cfg (dict): Normalization configuration of images.        &quot;&quot;&quot;        filename = results[&#39;img_filename&#39;]        # img is of shape (h, w, c, num_views)        # 这里根据数据集的输出，将图像地址找到加载起来，每一个img_filename内是一个时刻下6个相机的图像地址，将其堆叠起来        img = np.stack(            [mmcv.imread(name, self.color_type) for name in filename], axis=-1)        if self.to_float32:            img = img.astype(np.float32)        results[&#39;filename&#39;] = filename        # unravel to list, see `DefaultFormatBundle` in formating.py        # which will transpose each image separately and then stack into array        results[&#39;img&#39;] = [img[..., i] for i in range(img.shape[-1])]        # 转为列表形式，维数为 N，C，H，W。        results[&#39;img_shape&#39;] = img.shape        results[&#39;ori_shape&#39;] = img.shape        # Set initial values for default meta_keys        results[&#39;pad_shape&#39;] = img.shape        results[&#39;scale_factor&#39;] = 1.0        num_channels = 1 if len(img.shape) &lt; 3 else img.shape[2]        results[&#39;img_norm_cfg&#39;] = dict(            mean=np.zeros(num_channels, dtype=np.float32),            std=np.ones(num_channels, dtype=np.float32),            to_rgb=False)        return results</code></pre><p>这一部分看明白后，就可以知道送入<spanclass="math inline">\(\color{Red}{backbone}\)</span>的数据为什么是（B，N，C，H，W）的维数了。backbone通过一次直接处理BN张（C，H，W）的图像数据，一次性的可以提取N个视角下的多目图像特征，在后续的encoder-decoder模块内可以学习到多个图像特征间的关联，实现特征融合。</p><p>最后的<span class="math inline">\(\color{Red}{Collect3D}\)</span>步骤是将key内的元素提取出来。于是训练阶段的输入数据就包括了[‘gt_bboxes_3d’,‘gt_labels_3d’, ‘img’]这三个内容。</p><p>数据集的配置部分，这里只是配置了数据集的一些基本情况，重点部分还是上面流水线与数据集的接口部分比较重要。</p><pre><code>dataset_type = &#39;CustomNuScenesDataset&#39;data_root = &#39;./data/nuscenes/&#39;data = dict(    samples_per_gpu=4, # 这里是batch size，一般来说越大越好，我用的4090有24gb显存，只能开到4.    workers_per_gpu=4, # 多进程加载数据，这里用了4个进程。    train=dict(        type=dataset_type, # 数据集的定义        data_root=data_root, # 数据集的路径        ann_file=data_root + &#39;nuscenes_infos_train.pkl&#39;,        pipeline=train_pipeline,        classes=class_names,        modality=input_modality,        test_mode=False,        use_valid_flag=True,        # we use box_type_3d=&#39;LiDAR&#39; in kitti and nuscenes dataset        # and box_type_3d=&#39;Depth&#39; in sunrgbd and scannet dataset.        box_type_3d=&#39;LiDAR&#39;),    val=dict(type=dataset_type, pipeline=test_pipeline, classes=class_names, modality=input_modality),    test=dict(type=dataset_type, pipeline=test_pipeline, classes=class_names, modality=input_modality))</code></pre><p>剩下的部分就比较容易理解了，配置优化器和学习率等等，属于不需要较多改动的部分。</p><pre><code>optimizer = dict(    type=&#39;AdamW&#39;,     lr=2e-4,    paramwise_cfg=dict(        custom_keys=&#123;            &#39;img_backbone&#39;: dict(lr_mult=0.1),        &#125;),    weight_decay=0.01)optimizer_config = dict(type=&#39;Fp16OptimizerHook&#39;, loss_scale=512., grad_clip=dict(max_norm=35, norm_type=2))# learning policylr_config = dict(    policy=&#39;CosineAnnealing&#39;,    warmup=&#39;linear&#39;,    warmup_iters=500,    warmup_ratio=1.0 / 3,    min_lr_ratio=1e-3,    # by_epoch=False    )total_epochs = 24evaluation = dict(interval=24, pipeline=test_pipeline)find_unused_parameters = Falserunner = dict(type=&#39;EpochBasedRunner&#39;, max_epochs=total_epochs)load_from=Noneresume_from=&#39;work_dirs/petr_r50dcn_gridmask_p4/latest.pth&#39;</code></pre><h2 id="petr-head">PETR HEAD</h2><p>我们先从最上层的PETR模型开始</p><p><em>petr.py</em></p><pre><code>@DETECTORS.register_module()class Petr3D(MVXTwoStageDetector):    ...    def forward_train(...):        img_feats = self.extract_feat(img=img, img_metas=img_metas)        losses = dict()        losses_pts = self.forward_pts_train(img_feats, gt_bboxes_3d,                                            gt_labels_3d, img_metas,                                            gt_bboxes_ignore)        losses.update(losses_pts)        return losses    def forward_pts_train(...):        outs = self.pts_bbox_head(pts_feats, img_metas)        loss_inputs = [gt_bboxes_3d, gt_labels_3d, outs]        losses = self.pts_bbox_head.loss(*loss_inputs)        return losses</code></pre><p>通过 <em>backbone</em>提取特征后送入petr_head得到输出，和真值计算损失后输出一个训练损失，即为一个训练。</p><p>petr_head.py这个文件中就完成了PETR对于DETR的改进部分和自己的创新点。理解PETR文章即为理解这一部分代码。</p><pre><code>@HEADS.register_module()class PETRHead(AnchorFreeHead):    def forward(self, mlvl_feats, img_metas):        x = mlvl_feats[0] # 首先x为深层的特征图，即fpn输出的256维的tensor        batch_size, num_cams = x.size(0), x.size(1)        input_img_h, input_img_w, _ = img_metas[0][&#39;pad_shape&#39;][0]        masks = x.new_ones(            (batch_size, num_cams, input_img_h, input_img_w)) # 新生成与原始输入大小相同的mask        for img_id in range(batch_size):            for cam_id in range(num_cams):                img_h, img_w, _ = img_metas[img_id][&#39;img_shape&#39;][cam_id]                masks[img_id, cam_id, :img_h, :img_w] = 0        # 图像像素对齐操作        x = self.input_proj(x.flatten(0,1)) # self.input_proj = Conv2d(self.in_channels, self.embed_dims, kernel_size=1) 先经过一层卷积降维 self.embed_dims = 256        x = x.view(batch_size, num_cams, *x.shape[-3:]) # BNCHW        # interpolate masks to have the same spatial shape with x        masks = F.interpolate(            masks, size=x.shape[-2:]).to(torch.bool)        if self.with_position:            coords_position_embeding, _ = self.position_embeding(mlvl_feats, img_metas, masks) # 这里是PE的部分，PE的具体原理在下一部分说明            pos_embed = coords_position_embeding            if self.with_multiview:                sin_embed = self.positional_encoding(masks) # DETR的positional encoding，作用是图像的位置编码                sin_embed = self.adapt_pos3d(sin_embed.flatten(0, 1)).view(x.size())                pos_embed = pos_embed + sin_embed # 两部分相加作为transformer的positional encoding                # self.adapt_pos3d = nn.Sequential(                #     nn.Conv2d(self.embed_dims*3//2, self.embed_dims*4, kernel_size=1, stride=1, padding=0),                #     nn.ReLU(),                #     nn.Conv2d(self.embed_dims*4, self.embed_dims, kernel_size=1, stride=1, padding=0),                # )            else:                pos_embeds = []                for i in range(num_cams):                    xy_embed = self.positional_encoding(masks[:, i, :, :])                    pos_embeds.append(xy_embed.unsqueeze(1))                sin_embed = torch.cat(pos_embeds, 1)                sin_embed = self.adapt_pos3d(sin_embed.flatten(0, 1)).view(x.size())                pos_embed = pos_embed + sin_embed        else:            if self.with_multiview:                pos_embed = self.positional_encoding(masks)                pos_embed = self.adapt_pos3d(pos_embed.flatten(0, 1)).view(x.size())            else:                pos_embeds = []                for i in range(num_cams):                    pos_embed = self.positional_encoding(masks[:, i, :, :])                    pos_embeds.append(pos_embed.unsqueeze(1))                pos_embed = torch.cat(pos_embeds, 1)        reference_points = self.reference_points.weight # shape(num_query,3) 应该是每个query初始化一个point 这里的num_query=100        # self.reference_points = nn.Embedding(self.num_query, 3) 使用了里面的可学习参数作为querry，因此querry是通过学习不断改变的        query_embeds = self.query_embedding(pos2posemb3d(reference_points)) # querry后续操作        # self.query_embedding = nn.Sequential(        #     nn.Linear(self.embed_dims*3//2, self.embed_dims),        #     nn.ReLU(),        #     nn.Linear(self.embed_dims, self.embed_dims),        # )        reference_points = reference_points.unsqueeze(0).repeat(batch_size, 1, 1) #.sigmoid()        outs_dec, _ = self.transformer(x, masks, query_embeds, pos_embed, self.reg_branches) # transformer操作        outs_dec = torch.nan_to_num(outs_dec)        outputs_classes = []        outputs_coords = []        # outs_dec 输出的每一项表示一个视角的检测目标。这里的操作是将深度信息与之前的坐标系对齐（即加上参考点的位置）        for lvl in range(outs_dec.shape[0]):            reference = inverse_sigmoid(reference_points.clone())            assert reference.shape[-1] == 3            outputs_class = self.cls_branches[lvl](outs_dec[lvl])            tmp = self.reg_branches[lvl](outs_dec[lvl])            # 因为输出的格式是(cx, cy, w, l, cz, h, theta, vx, vy)            # 将输出的偏移量相加后再归一化，即网络计算的是位置的偏移量            tmp[..., 0:2] += reference[..., 0:2]            tmp[..., 0:2] = tmp[..., 0:2].sigmoid()            tmp[..., 4:5] += reference[..., 2:3] # 因为reference是(num_querry,3) 第三维是z，所以这里是2:3            tmp[..., 4:5] = tmp[..., 4:5].sigmoid()            outputs_coord = tmp            outputs_classes.append(outputs_class)            outputs_coords.append(outputs_coord)        all_cls_scores = torch.stack(outputs_classes)        all_bbox_preds = torch.stack(outputs_coords)        # 筛选出处于检测范围内的目标        all_bbox_preds[..., 0:1] = (all_bbox_preds[..., 0:1] * (self.pc_range[3] - self.pc_range[0]) + self.pc_range[0])        all_bbox_preds[..., 1:2] = (all_bbox_preds[..., 1:2] * (self.pc_range[4] - self.pc_range[1]) + self.pc_range[1])        all_bbox_preds[..., 4:5] = (all_bbox_preds[..., 4:5] * (self.pc_range[5] - self.pc_range[2]) + self.pc_range[2])        outs = &#123;            &#39;all_cls_scores&#39;: all_cls_scores,            &#39;all_bbox_preds&#39;: all_bbox_preds,            &#39;enc_cls_scores&#39;: None,            &#39;enc_bbox_preds&#39;: None,         &#125;        return outs</code></pre><p>这里输出了所有检测到的目标。 position_embedding部分</p><pre><code>def position_embeding(self, img_feats, img_metas, masks=None):    eps = 1e-5    pad_h, pad_w, _ = img_metas[0][&#39;pad_shape&#39;][0]    B, N, C, H, W = img_feats[self.position_level].shape    coords_h = torch.arange(H, device=img_feats[0].device).float() * pad_h / H # 生成像素平面内的网格    coords_w = torch.arange(W, device=img_feats[0].device).float() * pad_w / W    if self.LID: # 线性分划网络        index  = torch.arange(start=0, end=self.depth_num, step=1, device=img_feats[0].device).float() # 深度范围内的网格        index_1 = index + 1        bin_size = (self.position_range[3] - self.depth_start) / (self.depth_num * (1 + self.depth_num))        coords_d = self.depth_start + bin_size * index * index_1    else:        index  = torch.arange(start=0, end=self.depth_num, step=1, device=img_feats[0].device).float()        bin_size = (self.position_range[3] - self.depth_start) / self.depth_num        coords_d = self.depth_start + bin_size * index    D = coords_d.shape[0]    coords = torch.stack(torch.meshgrid([coords_w, coords_h, coords_d])).permute(1, 2, 3, 0) # W, H, D, 3 # meshgrid就是生成体素网格    coords = torch.cat((coords, torch.ones_like(coords[..., :1])), -1) #增加一维，与内参矩阵对应    coords[..., :2] = coords[..., :2] * torch.maximum(coords[..., 2:3], torch.ones_like(coords[..., 2:3])*eps)    img2lidars = []    for img_meta in img_metas:        img2lidar = []        for i in range(len(img_meta[&#39;lidar2img&#39;])):            img2lidar.append(np.linalg.inv(img_meta[&#39;lidar2img&#39;][i])) #乘内参矩阵的逆将相机坐标系转换到世界坐标系        img2lidars.append(np.asarray(img2lidar))    img2lidars = np.asarray(img2lidars)    img2lidars = coords.new_tensor(img2lidars) # (B, N, 4, 4)    coords = coords.view(1, 1, W, H, D, 4, 1).repeat(B, N, 1, 1, 1, 1, 1)    img2lidars = img2lidars.view(B, N, 1, 1, 1, 4, 4).repeat(1, 1, W, H, D, 1, 1)    coords3d = torch.matmul(img2lidars, coords).squeeze(-1)[..., :3] # 划定范围    coords3d[..., 0:1] = (coords3d[..., 0:1] - self.position_range[0]) / (self.position_range[3] - self.position_range[0])    coords3d[..., 1:2] = (coords3d[..., 1:2] - self.position_range[1]) / (self.position_range[4] - self.position_range[1])    coords3d[..., 2:3] = (coords3d[..., 2:3] - self.position_range[2]) / (self.position_range[5] - self.position_range[2])    coords_mask = (coords3d &gt; 1.0) | (coords3d &lt; 0.0) # 不在范围内的元素将被mask遮住    coords_mask = coords_mask.flatten(-2).sum(-1) &gt; (D * 0.5)    coords_mask = masks | coords_mask.permute(0, 1, 3, 2)    coords3d = coords3d.permute(0, 1, 4, 5, 3, 2).contiguous().view(B*N, -1, H, W)    coords3d = inverse_sigmoid(coords3d) # 归一化    coords_position_embeding = self.position_encoder(coords3d) # 送入几层卷积网络中，进一步加深编码信息        return coords_position_embeding.view(B, N, self.embed_dims, H, W), coords_mask</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> PETR </tag>
            
            <tag> code </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hook食用指南</title>
      <link href="/2023/11/23/Hook%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97/"/>
      <url>/2023/11/23/Hook%E9%A3%9F%E7%94%A8%E6%8C%87%E5%8D%97/</url>
      
        <content type="html"><![CDATA[<h2 id="hook-是什么">Hook 是什么</h2><h3 id="hook-介绍">Hook 介绍</h3><blockquote><p>钩子编程（hooking），也称作“挂钩”，是计算机程序设计术语，指通过拦截软件模块间的函数调用、消息传递、事件传递来修改或扩展操作系统、应用程序或其他软件组件的行为的各种技术。处理被拦截的函数调用、事件、消息的代码，被称为钩子（hook）。--维基百科</p></blockquote><p>在训练过程中，通常有十个关键位点，如下图所示，从训练开始到结束，所有关键位点已用红色标出，共有10个。我们可以在这十个位点插入各种逻辑，例如加载模型权重、保存模型权重。而我们将同一类型的逻辑组织成一个Hook。因此，MMCV 中 Hook的作用就是训练和验证模型时，在不改变其他代码的前提下，灵活地在不同位点插入定制化的逻辑。</p><p><imgsrc="https://pic4.zhimg.com/80/v2-d3dffff457528860519ef6e9d4371e87_720w.webp" /></p><p>而控制整个训练过程的抽象在 MMCV 中被设计为 <ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/zh_CN/latest/understand_mmcv/runner.html">Runner</a>，它的主要行为就是执行上图蓝色的工作流，MMCV提供了两种类型的 Runner，一种是以 epoch 为单位迭代的 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/epoch_based_runner.py">EpochBasedRunner</a>，另一种是以iteration 为单位迭代的 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/iter_based_runner.py">IterBasedRunner</a>。下面给出EpochBasedRunner 和 IterBasedRunner 在十个位点调用 Hook对应方法的代码。</p><pre class="python3"><code>class EpochBasedRunner(BaseRunner):     def run(self, data_loaders, workflow, max_epochs=None, **kwargs):         # 开始运行时调用         self.call_hook(&#39;before_run&#39;)          while self.epoch &lt; self._max_epochs:             # 开始 epoch 迭代前调用             self.call_hook(&#39;before_train_epoch&#39;)             for i, data_batch in enumerate(self.train_dataloader):                 # 开始 iter 迭代前调用                 self.call_hook(&#39;before_train_iter&#39;)                 # model forward                 # 经过一次迭代后调用                 self.call_hook(&#39;after_train_iter&#39;)             # 经过一个 epoch 迭代后调用             self.call_hook(&#39;after_train_epoch&#39;)             # 开始验证 epoch 迭代前调用             self.call_hook(&#39;before_val_epoch&#39;)             for i, data_batch in enumerate(self.val_dataloader):                 # 开始 iter 迭代前调用                 self.call_hook(&#39;before_val_iter&#39;)                 # model forward                 # 经过一次迭代后调用                 self.call_hook(&#39;after_val_iter&#39;)             # 经过一个 epoch 迭代后调用             self.call_hook(&#39;after_val_epoch&#39;)          # 运行完成前调用         self.call_hook(&#39;after_run&#39;)   class IterbasedRunner(BaseRunner):     def run(self, data_loaders, workflow, max_iters=None, **kwargs):         # 开始运行时调用         self.call_hook(&#39;before_run&#39;)         iter_loaders = [IterLoader(x) for x in data_loaders]         # 开始 epoch 迭代前调用         # 注意：IterBaseRunner 只会调用一次 before_epoch 的位点         self.call_hook(&#39;before_epoch&#39;)          while self.iter &lt; self._max_iters:             # 开始训练 iter 迭代前调用             self.call_hook(&#39;before_train_iter&#39;)             # model forward             # 经过一次训练迭代后调用             self.call_hook(&#39;after_train_iter&#39;)              # 开始验证 iter 迭代前调用             self.call_hook(&#39;before_val_iter&#39;)             # model forward             # 经过一次验证迭代后调用             self.call_hook(&#39;after_val_iter&#39;)          # 经过一个 epoch 迭代后调用         self.call_hook(&#39;after_epoch&#39;)         # 运行完成前调用         self.call_hook(&#39;after_run&#39;) </code></pre><p>我们以 CheckpointHook为例简单介绍一下位点对应的方法。注意：并不是每个位点都需要实现对应的方法。</p><pre class="python3"><code># https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py class CheckpointHook(Hook):     &quot;&quot;&quot;保存 checkpoint&quot;&quot;&quot;     def __init__(self,                  interval=-1,                  by_epoch=True,                  save_optimizer=True,                  out_dir=None,                  max_keep_ckpts=-1,                  save_last=True,                  sync_buffer=False,                  file_client_args=None,                  **kwargs):         # 参数初始化      def before_run(self, runner):         # 设置 out_dir 和创建 FileClient 对象，         # 其中 out_dir 是保存 checkpoint 的目录，         # FileClient 对象作为统一接口调用不同的文件后端操作 checkpoint，         # 在 CheckpointHook 中主要涉及保存 checkpoint 和删除 checkpoint         # 的操作      def after_train_epoch(self, runner):         # 处理 by_epoch 为 True 的情况         # 判断是否需要同步 buffer 参数以及         # 调用 _save_checkpoint 保存 checkpoint。      @master_only     def _save_checkpoint(self, runner):         # 保存 checkpoint 并且删除不想要的 checkpoint，         # 不想要的 checkpoint 是指假设我们只想保存最近的 5 个 checkpoint，         # 那么我们需要在第 6 个 checkpoint 生成的时候         # 删除第 1 个 checkpoint，可以通过设置 max_keep_ckpts         # 实现该功能      def after_train_iter(self, runner):         # 处理 by_epoch 为 Fasle 的情况         # 判断是否需要同步 buffer 参数以及         # 调用 _save_checkpoint 保存 checkpoint </code></pre><h3 id="hook-列表">Hook 列表</h3><p>MMCV 提供了很多 Hook，每个 Hook 都有对应的优先级，在 Runner训练过程中，同一位点，不同 Hook的调用顺序是按它们的优先级所定义的，优先级越高，越早被调用。如果优先级一样，被调用的顺序和Hook 注册的顺序一致。</p><p>我们将 MMCV 提供的 Hook 分为两类，一类是<strong>默认Hook</strong>，另一类是<strong>定制 Hook</strong>。前者表示当我们调用Runner 的 register_training_hooks方法时被默认注册（注意，我们同样需要提供配置），后者表示需要手动注册，这里的手动有两种方式，一种是调用Runner 的 register_hook 注册，另一种在调用 register_training_hooks时传入 custom_hooks_config 参数。</p><blockquote><p>注意：不建议修改 MMCV 默认 Hook的优先级，除非你有特殊需求。另外，定制 Hook 的优先级默认为Normal（50）</p></blockquote><ul><li>默认 Hook</li></ul><p><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py</a></p><table><colgroup><col style="width: 16%" /><col style="width: 17%" /><col style="width: 14%" /><col style="width: 51%" /></colgroup><thead><tr class="header"><th>名称</th><th>用途</th><th>优先级</th><th>源码路径</th></tr></thead><tbody><tr class="odd"><td>LrUpdaterHook</td><td>学习率调整</td><td>VERY_HIGH (10)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/lr_updater.py</a></td></tr><tr class="even"><td>MomentumUpdaterHook</td><td>动量更新</td><td>HIGH (30)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/momentum_updater.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/momentum_updater.py</a></td></tr><tr class="odd"><td>OptimizerHook</td><td>反向传播以及参数更新</td><td>ABOVE_NORMAL (40)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py</a></td></tr><tr class="even"><td>CheckPointHook</td><td>按指定间隔保存权重</td><td>NORMAL (50)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/checkpoint.py</a></td></tr><tr class="odd"><td>IterTimerHook</td><td>迭代耗时统计</td><td>LOW (70)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/iter_timer.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/iter_timer.py</a></td></tr><tr class="even"><td>LoggerHook</td><td>打印日志</td><td>VERY_LOW (90)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/tree/master/mmcv/runner/hooks/logger">https://github.com/open-mmlab/mmcv/tree/master/mmcv/runner/hooks/logger</a></td></tr></tbody></table><ul><li>定制 Hook</li></ul><table><colgroup><col style="width: 17%" /><col style="width: 18%" /><col style="width: 9%" /><col style="width: 54%" /></colgroup><thead><tr class="header"><th>名称</th><th>用途</th><th>优先级</th><th>源码路径</th></tr></thead><tbody><tr class="odd"><td>DistSamplerSeedHook</td><td>确保 shuffle 生效</td><td>NORMAL (50)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/sampler_seed.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/sampler_seed.py</a></td></tr><tr class="even"><td>EvalHook</td><td>按指定间隔测试验证集</td><td>NORMAL (50)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/evaluation.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/evaluation.py</a></td></tr><tr class="odd"><td>EmptyCacheHook</td><td>PyTorch CUDA 缓存清理</td><td>NORMAL (50)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/memory.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/memory.py</a></td></tr><tr class="even"><td>ProfilerHook</td><td>分析训练时间的瓶颈</td><td>NORMAL (50)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/profiler.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/profiler.py</a></td></tr><tr class="odd"><td>SyncBuffersHook</td><td>同步模型的 buffer</td><td>NORMAL (50)</td><td><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/sync_buffer.py">https://github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/sync_buffer.py</a></td></tr></tbody></table><blockquote><p>使用 IterBaseRunner 的时候，需设置 EvalHook 的优先级为Low（70），具体详情见 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmsegmentation/pull/766">https://github.com/open-mmlab/mmsegmentation/pull/766</a></p></blockquote><h2 id="hook-用法介绍">Hook 用法介绍</h2><h3 id="evalhook">EvalHook</h3><p><strong>介绍</strong></p><p><code>EvalHook</code> 是按照一定的间隔对模型进行验证，在<code>EvalHook</code> 出现之前，MMCV 对验证的支持是通过设置 workflow配置，形如 <code>workflow=[('train', 2), ('val', 1)]</code>，表示每训练2 个 epoch（假设使用的 Runner 是EpochBasedRunner）验证一次。但这种方式灵活度不够，例如不能保存最优的模型。</p><p>于是，我们设计了 <code>EvalHook</code>。<code>EvalHook</code>除了能很好地解决不能保存最优模型的问题，还提供了其他功能，例如支持从指定epoch 才开始验证模型（因为前面的 epoch模型效果较差，可以不验证从而节省时间）、支持恢复训练的时候先验证再训练（例如加载模型后想查看checkpoint 的性能）。</p><p>MMCV 除了提供 <code>EvalHook</code>，还提供了<code>DistEvalHook</code>，其继承自<code>EvalHook</code>，用于分布式环境下的验证。除了初始化参数有些不同，<code>DistEvalHook</code>还有一个不同点是重载了 <code>EvalHook</code> 中的<code>_do_evaluate</code> 方法。EvalHook 中的 _do_evaluate方法主要执行测试并保存最优模型（如果该模型是当前最优）。而 DistEvalHook中的 _do_evaluate 作用也是类似的，首先在进行测试前同步 BN 中的buffer（为了保证各个进程的模型是一致的），然后进行分布式测试（即每个进程单独测试）以及每个进程都会测试（分布式测试），最后 master进程收集其他进程的测试结果。</p><blockquote><p>推荐使用 <code>EvalHook</code> 代替 <code>workflow</code> 中的<code>val</code></p></blockquote><p><strong>用法</strong></p><p>使用 EvalHook 只需两行代码，一行实例化 EvalHook，另一个行将实例化的对象注册到 Runner</p><ul><li>最简例子</li></ul><pre class="python3"><code>from mmcv.runner.hooks import EvalHook  val_dataloader = ... runner = EpochBasedRunner(...) runner.register_hook(EvalHook(val_dataloader)) </code></pre><ul><li>间隔 5 个 epoch 验证一次</li></ul><pre class="python3"><code>from mmcv.runner.hooks import EvalHook  val_dataloader = ... runner = EpochBasedRunner(...) runner.register_hook(EvalHook(val_dataloader, interval=5)) </code></pre><ul><li>恢复训练时先验证再训练</li></ul><p>假设从第 5 个 epoch 恢复训练，将 start 设置小于等于 5 即可</p><pre class="python3"><code>from mmcv.runner.hooks import EvalHook  val_dataloader = ... runner = EpochBasedRunner(...) runner.register_hook(EvalHook(val_dataloader, start=5)) </code></pre><ul><li>保存最优的模型</li></ul><p>通过设置 save_best='acc'，<code>EvalHook</code> 会根据 'acc'来选择最优的模型。</p><pre class="python3"><code>from mmcv.runner.hooks import EvalHook  val_dataloader = ... runner = EpochBasedRunner(...) runner.register_hook(EvalHook(val_dataloader, save_best=&#39;acc&#39;)) </code></pre><p>当然，也可以设置为 'auto'，那么会自动根据返回的验证结果中的第一个 key作为选择最优模型的依据。</p><h3 id="checkpointhook">CheckPointHook</h3><p><strong>介绍</strong></p><p>CheckpointHook主要是对模型参数进行保存，如果是分布式多卡训练，则仅仅会在 master进程保存。另外，我们可以通过 <code>max_keep_ckpts</code>参数设置最多保存多少个权重文件，权重文件数超过<code>max_keep_ckpts</code> 时，前面的权重会被删除。</p><p>如果以 epoch 为单位进行保存，则该 Hook 实现<code>after_train_epoch</code> 方法即可，否则仅需实现<code>after_train_iter</code> 方法。</p><p><strong>用法</strong></p><ul><li>最简用法</li></ul><pre class="python3"><code>checkpoint_config = &#123;     &#39;interval&#39;: 5,  # 每训练 5 个 epoch 保存一次 checkpoint &#125; runner = EpochBasedRunner(...) runner.register_checkpoint_hook(checkpoint_config) </code></pre><ul><li>保存最新的 n 个 checkpoint</li></ul><div class="sourceCode" id="cb8"><preclass="sourceCode bash"><code class="sourceCode bash"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="ex">checkpoint_config</span> = &#123; </span><span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;interval&#39;</span><span class="ex">:</span> 5,  <span class="co"># 每训练 5 个 epoch 保存一次 checkpoint </span></span><span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;max_keep_ckpts&#39;</span><span class="ex">:</span> 5,  <span class="co"># 只保留最新的 5 个 checkpoint </span></span><span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="er">&#125;</span> </span><span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="ex">runner</span> = EpochBasedRunner<span class="er">(</span><span class="ex">...</span><span class="kw">)</span> </span><span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="ex">runner.register_checkpoint_hook</span><span class="er">(</span><span class="ex">checkpoint_config</span><span class="kw">)</span> </span></code></pre></div><ul><li>将 checkpoint 保存至指定的路径</li></ul><pre class="python3"><code>checkpoint_config = &#123;     &#39;interval&#39;: 5,  # 每训练 5 个 epoch 保存一次 checkpoint     &#39;out_dir&#39;: &#39;/path/of/expected_directory&#39;,  # 保存至 /path/of/expected_directory &#125; runner = EpochBasedRunner(...) runner.register_checkpoint_hook(checkpoint_config) </code></pre><ul><li>同步 buffer</li></ul><p>考虑到分布式训练过程，如果有必要（例如分布式训练中没有使用同步BN，而是普通 BN），则可以通过设置参数 <code>sync_buffer</code> 为True，在保存权重前，会对模型 buffers（典型的例如 BN的全局均值和方差参数）进行跨卡同步，让每张卡的 buffers参数都相同，此时在 master 进程保存权重和 buffer，才是合理的。</p><pre class="python3"><code>checkpoint_config = &#123;     &#39;interval&#39;: 5,  # 每训练 5 个 epoch 保存一次 checkpoint     &#39;sync_buffer&#39;: True,  # 同步 buffer &#125; runner = EpochBasedRunner(...) runner.register_checkpoint_hook(checkpoint_config) </code></pre><h3 id="optimizerhook">OptimizerHook</h3><p><strong>介绍</strong></p><p><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py">OptimizerHook</a>包含一些 optimizer 相关的操作</p><ul><li>梯度清零 runner.optimizer.zero_grad()</li><li>反向传播 runner.output['loss'].backward()</li><li>梯度阶段 clip_grads（可选）</li><li>参数更新 runner.optimizer.step()</li></ul><p>MMCV 还提供了 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py">Fp16OptimizerHook</a>和 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py">GradientCumulativeOptimizerHook</a>，前者用于混合精度训练，后者用于梯度累计。</p><figure><imgsrc="https://pic4.zhimg.com/80/v2-6d71b7a7fc533bfc8e34efcc4ecf77d3_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py">Fp16OptimizerHook</a>是混合精度训练在 MMCV 中的实现，主要逻辑如下：</p><ul><li><p>维护一个 FP32 数值精度模型的副本</p></li><li><p>在每个 iteration</p></li><li><ul><li>拷贝并且转换成 FP16 模型</li><li>前向传播（FP16 的模型参数)，此时 weights, activations 都是 FP16</li><li>loss 乘 scale factor s</li><li>反向传播（FP16 的模型参数和参数梯度)， 此时 gradients 也是 FP16</li><li>参数梯度乘 1/s</li><li>利用 FP16 的梯度更新 FP32 的模型参数</li></ul></li></ul><p><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/optimizer.py">GradientCumulativeOptimizerHook</a>用于节省显存，即通过指定梯度累积的次数，实现反向传播多次才更新参数，常常用于显存不足但想用比较大的batch size 训练模型。</p><p><strong>用法</strong></p><ul><li>最简用法</li></ul><pre class="python3"><code>optimizer_config = dict(grad_clip=None) runner = EpochBasedRunner(...) runner.register_optimizer_hook(optimizer_config) </code></pre><ul><li>梯度截断</li></ul><p>用于避免梯度爆炸，grad_clip 的设置可参考 <ahref="https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html">https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html</a>，</p><p>具体使用案例可参考 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmdetection/blob/master/configs/yolact/yolact_r50_8x8_coco.py">https://github.com/open-mmlab/mmdetection/blob/master/configs/yolact/yolact_r50_8x8_coco.py</a></p><pre class="python3"><code>optimizer_config=dict(grad_clip=dict(max_norm=35, norm_type=2)) runner = EpochBasedRunner(...) runner.register_optimizer_hook(optimizer_config) </code></pre><ul><li>检测异常的模型参数（mmcv&gt;=1.4.1）</li></ul><p>该设置会降低训练速度，故只应用于调试。该参数用于寻找不参与计算图的模型参数，不参与计算图的模型参数包括两种情况，一种是该模型参数没有参与前向计算，另一种参与了前向计算但没有参与loss 的计算。</p><pre class="text"><code>optimizer_config = dict(grad_clip=None, detect_anomalous_params=True) runner = EpochBasedRunner(...) runner.register_optimizer_hook(optimizer_config) </code></pre><ul><li>梯度累积</li></ul><p>可用于显存不足的情况下训练训练更大的 batch size，更多细节可参考<ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/pull/1221">https://github.com/open-mmlab/mmcv/pull/1221</a></p><pre class="text"><code>optimizer_config = dict(type=&quot;GradientCumulativeOptimizerHook&quot;, cumulative_iters=4) runner = EpochBasedRunner(...) runner.register_optimizer_hook(optimizer_config) </code></pre><blockquote><p>切记不能同时使用 <code>OptimizerHook</code> 和<code>GradientCumulativeOptimizerHook</code>，否则会遇到运行时错误:Trying to backward through the graph a second time，更多细节见 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/issues/1379">https://github.com/open-mmlab/mmcv/issues/1379</a></p></blockquote><ul><li>混合精度训练</li></ul><blockquote><p>更多细节见 https://zhuanlan.zhihu.com/p/430123077</p></blockquote><p>使用 MMCV 的 AMP 功能，只需遵循以下几个步骤：</p><ol type="1"><li>将 auto_fp16 装饰器应用到 model 的 forward 函数上</li><li>设置模型的 fp16_enabled 为 True 表示开启 AMP 训练，否则不生效</li><li>如果开启了 AMP，需要同时配置对应的 FP16 优化器配置Fp16OptimizerHook</li><li>在训练的不同时刻，调用 Fp16OptimizerHook，如果你同时使用了 MMCV 中的Runner 模块，那么直接将第 3 步的参数输入到 Runner 中即可</li><li>(可选) 如果对应某些 OP 希望强制运行在 FP32 上，则可以在对应位置引入force_fp32 装饰器</li></ol><pre class="text"><code># 1 作用到 forward 函数中 class ExampleModule(nn.Module):      @auto_fp16()     def forward(self, x, y):         return x, y  # 2 如果开启 AMP，则需要加入开启标志 model.fp16_enabled = True       # 3 配置 Fp16OptimizerHook optimizer_config = Fp16OptimizerHook(     **cfg.optimizer_config, **fp16_cfg, distributed=distributed)  # 4 传递给 runner runner.register_training_hooks(cfg.lr_config, optimizer_config,                                cfg.checkpoint_config, cfg.log_config,                                cfg.get(&#39;momentum_config&#39;, None))     # 5 可选 class ExampleModule(nn.Module):      @auto_fp16()     def forward(self, x, y):         features=self._forward(x, y)         loss=self._loss(features,labels)         return loss      def _forward(self, x, y):        pass      @force_fp32(apply_to=(&#39;features&#39;,))     def _loss(features,labels) :         pass     </code></pre><blockquote><p>注意 force_fp32 要生效，依然需要 fp16_enabled 为 True</p></blockquote><h3 id="emahook">EMAHook</h3><p><strong>介绍</strong></p><p><ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/mmcv/runner/hooks/ema.py">EMAHook</a>使用滑动平均策略对模型参数做平均以提高训练过程的稳定性。</p><blockquote><p>需保证 EMAHook 的优先级高于 CheckpointHook</p></blockquote><p><strong>用法</strong></p><ul><li>最简用法</li></ul><pre class="text"><code>ema_config = dict(type=&quot;EMAHook&quot;) runner = EpochBasedRunner(...) runner.register_hook(ema_config, priority=&#39;NORMAL&#39;) </code></pre><ul><li>设置更新 ema 参数的间隔数</li></ul><p>默认是每一次迭代之后都更新 ema 参数，我们可以通过 interval设置间隔</p><pre class="text"><code>ema_config = dict(type=&quot;EMAHook&quot;, interval=4) runner = EpochBasedRunner(...) runner.register_hook(ema_config, priority=&#39;NORMAL&#39;) </code></pre><ul><li>恢复训练</li></ul><p>当中断训练之后恢复训练，我们需要设置 resume_from参数（注意，这个参数是一定要设置的，否则和不中断训练的结果是不一致的），这样我们就可以加载ema 参数，以保证使用 EMAHook 训练的正确性。</p><pre class="text"><code>ema_config = dict(type=&quot;EMAHook&quot;, resume_from=&quot;/path/of/your/checkpoint.pth&quot;) runner = EpochBasedRunner(...) runner.register_hook(ema_config, priority=&#39;NORMAL&#39;) </code></pre><h3 id="lrupdaterhook">LrUpdaterHook</h3><p><strong>介绍</strong></p><p>学习率决定每次更新的步长，合适的学习率可以使训练快速收敛。MMCV中提供很多学习率衰减策略，其中部分学习率衰减策略也伴有动量衰减策略。下表是 MMCV 提供的学习率衰减策略和动量衰减策略</p><table><colgroup><col style="width: 31%" /><col style="width: 26%" /><col style="width: 10%" /><col style="width: 31%" /></colgroup><thead><tr class="header"><th>名称</th><th>描述</th><th>策略（policy）</th><th>API 文档</th></tr></thead><tbody><tr class="odd"><td>FixedLrUpdaterHook</td><td>固定学习率</td><td>fixed</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.FixedLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.FixedLrUpdaterHook</a></td></tr><tr class="even"><td>StepLrUpdaterHook StepMomentumUpdaterHook</td><td>等间隔调整学习率</td><td>step</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.StepLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.StepLrUpdaterHook</a><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.StepMomentumUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.StepMomentumUpdaterHook</a></td></tr><tr class="odd"><td>ExpLrUpdaterHook</td><td>指数调整学习率</td><td>exp</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.ExpLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.ExpLrUpdaterHook</a></td></tr><tr class="even"><td>PolyLrUpdaterHook</td><td>多项式调整学习率</td><td>poly</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.PolyLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.PolyLrUpdaterHook</a></td></tr><tr class="odd"><td>InvLrUpdaterHook</td><td>反比例调整学习率</td><td>Inv</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.InvLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.InvLrUpdaterHook</a></td></tr><tr class="even"><td>CosineAnnealingLrUpdaterHook CosineAnnealingMomentumUpdaterHook</td><td>余弦退火调整学习率</td><td>CosineAnnealing</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.CosineAnnealingLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.CosineAnnealingLrUpdaterHook</a></td></tr><tr class="odd"><td>FlatCosineAnnealingLrUpdaterHook</td><td>初始学习率训练一段时间再使用余弦退火调整学习率</td><td>FlatCosineAnnealing</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.FlatCosineAnnealingLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.FlatCosineAnnealingLrUpdaterHook</a></td></tr><tr class="even"><td>CosineRestartLrUpdaterHook</td><td>多次余弦退火调整学习率，每次的初始学习率可能不一样</td><td>CosineRestart</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.CosineRestartLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.CosineRestartLrUpdaterHook</a></td></tr><tr class="odd"><td>CyclicLrUpdaterHook CyclicMomentumUpdaterHook</td><td>循环调整学习率</td><td>cyclic</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.CyclicLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.CyclicLrUpdaterHook</a><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.CyclicMomentumUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.CyclicMomentumUpdaterHook</a></td></tr><tr class="even"><td>OneCycleLrUpdaterHook OneCycleMomentumUpdaterHook</td><td>一个循环内调整学习率，学习率从小增大再减小</td><td>OneCycle</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.OneCycleLrUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.OneCycleLrUpdaterHook</a><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.OneCycleMomentumUpdaterHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.OneCycleMomentumUpdaterHook</a></td></tr></tbody></table><blockquote><p>为了确保学习率的衰减符合期望，我们可以参考 <ahref="https://link.zhihu.com/?target=https%3A//mmclassification.readthedocs.io/en/latest/tools/visualization.html%23learning-rate-schedule-visualization">可视化学习率脚本</a>在开始训练前可视化学习率的变化。学习率调整策略虽然有很多种，但用法如出一辙，下面只举两个常用的用法。</p></blockquote><p>用法</p><ul><li>等间隔调整学习率</li></ul><pre class="text"><code>lr_config = dict(     policy=&#39;step&#39;,     step=[16, 19]) runner = EpochBasedRunner(...) runner.register_lr_hook(lr_config) </code></pre><ul><li>余弦退火学习率</li></ul><pre class="text"><code>lr_config = dict(     policy=&#39;CosineAnnealing&#39;,     min_lr=0.01,     ) runner = EpochBasedRunner(...) runner.register_lr_hook(lr_config) </code></pre><h3 id="loggerhook">LoggerHook</h3><p>MMCV 提供以下日志相关的 LoggerHook</p><table><colgroup><col style="width: 25%" /><col style="width: 74%" /></colgroup><thead><tr class="header"><th>名称</th><th>API 文档</th></tr></thead><tbody><tr class="odd"><td>TextLoggerHook</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.TextLoggerHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.TextLoggerHook</a></td></tr><tr class="even"><td>TensorboardLoggerHook</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.TensorboardLoggerHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.TensorboardLoggerHook</a></td></tr><tr class="odd"><td>NeptuneLoggerHook</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.NeptuneLoggerHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.NeptuneLoggerHook</a></td></tr><tr class="even"><td>DvcliveLoggerHook</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.DvcliveLoggerHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.DvcliveLoggerHook</a></td></tr><tr class="odd"><td>WandbLoggerHook</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.WandbLoggerHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.WandbLoggerHook</a></td></tr><tr class="even"><td>MlflowLoggerHook</td><td><ahref="https://link.zhihu.com/?target=https%3A//mmcv.readthedocs.io/en/latest/api.html%23mmcv.runner.MlflowLoggerHook">https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.MlflowLoggerHook</a></td></tr></tbody></table><p>面对这么多 LoggerHook，我们该如何选择合适的日志 Hook呢？以下是我们的一些推荐：</p><ul><li>如果你偏好在本地使用，想要一款能满足基本的实验记录需求、且上手容易的，推荐使用TensorBoard；</li><li>如果对可视化和实验记录有较高要求，推荐使用 Neptune 和 WandB。两者的实验记录功能都非常强大，并且都支持多人协作，适合大型项目的管理。</li><li>如果你是开源项目的爱好者，或者你希望记录完整的 ML 实验全过程，MLflow是一个不错的选择。</li><li>如果你只需要记录基本的实验数据，但是对于大规模数据的版本管理有比较高的需求，那么推荐你使用DVC。</li></ul><p>事实上，只要你喜欢，你可以同时使用的所有 LoggerHook。</p><blockquote><p>注意，MMCV 目前提供的 LoggerHook 功能有限，只用于记录标量数据，例如loss、acc 等，暂不支持可视化图像或特征图等。欢迎提 PR 完善LoggerHook。</p></blockquote><p>下面介绍几个常用的 LoggerHook 的用法，更多 LoggerHook的用法可见：https://zhuanlan.zhihu.com/p/387078211。</p><p><strong>TextLoggerHook</strong></p><p><strong>介绍</strong></p><p>TextLoggerHook 会将日志打印到终端以及保存到 json 文件。</p><p><strong>用法</strong></p><ul><li>最简用法</li></ul><p>间隔 100 个 iteration 打印一次日志</p><pre class="text"><code>log_config = &#123;     &#39;interval&#39;: 100,     &#39;hooks&#39;: [         &#123;             &#39;type&#39;: &#39;TextLoggerHook&#39;,         &#125;,      ] &#125; runner = EpochBasedRunner(...) runner.register_logger_hooks(log_config) </code></pre><ul><li>训练完成后将日志拷贝至指定路径</li></ul><pre class="text"><code>log_config = &#123;     &#39;interval&#39;: 50,     &#39;hooks&#39;: [         &#123;             &#39;type&#39;: &#39;TextLoggerHook&#39;,         &#125;,      ] &#125; runner = EpochBasedRunner(...) runner.register_logger_hooks(log_config)  </code></pre><ul><li>训练完成后将日志拷贝至指定路径</li></ul><pre class="text"><code>log_config = &#123;     &#39;hooks&#39;: [         &#123;             &#39;type&#39;: &#39;TextLoggerHook&#39;,             &#39;out_dir&#39;: &#39;/path/of/expected_directory&#39;,             &#39;out_suffix&#39;: (&#39;.log.json&#39;, &#39;.log&#39;),  # 可以指定拷贝的文件后缀         &#125;,      ] &#125; runner = EpochBasedRunner(...) runner.register_logger_hooks(log_config) </code></pre><p><strong>TensorBoard</strong></p><p><strong>介绍</strong></p><p>TensorBoard 最初是随 TensorFlow提出的一款可视化工具包，其便捷性和完善的记录功能使它得到了广泛应用，并扩展到PyTorch 等多种深度学习框架。TensorBoard 支持记录多种数据类型：</p><ul><li>指标和损失</li><li>超参数和模型 config</li><li>图片数据（可视化权重、张量、多个图像）</li><li>模型图</li><li>Embedding Projector（在低维空间可视化高维数据）</li></ul><p>注意：MMCV 中提供的 TensorboardLoggerHook 只支持记录指标和损失</p><p><strong>安装</strong></p><pre class="text"><code>pip install tensorboard </code></pre><p><strong>用法</strong></p><p>间隔 100 个 iteration 往 TensorBoard 写一次日志</p><pre class="text"><code>log_config = &#123;     &#39;interval&#39;: 100,     &#39;hooks&#39;: [         &#123;             &#39;type&#39;: &#39;TensorboardLoggerHook&#39;,         &#125;,      ] &#125; </code></pre><p>将 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/examples/train.py">https://github.com/open-mmlab/mmcv/blob/master/examples/train.py</a>中的 log_config 替换为上述配置，然后启动训练</p><pre class="text"><code>python examples/train.py </code></pre><p>另起一个终端输入</p><pre class="text"><code>tensorboard --logdir work_dirs # 也可以将 log 上传至 TensorBoard.dev tensorboard dev upload --logdir work_dirs  </code></pre><p>打开 chrome 浏览器，输入 <ahref="https://link.zhihu.com/?target=http%3A//localhost%3A6006/">http://localhost:6006/</a>（可点击<ahref="https://link.zhihu.com/?target=https%3A//tensorboard.dev/experiment/bTL4Q4D1RkGLcbFOXYL3Pw/%23scalars">shared_logs</a>查看我共享的日志）</p><figure><imgsrc="https://pic2.zhimg.com/80/v2-3ba1b0b08cf50b6862b927b5774c3229_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><p><strong>Neptune</strong></p><p><strong>介绍</strong></p><p>Neptune是一个集实验记录、数据存储、可视化、模型注册等多种功能于一体的机器学习实验管理工具，用户可以在网页端UI 轻松地查看所有的记录与可视化结果。Neptune支持记录的数据类型包括但不限于：</p><ul><li>指标和损失</li><li>超参数和模型 config</li><li>模型 checkpoints</li><li>Git 信息</li><li>数据版本管理</li><li>硬件消耗</li><li>文件</li><li>控制台日志</li><li>图片数据（图片文件、Matplotlib figure、PIL image、Numpyarray、Tensor）</li><li>交互式可视化（自动将 Matplotlib figure转为交互式，同时支持其他格式如 html 文件、Altair chart）</li></ul><p>相较于 TensorBoard，Neptune支持记录更多种类的数据，并且提供了用户友好的UI，使用户可以灵活地调整可视化界面。Neptune 还提供了 TensorBoard接口，可以很方便地把 TensorBoard logs 转换为 Neptune experiments。</p><blockquote><p>注意：MMCV 中提供的 NeptuneLoggerHook 只支持记录指标和损失</p></blockquote><p><strong>安装</strong></p><ul><li>安装 Neptune</li></ul><pre class="text"><code>pip install neptune-client </code></pre><ul><li>注册 <ahref="https://link.zhihu.com/?target=http%3A//neptune.ai/">neptune</a>账号并设置 <ahref="https://link.zhihu.com/?target=https%3A//docs.neptune.ai/getting-started/installation%23authentication-neptune-api-token">NEPTUNE_API_TOKEN</a></li></ul><p><strong>用法</strong></p><p>间隔 100 个 iteration 往 Neptune 写一次日志</p><pre class="python3"><code>log_config = &#123;      &#39;hooks&#39;: [         &#123;             &#39;type&#39;: &#39;NeptuneLoggerHook&#39;,             &#39;init_kwargs&#39;: &#123;                 # YOUR_WORKSPACE 是账号名，YOUR_PROJECT 是项目名                 &#39;project&#39;: &#39;&lt;YOUR_WORKSPACE/YOUR_PROJECT&gt;&#39;,             &#125;,         &#125;,      ] &#125;  </code></pre><p>将 <ahref="https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmcv/blob/master/examples/train.py">https://github.com/open-mmlab/mmcv/blob/master/examples/train.py</a>中的 log_config 替换为上述配置，然后启动训练</p><div class="sourceCode" id="cb30"><preclass="sourceCode bash"><code class="sourceCode bash"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> examples/train.py </span></code></pre></div><p>打开 <ahref="https://link.zhihu.com/?target=https%3A//neptune.ai/">https://neptune.ai/</a>并登录即可查看日志（可点击 <ahref="https://link.zhihu.com/?target=https%3A//app.neptune.ai/have-a-try/mmcv-tutorial/e/MMCVTUT-1/charts">shared_logs</a>查看我共享的日志）</p><figure><imgsrc="https://pic4.zhimg.com/80/v2-da7b0203881404d384a9d5eae8a75efb_720w.webp"alt="img" /><figcaption aria-hidden="true">img</figcaption></figure><h2 id="实现自己的-hook">实现自己的 Hook</h2><p>如果我们实现一个定制化的 Hook，我们要做的是考虑需要在 Hook的哪些方法中添加逻辑。 例如，我们想在训练的过程中判断 loss是否有效（无穷大即为无效），我们可以在每次迭代之后判断 loss的值，即可以在 after_train_iter 中添加判断的逻辑。</p><blockquote><p>注意：如无必要，不能在 Hook 中修改能够影响其他 Hook的属性或者方法。而且原则上 Hook 之间最好不要有前后依赖关系。Hook的主要目的是扩展功能，而不是修改已经实现的功能。</p></blockquote><pre class="python3"><code># https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/hook/checkloss_hook.py import torch from mmcv.runner.hooks import HOOKS, Hook  @HOOKS.register_module() class CheckInvalidLossHook(Hook):     &quot;&quot;&quot;Check invalid loss hook.      This hook will regularly check whether the loss is valid     during training.      Args:         interval (int): Checking interval (every k iterations).             Default: 50.     &quot;&quot;&quot;      def __init__(self, interval=50):         self.interval = interval      def after_train_iter(self, runner):         if self.every_n_iters(runner, self.interval):             assert torch.isfinite(runner.outputs[&#39;loss&#39;]), \                 runner.logger.info(&#39;loss become infinite or NaN!&#39;)  </code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> hook </tag>
            
            <tag> mmd3d </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>runner与hook</title>
      <link href="/2023/11/22/runner%E4%B8%8Ehook/"/>
      <url>/2023/11/22/runner%E4%B8%8Ehook/</url>
      
        <content type="html"><![CDATA[<h1 id="runner和hook详细解析">Runner和Hook详细解析</h1><h2 id="runner和hook概述">1.Runner和Hook概述</h2><p>  Runner又称执行器，负责模型训练过程的调度，主要目的是让用户使用更少的代码以及灵活可配置的方式开启训练。换句话说，MMCV将整个训练过程封装起来了，并使用Runner进行管理和配置。高度封装虽然减少了代码量，但如何对内部流程进行自定义的修改（比如动态调整学习率等）？这时就需要用到Hook机制。</p><p>  Hook是能够改变程序执行流程的一种技术统称。通俗的说，Hook可以理解为一种触发器，在程序预定义的位置执行预定义的函数。MMCV已经在几个常用的位置预留了接口函数（称为回调函数），如下图所示。MMCV已经实现了一些常用的Hook函数，同时用户也可以增加自己的Hook函数，非常方便。当程序执行到指定位置时，就会进入到回调函数中，执行相应的功能，执行结束后再接着执行主流程。</p><p><imgsrc="https://img-blog.csdnimg.cn/8c2a699f7d084388bb2add311ecff379.png" /></p><p>  上图对应到具体的代码：</p><pre><code># 开始运行时调用before_run()while self.epoch &lt; self._max_epochs:    # 开始 epoch 迭代前调用    before_train_epoch()    for i, data_batch in enumerate(self.data_loader):        # 开始 iter 迭代前调用        before_train_iter()        self.model.train_step()        # 经过一次迭代后调用        after_train_iter()    # 经过一个 epoch 迭代后调用    after_train_epoch()# 运行完成前调用after_run()</code></pre><p>  总的来说，Runner封装了OpenMMLab体系下各个框架的训练和验证流程，负责管理训练/验证过程的整个生命周期；通过预定义的回调函数，用户可以插入定制化Hook，实现各种各样定制化的需求。## 2.Runner类</p><p>  Runner分为EpochBasedRunner和IterBasedRunner，顾名思义，前者以epoch的方式管理流程，后者以iter的方式管理流程，它们都是BaseRunner的子类。BaseRunner的任何子类都需要实现run()、train()、val()和save_checkpoint()四个方法，这也是Runner的核心方法。这里以EpochBasedRunner为例对上述四个函数进行分析，为了使代码结构看起来更清晰，删去了和核心功能无关的代码。<strong>hook的本质是回调函数，也就是在特定时刻会调用被提前注册好的函数。文章中说的拦截功能大体意思是说触发函数调用，具体实现方式其实没有限制，可以直接通过函数实现，也可以通过装饰器实现</strong></p><h3 id="构造函数">2.1 构造函数</h3><p>  EpochBasedRunner和IterBasedRunner都是BaseRunner的子类，继承了BaseRunner的构造函数。runner默认调用model类中的train_step()和val_step()进行训练和验证，如果指定了batch_processor，则会调用batch_processor对data_loader中的数据进行处理。</p><pre><code>class BaseRunner(metaclass=ABCMeta):    def __init__(self,                 model,                 # [torch.nn.Module] 要运行的模型                 batch_processor=None,  # 过时用法, 通过实现模型中的train_step()和val_step()方法替代                 optimizer=None,        # [torch.optim.Optimizer] 优化器, 可以是一个也可以是一组通过dict配置的优化器                 work_dir=None,         # [str] 保存检查点和Log的目录                 logger=None,           # [logging.Logger] 训练中使用的日志记录器                 meta=None,             # [dict] 一些信息, 这些信息会在logger hook中记录                 max_iters=None,        # [int] 训练epoch数                 max_epochs=None):      # [int] 训练迭代次数</code></pre><h3 id="run函数">2.2 run()函数</h3><p>  run()是runner类的主调函数，会根据workflow指定的工作流，对data_loaders中的数据进行处理。目前MMCV支持训练和验证两种工作流，对于EpochBasedRunner而言，workflow配置为[('train',2)，('val', 1)]表示先训练2个epoch，然后验证一个epoch；[('train',1)]表示只进行训练，不进行验证。如果是IterBasedRunner，[('train',2)，('val', 1)]则表示先训练2个iter，然后验证一个iter。</p><pre><code>def run(self, data_loaders, workflow, max_epochs=None, **kwargs):    while self.epoch &lt; self._max_epochs:        for i, flow in enumerate(workflow):            mode, epochs = flow                        # 根据工作流确定当前是运行train()还是val(), getattr返回对应的函数句柄            epoch_runner = getattr(self, mode)            for _ in range(epochs):                if mode == &#39;train&#39; and self.epoch &gt;= self._max_epochs:                    break                # 运行train()或val()                epoch_runner(data_loaders[i], **kwargs)</code></pre><h3 id="train和val函数">2.3 train()和val()函数</h3><p>  train()和val()函数循环调用run_iter()完成一个epoch流程。函数开头的self.model.train()和self.model.eval()实际上调用的是torch.nn.module.Module的成员函数，将当前模块设置为训练模式或验证模式，两种不同模式下batchnorm、dropout等层的操作会有区别。然后由于测试过程不需要梯度回传，所以val函数加了一个装饰器@torch.no_grad()。</p><pre><code>def train(self, data_loader, **kwargs):    # 将模块设置为训练模式    self.model.train()    self.mode = &#39;train&#39;    self.data_loader = data_loader    self._max_iters = self._max_epochs * len(self.data_loader)    for i, data_batch in enumerate(self.data_loader):        self.run_iter(data_batch, train_mode=True, **kwargs)        self._iter += 1    self._epoch += 1@torch.no_grad()def val(self, data_loader, **kwargs):    # 将模块设置为验证模式    self.model.eval()    self.mode = &#39;val&#39;    self.data_loader = data_loader    for i, data_batch in enumerate(self.data_loader):        self.run_iter(data_batch, train_mode=False)</code></pre><p>  train()和val()的核心函数是run_iter()，根据train_mode参数调用model.train_step()或model.val_step()，这两个函数最终会执行我们自己模型的forward()函数，返回loss值.</p><pre><code>def run_iter(self, data_batch, train_mode, **kwargs):    if self.batch_processor is not None:        outputs = self.batch_processor(self.model, data_batch, train_mode=train_mode, **kwargs)    elif train_mode:        outputs = self.model.train_step(data_batch, self.optimizer, **kwargs)    else:        outputs = self.model.val_step(data_batch, self.optimizer, **kwargs)        self.outputs = outputs</code></pre><p>2.4 save_checkpoint()函数</p><p>  save_checkpoint()函数调用torch.save将检查点以下列格式保存。</p><pre><code>checkpoint = &#123;              &#39;meta&#39;: dict(),           # 环境信息(比如epoch_num, iter_num)              &#39;state_dict&#39;: dict(),     # 模型的state_dict()              &#39;optimizer&#39;: dict())      # 优化器的state_dict()&#125;</code></pre><h2 id="hook类">3.Hook类</h2><p>  MMCV在./mmcv/runner/hooks/hook.py中定义了Hook的基类以及Hook的注册器HOOKS。作为基类，Hook本身没有实现具体的函数，只是提供了before_run、after_run等6个接口函数，其他所有的Hooks都通过继承Hook类并重写相应的函数完整指定功能。</p><pre><code>from mmcv.utils import RegistryHOOKS = Registry(&#39;hook&#39;)</code></pre><p>​<br />​class Hook: ​ def before_run(self, runner): ​ pass ​<br />def after_run(self, runner): pass</p><pre><code>    def before_epoch(self, runner):        pass    def after_epoch(self, runner):        pass    def before_iter(self, runner):        pass    def after_iter(self, runner):        pass</code></pre><p> MMCV已经实现了部分常用的Hooks，如下图所示。默认Hook不需要用户自行注册，通过配置文件配置对应的参数即可；定制Hook则需要用户手动注册进去。</p><p><imgsrc="https://img-blog.csdnimg.cn/c659b14d05c143549545648c24885f56.png" /></p><p>  Hook也是一个模块，使用时需要定义、注册、调用3个步骤。</p><h3 id="定义">3.1 定义</h3><p>  MMCV实现的Hook都在./mmcv/runner/hooks目录下，这里以CheckpointHook为例介绍一下怎么新建一个Hook。</p><p>  首先从hook.py中导入注册器HOOKS以及基类Hook。然后新建一个名为CheckpointHook类继承Hook基类，由于Hook基类没有定义构造函数，这里首先必须自己定义__init__函数，然后根据Hook需要实现的功能，重写Hook基类中的一种或几种方法。比如MMCV会在每次训练开始前打印checkpoint的保存路径，会在每次循环结束后或每个epoch执行完成后保存checkpoint，因此CheckpointHook类重写了before_run、after_train_iter和after_train_epoch这3个方法。</p><pre><code>from .hook import HOOKS, Hook@HOOKS.register_module()class CheckpointHook(Hook):    def __init__(self,                 interval=-1,                 by_epoch=True,                 save_optimizer=True,                 out_dir=None,                 max_keep_ckpts=-1,                 save_last=True,                 sync_buffer=False,                 file_client_args=None,                 **kwargs):        ...    def before_run(self, runner):        ...    def after_train_iter(self, runner):        ...    def after_train_epoch(self, runner):        ...</code></pre><h3 id="注册">3.2 注册</h3><p>  对于MMCV的默认Hook，在执行runner.run()前会调用BaseRunner类中的<code>register_training_hooks</code>方法进行注册：</p><pre><code>def register_training_hooks(self,                            lr_config,                            optimizer_config=None,                            checkpoint_config=None,                            log_config=None,                            momentum_config=None,                            timer_config=dict(type=&#39;IterTimerHook&#39;),                            custom_hooks_config=None):    &quot;&quot;&quot;Register default and custom hooks for training.    Default and custom hooks include:    +----------------------+-------------------------+    | Hooks                | Priority                |    +======================+=========================+    | LrUpdaterHook        | VERY_HIGH (10)          |    +----------------------+-------------------------+    | MomentumUpdaterHook  | HIGH (30)               |    +----------------------+-------------------------+    | OptimizerStepperHook | ABOVE_NORMAL (40)       |    +----------------------+-------------------------+    | CheckpointSaverHook  | NORMAL (50)             |    +----------------------+-------------------------+    | IterTimerHook        | LOW (70)                |    +----------------------+-------------------------+    | LoggerHook(s)        | VERY_LOW (90)           |    +----------------------+-------------------------+    | CustomHook(s)        | defaults to NORMAL (50) |    +----------------------+-------------------------+    If custom hooks have same priority with default hooks, custom hooks    will be triggered after default hooks.    &quot;&quot;&quot;    self.register_lr_hook(lr_config)    self.register_momentum_hook(momentum_config)    self.register_optimizer_hook(optimizer_config)    self.register_checkpoint_hook(checkpoint_config)    self.register_timer_hook(timer_config)    self.register_logger_hooks(log_config)    self.register_custom_hooks(custom_hooks_config)</code></pre><h3 id="调用">3.3 调用</h3><p>  在runner执行过程中，会在特定的程序位点通过<code>call_hook()</code>函数调用相应的Hook。</p><pre><code>def train(self, data_loader, **kwargs):    self.model.train()    self.mode = &#39;train&#39;    self.data_loader = data_loader    self._max_iters = self._max_epochs * len(self.data_loader)    self.call_hook(&#39;before_train_epoch&#39;)    time.sleep(2)  # Prevent possible deadlock during epoch transition    for i, data_batch in enumerate(self.data_loader):        self._inner_iter = i        self.call_hook(&#39;before_train_iter&#39;)        self.run_iter(data_batch, train_mode=True, **kwargs)        self.call_hook(&#39;after_train_iter&#39;)        self._iter += 1    self.call_hook(&#39;after_train_epoch&#39;)    self._epoch += 1</code></pre><p>前面调用<code>register_hook()</code>注册Hook的时候，会根据优先级将Hook加入到<code>self._hooks</code>这个列表中，在执行<code>call_hook()</code>时候，使用for循环就可以很简单的实现按照优先级依次调用指定的Hook了。</p><div class="sourceCode" id="cb12"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> call_hook(<span class="va">self</span>, fn_name):</span><span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> hook <span class="kw">in</span> <span class="va">self</span>._hooks:</span><span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">getattr</span>(hook, fn_name)(<span class="va">self</span>)</span></code></pre></div><h3 id="hook-机制的工作流程">3.4 Hook 机制的工作流程</h3><p>Hook 机制, 其实并不是 OpenMMLab的特例，只是由于我代码经验太少，第一次见而已。 钩子编程 (hooking)，是计算机程序设计术语，指通过拦截软件模块间的函数调用、消息传递、事件传递来修改或扩展操作系统、应用程序或其他软件组件的程序执行流程。其中，处理被拦截的函数调用、事件、消息的代码，被称为钩子 (hook)，应该也就是前文 AOP 编程里面的切面。</p><p>在 OpenMMLab 中，Hook 机制是由 <code>Runner</code> 类 (比如<code>IterBasedRunner</code>, <code>EpochBasedRunner</code>) 和<code>HOOK</code> 类 (比如 <code>EvalHook</code>) 配合完成的,共同构成一套训练框架的架构规范.</p><p>首先, 在 OpenMMLab 中, 负责网络训练测试全流程的 <code>Runner</code>类在训练测试周期中定义好了一系列<strong>触发器</strong>, 如下所示:</p><div class="sourceCode" id="cb13"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 省略 ...</span></span><span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.call_hook(<span class="st">&#39;before_train_epoch&#39;</span>)</span><span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, data_batch <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.data_loader):</span><span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 省略 ...</span></span><span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.call_hook(<span class="st">&#39;before_train_iter&#39;</span>)</span><span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 省略 ...</span></span><span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>    <span class="va">self</span>.call_hook(<span class="st">&#39;after_train_iter&#39;</span>)</span><span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 省略 ...</span></span><span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="va">self</span>.call_hook(<span class="st">&#39;after_train_epoch&#39;</span>)</span></code></pre></div><p>其次, 在与 <code>Runner</code> 类配合的 <code>Hook</code>类及其子类中, 也定义了一堆与上面 Runner 类的触发器中<code>before_run</code>, <code>before_epoch</code>,<code>before_train_iter</code>, <code>after_train_iter</code>,<code>after_epoch</code>, <code>after_run</code>等步骤/时刻/节点同名的函数, 被称之为<strong>钩子函数</strong>,如下所示:</p><div class="sourceCode" id="cb14"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Hook:</span><span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span><span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> before_run(<span class="va">self</span>, runner):</span><span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span><span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span><span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> after_run(<span class="va">self</span>, runner):</span><span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span><span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a></span><span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> before_epoch(<span class="va">self</span>, runner):</span><span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span><span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span><span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> after_epoch(<span class="va">self</span>, runner):</span><span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span><span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a></span><span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> before_iter(<span class="va">self</span>, runner):</span><span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span><span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a></span><span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> after_iter(<span class="va">self</span>, runner):</span><span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">pass</span></span><span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span><span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    <span class="co"># ... 省略</span></span></code></pre></div><p>当然, 上面这个 Hook 类是最最原始的实现, 也就是基本什么功能都没有实现.如果想定义一些操作, 实现一些功能，可以继承这个类并定制我们需要的功能,比如 <code>mmcv.runner.hooks.evaluation</code> 模块中的<code>EvalHook</code> 类继承了最最原始的 <code>Hook</code> 类,将里面的子函数基本都具体实现了一下; 而<code>mmseg.core.evaluation</code> 模块中的 <code>EvalHook</code>类则进一步继承了前一个 <code>EvalHook</code> 类, 重写了<code>after_train_iter</code> 和 <code>after_train_epoch</code>两个子函数.</p><p>有了相互配合的 Runner 类和 Hook 类之后, Runner 类实例运行到特定时刻,就会通过触发器函数调用各个 Hook 类中的钩子函数, 从而完成特定的功能.例如, 每个或者隔几个 <code>after_epoch</code> 或者<code>after_train_iter</code> 触发器时刻, 可以通过 <code>EvalHook</code>的 <code>after_train_iter</code> 函数调用 <code>_do_evaluate</code>函数完成对 validation set 的 evaluation.</p><p>个人感觉, 这套 Hook机制很像通信系统里面的<strong>轮流询问</strong>机制,是<strong>一套在算法生命周期中规定好了种种操作的训练框架规范</strong>.其之所以起作用，是因为在 Runner 类的被调用方法中, 每一个节点都规定了call 相应 hook 函数的操作. Runner 类在训练过程中会依次轮流询问端口,也就是依次 call 下每个节点的 hook 函数, 如果对应钩子函数有被专门定制过,那就执行下该功能. 如果没有, 那就是个空函数, 直接 pass 了,继续执行下一步，从而实现了拦截模块间的函数调用、消息传递、事件传递，从而修改或扩展组件的行为.</p><h3 id="hook-机制的底层实现">3.5 Hook 机制的底层实现</h3><p>在清楚了 Runner 类与 Hook 类配合实现 Hook 机制的工作流程后,还剩下的问题两个问题. 第一个问题是, 怎么让 Runner类实例知道去调用某个具体的 Hook 类实例的子函数, 也就是怎么将 Runner类实例和 Hook 类实例关联起来? 第二个问题是, Runner 类实例可能会调用多个Hook 对象, 每个 Hook 对象都会有各自同名的子函数, 比如<code>after_train_iter</code>, 这种情况是如何处理的?</p><p>对于第一个问题, 是通过 Runner 类的 <code>register_hook</code> 函数将<code>HOOK</code> 类实例注册进 Runner 类实例的. 我们以 MMSegmentation为例, 在训练模型的时候, 会调用 <code>mmseg.apis</code> 模块的<code>train_segmentor</code> 函数. 其中有两步是给<code>IterBasedRunner</code> 类实例 <code>runner</code> 注册 traininghooks 和 validation hooks:</p><div class="sourceCode" id="cb15"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>runner.register_training_hooks(cfg)</span><span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>runner.register_hook(eval_hook(val_dataloader, eval_cfg))</span></code></pre></div><p>Runner 类提供了两种注册 hook 的方法:</p><ol type="1"><li><code>register_hook</code> 方法是直接传入一个实例化的<code>HOOK</code> 对象，并将它插入到 Runner 类实例的<code>self._hooks</code> 列表中;</li><li><code>register_hook_from_cfg</code> 方法是传入一个配置项<code>cfg</code>，根据配置项来实例化 <code>HOOK</code> 对象,然后再将其插入到 <code>self._hooks</code> 列表中.</li></ol><p>其实, 第二种方法就是先调用 <code>mmcv.build_from_cfg</code>方法生成一个实例化的 <code>HOOK</code> 对象，然后再调用第一种<code>register_hook</code> 方法将实例化后的 <code>HOOK</code> 对象插入到<code>self._hooks</code> 列表中。</p><p>有了存有注册了的 Hook 类实例的 <code>self._hooks</code> 列表, Runner类在运行中调用注册了的 Hook 类实例的子函数也就顺理成章了. 看一下<code>BaseRunner</code> 类中 <code>call_hook</code> 函数的定义, 其中<code>fn_name</code> 就是<code>self.call_hook('after_train_iter')</code> 传入的<code>after_train_iter</code>. <code>getattr(hook, fn_name)(self)</code>其实就是在调用 <code>self._hooks</code> 列表中的 hook 对象的名为<code>fn_name</code> 的函数, 比如 <code>EvalHook</code> 类实例的<code>after_train_iter</code> 方法. 至此, 第一个问题, 如何动态地将想要的Hook 类实例的某个方法切入到 Runner 类实例的运行过程中已经实现了.</p><div class="sourceCode" id="cb16"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> call_hook(<span class="va">self</span>, fn_name):</span><span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>        <span class="co">&quot;&quot;&quot;Call all hooks.</span></span><span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span><span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co">        Args:</span></span><span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co">            fn_name (str): The function name in each hook to be called, such as</span></span><span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co">                &quot;before_train_epoch&quot;.</span></span><span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a><span class="co">        &quot;&quot;&quot;</span></span><span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> hook <span class="kw">in</span> <span class="va">self</span>._hooks:</span><span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>            <span class="bu">getattr</span>(hook, fn_name)(<span class="va">self</span>)</span></code></pre></div><p>对于第二个问题, 从上面 <code>call_hook</code> 函数的定义也可以看出,在 Runner 实例的 <code>run</code> 函数运行过程中, 在每一个设置<code>call_hook</code> 函数的节点, 都会就轮流执行一遍<code>self._hooks</code> 列表中所有 hook 实例中该时刻对应的方法. 比如,对于 <code>after_train_iter</code> 这个时刻, 就是遍历一遍所有 hook实例的 <code>after_train_iter</code> 方法. 如果只有一个 Hook实例重写了该方法, 而其他实例的该方法都是 <code>pass</code>, 那也无所谓.但如果有两个及以上实例的该方法实现不是 <code>pass</code>,那这就涉及到一个哪个实例的方法该先被调用的问题, 具体到程序中, 则是每个Hook 了实例被插入到 <code>self._hooks</code> 列表的位置的前后, 因为<code>call_hook</code> 函数是依次调用的.</p><p>优先级这点, 在注册 hook 的时候就已经实现了, <code>priority</code>是默认变量. 从下面 <code>register_hook</code> 函数的定义就可以看出,对于新注册的一个 Hook 实例, 按照其指定的优先级, 没有指定就默认<code>'NORMAL'</code> 优先级, 插入到 <code>self._hooks</code> 中,优先级越高的, 越靠前. 如果新注册的 Hook 实例与就有的 Hook实例优先级相同, 那就按照先来后到, 先来的排在更前面. 至此,第二个问题也解决了.</p><div class="sourceCode" id="cb17"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> register_hook(<span class="va">self</span>, hook, priority<span class="op">=</span><span class="st">&#39;NORMAL&#39;</span>):</span><span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">&quot;&quot;&quot;Register a hook into the hook list.</span></span><span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a></span><span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="co">    The hook will be inserted into a priority queue, with the specified</span></span><span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co">    priority (See :class:`Priority` for details of priorities).</span></span><span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">    For hooks with the same priority, they will be triggered in the same</span></span><span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">    order as they are registered.</span></span><span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span><span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">    Args:</span></span><span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">        hook (:obj:`Hook`): The hook to be registered.</span></span><span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">        priority (int or str or :obj:`Priority`): Hook priority.</span></span><span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">            Lower value means higher priority.</span></span><span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">    &quot;&quot;&quot;</span></span><span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">assert</span> <span class="bu">isinstance</span>(hook, Hook)</span><span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">hasattr</span>(hook, <span class="st">&#39;priority&#39;</span>):</span><span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&#39;&quot;priority&quot; is a reserved attribute for hooks&#39;</span>)</span><span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>    priority <span class="op">=</span> get_priority(priority)</span><span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>    hook.priority <span class="op">=</span> priority</span><span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>    <span class="co"># insert the hook to a sorted list</span></span><span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>    inserted <span class="op">=</span> <span class="va">False</span></span><span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(<span class="va">self</span>._hooks) <span class="op">-</span> <span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>):</span><span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> priority <span class="op">&gt;=</span> <span class="va">self</span>._hooks[i].priority:</span><span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._hooks.insert(i <span class="op">+</span> <span class="dv">1</span>, hook)</span><span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>            inserted <span class="op">=</span> <span class="va">True</span></span><span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>            <span class="cf">break</span></span><span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="kw">not</span> inserted:</span><span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>._hooks.insert(<span class="dv">0</span>, hook)</span></code></pre></div><h3 id="示例mmseg-中的-hooks">3.6 示例：<code>mmseg</code> 中的Hooks</h3><p>在下图中，我整理了 <code>mmseg</code> 的 <code>tools/train.py</code>整个运行周期中会用到的所有 hooks 对应的具体的 Hook类以及相应被调用的时刻。</p><p><imgsrc="https://pic2.zhimg.com/80/v2-e0c95b00559f570c4efd35702de51d05_720w.webp" /></p>]]></content>
      
      
      
        <tags>
            
            <tag> hook </tag>
            
            <tag> runner </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>cnn_batch形成</title>
      <link href="/2023/11/22/cnn-batch%E5%BD%A2%E6%88%90/"/>
      <url>/2023/11/22/cnn-batch%E5%BD%A2%E6%88%90/</url>
      
        <content type="html"><![CDATA[<h1 id="sampler-dataloader和数据batch的形成">Sampler,DataLoader和数据batch的形成</h1><h2 id="简介">1. 简介</h2><p>本文将简介pytorch<strong>采样器Sampler</strong>和<strong>数据加载器DataLoader</strong>，并解释在读取数据时每个batch形成的过程</p><h2 id="整体流程">2. 整体流程</h2><p>简要来说在pytorch中，Sampler负责决定读取数据时的先后顺序，DataLoader负责装载数据并根据Sampler提供的顺序安排数据，具体过程绘图和描述如下。</p><p>初始化DataLoader的时候需指定数据集Dataset（包括数据和标签)，Sampler可选，没有Sampler时会根据是否打乱数据顺序（shuffle）分别采用顺序采样器（sequentialsampler）和随机采样器（random sampler）。</p><p>第①步，Sampler首先根据Dataset的大小n形成一个可迭代的序号列表[0~n-1]。</p><p>第②步，BatchSampler根据DataLoader的batch_size参数将Sampler提供的序列划分成多个batch大小的可迭代序列组，drop_last参数决定是否保留最后一组。</p><p>第③步，兵分两路的Sampler(BatchSampler)和Dataset合二为一，在迭代读取DataLoader时，用BatchSampler中一个batch的编号查找Dataset中对应的数据和标签，读出一个batch数据。</p><p><imgsrc="https://pic1.zhimg.com/80/v2-fa13aa41ffc69576762be46631ad7448_720w.webp" /></p><p>举个例子。</p><p>对数据集D={X,Y}，其中数据X为[野兔在野外.png，野猫在野外.png，野猫在家.png，野狗在家.png，野狗在野外.png]，标签Y为[0，1，1，2，2]</p><p>第①步，初始的序号列表为<strong>[0, 1, 2, 3,4]</strong>，使用RandomSampler采样，采样不重复（replacement==FALSE），得到了采样后的序号列表<strong>[3,2, 1, 0, 4]</strong></p><p>第②步：输入的batch_size为2，drop_last为FALSE，所以用BatchSampler批次采样，形成列表[[3,2], [1, 0], [4]]；若drop_last为TRUE，则列表变为[[3, 2], [1, 0]]</p><p>第③步：迭代读取数据，根据序号从Dataset里找到相应数据和标签，如第一个batch为：</p><p>[[野狗在家.png, 野猫在家.png], [3, 2]]</p><p>以上就是形成一个batch数据的整个流程，下文将从代码角度深入介绍各个Class中的重要参数和函数。我是用较旧的pytorch版本（0.4.1.post2），也自己对照了一下1.7.0版本的代码。其中BatchSampler类基本一致，Sampler类去掉了__len__()方法，总的来说采样改动不大；DataLoader类主要是针对多线程做了很多优化，具体代码中也补充了大量注释，整体基础仍然是本文提到的几个方法。</p><h2 id="sampler和batchsampler">3. Sampler和BatchSampler</h2><h3 id="sampler">3.1 Sampler</h3><p><ahref="https://www.zhihu.com/people/6b2df8f2c5dae1c6b27be02f8bc53bfe"><spanclass="citation" data-cites="marsggbo">@marsggbo</span></a> 的文章<ahref="https://zhuanlan.zhihu.com/p/82985227">sampler介绍</a></p><p>简要来说，Sampler类__init__()方法用于初始化采样算法，<strong>iter</strong>()方法用torch的random、multinomial方法实现随机和基于权重的采样并返回可迭代对象，<strong>len</strong>()是返回采样长度。</p><h3 id="batchsampler">3.2 BatchSampler</h3><p>参数：</p><p>sampler（Sampler类）：输入的sampler</p><p>batch_size（int类）：设定的批次大小</p><p>drop_last（bool类）：是否弃掉不足batch_size大小的最后一个批次</p><p>重要函数：</p><p>__init__初始化各项参数</p><div class="sourceCode" id="cb1"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, sampler, batch_size, drop_last):</span><span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span><span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sampler <span class="op">=</span> sampler</span><span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span><span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.drop_last <span class="op">=</span> drop_last</span></code></pre></div><p>__iter__循环读取sampler生成的序号列表，采样够batch_size大小后，返回batch，下一次清空batch继续采集。</p><div class="sourceCode" id="cb2"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__iter__</span>(<span class="va">self</span>):</span><span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>        batch <span class="op">=</span> []</span><span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> idx <span class="kw">in</span> <span class="va">self</span>.sampler:</span><span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>            batch.append(idx)</span><span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="bu">len</span>(batch) <span class="op">==</span> <span class="va">self</span>.batch_size:</span><span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>                <span class="co"># 通过yield返回，下一个iter时清空batch继续采集</span></span><span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>                <span class="cf">yield</span> batch</span><span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> []</span><span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 如果不需drop最后一组返回最后一组</span></span><span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="bu">len</span>(batch) <span class="op">&gt;</span> <span class="dv">0</span> <span class="kw">and</span> <span class="kw">not</span> <span class="va">self</span>.drop_last:</span><span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> batch</span></code></pre></div><p>__len__返回batch数量，如果drop最后一个，则序列长度对batch_size取整，否则加上一</p><div class="sourceCode" id="cb3"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__len__</span>(<span class="va">self</span>):</span><span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.drop_last:</span><span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="bu">len</span>(<span class="va">self</span>.sampler) <span class="op">//</span> <span class="va">self</span>.batch_size</span><span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span><span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> (<span class="bu">len</span>(<span class="va">self</span>.sampler) <span class="op">+</span> <span class="va">self</span>.batch_size <span class="op">-</span> <span class="dv">1</span>) <span class="op">//</span> <span class="va">self</span>.batch_size</span></code></pre></div><h2 id="dataloader">4. DataLoader</h2><h3 id="dataloader-1">4.1 DataLoader</h3><p>重要参数：</p><p>dataset（Dataset类）：Dataset类型的输入数据，由数据和标签组成</p><p>batch_size（int类）：同BatchSampler</p><p>shuffle（bool类）：是否打乱数据顺序</p><p>sampler（Sampler类）：同BatchSampler</p><p>batch_sampler（BatchSampler类）</p><p>drop_last（bool类）：同BatchSampler</p><p>重要函数：</p><p>__init__中对参数关系中的互斥情况进行了排除，指定sampler并通过batch_sampler分出batch，</p><div class="sourceCode" id="cb4"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, dataset, batch_size<span class="op">=</span><span class="dv">1</span>, shuffle<span class="op">=</span><span class="va">False</span>, sampler<span class="op">=</span><span class="va">None</span>, batch_sampler<span class="op">=</span><span class="va">None</span>,</span><span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>                 num_workers<span class="op">=</span><span class="dv">0</span>, collate_fn<span class="op">=</span>default_collate, pin_memory<span class="op">=</span><span class="va">False</span>, drop_last<span class="op">=</span><span class="va">False</span>,</span><span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>                 timeout<span class="op">=</span><span class="dv">0</span>, worker_init_fn<span class="op">=</span><span class="va">None</span>):</span><span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span><span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span><span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 互斥关系，指定了batch_sampler时，batch_size，shuffle，sampler和drop_last无效</span></span><span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch_sampler <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span><span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> batch_size <span class="op">&gt;</span> <span class="dv">1</span> <span class="kw">or</span> shuffle <span class="kw">or</span> sampler <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">or</span> drop_last:</span><span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>                <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&#39;batch_sampler option is mutually exclusive &#39;</span></span><span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>                                 <span class="st">&#39;with batch_size, shuffle, sampler, and &#39;</span></span><span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>                                 <span class="st">&#39;drop_last&#39;</span>)</span><span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.batch_size <span class="op">=</span> <span class="va">None</span></span><span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.drop_last <span class="op">=</span> <span class="va">None</span></span><span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span><span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 互斥关系，指定了sampler时，shuffle无效</span></span><span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> sampler <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span> <span class="kw">and</span> shuffle:</span><span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&#39;sampler option is mutually exclusive with &#39;</span></span><span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&#39;shuffle&#39;</span>)</span><span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a></span><span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_workers <span class="op">&lt;</span> <span class="dv">0</span>:</span><span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">&#39;num_workers option cannot be negative; &#39;</span></span><span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>                             <span class="st">&#39;use num_workers=0 to disable multiprocessing.&#39;</span>)</span><span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>        </span><span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 此处可以看出，shuffle与否其实还是靠sampler类型实现的</span></span><span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 当不指定sampler时，不shuffle就是顺序采样，shuffle就是随机采样</span></span><span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> batch_sampler <span class="kw">is</span> <span class="va">None</span>:</span><span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> sampler <span class="kw">is</span> <span class="va">None</span>:</span><span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> shuffle:</span><span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>                    sampler <span class="op">=</span> RandomSampler(dataset)</span><span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>                <span class="cf">else</span>:</span><span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>                    sampler <span class="op">=</span> SequentialSampler(dataset)</span><span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>            <span class="co"># 用batch_sampler对sampler产生的序列划分batch</span></span><span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>            batch_sampler <span class="op">=</span> BatchSampler(sampler, batch_size, drop_last)</span><span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a></span><span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sampler <span class="op">=</span> sampler</span><span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_sampler <span class="op">=</span> batch_sampler</span><span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.__initialized <span class="op">=</span> <span class="va">True</span></span></code></pre></div><p>DataLoader的__iter__是在_DataLoaderIter类中实现的，该类也是整个迭代方法的核心</p><pre class="text"><code>def __iter__(self):        return _DataLoaderIter(self)</code></pre><h3 id="dataloaderiter">4.2 _DataLoaderIter</h3><p>__init__初始化并指定了sampler_iter，即batch_sampler</p><div class="sourceCode" id="cb6"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, loader):</span><span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.dataset <span class="op">=</span> loader.dataset</span><span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.collate_fn <span class="op">=</span> loader.collate_fn</span><span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_sampler <span class="op">=</span> loader.batch_sampler</span><span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_workers <span class="op">=</span> loader.num_workers</span><span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pin_memory <span class="op">=</span> loader.pin_memory <span class="kw">and</span> torch.cuda.is_available()</span><span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.timeout <span class="op">=</span> loader.timeout</span><span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.done_event <span class="op">=</span> threading.Event()</span><span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a></span><span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.sample_iter <span class="op">=</span> <span class="bu">iter</span>(<span class="va">self</span>.batch_sampler)</span><span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="co"># ...</span></span></code></pre></div><p>_get_batch读取数据，加入了连接超时的判断</p><div class="sourceCode" id="cb7"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> _get_batch(<span class="va">self</span>):</span><span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>        <span class="co"># 连接超时</span></span><span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.timeout <span class="op">&gt;</span> <span class="dv">0</span>:</span><span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>            <span class="cf">try</span>:</span><span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>                <span class="cf">return</span> <span class="va">self</span>.data_queue.get(timeout<span class="op">=</span><span class="va">self</span>.timeout)</span><span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>            <span class="cf">except</span> queue.Empty:</span><span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>                <span class="cf">raise</span> <span class="pp">RuntimeError</span>(<span class="st">&#39;DataLoader timed out after </span><span class="sc">&#123;&#125;</span><span class="st"> seconds&#39;</span>.<span class="bu">format</span>(<span class="va">self</span>.timeout))</span><span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span><span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>.data_queue.get()</span></code></pre></div><p>_DataLoaderIter在每次调用时会执行__next__方法返回下一个batch</p><div class="sourceCode" id="cb8"><preclass="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> <span class="fu">__next__</span>(<span class="va">self</span>):</span><span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.num_workers <span class="op">==</span> <span class="dv">0</span>:  <span class="co"># same-process loading</span></span><span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>            indices <span class="op">=</span> <span class="bu">next</span>(<span class="va">self</span>.sample_iter)  <span class="co"># may raise StopIteration</span></span><span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> <span class="va">self</span>.collate_fn([<span class="va">self</span>.dataset[i] <span class="cf">for</span> i <span class="kw">in</span> indices])</span><span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.pin_memory:</span><span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>                batch <span class="op">=</span> pin_memory_batch(batch)</span><span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> batch</span><span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span><span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>        <span class="co"># check if the next sample has already been generated</span></span><span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.rcvd_idx <span class="kw">in</span> <span class="va">self</span>.reorder_dict:</span><span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>            batch <span class="op">=</span> <span class="va">self</span>.reorder_dict.pop(<span class="va">self</span>.rcvd_idx)</span><span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._process_next_batch(batch)</span><span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a></span><span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.batches_outstanding <span class="op">==</span> <span class="dv">0</span>:</span><span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>._shutdown_workers()</span><span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">StopIteration</span></span><span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span><span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">while</span> <span class="va">True</span>:</span><span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>            <span class="cf">assert</span> (<span class="kw">not</span> <span class="va">self</span>.shutdown <span class="kw">and</span> <span class="va">self</span>.batches_outstanding <span class="op">&gt;</span> <span class="dv">0</span>)</span><span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>            idx, batch <span class="op">=</span> <span class="va">self</span>._get_batch()</span><span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.batches_outstanding <span class="op">-=</span> <span class="dv">1</span></span><span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> idx <span class="op">!=</span> <span class="va">self</span>.rcvd_idx:</span><span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>                <span class="co"># store out-of-order samples</span></span><span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.reorder_dict[idx] <span class="op">=</span> batch</span><span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>                <span class="cf">continue</span></span><span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">return</span> <span class="va">self</span>._process_next_batch(batch)</span><span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a></span><span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 调用时执行__next__</span></span><span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="bu">next</span> <span class="op">=</span> <span class="fu">__next__</span>  <span class="co"># Python 2 compatibility</span></span></code></pre></div>]]></content>
      
      
      
        <tags>
            
            <tag> Sampler </tag>
            
            <tag> DataLoader </tag>
            
            <tag> batch </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Logging日志模块</title>
      <link href="/2023/11/21/Logging%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97/"/>
      <url>/2023/11/21/Logging%E6%97%A5%E5%BF%97%E6%A8%A1%E5%9D%97/</url>
      
        <content type="html"><![CDATA[<h1 id="python中logging-日志模块">Python中Logging 日志模块</h1><h2 id="一基础知识">一、基础知识</h2><p>Logging库是非常常用的记录日志库，通过<code>logging</code>模块存储各种格式的日志，主要用于输出运行日志，可以设置输出日志的等级、日志保存路径、日志文件回滚等</p><p><strong>Logging优点：</strong></p><ul><li>1.你可以控制消息的级别，过滤掉那些并不重要的消息。</li><li>2.你可决定输出到什么地方，以及怎么输出。有许多的重要性别级可供选择，<code>debug、info、warning、error 以及 critical</code>。通过赋予<code>logger</code> 或者 <code>handler</code>不同的级别，你就可以只输出错误消息到特定的记录文件中，或者在调试时只记录调试信息。</li></ul><p>for example:</p><pre class="python3"><code>import logging# 1、创建一个loggerlogger = logging.getLogger(&#39;mylogger&#39;)logger.setLevel(logging.DEBUG)# 2、创建一个handler，用于写入日志文件fh = logging.FileHandler(&#39;test.log&#39;)fh.setLevel(logging.DEBUG)# 再创建一个handler，用于输出到控制台ch = logging.StreamHandler()ch.setLevel(logging.DEBUG)# 3、定义handler的输出格式（formatter）formatter = logging.Formatter(&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;)# 4、给handler添加formatterfh.setFormatter(formatter)ch.setFormatter(formatter)# 5、给logger添加handlerlogger.addHandler(fh)logger.addHandler(ch)</code></pre><p>上面代码的用到了getLogger()、setLevel()、setFormatter()、StreamHandler()。后续进阶部分，我们会重点讲解这些函数。如果想系统了解python的日志写入，又不想趴英文网站，可以继续往下看，绝对详细、好理解。</p><p>根据它们用来跟踪的事件的级别或事件的严重程度命名的。以下描述了标准水平及其适用性（按严重程度的增加顺序）</p><p><imgsrc="https://pic2.zhimg.com/80/v2-52dd1e56f885cfebe649febabfeb55b9_720w.jpg" /></p><p>可以看到，严重程度的级别依次是DEBUG&lt;INFO&lt;WARNING&lt;ERROR&lt;CRITICAL</p><h3 id="简单栗子"><strong>1.1 简单栗子</strong></h3><pre class="text"><code>import logginglogging.warning(&#39;Watch out!&#39;)  # will print a message to the consolelogging.info(&#39;I told you so&#39;)  # will not print anything</code></pre><h3 id="将日志写入到一个文件中"><strong>1.2将日志写入到一个文件中</strong></h3><pre class="text"><code>import loggingimport osos.chdir(&quot;./&quot;) # 日志写入地址logging.basicConfig(filename=&#39;example.log&#39;, level=logging.DEBUG) # 注意：上面level设置的是显示的最低严重级别，小于level设置的最低严重级别将不会打印出来logging.debug(&#39;This message should go to the log file&#39;)logging.info(&#39;So should this&#39;)logging.warning(&#39;And this, too&#39;)logging.error(&#39;And non-ASCII stuff, too, like Øresund and Malmö&#39;)</code></pre><p>basicConfig()函数要在debug()、info()等运行，且只要第一次运行才生效。后续的调用都是无效的。上述logging.basicConfig()写入的日志是增量的写入。如果想要覆盖之前的日志，可以设定为：</p><pre class="text"><code>logging.basicConfig(filename=&#39;example.log&#39;,filemode=&#39;w&#39;,level=logging.DEBUG)</code></pre><p><strong>2. 多个模块日志调用</strong></p><p>logger.py</p><pre class="text"><code>import loggingimport mylibdef main():    logging.basicConfig(filename=&#39;myapp.log&#39;, level=logging.INFO)    logging.info(&#39;Started&#39;)    mylib.do_something() # 这里打印的是另一个模块的日志    logging.info(&#39;Finished&#39;)if __name__ == &#39;__main__&#39;:    main()</code></pre><p>mylib.py</p><pre class="text"><code>import loggingdef do_something():    logging.info(&quot;Doing things&quot;)</code></pre><p>输出结果(下面打印结果中含有root，后续我们会说到怎样避免打印root)</p><p>INFO:root:Started</p><p>INFO:root:Doing something</p><p>INFO:root:Finished</p><h3 id="改变呈现message的format格式"><strong>1.3.改变呈现message的format(格式)</strong></h3><p>：定义日志呈现中预想的日志呈现格式</p><pre class="text"><code>import logginglogging.basicConfig(format=&#39;%(levelname)s:%(message)s&#39;, level=logging.DEBUG)logging.debug(&#39;This message should appear on the console&#39;)logging.info(&#39;So should this&#39;)logging.warning(&#39;And this, too&#39;)</code></pre><p>输出结果：</p><p>DEBUG:This message should appear on the console</p><p>INFO:So should this</p><p>WARNING:And this, too</p><p>上面日志打印的结果格式中，少了root:。有一系列可以用做格式化的属性，如下：</p><table><colgroup><col style="width: 12%" /><col style="width: 36%" /><col style="width: 50%" /></colgroup><thead><tr class="header"><th>Attribute name</th><th>Format</th><th>Description</th></tr></thead><tbody><tr class="odd"><td>args</td><td>You shouldn’t need to format this yourself.</td><td>The tuple of arguments merged into msg to produce message, or a dictwhose values are used for the merge (when there is only one argument,and it is a dictionary).</td></tr><tr class="even"><td>asctime</td><td>%(asctime)s</td><td>Human-readable time when the LogRecord was created. By default thisis of the form ‘2003-07-08 16:49:45,896’ (the numbers after the commaare millisecond portion of the time).</td></tr><tr class="odd"><td>created</td><td>%(created)f</td><td>Time when the LogRecord was created (as returned bytime.time()).</td></tr><tr class="even"><td>exc_info</td><td>You shouldn’t need to format this yourself.</td><td>Exception tuple (à la sys.exc_info) or, if no exception hasoccurred, None.</td></tr><tr class="odd"><td>filename</td><td>%(filename)s</td><td>Filename portion of pathname.</td></tr><tr class="even"><td>funcName</td><td>%(funcName)s</td><td>Name of function containing the logging call.</td></tr><tr class="odd"><td>levelname</td><td>%(levelname)s</td><td>Text logging level for the message ('DEBUG', 'INFO', 'WARNING','ERROR', 'CRITICAL').</td></tr><tr class="even"><td>levelno</td><td>%(levelno)s</td><td>Numeric logging level for the message (DEBUG, INFO, WARNING, ERROR,CRITICAL).</td></tr><tr class="odd"><td>lineno</td><td>%(lineno)d</td><td>Source line number where the logging call was issued (ifavailable).</td></tr><tr class="even"><td>message</td><td>%(message)s</td><td>The logged message, computed as msg % args. This is set whenFormatter.format() is invoked.</td></tr><tr class="odd"><td>module</td><td>%(module)s</td><td>Module (name portion of filename).</td></tr><tr class="even"><td>msecs</td><td>%(msecs)d</td><td>Millisecond portion of the time when the LogRecord was created.</td></tr><tr class="odd"><td>msg</td><td>You shouldn’t need to format this yourself.</td><td>The format string passed in the original logging call. Merged withargs to produce message, or an arbitrary object (see Using arbitraryobjects as messages).</td></tr><tr class="even"><td>name</td><td>%(name)s</td><td>Name of the logger used to log the call.</td></tr><tr class="odd"><td>pathname</td><td>%(pathname)s</td><td>Full pathname of the source file where the logging call was issued(if available).</td></tr><tr class="even"><td>process</td><td>%(process)d</td><td>Process ID (if available).</td></tr><tr class="odd"><td>processName</td><td>%(processName)s</td><td>Process name (if available).</td></tr><tr class="even"><td>relativeCreated</td><td>%(relativeCreated)d</td><td>Time in milliseconds when the LogRecord was created, relative to thetime the logging module was loaded.</td></tr><tr class="odd"><td>stack_info</td><td>You shouldn’t need to format this yourself.</td><td>Stack frame information (where available) from the bottom of thestack in the current thread, up to and including the stack frame of thelogging call which resulted in the creation of this record.</td></tr><tr class="even"><td>thread</td><td>%(thread)d</td><td>Thread ID (if available).</td></tr><tr class="odd"><td>threadName</td><td>%(threadName)s</td><td>Thread name (if available)</td></tr></tbody></table><p>比如，我们将上面logging.basicConfig(format='%(levelname)s:%(message)s',level=logging.DEBUG) <strong>修改为</strong>logging.basicConfig(format='%(levelname)s:%(message)s:%(module)s',level=logging.DEBUG)。</p><p>输出的结果将会变为：</p><p>DEBUG:This message should appear on the console:logger</p><p>INFO:So should this:logger</p><p>WARNING:And this, too:logger</p><p>如果你想加入时间，可以试试加上%(asctime)s。</p><pre class="text"><code>import logginglogging.basicConfig(format=&#39;%(asctime)s %(message)s&#39;)logging.warning(&#39;is when this event was logged.&#39;)</code></pre><p>输出：</p><p>2010-12-12 11:41:42,612 is when this event was logged.</p><p>如果你希望控制输出时间的格式，可以使用datefmt.</p><pre class="text"><code>import logginglogging.basicConfig(format=&#39;%(asctime)s %(message)s&#39;, datefmt=&#39;%m/%d/%Y %I:%M:%S %p&#39;)logging.warning(&#39;is when this event was logged.&#39;)</code></pre><p>输出：</p><p>12/12/2010 11:46:36 AM is when this event was logged.</p><h2 id="二进阶知识"><strong>二、进阶知识</strong></h2><p>logging库提供了模块化的方法和几个组件<strong>，下列列出了模块定义的基础类和函数</strong></p><blockquote><p>Loggers ：记录器公开应用程序代码直接使用的接口。 Handlers：处理程序将日志记录（由记录器创建）发送到相应的目标。 Filters：过滤器提供了更细粒度的工具，用于确定要输出哪些日志记录。 Formatters：格式化程序指定最终输出中日志记录的布局。</p></blockquote><pre class="text"><code>logger = logging.getLogger(__name__)</code></pre><p>这意味着logger的名称和包/模块层次结构一致，从logger的名称记录事件是非常直观的方法。logger的根层级调用根logger.根logger是函数debug（）、info（）、warning（）、error（）和critical（）使用的记录器，这些函数只调用根记录器的同名方法。<strong>根logger名称会在打印时以'root'出现在输出结果中。</strong></p><p>当然，可以将消息记录到不同的目的地。该软件包支持将日志消息写入文件、HTTPGET/POST位置、通过SMTP发送的电子邮件、通用套接字、队列或特定于操作系统的日志机制，如syslog或WindowsNT事件日志。目的地由handler classes提供服务。如果有任何内置handlerclasses都无法满足的特殊要求，则可以创建自己的日志目标类。</p><p>默认情况下，不会为任何日志消息设置目标。可以使用basicConfig（）指定目标（如控制台或文件），如上述所示。如果调用函数debug（）、info（）、warning（）、error（）和critical（），它们将检查是否未设置目标位置（如控制台或文件）；如果没有设置，他们将设置控制台的目的地（sys.stderr）和显示消息的默认格式，然后再委托rootlogger进行实际的消息输出。</p><p>basicConfig()设定的默认形式为：severity:logger name:message</p><h3 id="logger对象"><strong>2.1 Logger对象</strong></h3><p>Logger对象有三方面的工作。</p><ol type="1"><li>logger对象向应用程序代码公开了几种方法，以便应用程序可以在运行时记录消息。</li><li>logger对象根据severity,即严重性（默认过滤功能）或过滤对象确定要对哪些日志消息采取行动。</li><li>logger对象对象将相关日志消息传递给所有感兴趣的日志处理程序。</li></ol><p>在Logger对象中最常用的方方有两类：<strong>配置和消息发送。</strong></p><p><strong>最常用的配置方法：</strong></p><ul><li>Logger.setLevel()指定处理的最低严重性日志消息，其中debug是最低的内置严重性级别，critical是最高的内置严重性级别。例如，如果严重性级别为INFO，Logger将只处理INFO, WARNING, ERROR和CRITICAL messages，并将忽略DEBUG 消息。</li></ul><p>举个栗子，比如我们在logging.basicConfig(format='%(levelname)s:%(message)s',level=logging.DEBUG)。这里的Level设置的是最低严重性级别DEBUG,那么，将打印所有的信息，包括DEBUG，INFO，WARNING, ERROR和CRITICAL；但是当上面的basicConfig，则打印当中没有DEBUG，只有INFO，WARNING,ERROR和CRITICAL。这是因为level设置的最低级别是INFO，而DEBUG的严重性级别最低，所有在此不用打印。</p><ul><li>Logger.addHandler()和 Logger.removeHandler()从Logger对象中添加和移出handler对象</li><li>Logger.addFilter()和Logger.removeFilter()从Logger对象中添加和移出filter对象</li></ul><p>配置logger对象后，以下方法将创建日志消息：</p><ul><li>Logger.debug(), Logger.info(),Logger.warning(),Logger.error()和Logger.critical()都会创建日志记录，其中包含一条message和一个对应于各自方法名称的级别，message实际上是一个格式字符串，它可能包含%s、%d、%f等标准字符串替换语法。其余参数是与message中的替换字段相对应的对象列表。</li><li>Logger.exception()创建了一个和Logger.error()相似的message。不同的是Logger.exception()伴随的是一堆轨迹，只能从exceptionhandler中调用此方法。</li><li>Logger.log()将日志级别作为显式参数。与使用上面列出的日志级别便利方法相比，记录消息要详细一些，但这是如何使用自定义方法对日志进行记录。</li><li>getLogger()返回对具有指定名称的Logger实例的引用（如果提供了），或者如果没有指定，则返回对根实例的引用。这些名称是以句点分隔的层次结构。使用相同名称多次调用getLogger（）将返回对同一记录器对象的引用。在层级列表中较低的记录器是列表中较高记录器的子级。例如，给定一个名为foo的Logger,那么，foo.bar, foo.bar.baz, and foo.bam 皆是foo的后代</li></ul><h3 id="handle对象"><strong>2.2</strong>Handle<strong>对象</strong></h3><p>Handler对象负责将适当的日志消息（基于日志消息的严重性）分派到处理程序的指定目标。Handler对象可以使用addHandler（）方法将零个或多个handler对象添加。应用程序可能希望将所有日志消息发送到日志文件，将所有错误或更高级别的日志消息发送到标准输出，并将所有关键消息发送到电子邮件地址。此场景需要三个单独的处理程序，每个处理程序负责将特定严重性的消息发送到特定位置。</p><p>Handler方法有很多，下面主要介绍两种：StreamHandle和FileHandle</p><p>回到文章最开始的代码，我们看到</p><pre class="text"><code>fh=logging.FileHandler(&#39;test.log&#39;) # 将日志写入到test.log文件 fh.setLevel(logging.DEBUG) # 并且需要指定写入的内容严重级别</code></pre><p>同理，</p><pre class="text"><code>ch=logging.StreamHandler() # 将日志写入控制台ch.setLevel(loggong.DEBUG) # 并且需要指定写入的内容严重级别</code></pre><p>除此之外，我们会发现，文中最开始的栗子exam.py中在最开始创建Logger时设置了setLevel</p><pre class="text"><code>logger=logging.getLogger(&#39;mylogger&#39;) # 创建loggerlogger.setLevel(logging.DEBUG) # 写入内容的严重级别</code></pre><p>那么为什么后续在定义Handler时又做了一次setLevel操作呢？原因是：<strong>Logger中设置的级别决定它将传递给Handler的消息严重性。每个Handler设置的setLevel()决定了该处理程序将发送哪些消息</strong>（记住：日志中消息是分严重程度的，当确定严重级别是某个层级时，该层级以下的消息不被发送或者记录，该层级以上的消息才被发送或者记录）。</p><ul><li>setLevel()方法，就像在logger对象中一样，指定将被分派到相应目标的最低严重性。为什么有两个setLevel()方法？logger中设置的级别决定它将传递给其Handler的消息的严重性。每个Handler设置的级别决定了该处理程序将发送哪些消息。</li><li>setFormatter()选择此处理程序Handler要使用的格式化程序对象.</li><li>addFilter()和removeFilter()分别在处理程序上配置和取消配置筛选器对象。</li></ul><p>到此，我们再次回顾一下exam.py中的代码，相信看到这里大家就明白了。</p><pre class="text"><code>import logging# 1、创建一个loggerlogger = logging.getLogger(&#39;mylogger&#39;)logger.setLevel(logging.DEBUG)# 2、创建一个handler，用于写入日志文件fh = logging.FileHandler(&#39;test.log&#39;)fh.setLevel(logging.DEBUG)# 再创建一个handler，用于输出到控制台ch = logging.StreamHandler()ch.setLevel(logging.DEBUG)# 3、定义handler的输出格式（formatter）formatter = logging.Formatter(&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;)# 4、给handler添加formatterfh.setFormatter(formatter)ch.setFormatter(formatter)# 5、给logger添加handlerlogger.addHandler(fh)logger.addHandler(ch)</code></pre><h3 id="formatters对象"><strong>2.3 Formatters对象</strong></h3><p>Formatters对象配置了最终的顺序、结构和日志消息内容。</p><p>logging.Formatter.<strong><strong>init</strong></strong>(<em>fmt=None</em>,<em>datefmt=None</em>, <em>style='%'</em>)</p><p>fmt:消息格式</p><p>datefmt:时间格式，默认为：%Y-%m-%d %H:%M:%S</p><h3 id="configuring-logging"><strong>2.4 ConfiguringLogging</strong></h3><p>程序配置日志有三种方式：</p><ul><li>调用上述配置方法的Python代码显式创建Loggers、handlers和formatters</li><li>创建日志配置文件并使用fileConfig（）函数读取它</li><li>创建配置信息字典并将其传递给dictConfig（）函数</li></ul><p>*<strong>我们再举个简单的例子说明第一种方式，显示的创建Loggers、handlers和formatters*</strong></p><pre class="text"><code>import logging# 创建loggerlogger = logging.getLogger(&#39;simple_example&#39;) # logger名称logger.setLevel(logging.DEBUG) # 设定logger显示的严重级别# 创建一个handler，用于输出控制台，并且设定严重级别ch = logging.StreamHandler()ch.setLevel(logging.DEBUG)# 创建handler的输出格式（formatter）formatter = logging.Formatter(&#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;)# 将formatter添加到handler中ch.setFormatter(formatter)# 将handler添加到logger中logger.addHandler(ch)# 输出以下内容# &#39;application&#39; codelogger.debug(&#39;debug message&#39;)logger.info(&#39;info message&#39;)logger.warning(&#39;warn message&#39;)logger.error(&#39;error message&#39;)logger.critical(&#39;critical message&#39;)</code></pre><p><strong>$</strong> python simple_logging_module.py</p><p>#输出结果如下</p><p>2005-03-19 15:10:26,618 - simple_example - DEBUG - debug message</p><p>2005-03-19 15:10:26,620 - simple_example - INFO - info message</p><p>2005-03-19 15:10:26,695 - simple_example - WARNING - warn message</p><p>2005-03-19 15:10:26,697 - simple_example - ERROR - error message</p><p>2005-03-19 15:10:26,773 - simple_example - CRITICAL - criticalmessage</p><p>*<strong>第二种方式：引入配置文件，配置文件写在logging.conf中*</strong></p><pre class="text"><code>import loggingimport logging.configlogging.config.fileConfig(&#39;logging.conf&#39;)# create loggerlogger = logging.getLogger(&#39;simpleExample&#39;)# &#39;application&#39; codelogger.debug(&#39;debug message&#39;)logger.info(&#39;info message&#39;)logger.warning(&#39;warn message&#39;)logger.error(&#39;error message&#39;)logger.critical(&#39;critical message&#39;)</code></pre><p>配置文件的内容如下：</p><pre class="text"><code>[loggers]keys=root,simpleExample[handlers]keys=consoleHandler[formatters]keys=simpleFormatter[logger_root]level=DEBUGhandlers=consoleHandler[logger_simpleExample]level=DEBUGhandlers=consoleHandlerqualname=simpleExamplepropagate=0[handler_consoleHandler]class=StreamHandlerlevel=DEBUGformatter=simpleFormatterargs=(sys.stdout,)[formatter_simpleFormatter]format=%(asctime)s - %(name)s - %(levelname)s - %(message)s</code></pre><p><strong>$</strong> python simple_logging_module.py</p><p>#输出结果如下</p><p>2005-03-19 15:10:26,618 - simple_example - DEBUG - debug message</p><p>2005-03-19 15:10:26,620 - simple_example - INFO - info message</p><p>2005-03-19 15:10:26,695 - simple_example - WARNING - warn message</p><p>2005-03-19 15:10:26,697 - simple_example - ERROR - error message</p><p>2005-03-19 15:10:26,773 - simple_example - CRITICAL - criticalmessage</p><p><strong>配置文件的好处是：1.配置文件和代码的分离；2.非代码人员也能轻松定义配置文件的内容</strong></p><p>*<strong>第三种方式：dictConfig()*</strong></p><pre class="text"><code>version: 1formatters:  simple:    format: &#39;%(asctime)s - %(name)s - %(levelname)s - %(message)s&#39;handlers:  console:    class: logging.StreamHandler    level: DEBUG    formatter: simple    stream: ext://sys.stdoutloggers:  simpleExample:    level: DEBUG    handlers: [console]    propagate: noroot:  level: DEBUG  handlers: [console]</code></pre><p><strong>这种方式是我个人感觉非常非常赞的方式，即实现了代码和配置的分离，又简单好理解。</strong></p><p>最后，总结一下整个操作流（官网上down下来的）：</p><figure><imgsrc="https://pic3.zhimg.com/80/v2-d69005a3c3ee464c7c68e7bcf5012682_720w.webp"alt="w" /><figcaption aria-hidden="true">w</figcaption></figure>]]></content>
      
      
      
        <tags>
            
            <tag> log </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd3d数据提取、模型搭建过程</title>
      <link href="/2023/11/17/mmd3d%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E3%80%81%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B/"/>
      <url>/2023/11/17/mmd3d%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E3%80%81%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="熟悉mmdetection3d数据提取、模型搭建过程"><a href="#熟悉mmdetection3d数据提取、模型搭建过程" class="headerlink" title="熟悉mmdetection3d数据提取、模型搭建过程"></a>熟悉mmdetection3d数据提取、模型搭建过程</h1><h3 id="1、读取配置文件"><a href="#1、读取配置文件" class="headerlink" title="1、读取配置文件"></a>1、读取配置文件</h3><h4 id="1-1-mmdetection3d配置文件的组成"><a href="#1-1-mmdetection3d配置文件的组成" class="headerlink" title="1.1 mmdetection3d配置文件的组成"></a>1.1 mmdetection3d配置文件的组成</h4><p>配置文件存放于mmdetection3d/config目录下，其中<strong><em>base</em>目录为mmdetection3d自带的基础配置，即原始配置，从<em>base</em></strong>目录的组成来看，mmdetection3d将配置文件分为四种，分别是：<strong>数据集 (dataset)，模型 (model)，训练策略 (schedule) 和运行时的默认设置 (default runtime)</strong></p><p>下面基于一个配置文件的部分内容，解释一下该怎么看</p><pre><code># configs/centerpoint/centerpoint_01voxel_second_secfpn_4x8_cyclic_20e_nus.py_base_ = [    &#39;../_base_/datasets/nus-3d.py&#39;,    &#39;../_base_/models/centerpoint_01voxel_second_secfpn_nus.py&#39;, # 继承了这个模型的基础文件    &#39;../_base_/schedules/cyclic_20e.py&#39;, &#39;../_base_/default_runtime.py&#39;]model = dict(    pts_voxel_layer=dict(point_cloud_range=point_cloud_range),    pts_bbox_head=dict(bbox_coder=dict(pc_range=point_cloud_range[:2])),    # model training and testing settings    train_cfg=dict(pts=dict(point_cloud_range=point_cloud_range)),    test_cfg=dict(pts=dict(pc_range=point_cloud_range[:2])))</code></pre><p>可以看出，在centerpoint_01voxel_second_secfpn_4x8_cyclic_20e_nus.py这个文件中，model部分只有一小段内容，这是因为继承了centerpoint_01voxel_second_secfpn_nus.py，只是在继承文件的基础上来修改或添加某些特定字段</p><p>为了方便说明，来一份简化版的配置文件</p><pre><code># configs/_base_/models/centerpoint_01voxel_second_secfpn_nus.pymodel = dict(    type=&#39;CenterPoint&#39;,    pts_voxel_layer=dict(         max_num_points=10, voxel_size=voxel_size, max_voxels=(90000, 120000)),    pts_voxel_encoder=dict(type=&#39;HardSimpleVFE&#39;, num_features=5),    pts_middle_encoder=dict(),    pts_backbone=dict(),    pts_neck=dict(),    pts_bbox_head=dict(),    # model training and testing settings    train_cfg=dict(),    test_cfg=dict())</code></pre><p>为了查看具体网络是怎么实现的，我们首先从model最开始出发，根据配置文件，第一个字段为type，上述例子中使用了CenterPoint，我们需要在mmdetection3d/mmdet3d/models/detectors/<strong>init</strong>.py中，找到CenterPoint，看一下是从哪里引入的，如下图所示，这样一来，我们找到了实现网络的具体位置，路径为:mmdetection3d/mmdet3d/models/detectors/centerpoint.py<br><img src="https://img-blog.csdnimg.cn/55d1efc693924069b6d35942f7fcf8b4.png#pic_center" alt=""></p><p><img src="https://img-blog.csdnimg.cn/20908a38ed224a8c845697489d6aa152.png" alt=""></p><p>再往下走，有一句：python pts_voxel_layer=dict( max_num_points=10, voxel_size=voxel_size, max_voxels=(90000, 120000)),</p><p>我们在mmdetection3d/mmdet3d/models/detectors/centerpoint.py中的<strong>init</strong>方法中，找到对应初始化字段pts_voxel_layer</p><p><img src="https://img-blog.csdnimg.cn/3be861f1d1d04d4ea6f9ecaf059545b9.png#pic_center" alt=""></p><p>但是我们在此发现，这里并没有使用这个字段，这是因为CenterPoint类继承了MVXTwoStageDetector类，我们顺藤摸瓜，查看MVXTwoStageDetector类，发现这个类使用了pts_voxel_layer字段，并且给出了使用过程。Voxelization(**pts_voxel_layer)为封装好的一个体素化函数，它返回一组能表示体素的参数，这里我们不关心具体实现。另外，根据上图可以看出，init方法里所有的字段与配置文件中的字段是对应着顺下来的，也就是说，我们可以从centerpoint类里顺藤摸瓜，找到所有配置的具体实现<br><img src="https://img-blog.csdnimg.cn/b4f7508106fb4a21b1f29856de870e56.png#pic_center" alt=""></p><p>至此，第一行分析完毕，再往下走，是一句<code>pts_voxel_encoder=dict(type=&#39;HardSimpleVFE&#39;, num_features=5)</code>，分析方法与上面相同。</p><h4 id="1-2-使用base配置文件构建自己的配置文件"><a href="#1-2-使用base配置文件构建自己的配置文件" class="headerlink" title="1.2 使用base配置文件构建自己的配置文件"></a>1.2 使用base配置文件构建自己的配置文件</h4><p>这部分我们继承基础配置文件，构建一个简单的配置文件，以便接下来使用</p><ol><li>首先，我们在configs目录下创建一个文件夹，用于保存自己的配置文件，并新建一个my_config.py文件</li><li>在新建的配置文件中，写入以下内容</li></ol><pre><code>_base_ = [    &#39;../_base_/datasets/nus-3d-mini.py&#39;, # 这里我继承了基础文件中的nus-3d.py构建了一个mini版本，主要就是修改了一下数据集路径    &#39;../_base_/schedules/schedule_2x.py&#39;,    &#39;../_base_/default_runtime.py&#39;,]voxel_size = [0.1, 0.1, 0.1]norm_cfg = NoneDOUBLE_FLIP = False# 为了简单演示，这里只实现了体素构造层和编码层model = dict(    type=&quot;MY_MODEL&quot;,    voxel_layer=dict(        max_num_points=32,        point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],        voxel_size=voxel_size,        max_voxels=(16000, 40000)),    voxel_encoder=dict(        type=&#39;VoxelFeatureExtractorV3&#39;,        num_input_features=4    ),    train_cfg=dict(),    test_cfg=dict())data = dict(    samples_per_gpu=1,    workers_per_gpu=4)</code></pre><p>1.3 根据配置文件搭建网络</p><p>接下来要做的，是根据我们配置文件中的model部分，开始搭建网络，具体步骤如下：</p><ul><li>在mmdet3d/models/detectors目录下，创建一个py文件，这里取名为my_model.py</li><li>构造一个类，类名要和配置文件中的type一致，当然也可以在注册的时候用import … as …来替换:</li></ul><pre><code>from ..builder import DETECTORS # 引入构造器@DETECTORS.register_module() # 注册，这一句必须要有class MY_MODEL():    def __init__(self):        pass</code></pre><ul><li><strong>在mmdet3d/models/detectors/<em>*init*</em>.py中注册</strong>：</li></ul><p><img src="https://img-blog.csdnimg.cn/04a4d3ce9a854208a7531fe0d9af7eac.png#pic_center" alt=""></p><ul><li>在此例中，便于理解，我们就不继承任何文件了，仅写出初始化方法</li><li>接下来要做的，是要在init方法中定义相关参数并给出相应实现</li></ul><pre><code>from mmcv.ops import Voxelization # 引入mmcv中的体素化方法from .. import builder    # 引入构造器from ..builder import DETECTORS@DETECTORS.register_module()class my_model():    def __init__(self, voxel_layer, voxel_encoder, train_cfg, test_cfg):        self.voxel_layer = Voxelization(**voxel_layer) # 这一层是mmcv自带的，在3.4中会再介绍一下        self.voxel_encoder = builder.build_voxel_encoder(voxel_encoder) # 这里表示这个层是需要我们自己构造的</code></pre><ul><li>再一步，是实现我们的voxel_encoder层，我们在<strong>mmdet3d/models/voxel_encoders</strong>目录下，新建一个文件也好，直接写在现有文件里也行，这里我写在了voxel_encoder.py文件下</li></ul><pre><code>@VOXEL_ENCODERS.register_module() # 注册为体素编码层class VoxelFeatureExtractorV3(nn.Module):    def __init__(            self, num_input_features=4, norm_cfg=None, name=&quot;VoxelFeatureExtractorV3&quot;    ):        super(VoxelFeatureExtractorV3, self).__init__()        self.name = name        self.num_input_features = num_input_features    def forward(self, features, num_voxels, coors=None):        &quot;&quot;&quot;            features: 输入的体素            num_voxels: 体素数目        &quot;&quot;&quot;        points_mean = features[:, :, : self.num_input_features].sum(            dim=1, keepdim=False        ) / num_voxels.type_as(features).view(-1, 1)        return points_mean.contiguous()</code></pre><ul><li><p>再一步，是在mmdet3d/models/voxel<em>encoders/<em>_init</em></em>.py文件中，引入写好的VoxelFeatureExtractorV3，这样，我们就能在配置文件中，使用voxel_encoder=dict(type=’VoxelFeatureExtractorV3’, num_input_features=4)来调用我们的体素编码模块了</p><p><img src="https://img-blog.csdnimg.cn/2a4c35e92d0f4166a656f5b6de878aa9.png#pic_center" alt=""></p><h3 id="2、构建模型"><a href="#2、构建模型" class="headerlink" title="2、构建模型"></a>2、构建模型</h3><pre><code>此部分，我们使用jupyter notebook逐步、分解的从数据抓取开始，演示一下数据在我们搭建的网络中的运行流程</code></pre><h4 id="2-1-读取配置文件"><a href="#2-1-读取配置文件" class="headerlink" title="2.1 读取配置文件"></a>2.1 读取配置文件</h4><p>在真正的训练过程中，是通过传入的参数，根据配置文件路径导入整个参数的，相关代码位于tools/train.py。这里为简便期间，我们直接使用路径读取配置文件</p><pre><code># 读取配置文件from mmcv import Configconfig_file = &quot;/home/wistful/work/mmdetection3d/configs/my_config/my_config.py&quot;cfg = Config.fromfile(config_file)print(&quot;cfg type:&quot;,type(cfg))print(&quot;cfg.model type:&quot;,type(cfg.model))cfg.model  # 打印模型部分</code></pre><p><img src="https://img-blog.csdnimg.cn/27d9011ca29a4803a285a7d6cfb7edf6.png" alt=""></p></li></ul><p>可以看出，打印出来的模型结构，与我们配置文件中的一样。其中，cfg和cfg.model等等的数据类型在此就不介绍了</p><h4 id="2-2-读取数据"><a href="#2-2-读取数据" class="headerlink" title="2.2 读取数据"></a>2.2 读取数据</h4><pre><code># 取数据from mmdet3d.datasets import build_datasetdatasets = [build_dataset(cfg.data.train)]print(&quot;datastes type:&quot;, type(datasets))print(&quot;datastes[0] type&quot;, type(datasets[0]))print(&quot;datastes[0][0] type&quot;, type(datasets[0][0]))datasets[0][0].keys()</code></pre><p><img src="https://img-blog.csdnimg.cn/ae951ca5367d4446b5f3cab978c2783b.png" alt=""></p><p>这里，就不再解释相关内容了，只需要明白datasets为一个长度1的列表，datasets[0]为一个nuscenes数据集类型，datasets[0][i]是nuscenes数据集的所有内容，每一项包含了四部分内容：‘img_metas’, ‘points’, ‘gt_bboxes_3d’, ‘gt_labels_3d’</p><p>实际上，在真正训练或测试过程中，还需要一个data_loader迭代器，方便我们去多线程地读取数据，并且可以实现batch以及shuffle的读取等，mmdet已经帮我们实现了，这里我们由于只需要一条数据模拟一下流程，就不构造data_loader了</p><h4 id="2-3-构造模型"><a href="#2-3-构造模型" class="headerlink" title="2.3 构造模型"></a>2.3 构造模型</h4><pre><code># 构建模型from mmdet3d.models import build_modelmodel = build_model(    cfg.model,    train_cfg=cfg.get(&#39;train_cfg&#39;),    test_cfg=cfg.get(&#39;test_cfg&#39;))model</code></pre><p><img src="https://img-blog.csdnimg.cn/b172c33b34034c738e94a42552c79c2b.png#pic_center" alt=""></p><h3 id="3、运行流程"><a href="#3、运行流程" class="headerlink" title="3、运行流程"></a>3、运行流程</h3><h4 id="3-1-voxel-layer：点云-gt-体素"><a href="#3-1-voxel-layer：点云-gt-体素" class="headerlink" title="3.1 voxel_layer：点云 -&gt; 体素"></a>3.1 voxel_layer：点云 -&gt; 体素</h4><pre><code># 示例文件配置中，第一步是voxel_layer层，将点云编码为体素voxel_layer = model.voxel_layer# 取点云数据points = datasets[0][0].get(&#39;points&#39;).data# 将点云数据送入 voxel_layervoxels_out, coors_out, num_points_per_voxel_out = voxel_layer(points)</code></pre><p>上述代码中，voxel_layer(points)执行的是self.voxel_layer = Voxelization(**voxel_layer)，Voxelization的输入输出大家可以去具体看一下</p><p>我们再使用voxel_layer.parameters打印一下参数，得到下面输出：<br><img src="https://img-blog.csdnimg.cn/08999b11c0d444cd996ae7f2dbc8402d.png#pic_center" alt=""></p><p>现在再来回想一下我们自定义的配置文件，这里再放一下：</p><pre><code>voxel_size = [0.1, 0.1, 0.1]model = dict(    type=&quot;MY_MODEL&quot;,    voxel_layer=dict(        max_num_points=32,        point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],        voxel_size=voxel_size,        max_voxels=(16000, 40000)),    voxel_encoder=dict(        type=&#39;VoxelFeatureExtractorV3&#39;,        num_input_features=4    ),    train_cfg=dict(),    test_cfg=dict())</code></pre><p>可以看出，voxel_layer层传入的参数是我们配置文件中的内容，根据前面提到过的Voxelization的输入输出，可以看到，forward部分只缺一个points input，即点云。在本节刚开始的代码块中，voxels_out, coors_out, num_points_per_voxel_out = voxel_layer(points)执行的便是将点云转换为体素操作，我们输出前后形状来看一下：<br><img src="https://img-blog.csdnimg.cn/7703fb82834b472a8116af8b2130bc1d.png#pic_center" alt=""></p><p>即将自定范围内的点云，按照自定体素大小[0.1,0.1,0.1]，每块体素最多保留32个点，最终将32242个点，转换为了6051个体素，每个体素包含的点不一样，但都记录下来了。<br>3.2 voxel_encoder：体素编码</p><p>这一层，主要是将上一层(voxel_layer)的输出进行encoder，往上翻到1.3，我们给出了相应实现，这里实现较为简单，即求每个体素中的平均点。我们现在这里记一下实现中的forward函数：def forward(self, features, num_voxels, coors=None)</p><p>我们先打印一下这一层的参数<br><img src="https://img-blog.csdnimg.cn/d27ce630aa214c45a2e050f4453dc2d8.png" alt=""></p><p>发现没有输出，这是因为我们没有定义相关方法，我们在VoxelFeatureExtractorV3类中加一个方法：</p><pre><code>    def __repr__(self):        s = self.__class__.__name__ + &#39;(&#39;        s += &#39;num_input_features=&#39; + str(self.num_input_features)        s += &#39;)&#39;        return s</code></pre><p>再次执行就有输出了，参数也是与配置文件相同。下面代码将上一层的输出传递到这一层</p><p>```import torch<br>import torch</p><p>voxel_encoder = model.voxel_encoder<br>print(voxel_encoder.parameters)<br>voxel_encoder_inputs = voxels_out  # 将上一层的输出作为输入<br>num_voxels = torch.tensor(voxels_out.shape[0])  # 这里只用一条数据作为演示，所以要转一下tensor<br>voxel_encoder_result = voxel_encoder(voxel_encoder_inputs, num_voxels)<br>print(“voxel_encoder output shape:”, voxel_encoder_result.shape)<br>```</p><p><img src="https://img-blog.csdnimg.cn/d6f781b6c7d245fb80ef3215cb0fb6ea.png#pic_center" alt=""></p><p>我们的配置文件和网络只给出了两个基础层的定义和实现，剩下的几层（neck、backbone…）都大同小异，都是这么个流程，完整的流程还会有损失函数的计算、反向更新等等，这一步是写在模型的forward里，此篇就不再详解了</p>]]></content>
      
      
      
        <tags>
            
            <tag> mmd3d </tag>
            
            <tag> 数据提取 </tag>
            
            <tag> 模型搭建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/importlib/"/>
      <url>/2023/11/17/importlib/</url>
      
        <content type="html"><![CDATA[<h1 id="python-importlib-用法小结"><a href="#python-importlib-用法小结" class="headerlink" title="python importlib 用法小结"></a>python importlib 用法小结</h1><p>在使用Python的时候，大部分时候引入包，都是通过<code>import</code>  语句，比如</p><pre><code class="lang-python">import numpy as np</code></pre><p>有时候为了更复杂的需求，我们需要用<strong>程序化</strong>的方式来引入包 (Programmatic Importing), 比如根据输入不同，选择执行两个不同包里面的同名函数，这时候就需要用到<code>importlib</code>这个库了。这里先从一个简单例子开始，逐渐深入地讲一下这个库的用法。 </p><h3 id="import-module用法"><a href="#import-module用法" class="headerlink" title="import_module用法"></a>import_module用法</h3><p><code>importlib</code> 是Python3.1增加的系统库，其中最常用的函数是其中的<code>import_module</code> ，功能是用程序语句的方式替代<code>import</code> 语句，用法如下：</p><pre><code class="lang-python">import importlib# 与 import time 效果一样time = importlib.import_module(&#39;time&#39;)print(time.time())# 与 import os.path as path 效果一样path = importlib.import_module(&#39;os.path&#39;)path.join(&#39;a&#39;, &#39;b&#39;)  # results: &#39;a/b&#39;# 相对引入, 一级目录，与 import os.path as path 效果一样path = importlib.import_module(&#39;.path&#39;, package=&#39;os&#39;)path.join(&#39;a&#39;, &#39;b&#39;)  # results: &#39;a/b&#39;# 相对引入，二级目录，与 import os.path as path 效果一样path = importlib.import_module(&#39;..path&#39;, package=&#39;os.time&#39;)path.join(&#39;a&#39;, &#39;b&#39;)  # results: &#39;a/b&#39;</code></pre><p>注意最后的例子中，相对引入时需要在前面增加<code>.</code> </p><p>或者<code>..</code> 来表示相对目录，如果直接使用<code>importlib.import_module(&#39;path&#39;, package=&#39;os&#39;)</code> 会报错。</p><p>如果光看这几个例子的话，貌似跟<code>import</code> 没什么区别，而且语句变得更复杂了，有点多此一举的感觉。</p><p>其实不是的，<strong>个人认为，<code>importlib</code></strong> <strong>的强大之处是将<code>import</code></strong> <strong>语句中写死的字面值改成了<code>import_module</code></strong> <strong>函数中的参数，因此可以通过修改参数在外部用变量来控制实际import的包或者模块，大大地增加了灵活性。</strong> 下面会举一个稍微实用一些的例子。</p><h3 id="一个实际例子"><a href="#一个实际例子" class="headerlink" title="一个实际例子"></a>一个实际例子</h3><p>假设我们在设计一个深度学习工具库，里面包含了N个网络模型（ResNet50, HRNet, MobileNet等等），每个模型的实现都有一个<code>load_model</code> 的函数。由于计算设备的性能不同，需要调用的网络结构也会变化，我们需要根据外部传入的参数来判断实际load哪一个模型。</p><p>虽然采用<code>import</code> 语句+<code>if-else</code> 判断也能完成这个需求，举例实现如下:</p><pre><code class="lang-python">def run(model_name, input):    if model_name == &#39;resnet_50&#39;:        from resnet_50.model import load_model    elif model_name == &#39;hrnet&#39;:        from hrnet.model import load_model    elif model_name == &#39;moblienet&#39;:        from mobilenet.model import load_model    model = load_model()    output = model(input)    return output</code></pre><p>这种写法存在下面的两个问题：  </p><ol><li><p>写法很冗余, N个模型的话需要添加2N条语句  </p></li><li><p>新增模型时需要修改调用处的代码，添加对应的<code>import</code>语句，不符合模块化的要求。</p></li></ol><p>这时候采用<code>importlib</code> 就能比较简洁地解决这个问题:</p><pre><code class="lang-python">import importlibdef run(model_name, input):    load_model = importlib.import_module(&#39;load_model&#39;, package=&#39;&#123;&#125;.model&#39;.format(model_name))    model = load_model()    output = model(input)    return output</code></pre><p>可以看到在这种场景下<code>importlib</code> 确实能大大简化代码。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd-custom_imports/"/>
      <url>/2023/11/17/mmd-custom_imports/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV-自定义"><a href="#MMCV-自定义" class="headerlink" title="MMCV  自定义"></a>MMCV  自定义</h1><p>假设想要添加<code>MyOptimizer</code>的新优化器，有<code>a</code>，<code>b</code>，<code>c</code>三个参数，需要创建一个新的路径 <code>mmdet/core/optimizer</code>。然后在config文件中应用一个新的优化器 <code>mmdet/core/optimizer/my_optimizer.py</code>：</p><pre><code class="lang-python">from .registry import OPTIMIZERSfrom torch.optim import Optimizer@OPTIMIZERS.register_module()class MyOptimizer(Optimizer):    def __init__(self, a, b, c)</code></pre><h4 id="1-2-2-将新的优化器添加到注册器中"><a href="#1-2-2-将新的优化器添加到注册器中" class="headerlink" title="1.2.2 将新的优化器添加到注册器中"></a>1.2.2 将新的优化器添加到注册器中</h4><p>上边定义完成的模块想要在config文件中使用，就必须import到一个明明空间中，两种方法，实现这个工作：</p><ul><li><p>直接在<code>__init__.py</code>文件中，导入，在<code>mmdet/core/optimizer/__init__.py</code>中</p><pre><code class="lang-python">from .my_optimizer import MyOptimizer</code></pre></li><li><p>在config文件中实现</p><pre><code class="lang-python">custom_imports = dict(imports=[&#39;mmdet.core.optimizer.my_optimizer&#39;], allow_failed_imports=False)</code></pre></li></ul><p>该模块<code>mmdet.core.optimizer.my_optimizer</code>将在程序开始时导入，然后自动注册<code>MyOptimizer</code>这个类。请注意，仅应该导入包含<code>MyOptimizer</code>的包。 <code>mmdet.core.optimizer.my_optimizer.MyOptimizer</code> <strong>无法</strong>直接导入。</p><p>实际上，使用这种导入的方式，使用者可以直接使用不同的文件路径结构，只要模块的路径在<code>PYTHONPATH</code>中可以找到即可。</p><h4 id="1-2-3-在config文件中指定优化器"><a href="#1-2-3-在config文件中指定优化器" class="headerlink" title="1.2.3 在config文件中指定优化器"></a>1.2.3 在config文件中指定优化器</h4><p>在config文件中的<code>optimizer</code>字段中使用<code>MyOptimizer</code>：</p><pre><code class="lang-python"># 原始的优化器使用方法optimizer = dict(type=&#39;SGD&#39;, lr=0.02, momentum=0.9, weight_decay=0.0001)# 自定义优化器使用方法optimizer = dict(type=&#39;MyOptimizer&#39;, a=a_value, b=b_value, c=c_value）</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd-hook/"/>
      <url>/2023/11/17/mmd-hook/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV核心组件：Hook"><a href="#MMCV核心组件：Hook" class="headerlink" title="MMCV核心组件：Hook"></a>MMCV核心组件：Hook</h1><h2 id="0-摘要"><a href="#0-摘要" class="headerlink" title="0 摘要"></a>0 摘要</h2><p>Hook 机制在 OpenMMLab 系列框架中应用非常广泛，结合 Runner 类可以实现对训练过程的整个生命周期进行管理。同时内置了多种 Hook，通过注册的形式注入 Runner 中实现了丰富的扩展功能，例如模型权重保存、日志记录等等。</p><h2 id="1-Hook-通俗理解"><a href="#1-Hook-通俗理解" class="headerlink" title="1 Hook 通俗理解"></a>1 Hook 通俗理解</h2><h3 id="（1）Hook是什么"><a href="#（1）Hook是什么" class="headerlink" title="（1）Hook是什么"></a>（1）Hook是什么</h3><p>在wiki百科中的定义如下：</p><p><code>钩子编程（hooking），也称作“挂钩”，是计算机程序设计语，指通过拦截软件模块间的函数调用、消息传递、事件传递来修改或扩展操作系统、应用程序或其他软件组件的行为的各种技术。处理被拦截的函数调用、事件、消息的代码，被称为（钩子hook）</code></p><p>简而言之，就是能改变程序执行流程的一种技术统称。</p><h3 id="（2）Hook用途"><a href="#（2）Hook用途" class="headerlink" title="（2）Hook用途"></a>（2）Hook用途</h3><p>Hook 技术应用非常广泛，可以随便找一个简单例子来说明其用途。在软件编程的设计模式中，有一种设计模式叫做观察者设计模式，该设计模式实现的功能是：对于被观察者的一举一动，观察者都能够立即观测到，其内部实现机制可以简单通过 hook 机制实现，下面具体说明。</p><p>假设气象台可以提供两种对外服务：各大城市未来五天的天气情况和是否会出现地质灾害，你下个月由于要出差想知道深圳未来五天的天气情况，很简单，只需要订阅该气象台发布的其中一个天气预报服务即可，然后每天早上八点你手机会自动收到气象台发布的天气情况，注意：你不需要每时每刻关注气象台是否有发布天气情况，而是等它通知即可，如果不想再收到天气预报了，那么取消订阅即可。</p><p>这是非常典型的观察者设计模式：<strong>被观察者(气象台)对外提供注册机制，观察者可以通过插入和移除 Hook 实现订阅和取消订阅消息的功能，无论观察者有没有注册 Hook,都不会影响被观察者发布消息</strong>，伪代码如下：</p><pre><code class="lang-python">class 气象台():    def __init__():       self.天气预报服务=&#39;&#39;       self.是否存在地质灾害服务=&#39;&#39;       self.天气预报_hooks=[]       self.是否存在地质灾害_hooks=[]    def 订阅天气预报服务(hook_fn)        self.天气预报_hooks.append(hook_fn)     def 取消订阅天气预报服务(hook_fn)：       del self.天气预报_hooks[hook_fn]    def 订阅是否存在地质灾害服务(hook_fn)        self.是否存在地质灾害_hooks.append(hook_fn)     def 取消订阅是否存在地质灾害服务(hook_fn)：       del self.是否存在地质灾害_hooks[hook_fn]    # 每天早上8点，气象台自动调用    def 发布消息():      天气预报信息=获取天气信息()      是否存在地质灾害信息=获取是否存在地质灾害信息()      for hook in self.天气预报_hooks:            hook(天气预报信息)      for hook in self.是否存在地质灾害_hooks:            hook(是否存在地质灾害信息)</code></pre><p>针对个人用户气象台伪代码如下所示：</p><pre><code class="lang-python">def 天气预报信息_hook(str):    print(str)    我收到消息了，天气预报内容是strif __name__ == &#39;__main__&#39;:    # 实例化   气象台实例=气象台()   # 注册 hook   气象台实例.订阅天气预报服务(天气预报信息_hook)   # 接收消息，此时我就能够自动收到消息了   气象台实例.发布消息()   # 不打算再订阅了   气象台实例.取消订阅天气预报服务(天气预报信息_hook)</code></pre><p>注意，实际上气象台实例不需要我们自己实例化，发布消息也不是我们控制的，这些都是被观察者自己的事情，个人用户只需要订阅和取消订阅即可。</p><p><strong>在 python 中由于函数是一等公民，实现 hook 机制其实只需要传入一个函数即可，在该函数中我们可以获取到内部信息，可以修改或者访问该内容，从而实现一些类似黑科技一般的功能</strong>。</p><h3 id="（3）Hook如何用"><a href="#（3）Hook如何用" class="headerlink" title="（3）Hook如何用"></a>（3）Hook如何用</h3><p>在 python 中要实现 hook 机制，非常简单，传入一个函数即可，如下是一个简单的 hook，该 hook 的功能是打印内部变量</p><pre><code class="lang-python">def hook(d):   print(d)def add(a,b,c,hook_fn=None)：   sum1=a+b   if hook_fn is not None:       hook_fn(sum1)    return sum1+c# 调用add(1,2,3,hook)</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_build_from_cfg/"/>
      <url>/2023/11/17/mmd3d_build_from_cfg/</url>
      
        <content type="html"><![CDATA[<h1 id="build-from-cfg"><a href="#build-from-cfg" class="headerlink" title="build_from_cfg()"></a>build_from_cfg()</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p> 本篇主要介绍mmdetection如何构建目标检测模型的。在读本文之前，建议读者先阅读mmcv之Config类介绍。该系列文章以构建FasterRcnn为具体例子。当然，本文不会详细介绍如何构建FasterRcnn，仅仅介绍mmdetection是如何建立目标检测模型的。</p><h3 id="1、总体流程"><a href="#1、总体流程" class="headerlink" title="1、总体流程"></a>1、总体流程</h3><p><img src="https://img-blog.csdnimg.cn/20210226165323994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>我这里简单介绍下流程：“模型配置字典”以字典形式存储着实例化类的信息。而检测器注册类里面存储了目标检测类(FasterRcnn,Yolo,ssd等，里面存储着是类，不是实例）。而函数build_from_cfg则是根据模型配置字典中type字段FasterRcnn来从 检测器注册类 中提取出FasterRcnn类。然后完成实例化。<br> 本篇文章分配顺序如下：</p><ul><li><p>介绍“模型配置字典”和“检测器注册类”；</p></li><li><p>介绍build_from_cfg；</p></li><li><p>实例化faster_rcnn。</p></li></ul><h3 id="2、模型配置字典和检测器注册类"><a href="#2、模型配置字典和检测器注册类" class="headerlink" title="2、模型配置字典和检测器注册类"></a>2、模型配置字典和检测器注册类</h3><h4 id="2-1-模型配置字典"><a href="#2-1-模型配置字典" class="headerlink" title="2.1.模型配置字典"></a>2.1.模型配置字典</h4><p> 这里放张FasterRcnn的配置字典。关于这个字典怎么生成的请转<a href="https://blog.csdn.net/wulele2/article/details/113870217">mmdet之Config类介绍</a>。</p><p><img src="https://img-blog.csdnimg.cn/20210227103744125.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>这里注意下‘type’字段。type字段是用来辨别采用何种检测器/backbone等等（比如FasterRcnn,ResNet,FPN）。</p><h4 id="2-2-检测器注册类"><a href="#2-2-检测器注册类" class="headerlink" title="2.2.检测器注册类"></a>2.2.检测器注册类</h4><p> 注册器是mmdetection中一大特色，要讲清需要很大篇幅，后续我会单独出一篇博文介绍。这里只需明白注册器就是一个字典，里面存储了各个类。比如检测器注册器类，里面存储着（FasterRcnn类、SSD类、Yolo类）。这里贴下注册器类：</p><p><img src="https://img-blog.csdnimg.cn/20210227104650126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>从上图可以看出，注册器Registry里面包括了多种检测器类。</p><h3 id="3、build-from-cfg函数介绍"><a href="#3、build-from-cfg函数介绍" class="headerlink" title="3、build_from_cfg函数介绍"></a>3、build_from_cfg函数介绍</h3><p> 在弄懂了模型配置字典和注册器类之后，build_from_cfg就是根据模型配置字典中的 type字段 来从注册器类中索引出 对应的 类 完成初始化。举个例子，type为FasterRcnn，则就从Registry中提取出FasterRcnn类。贴下代码：</p><pre><code>def build_from_cfg(cfg, registry, default_args=None):    args = cfg.copy()    obj_type = args.pop(&#39;type&#39;)            # 从配置文件中索引出type字段对应的obj    if isinstance(obj_type, str):        obj_cls = registry.get(obj_type)   # 根据字段从Registry中索引出类        if obj_cls is None:            raise KeyError(                f&#39;&#123;obj_type&#125; is not in the &#123;registry.name&#125; registry&#39;)    elif inspect.isclass(obj_type):        obj_cls = obj_type    else:        raise TypeError(            f&#39;type must be a str or valid type, but got &#123;type(obj_type)&#125;&#39;)    return obj_cls(**args)                 # 完成类的初始化</code></pre><p>这里比较难以理解最后一行代码：<strong>obj_cls(args)</strong> 。其实作用就是用模型配置字典中参数完成类的初始化。这里贴下FasterRcnn初始化代码：</p><pre><code>@DETECTORS.register_module()class TwoStageDetector(BaseDetector):    def __init__(self,                 backbone,                 neck=None,                 rpn_head=None,                 roi_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        super(TwoStageDetector, self).__init__()</code></pre><p>就是用模型配置字典中剩下的字段完成上述参数的初始化。<br>  这是类继承关系图:</p><p><img src="https://img-blog.csdnimg.cn/20210227125122257.png#pic_center" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> Registry </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_model/"/>
      <url>/2023/11/17/mmd3d_model/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV核心组件：Hook"><a href="#MMCV核心组件：Hook" class="headerlink" title="MMCV核心组件：Hook"></a>MMCV核心组件：Hook</h1><h2 id="0-摘要"><a href="#0-摘要" class="headerlink" title="0 摘要"></a>0 摘要</h2>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_registry_builder/"/>
      <url>/2023/11/17/mmd3d_registry_builder/</url>
      
        <content type="html"><![CDATA[<h1 id="MMD3D：模型之registry-py和builder-py解读"><a href="#MMD3D：模型之registry-py和builder-py解读" class="headerlink" title="MMD3D：模型之registry.py和builder.py解读"></a>MMD3D：模型之registry.py和builder.py解读</h1><h3 id="1-引言："><a href="#1-引言：" class="headerlink" title="1.引言："></a>1.引言：</h3><p>本篇文章主要就是讲一下，搭建模型的思路，以及registry.py和builder.py中各个函数块的作用。</p><p>注：builder.py是在mmdet/models文件夹下，是用来创建BACKBONES、NECKS、ROI_EXTRACTORS、SHARED_HEADS、HEADS、LOSSES、DETECTORS的模型的。而关于build_dataset()（在mmdet/datasets/builder.py中），在后面讲到数据集的时候再来讲它。</p><p>在mmdet/utils文件夹下的registry.py为主要的实现过程，后面详细讲解。</p><p>先来看在mmdet/models文件夹下的registry.py，较简单，代码如下：</p><pre><code class="lang-python3"># -*- coding: utf-8 -*-  from mmdet.utils import RegistryBACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;) #类的实例化，Registry是一个类，传入的是一个字符串。该字符串为Registry类的name属性值</code></pre><p>举个例子：DETECTORS为注册表Registry的实例化对象，DETECTORS.name = ‘detector’，Registry类的定义在mmdet/utils/文件中。</p><blockquote><p>所以，根据上面代码，我们就应该知道了，不止一个名为DETECTORS的注册表Registry，后面还会有名为NECKS、ROI_EXTRACTORS 、SHARED_HEADS 、HEADS 、LOSSES  的注册表，这些注册表下的_module_dict属性，则是用来存对应的相同类对象的，举个例子：比如DETECTORS的_module_dict下就有可能有：Faster R-CNN、Cascade R-CNN、FPN、HTC等常见的检测器，到这或许你就明白了注册表的作用咯。</p></blockquote><p>而在mmdet/utils/Registry.py中，有一个类Registry的定义和一个方法：build_from_cfg()的实现。</p><p>build_from_cfg()方法的作用是从  congfig/py配置文件中获取字典数据，创建module（其实也就是一个class类），然后将这个module添加到之前创建的注册表Registry的属性_module_dict中（这是一个字典，key为类名，value为具体的类），返回值是一个实例化后的类对象。</p><p>所以，可以这样理解，从config/py配置文件中，将字典提取出来，然后为其映射成一个类，放进Registry对象的_module_dict属性中。（具体看下面的代码）</p><h3 id="2-Registry-py文件"><a href="#2-Registry-py文件" class="headerlink" title="2.Registry.py文件"></a>2.Registry.py文件</h3><p>以下代码分三部分</p><h4 id="2-1Part-one："><a href="#2-1Part-one：" class="headerlink" title="2.1Part one："></a><strong>2.1Part one：</strong></h4><p><strong>inspect</strong>模块是针对模块，类，方法，功能等对象提供些有用的方法。例如可以帮助我们检查类的内容，检查方法的代码，提取和格式化方法的参数等。</p><pre><code class="lang-python3"># -*- coding: utf-8 -*-  import inspectimport mmcv</code></pre><h4 id="2-2Part-two："><a href="#2-2Part-two：" class="headerlink" title="2.2Part two："></a><strong>2.2Part two：</strong></h4><p>通过前面第一段的代码段，我们知道DETECTORS = Registry(‘detector’)</p><p>detector是干什么的 ？？？</p><p>其实，DETECTORS = Registry(‘detector’) 只是注册了一个对象名为DETECTORS  ，属性name为detector的对象。然后用属性_module_dict  来保存config配置文件中的对应的字典数据所对应的class类（看第三部分代码）。请看如下类Registry的定义代码：</p><pre><code class="lang-python3">class Registry(object):    def __init__(self, name):        #此处的self，是个对象（Object），是当前类的实例，name即为传进来的&#39;detector&#39;值        self._name = name        self._module_dict = dict()  #定义的属性，是一个字典    def __repr__(self):    #返回一个可以用来表示对象的可打印字符串，可以理解为java中的toString()。        format_str = self.__class__.__name__ + &#39;(name=&#123;&#125;, items=&#123;&#125;)&#39;.format(            self._name, list(self._module_dict.keys()))        return format_str    @property                        #把方法变成属性，通过self.name 就能获得name的值。    def name(self):        return self._name         #因为没有定义它的setter方法，所以是个只读属性，不能通过 self.name = newname进行修改。    @property    def module_dict(self):         #同上，通过self.module_dict可以获取属性_module_dict，也是只读的        return self._module_dict    def get(self, key):        #普通方法，获取字典中指定key的value，_module_dict是一个字典，然后就可以通过self.get(key),获取value值        return self._module_dict.get(key, None)    def _register_module(self, module_class):          #关键的一个方法，作用就是Register a module.         #在model文件夹下的py文件中，里面的class定义上面都会出现 @DETECTORS.register_module，意思就是将类当做形参，                #将类送入了方法register_module()中执行。@的具体用法看后面解释。        &quot;&quot;&quot;Register a module.        Args:            module (:obj:`nn.Module`): Module to be registered.        &quot;&quot;&quot;        if not inspect.isclass(module_class):          #判断是否为类，是类的话，就为True，跳过判断            raise TypeError(&#39;module must be a class, but got &#123;&#125;&#39;.format(                type(module_class)))        module_name = module_class.__name__           #获取类名        if module_name in self._module_dict:          #看该类是否已经登记在属性_module_dict中            raise KeyError(&#39;&#123;&#125; is already registered in &#123;&#125;&#39;.format(                module_name, self.name))        self._module_dict[module_name] = module_class #在module中dict新增key和value。key为类名，value为类对象    def register_module(self, cls):                   #对上面的方法，修改了名字，添加了返回值，即返回类本身        self._register_module(cls)        return cls</code></pre><p><strong>note：</strong></p><p><strong>@的含义：</strong><br>Python当解释器读到@的这样的修饰符之后，会先解析@后的内容，直接就把@下一行的函数或者类作为@后边的函数的参数，然后将返回值赋值给下一行修饰的函数对象。<br>在网上看到一个这样的例子：</p><pre><code class="lang-python3">def a(x):    if x==2:        return 4    return 6def b(x):    if x==1:        return 2    return 3@a@bdef c():    return 1</code></pre><p>python会按照自下而上的顺序把各自的函数结果作为下一个函数（上面的函数）的形参输入，也就是a(b(c()))。</p><h4 id="2-3-Part-three："><a href="#2-3-Part-three：" class="headerlink" title="2.3 Part three："></a>2.3 Part three：</h4><p>以下我们通过配置文件<code>cascade_rcnn_r50_fpn_1x.py</code>进行讲解 build 模型的过程。<br>在train中，最先执行Registry的是DETECTORS，传入的参数是配置文件中的model字典。</p><pre><code class="lang-python3">#在 train.py中 model = build_detector(        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)#在builder.py中def build_detector(cfg, train_cfg=None, test_cfg=None):    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))</code></pre><p>所以，后面出现的参数cfg，指的就是配置文件中的model字典。下面是model字典的部分代码：</p><pre><code class="lang-python3"># model settingsmodel = dict(    type=&#39;CascadeRCNN&#39;,    num_stages=3,    pretrained=&#39;torchvision://resnet50&#39;,    backbone=dict(        type=&#39;ResNet&#39;,        depth=50,        num_stages=4,        out_indices=(0, 1, 2, 3),        frozen_stages=1,        style=&#39;pytorch&#39;),    neck=dict(        type=&#39;FPN&#39;,        in_channels=[256, 512, 1024, 2048],        out_channels=256,        num_outs=5),    rpn_head=dict(        type=&#39;RPNHead&#39;,        in_channels=256,        feat_channels=256,        anchor_scales=[8],        anchor_ratios=[0.5, 1.0, 2.0],        anchor_strides=[4, 8, 16, 32, 64],        target_means=[.0, .0, .0, .0],        target_stds=[1.0, 1.0, 1.0, 1.0],        loss_cls=dict(            type=&#39;CrossEntropyLoss&#39;, use_sigmoid=True, loss_weight=1.0),        loss_bbox=dict(type=&#39;SmoothL1Loss&#39;, beta=1.0 / 9.0, loss_weight=1.0)),</code></pre><p>我们继续往下看</p><p>先看build_from_cfg()方法的参数：</p><p><strong>Args:</strong></p><ul><li>cfg (dict): Config dict. It should at least contain the key  “type”.这个cfg就是py配置文件中的字典。在py配置文件中，基本上dict都会有一个key为”type”，当然也有不是的，不是的，这一步就不会执行，也就不会为他创建module。也就是这边创建成module的dict，都必须有key为”type”才可以创建（这里，我们主要讲的是注册表DETECTORS，所以此时cfg对应的是配置文件中的model字典，看上面截图）。举个例子：比如type=’CascadeRCNN’，后面我们会知道，这个value为”CascadeRCNN”的，其实就是models文件夹中某py文件中的类名，他们通过@DETECTORS.register_module，将类名当做形参，传入register_module。并保存下来。</li><li>registry (:obj:Registry): The registry to search the type from.</li><li>default_args (dict, optional): Default initialization arguments.</li></ul><pre><code class="lang-python3">def build_from_cfg(cfg, registry, default_args=None):    &quot;&quot;&quot;Build a module from config dict.    Args:        cfg (dict): Config dict. It should at least contain the key &quot;type&quot;.        registry (:obj:`Registry`): The registry to search the type from.        default_args (dict, optional): Default initialization arguments.    Returns:        obj: The constructed object.    &quot;&quot;&quot;    assert isinstance(cfg, dict) and &#39;type&#39; in cfg    assert isinstance(default_args, dict) or default_args is None #两个是断言，相当于判断，否的话抛出异常。    args = cfg.copy()                        #args相当于temp中间变量，是个字典。    obj_type = args.pop(&#39;type&#39;)             #字典的pop作用：移除序列中key为‘type’的元素，并且返回该元素的值    if mmcv.is_str(obj_type):                        obj_type = registry.get(obj_type)    #获取obj_type的value。        #如果obj_type已经注册到注册表registry中，即在属性_module_dict中，则obj_type 不为None        if obj_type is None:            raise KeyError(&#39;&#123;&#125; is not in the &#123;&#125; registry&#39;.format(                obj_type, registry.name))    elif not inspect.isclass(obj_type):             raise TypeError(&#39;type must be a str or valid type, but got &#123;&#125;&#39;.format(            type(obj_type)))    if default_args is not None:        for name, value in default_args.items():#items()返回字典的键值对用于遍历            args.setdefault(name, value)            #将default_args的键值对加入到args中，将模型和训练配置进行整合，然后送入类中返回    return obj_type(**args)</code></pre><p>obj_type(<em>*args)，</em>  *args是将字典unpack得到各个元素，分别与形参匹配送入函数中；看上面model的截图，所以这边，其实就是将除了’type’的所有字段，当做形参，送入了名为CascadeRCNN()的类中（type =’ CascadeRCNN’）。所以字典里的key就是类中的属性？继续看下面。</p><p>根据Cascade R-CNN的例子，我们在models/detectors找cascade_rcnn的py文件。</p><p>参考里面的参数时，直接打开对应的cascade_rcnn配置文件，在init中，里面的参数则</p><p>对应了配置文件中的字典名。下面两个截图分别是配置文件cascade_rcnn.py和model/detectors/cascade_rcnn.py中的类定义。</p><p><strong>configs/cascade_rcnn.py：</strong></p><pre><code class="lang-python3"># model settingsmodel = dict(    type=&#39;CascadeRCNN&#39;,    num_stages=3,    pretrained=&#39;torchvision://resnet50&#39;,    backbone=dict(        type=&#39;ResNet&#39;,        depth=50,        num_stages=4,        out_indices=(0, 1, 2, 3),        frozen_stages=1,        style=&#39;pytorch&#39;),    neck=dict(        type=&#39;FPN&#39;,        in_channels=[256, 512, 1024, 2048],        out_channels=256,        num_outs=5),    rpn_head=dict(        type=&#39;RPNHead&#39;,</code></pre><p><strong>model/detectors/cascade_rcnn.py：</strong></p><pre><code class="lang-text">@DETECTORS.register_moduleclass CascadeRCNN(BaseDetector, RPNTestMixin):    def __init__(self,                 num_stages,                 backbone,                 neck=None,                 shared_head=None,                 rpn_head=None,                 bbox_roi_extractor=None,                 bbox_head=None,                 mask_roi_extractor=None,                 mask_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        assert bbox_roi_extractor is not None        assert bbox_head is not None        super(CascadeRCNN, self).__init__()</code></pre><p>注意的是，在py配置文件中，好多py文件中都有type = ‘CascadeRCNN’，所以有些参数和属性对不上很正常（毕竟已经设置为None了），因为这个参数可能是其他的cascade R-CNN里面的字典。</p><p>所以，我们在训练时，测试时，就要给出配置文件，配置文件可以不同，但相同type</p><p>detector等文件是相同的，毕竟已经将数据和实现完全的分离了。</p><p>注意：无论训练/检测，都会build DETECTORS；</p><h4 id="2-4-builder-py文件"><a href="#2-4-builder-py文件" class="headerlink" title="2.4 builder.py文件"></a>2.4 builder.py文件</h4><p>builder文件较为简单，因为train.py中，只出现了build_detector()，所以我们先记住里面的两个方法：build_detector和build()。</p><ul><li>build_detector：是创建一个detector，方法里调用了build()方法（所有的build_xx都是直接调用build方法，所以看懂这一个也就看懂所有了）。</li><li>build()：则是调用的Registry.py文件中的build_from_cfg()方法，这个方法我们已经在上面讲过了。</li></ul><p>import：</p><pre><code class="lang-python3"># -*- coding: utf-8 -*-  from torch import nnfrom mmdet.utils import build_from_cfg#此处不会在执行registry而是直接进行sys.modules查询得到from .registry import (BACKBONES, NECKS, ROI_EXTRACTORS, SHARED_HEADS, HEADS,                       LOSSES, DETECTORS)#上面的registry是在models文件夹下，registry类的具体实现是在mmdet/utils文件夹下</code></pre><p>只需要看一下build()的两个参数：cfg, registry</p><p>build_detector()在train.py中的调用，我们就可以知道，cfg是py配置文件中的字典， 以registry是DETECTORS为例，cfg就是model字典  （后面注册表为BACKBONES、NECKS等时，就是配置文件中的其他的字典了，不是model） 。</p><p>build()方法中，主干是一个判断结构，其实就是判断传进来的cfg是字典列表还是单独的字典，来分情况处理。（以注册表DETECTORS为例，是一个单独的字典）</p><ul><li>字典列表的话：挨个调用build_from_cfg()，将其加到注册表的_module_dict中，然后再返回return nn.Sequential(*modules)，这个地方的作用，有待博主继续研究一下下？？？</li><li>字典的话：直接调用build_from_cfg()，将其添加到注册表DETECTORS中（以DETECTORS为例）。</li></ul><pre><code class="lang-python3">def build(cfg, registry, default_args=None):    if isinstance(cfg, list):        modules = [            build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg            #build_from_cfg()返回值是一个带形参的类，返回时也就完成了实例化的过程。        ]        #所以modules就是一个class类的列表        return nn.Sequential(*modules)        #nn.Sequential 一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数    else:        return build_from_cfg(cfg, registry, default_args) #Config dictdef build_detector(cfg, train_cfg=None, test_cfg=None):    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))    #DETECTORS = Registry(&#39;detector&#39;)，创建一个名为DETECTORS的注册表Registry。def build_backbone(cfg):    return build(cfg, BACKBONES)def build_neck(cfg):    return build(cfg, NECKS)def build_roi_extractor(cfg):    return build(cfg, ROI_EXTRACTORS)def build_shared_head(cfg):    return build(cfg, SHARED_HEADS)def build_head(cfg):    return build(cfg, HEADS)def build_loss(cfg):    return build(cfg, LOSSES)</code></pre><p>后面的几个build_XXXXX()的方法也就跟build_detector()相同咯。</p><p>还是以注册表DETECTORS为例，配置文件为cascade_rcnn_r50_fpn_1x.py来讲解：在model文件夹下的cascade_rcnn.py文件中，有类Cascade_RCNN()的定义，在配置文件中，对应的key被传入类中当做属性，这些属性被初始化的时候，调用对应的build_XXXXX()，由此创建它们对应的注册表。</p><p>再以NECK为例，调用build_neck(cfg)；然后执行build(cfg,  NECKS)，这一步，形参用到NECKS，所以在Registry中，又多了一个名为NECKS的注册表了。然后将配置文件中，字典名为neck的，然后生成一个类(类名是neck字典中的type的值，该类在models/necks文件夹下)，同时将该类添加到了注册表NECKS的_module_dict中。</p><pre><code class="lang-python3">#在model/detectors/cascade_rcnn.py中if neck is not None:            self.neck = builder.build_neck(neck)#再builder.py中def build_neck(cfg):    return build(cfg, NECKS)#在configs/cascade_rcnn_r50_fpn_1x.py中neck=dict(        type=&#39;FPN&#39;,        in_channels=[256, 512, 1024, 2048],        out_channels=256,        num_outs=5),</code></pre><p>到这，NECK的注册和数据读入，相信大家已经很清楚了，其他的注册表也是类似的。</p><h3 id="3-总结："><a href="#3-总结：" class="headerlink" title="3.总结："></a>3.总结：</h3><p><strong>搭建模型思路：</strong></p><ul><li>首先，创建一个名为DETECTORS的注册表Registry。这个注册表有属性name=’detector’，和属性_module_dict。_module_dict 是一个字典，专门用来存各个对象名和对应的对象。</li><li>其次，读取py配置文件，py配置文件是个字典，（字典里还有字典，这里面的字典，也是后面来创建模型的，道理是一样的）。根据key为’type’的字典，创建module，对于的value为其module名，然后再models文件夹下中，已经存在了这些module的类。将字典中的其他数据，作为形参，实例化这些类。并保存这些module到属性_module_dict中。</li><li>到这，配置文件的数据，里面的字典（含有type的字典）对应着一个类，type为类名，其他字段则为其属性（其他字段也可能是个字典，后面也有可能要再为它们搭建模型哦）。由此完成模型的搭建。</li></ul><p>这是搭建模型的一个思路，虽然讲得篇幅很大，有点乱乱的感觉，但是看懂后，就会发现很简单。</p><p><strong>mmdetection搭建模型用途：</strong></p><p>mmdetection将配置文件中，字典名为：backbone、neck、roi_extractor、shared_head、head、loss、detector的字典，全部实例化成注册表（Registry），然后这些字典里的type，都被实例化成对应的类（module），并添加到注册表的属性_module_dict中，其他的字段，则为这个类的属性，由此完成模型的建立，实际上，就是将配置文件的字典数据保存到类（module）中，以便后面读取数据，加载数据。</p><h3 id="Problem："><a href="#Problem：" class="headerlink" title="Problem："></a>Problem：</h3><p><strong>Importance：</strong></p><p><strong>总体讲的通俗易懂，但是有一点疑问。文中多次出现类似于”通过build实例化模块类，然后把实例存入model_dict”的表述。但是，结合我目前掌握的相关知识，我的理解是，模块类的注册是通过register_module方法，把模块类加入到model_dict，然后bulid方法根据cfg提供的type类名，从Register类中通过get方法从model_dict获取模块类，然后利用cfg提供的参数对模块类进行实例化</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_train_see/"/>
      <url>/2023/11/17/mmd3d_train_see/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV核心组件：Hook"><a href="#MMCV核心组件：Hook" class="headerlink" title="MMCV核心组件：Hook"></a>MMCV核心组件：Hook</h1><h2 id="0-摘要"><a href="#0-摘要" class="headerlink" title="0 摘要"></a>0 摘要</h2>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_%E6%B3%A8%E5%86%8C%E6%A8%A1%E5%9E%8B/"/>
      <url>/2023/11/17/mmd3d_%E6%B3%A8%E5%86%8C%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection3D-注册模型"><a href="#MMDetection3D-注册模型" class="headerlink" title="MMDetection3D:注册模型"></a>MMDetection3D:注册模型</h1><p>train.py的开头中，已经开始注册必要的模块了 </p><pre><code>from mmcv import Configfrom mmdet import __version__from mmdet.datasets import build_datasetfrom mmdet.apis import (train_detector, init_dist, get_root_logger,                        set_random_seed)from mmdet.models import build_detector</code></pre><p>看mmdet文件夹下的<strong>init</strong>.py，以及datasets , apis , models 下的<strong>init</strong>.py文件，发现：<br> mmdet.<strong>init</strong>py:</p><pre><code>from .backbones import *  # noqa: F401,F403 from .necks import *  #    noqa: F401,F403 from .roi_extractors import *  # noqa: F401,F403 from    .anchor_heads import *  # noqa: F401,F403 from .shared_heads import *    # noqa: F401,F403 from .bbox_heads import *  # noqa: F401,F403 from .mask_heads import *  # noqa: F401,F403 from .losses import *  #    noqa: F401,F403 from .detectors import *  # noqa: F401,F403 from    .registry import (BACKBONES, NECKS, ROI_EXTRACTORS, SHARED_HEADS,    HEADS,                      LOSSES, DETECTORS) from .builder import (build_backbone, build_neck, build_roi_extractor,                     build_shared_head, build_head, build_loss,                     build_detector)       __all__ = [    &#39;BACKBONES&#39;, &#39;NECKS&#39;, &#39;ROI_EXTRACTORS&#39;, &#39;SHARED_HEADS&#39;, &#39;HEADS&#39;, &#39;LOSSES&#39;,    &#39;DETECTORS&#39;, &#39;build_backbone&#39;, &#39;build_neck&#39;, &#39;build_roi_extractor&#39;,    &#39;build_shared_head&#39;, &#39;build_head&#39;, &#39;build_loss&#39;, &#39;build_detector&#39; ]</code></pre><p>这个文件，第一行，导入了backbone.<em><em>init</em></em>.py，看一下里面内容：<br> mmdet.models.backbones.<em><em>init</em></em>.py</p><pre><code>from .resnet import ResNet, make_res_layerfrom .resnext import ResNeXtfrom .ssd_vgg import SSDVGGfrom .hrnet import HRNet__all__ = [&#39;ResNet&#39;, &#39;make_res_layer&#39;, &#39;ResNeXt&#39;, &#39;SSDVGG&#39;, &#39;HRNet&#39;]</code></pre><p>这里又导入了resnet，resnext等几个卷积神经网络，那么以resnet为例，看一下里面都有啥<br> mmdet.models.backbones.resnet.py<br> 第13.14行：</p><pre><code>from ..registry import BACKBONESfrom ..utils import build_conv_layer, build_norm_layer</code></pre><p>其中又从registry中导入BACKBONES，那么再来看看registry和他的BACKBONES<br> mmdet.registry.py:</p><pre><code>from mmdet.utils import RegistryBACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;)</code></pre><p>那么这个Registry又是何方神圣？意欲何为？看看去<br> mmdet.utils.<em><em>init</em></em>.py:</p><pre><code>from .registry import Registry, build_from_cfg__all__ = [&#39;Registry&#39;, &#39;build_from_cfg&#39;]</code></pre><p>顺藤摸瓜，找到registry.py<br> mmdet.utils.registry.py<br> 代码稍长，分两段看吧。只看主要代码，能帮助理解其机制的代码，删除部分不影响理解的代码，全文都是。<br> Registry:</p><pre><code>import inspectimport mmcvclass Registry(object):    def __init__(self, name):        self._name = name        self._module_dict = dict()    def __repr__(self):        format_str = self.__class__.__name__ + &#39;(name=&#123;&#125;, items=&#123;&#125;)&#39;.format(            self._name, list(self._module_dict.keys()))        return format_str    @property    def name(self):        return self._name    @property    def module_dict(self):        return self._module_dict    def get(self, key):        return self._module_dict.get(key, None)    def _register_module(self, module_class):        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, but got &#123;&#125;&#39;.format(                type(module_class)))        module_name = module_class.__name__        if module_name in self._module_dict:            raise KeyError(&#39;&#123;&#125; is already registered in &#123;&#125;&#39;.format(                module_name, self.name))        self._module_dict[module_name] = module_class    def register_module(self, cls):        self._register_module(cls)        return cls</code></pre><p>这段代码呢，生成了一个字典，里面包含了模块名字，以后模块都要挂在这个名字下。此时我们反过头来再看registry.py中的代码，其实是生成了各个主要部分，并向外提供了接口。<br> 这段代码到现在，暂时没有了下文，我们再来看build_from_cfg函数：</p><pre><code>def build_from_cfg(cfg, registry, default_args=None):    &quot;&quot;&quot;Build a module from config dict.    Args:        cfg (dict): Config dict. It should at least contain the key &quot;type&quot;.        registry (:obj:`Registry`): The registry to search the type from.        default_args (dict, optional): Default initialization arguments.    Returns:        obj: The constructed object.    &quot;&quot;&quot;    assert isinstance(cfg, dict) and &#39;type&#39; in cfg    assert isinstance(default_args, dict) or default_args is None    args = cfg.copy()    obj_type = args.pop(&#39;type&#39;)    if mmcv.is_str(obj_type):        obj_type = registry.get(obj_type)        if obj_type is None:            raise KeyError(&#39;&#123;&#125; is not in the &#123;&#125; registry&#39;.format(                obj_type, registry.name))    elif not inspect.isclass(obj_type):        raise TypeError(&#39;type must be a str or valid type, but got &#123;&#125;&#39;.format(            type(obj_type)))    if default_args is not None:        for name, value in default_args.items():            args.setdefault(name, value)    return obj_type(**args)</code></pre><p>这段代码比较难弄，尤其是最后哪行。我们来分析一波吧，既然难懂，就先来看他在那里被调用的吧。回到tools.train.py：</p><pre><code>...def parse_args():    ...    parser.add_argument(&#39;config&#39;, help=&#39;train config file path&#39;)...def main():    args = parse_args()    cfg = Config.fromfile(args.config)    ...    model = build_detector(        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)    ...</code></pre><p>因为其有个cfg参数，而这build_detector是用到了cfg，可以算个线索（如果你使用IDE的话，可以看看build_from_cfg是被谁引用的，顺藤摸瓜，推荐）。再来看build_detector,文章第一个代码段train.py最后一行引入进来，在mmet.models里，而mmet.models.<strong>init</strong>py中，有</p><pre><code>from .builder import (build_backbone, build_neck, build_roi_extractor,                      build_shared_head, build_head, build_loss,                      build_detector)</code></pre><p>我们来看这build_detector具体内容吧mmet.models.builder.py:</p><pre><code>from torch import nnfrom mmdet.utils import build_from_cfgfrom .registry import (BACKBONES, NECKS, ROI_EXTRACTORS, SHARED_HEADS, HEADS,                       LOSSES, DETECTORS)def build(cfg, registry, default_args=None):    if isinstance(cfg, list):        modules = [            build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg        ]        return nn.Sequential(*modules)    else:        return build_from_cfg(cfg, registry, default_args)def build_backbone(cfg):    return build(cfg, BACKBONES)def build_neck(cfg):    return build(cfg, NECKS)def build_roi_extractor(cfg):    return build(cfg, ROI_EXTRACTORS)def build_shared_head(cfg):    return build(cfg, SHARED_HEADS)def build_head(cfg):    return build(cfg, HEADS)def build_loss(cfg):    return build(cfg, LOSSES)def build_detector(cfg, train_cfg=None, test_cfg=None):    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))</code></pre><p>看到参数又传到build里，而cfg是个dict类型，所以又到了build_from_cfg,此刻我们来分析build_from_cfg：</p><pre><code>def build_from_cfg(cfg, registry, default_args=None):    ...    args = cfg.copy()    obj_type = args.pop(&#39;type&#39;)    ...    return obj_type(**args)</code></pre><p>再在你的配置文件里看到这个obj_type：<br> configs.faster_rcnn_r50_fpn_1x.py:</p><pre><code>model = dict(    type=&#39;FasterRCNN&#39;,</code></pre><p>其实也就是执行了FasterRCNN(),那么，FasterRCNN又是从何而来呢？<br> 答：在mmdet.models.<em><em>init里，可以看到`from .detectors import \</em>`这行代码，再来瞧瞧mmdet.models.detectors.</em>*init**.py：</p><pre><code>from .base import BaseDetectorfrom .single_stage import SingleStageDetectorfrom .two_stage import TwoStageDetectorfrom .rpn import RPNfrom .fast_rcnn import FastRCNNfrom .faster_rcnn import FasterRCNNfrom .mask_rcnn import MaskRCNNfrom .cascade_rcnn import CascadeRCNNfrom .htc import HybridTaskCascadefrom .retinanet import RetinaNetfrom .fcos import FCOSfrom .grid_rcnn import GridRCNNfrom .mask_scoring_rcnn import MaskScoringRCNN__all__ = [    &#39;BaseDetector&#39;, &#39;SingleStageDetector&#39;, &#39;TwoStageDetector&#39;, &#39;RPN&#39;,    &#39;FastRCNN&#39;, &#39;FasterRCNN&#39;, &#39;MaskRCNN&#39;, &#39;CascadeRCNN&#39;, &#39;HybridTaskCascade&#39;,    &#39;RetinaNet&#39;, &#39;FCOS&#39;, &#39;GridRCNN&#39;, &#39;MaskScoringRCNN&#39;]</code></pre><p>可以看到这里注册了一大堆的模型，取出faster_rcnn来看，在mmdet.models.detectors.faster_rcnn.py里：</p><pre><code>from .two_stage import TwoStageDetectorfrom ..registry import DETECTORS@DETECTORS.register_moduleclass FasterRCNN(TwoStageDetector):    def __init__(self,                 backbone,                 rpn_head,                 bbox_roi_extractor,                 bbox_head,                 train_cfg,                 test_cfg,                 neck=None,                 shared_head=None,                 pretrained=None):        super(FasterRCNN, self).__init__(            backbone=backbone,            neck=neck,            shared_head=shared_head,            rpn_head=rpn_head,            bbox_roi_extractor=bbox_roi_extractor,            bbox_head=bbox_head,            train_cfg=train_cfg,            test_cfg=test_cfg,            pretrained=pretrained)</code></pre><p>看到这里以TwoStageDetector作为其父类，看TwoStageDetector：</p><pre><code>import torchimport torch.nn as nnfrom .base import BaseDetectorfrom .test_mixins import RPNTestMixin, BBoxTestMixin, MaskTestMixinfrom .. import builderfrom ..registry import DETECTORSfrom mmdet.core import bbox2roi, bbox2result, build_assigner, build_sampler@DETECTORS.register_moduleclass TwoStageDetector(BaseDetector, RPNTestMixin, BBoxTestMixin,                       MaskTestMixin):    def __init__(self,                 backbone,                 neck=None,                 shared_head=None,                 rpn_head=None,                 bbox_roi_extractor=None,                 bbox_head=None,                 mask_roi_extractor=None,                 mask_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        super(TwoStageDetector, self).__init__()        self.backbone = builder.build_backbone(backbone)        if neck is not None:            self.neck = builder.build_neck(neck)        if shared_head is not None:            self.shared_head = builder.build_shared_head(shared_head)        if rpn_head is not None:            self.rpn_head = builder.build_head(rpn_head)        if bbox_head is not None:            self.bbox_roi_extractor = builder.build_roi_extractor(                bbox_roi_extractor)            self.bbox_head = builder.build_head(bbox_head)        if mask_head is not None:            if mask_roi_extractor is not None:                self.mask_roi_extractor = builder.build_roi_extractor(                    mask_roi_extractor)                self.share_roi_extractor = False            else:                self.share_roi_extractor = True                self.mask_roi_extractor = self.bbox_roi_extractor            self.mask_head = builder.build_head(mask_head)        self.train_cfg = train_cfg        self.test_cfg = test_cfg        self.init_weights(pretrained=pretrained)    @property    def with_rpn(self):        return hasattr(self, &#39;rpn_head&#39;) and self.rpn_head is not None</code></pre><p>可以看到，在这里形成了整个模型。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> registry model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Registry</title>
      <link href="/2023/11/16/Registry/"/>
      <url>/2023/11/16/Registry/</url>
      
        <content type="html"><![CDATA[<h1 id="Registry"><a href="#Registry" class="headerlink" title="Registry"></a>Registry</h1><p>Registry 类可以提供一种完全相似的对外装饰函数来管理构建不同的组件，例如 backbones、head 和 necks  等等，Registry 类内部其实维护的是一个全局 key-value 对。通过 Registry  类，用户可以通过字符串方式实例化任何想要的模块。</p><p>Registry 类最大好处是：<strong>解耦性强、可扩展性强，代码更易理解</strong>。</p><p>回到 Registry 类本身，有如下几种用法：</p><pre><code># 0. 先构建一个全局的 CATS 注册器类CATS = mmcv.Registry(&#39;cat&#39;)# 通过装饰器方式作用在想要加入注册器的具体类中#===============================================================# 1. 不需要传入任何参数，此时默认实例化的配置字符串是 str (类名)@CATS.register_module()class BritishShorthair:    pass# 类实例化CATS.get(&#39;BritishShorthair&#39;)(**args)#==============================================================# 2.传入指定 str，实例化时候只需要传入对应相同 str 即可@CATS.register_module(name=&#39;Siamese&#39;)class SiameseCat:    pass# 类实例化CATS.get(&#39;Siamese&#39;)(**args)#===============================================================# 3.如果出现同名 Registry Key，可以选择报错或者强制覆盖# 如果指定了 force=True，那么不会报错# 此时 Registry 的 Key 中，Siamese2Cat 类会覆盖 SiameseCat 类# 否则会报错@CATS.register_module(name=&#39;Siamese&#39;,force=True)class Siamese2Cat:    pass# 类实例化CATS.get(&#39;Siamese&#39;)(**args)#==============================================================# 4. 可以直接注册类class Munchkin:    passCATS.register_module(Munchkin)# 类实例化CATS.get(&#39;Munchkin&#39;)(**args)</code></pre><p><strong>(1) 最简实现</strong></p><pre><code class="lang-python"># 方便起见，此处并未使用类方式构建，而是直接采用全局变量_module_dict = dict()# 定义装饰器函数def register_module(name):    def _register(cls):        _module_dict[name] = cls        return cls    return _register# 装饰器用法@register_module(&#39;one_class&#39;)class OneTest(object):    pass@register_module(&#39;two_class&#39;)class TwoTest(object):    pass</code></pre><p>进行简单测试：</p><pre><code class="lang-python">if __name__ == &#39;__main__&#39;:    # 通过注册类名实现自动实例化功能    one_test = _module_dict[&#39;one_class&#39;]()    print(one_test)# 输出&lt;__main__.OneTest object at 0x7f1d7c5acee0&gt;</code></pre><p>可以发现只要将所定义的简单装饰器函数作用到类名上，然后内部采用 <code>_module_dict</code> 保存信息即可</p><p><strong>(2) 实现无需传入参数，自动根据类名初始化类</strong></p><pre><code class="lang-python">_module_dict = dict()def register_module(module_name=None):    def _register(cls):        name = module_name        # 如果 module_name 没有给，则自动获取        if module_name is None:            name = cls.__name__        _module_dict[name] = cls        return cls    return _register@register_module(&#39;one_class&#39;)class OneTest(object):    pass@register_module()class TwoTest(object):    pass</code></pre><p>进行简单测试：</p><pre><code class="lang-python">if __name__ == &#39;__main__&#39;:    one_test = _module_dict[&#39;one_class&#39;]    # 方便起见，此处仅仅打印了类对象，而没有实例化。如果要实例化，只需要 one_test() 即可    print(one_test)    two_test = _module_dict[&#39;TwoTest&#39;]    print(two_test)# 输出&lt;class &#39;__main__.OneTest &#39;&gt;&lt;class &#39;__main__.TwoTest&#39;&gt;</code></pre><h3 id="Registry-类实现"><a href="#Registry-类实现" class="headerlink" title="Registry 类实现"></a>Registry 类实现</h3><p>基于上面的理解，此时再来看 MMCV 实现就会非常简单了，核心逻辑如下：</p><pre><code class="lang-python">class Registry:    def __init__(self, name):        # 可实现注册类细分功能        self._name = name         # 内部核心内容，维护所有的已经注册好的 class        self._module_dict = dict()    def _register_module(self, module_class, module_name=None, force=False):        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, &#39;                            f&#39;but got &#123;type(module_class)&#125;&#39;)        if module_name is None:            module_name = module_class.__name__        if not force and module_name in self._module_dict:            raise KeyError(f&#39;&#123;module_name&#125; is already registered &#39;                           f&#39;in &#123;self.name&#125;&#39;)        # 最核心代码        self._module_dict[module_name] = module_class    # 装饰器函数    def register_module(self, name=None, force=False, module=None):        if module is not None:            # 如果已经是 module，那就知道 增加到字典中即可            self._register_module(                module_class=module, module_name=name, force=force)            return module        # 最标准用法        # use it as a decorator: @x.register_module()        def _register(cls):            self._register_module(                module_class=cls, module_name=name, force=force)            return cls        return _register</code></pre><p>在 MMCV 中所有的类实例化都是通过 <code>build_from_cfg</code> 函数实现，做的事情非常简单，就是给定 <code>module_name</code>，然后从 <code>self._module_dict</code> 提取即可。</p><pre><code class="lang-python">def build_from_cfg(cfg, registry, default_args=None):    args = cfg.copy()    if default_args is not None:        for name, value in default_args.items():            args.setdefault(name, value)    obj_type = args.pop(&#39;type&#39;) # 注册 str 类名    if is_str(obj_type):        # 相当于 self._module_dict[obj_type]        obj_cls = registry.get(obj_type)        if obj_cls is None:            raise KeyError(                f&#39;&#123;obj_type&#125; is not in the &#123;registry.name&#125; registry&#39;)    # 如果已经实例化了，那就直接返回    elif inspect.isclass(obj_type):        obj_cls = obj_type    else:        raise TypeError(            f&#39;type must be a str or valid type, but got &#123;type(obj_type)&#125;&#39;)    # 最终初始化对于类，并且返回，就完成了一个类的实例化过程    return obj_cls(**args)</code></pre><p>一个完整的使用例子如下：</p><pre><code class="lang-python">CONVERTERS = Registry(&#39;converter&#39;)@CONVERTERS.register_module()class Converter1(object):    def __init__(self, a, b):        self.a = a        self.b = bconverter_cfg = dict(type=&#39;Converter1&#39;, a=a_value, b=b_value)converter = build_from_cfg(converter_cfg,CONVERTERS)</code></pre><p>​       </p><hr><h1 id="mmdetection模型构建及Registry注册器机制"><a href="#mmdetection模型构建及Registry注册器机制" class="headerlink" title="mmdetection模型构建及Registry注册器机制"></a>mmdetection模型构建及Registry注册器机制</h1><p>mmdetection封装的很好，很方便使用，比如我想训练的话只需如下的一条指令。在train.py中，通过build_detector来构建模型，</p><pre><code>python tools/train.py  configs/pascal_voc/faster_rcnn_r50_fpn_1x_voc0712.py</code></pre><p>build_detector的定义如下，最后通过build_from_cfg来构建模型，这里看到了让人困惑的Registry.</p><pre><code>from mmdet.cv_core.utils import Registry, build_from_cfgfrom torch import nnBACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;)def build(cfg, registry, default_args=None):    &quot;&quot;&quot;Build a module.    Args:        cfg (dict, list[dict]): The config of modules, is is either a dict            or a list of configs.        registry (:obj:`Registry`): A registry the module belongs to.        default_args (dict, optional): Default arguments to build the module.            Defaults to None.    Returns:        nn.Module: A built nn module.    &quot;&quot;&quot;    if isinstance(cfg, list):        modules = [            build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg        ]        return nn.Sequential(*modules)    else:        return build_from_cfg(cfg, registry, default_args)def build_detector(cfg, train_cfg=None, test_cfg=None):    &quot;&quot;&quot;Build detector.&quot;&quot;&quot;    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg)</code></pre><h2 id="一、Registry是干什么的"><a href="#一、Registry是干什么的" class="headerlink" title="一、Registry是干什么的"></a>一、Registry是干什么的</h2><p>Registry完成了从字符串到类的映射，这样模型信息、训练时的参数信息，只需要写入到一个配置文件里，然后使用注册器来实例化即可。</p><h2 id="二、如何实现"><a href="#二、如何实现" class="headerlink" title="二、如何实现"></a>二、如何实现</h2><p> 通过装饰器来实现。在mmcv/mmcv/registry.py中，我们看到了Registry类。其中完成字符串到类的映射，实际上就是下面的成员函数来实现的，核心代码就一句，将要注册的类添加到字典里，key为类的名字（字符串）。下面通过一个小例子，</p><pre><code>def _register_module(self, module_class, module_name=None, force=False):        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, &#39;                            f&#39;but got &#123;type(module_class)&#125;&#39;)        if module_name is None:            module_name = module_class.__name__        if not force and module_name in self._module_dict:            raise KeyError(f&#39;&#123;module_name&#125; is already registered &#39;                           f&#39;in &#123;self.name&#125;&#39;)        self._module_dict[module_name] = module_class</code></pre><p> 来看看它的构建过程。在导入下面这个文件时，首先创建FRUIT实例，接着通过装饰器（这里是用成员函数装饰类）来注册Apple类，调用register_module，然后调用_register（注意：参数cls即为类Apple），最后调用_register_module完成Apple的添加。完成后，FRUIT就有了个字典成员：[‘Apple’]=APPle。在build_from_cfg中，传入模型参数，即可通过FRUIT构建Apple的实例化对象。</p><pre><code>class Registry():    def __init__(self, name):        self._name = name        self._module_dict = dict()    def _register_module(self, module_class, module_name, force):        self._module_dict[module_name] = module_class        print(&#39;self._module_dict&#39;,self._module_dict)    def register_module(self, name=None, force=False, module=None):        print(&#39;register module ...&#39;)        def _register(cls):            print(&#39;cls &#39;, cls)            self._register_module(                module_class=cls, module_name=name, force=force)            return cls        return _registerFRUIT = Registry(&#39;fruit&#39;)@FRUIT.register_module()class Apple():    def __init__(self, name):        self.name = name</code></pre><p>运行结果：</p><pre><code>register module ...cls  &lt;class &#39;__main__.Apple&#39;&gt;self._module_dict &#123;None: &lt;class &#39;__main__.Apple&#39;&gt;&#125;</code></pre><h2 id="三、Registry在mmdetection中是如何构建模型的"><a href="#三、Registry在mmdetection中是如何构建模型的" class="headerlink" title="三、Registry在mmdetection中是如何构建模型的"></a>三、Registry在mmdetection中是如何构建模型的</h2><p> 我们来看一下构建模型的流程：</p><p>​        1、在train.py中通过build_detector构建模型，其中cfg.model, cfg.train_cfg如下，包括模型信息和训练信息。</p><pre><code>model = build_detector(        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)</code></pre><p><img src="https://s2.51cto.com/images/blog/202112/30151824_61cd5d40bbd4586669.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp/resize,m_fixed,w_1184" alt=""></p><p> 2、最关键的部分来了。首先通过build_detector构建模型， 其中传入的DETECTORS是Registry的实例，在该实例中，包含了所有已经实现的检测器，如图。那么它是在哪里实现添加这些检测的类的呢？</p><pre><code>def build_detector(cfg, train_cfg=None, test_cfg=None):    &quot;&quot;&quot;Build detector.&quot;&quot;&quot;    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))</code></pre><p><img src="https://s2.51cto.com/images/blog/202112/30151825_61cd5d410366b83654.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp/resize,m_fixed,w_1184" alt=""></p><p>  看了前面那个小例子我们就能猜到，一定是在这些检测类上，用Registry对其进行了注册，看看faster rcnn的实现，证明了我们的猜想。这样只要</p><p>在定义这些类时，对其进行注册，那么就会自动加入到DETECTORS这个实例的成员字典里，非常的巧妙。当我们想实例化某个检测网络时，传入其字符名称即可。</p><p><img src="https://s2.51cto.com/images/blog/202112/30151825_61cd5d4138de211806.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp/resize,m_fixed,w_1184" alt=""></p><p> 既然都看到这里了，就进一步看看网络时如何继续构建的吧。mmdetection将网络分成了几个部分，backbone，head，neck等。在TwoStageDetector（</p><p>faster rcnn的基类）中，可以看到分别构建了这几个部分。head, neck, loss等，同样是通过Registry来注册实现的。最后就是将这几个部分组合起来即可。</p><pre><code>@DETECTORS.register_module()class TwoStageDetector(BaseDetector):    &quot;&quot;&quot;Base class for two-stage detectors.    Two-stage detectors typically consisting of a region proposal network and a    task-specific regression head.    &quot;&quot;&quot;    def __init__(self,                 backbone,                 neck=None,                 rpn_head=None,                 roi_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        super(TwoStageDetector, self).__init__()        self.backbone = build_backbone(backbone)        if neck is not None:            self.neck = build_neck(neck)        if rpn_head is not None:            rpn_train_cfg = train_cfg.rpn if train_cfg is not None else None            rpn_head_ = rpn_head.copy()            rpn_head_.update(train_cfg=rpn_train_cfg, test_cfg=test_cfg.rpn)            self.rpn_head = build_head(rpn_head_)        if roi_head is not None:            # update train and test cfg here for now            # TODO: refactor assigner &amp; sampler            rcnn_train_cfg = train_cfg.rcnn if train_cfg is not None else None            roi_head.update(train_cfg=rcnn_train_cfg)            roi_head.update(test_cfg=test_cfg.rcnn)            self.roi_head = build_head(roi_head)        self.train_cfg = train_cfg        self.test_cfg = test_cfg        self.init_weights(pretrained=pretrained)</code></pre><hr><h1 id="简单理解mmdetection中的registry类"><a href="#简单理解mmdetection中的registry类" class="headerlink" title="简单理解mmdetection中的registry类"></a>简单理解mmdetection中的registry类</h1><h3 id="注册器类-Registry"><a href="#注册器类-Registry" class="headerlink" title="注册器类(Registry)"></a>注册器类(Registry)</h3><p>在mmdetection中，将会使用该类构建9个注册类实例，其实就是对类做一个划分管理。Python 装饰器的特性就是 被装饰对象（比如 ResNet 类）被定义的时候就立刻运行，从而将 ResNet 注册进 BACKBONES。</p><p>比如，backbone 作为一族（vgg,resnet等）</p><p><strong>文件：mmdet\models\registry.py</strong></p><pre><code class="lang-python">BACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;)</code></pre><p><strong>文件：mmdet\datasets\registry.py</strong></p><pre><code class="lang-python">DATASETS = Registry(&#39;dataset&#39;)PIPELINES = Registry(&#39;pipeline&#39;)</code></pre><p>每一个实例，都是存放属于这一簇的类，将来通过get key方式获取，key 来自于config文件.</p><p>mmdetection在构建模型的过程中，一直是通过key 去查找对应的类（在注册器中），找到对应的类，然后实例化，最终将配置描述的模型，构建出来.</p><p>举个栗子：</p><pre><code class="lang-python">key = &#39;vgg&#39;VGG = BACKBONES.get(key)key = &#39;bce&#39;BCE = LOSSES .get(key)</code></pre><h3 id="Registry-类"><a href="#Registry-类" class="headerlink" title="Registry 类"></a>Registry 类</h3><pre><code class="lang-python">#!/usr/bin/python3# -*- coding: utf-8 -*-import inspectclass Registry(object):    def __init__(self, name):        self._name = name        self._module_dict = dict()    def __repr__(self):        format_str = self.__class__.__name__ + &#39;(name=&#123;&#125;, items=&#123;&#125;)&#39;.format(            self._name, list(self._module_dict.keys()))        return format_str    @property    def name(self):        return self._name    @property    def module_dict(self):        return self._module_dict    def get(self, key):        return self._module_dict.get(key, None)    def _register_module(self, module_class):        &quot;&quot;&quot;Register a module.        Args:            module (:obj:`nn.Module`): Module to be registered.        &quot;&quot;&quot;        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, but got &#123;&#125;&#39;.format(                type(module_class)))        module_name = module_class.__name__        if module_name in self._module_dict:            raise KeyError(&#39;&#123;&#125; is already registered in &#123;&#125;&#39;.format(                module_name, self.name))        self._module_dict[module_name] = module_class    def register_module(self, cls):        self._register_module(cls)        return cls</code></pre><h3 id="举个栗子："><a href="#举个栗子：" class="headerlink" title="举个栗子："></a>举个栗子：</h3><p>在mmdetection的代码中，将一个类注册（插入）到（某一个）注册器里面，是直接写在类的声明上方.</p><pre><code class="lang-python">ANIMAL = Registry(&#39;animal&#39;)@ANIMAL.register_moduleclass Dog(object):    def __init__(self):        pass    def run(self):        print(&#39;running dog&#39;)# ANIMAL.register_module(Dog)dog = ANIMAL.get(&#39;Dog&#39;)d = dog()d.run()</code></pre><p>等价写法：</p><pre><code class="lang-python">ANIMAL = Registry(&#39;animal&#39;)class Dog(object):    def __init__(self):        pass    def run(self):        print(&#39;running dog&#39;)ANIMAL.register_module(Dog)dog = ANIMAL.get(&#39;Dog&#39;)d = dog()d.run(）</code></pre><p>两者输出结果皆为：</p><p><code>running dog</code></p><hr><h1 id="mmcv之Registry类解读-增删改查"><a href="#mmcv之Registry类解读-增删改查" class="headerlink" title="mmcv之Registry类解读(增删改查)"></a>mmcv之Registry类解读(增删改查)</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p> 本文主要介绍mmcv的Registry类。建议读者先配置下mmcv环境：mmcv源码安装。我相信读者大多数对于Registry类有点儿迷，主要涉及python中装饰器的知识。因此，本文尽量做到面面俱到，会简要介绍一部分装饰器的用法。</p><h3 id="1、Registry作用"><a href="#1、Registry作用" class="headerlink" title="1、Registry作用"></a>1、Registry作用</h3><p> Registry类可以简单理解为一个字典，举个例子，在mmdetection中，比如说创建了名为dataset的注册器对象，则注册器dataset中包含(CocoDataset类，VOCDataset类，Lvis类)；同理，detector注册器对象中包含(FasterRcnn类，SSD类，YOLO类等)。因此，Registry对象完全可以理解为一个字典，里面存储着同系列的类。</p><h3 id="2、源码分析"><a href="#2、源码分析" class="headerlink" title="2、源码分析"></a>2、源码分析</h3><p> Registry虽说是一个字典，但是得实现增删改查的功能。增即往字典中添加新的类；查即查询字典中是否有这个类。那么在Registry类中如何实现这些功能呢？</p><h4 id="2-1-初始化部分"><a href="#2-1-初始化部分" class="headerlink" title="2.1.初始化部分"></a>2.1.初始化部分</h4><pre><code>class Registry:    &quot;&quot;&quot;A registry to map strings to classes.Args:    name (str): Registry name.&quot;&quot;&quot;def __init__(self, name):    self._name = name    self._module_dict = dict()def __len__(self):    return len(self._module_dict)def __contains__(self, key):    return self.get(key) is not Nonedef __repr__(self):    format_str = self.__class__.__name__ + \                 f&#39;(name=&#123;self._name&#125;, &#39; \                 f&#39;items=&#123;self._module_dict&#125;)&#39;    return format_str</code></pre><p>这部分比较简单，就是传入了一个name并内部定义了一个self._module_dict字典。</p><h4 id="2-2-查"><a href="#2-2-查" class="headerlink" title="2.2.查"></a>2.2.查</h4><p> 查找self._module_dict存在一个某个类 实现也比较简单：</p><pre><code>def get(self, key):    return self._module_dict.get(key, None)</code></pre><p> 主要借助get方法，若有key则返回对应的value；若无key则返回None。</p><h4 id="2-3-增"><a href="#2-3-增" class="headerlink" title="2.3.增"></a>2.3.增</h4><p> 增的方法mmdetection中提供了两种方式，区别是方法_register_module()是否指定了module参数：</p><p><img src="https://img-blog.csdnimg.cn/20210227202037668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>该函数主要往self._module_dict中添加类。注意，往字典里面添加的是类。以下代码包含了上图中两种方式。这里我截取了核心代码：</p><pre><code>def _register_module(self, module_class, module_name=None, force=False):    if module_name is None:        module_name = module_class.__name__    if isinstance(module_name, str):        module_name = [module_name]    self._module_dict[name] = module_classdef register_module(self, name=None, force=False, module=None):    # 若指定module，则执行if语句，执行完后完成module类添加    if module is not None:        self._register_module(            module_class=module, module_name=name, force=force)        return module    # 若没有指定module，则执行_register函数。    def _register(cls):        self._register_module(            module_class=cls, module_name=name, force=force)        return cls    return _register</code></pre><p> 我将分两小节来介绍这两种方式。</p><h4 id="2-3-1-指定module参数"><a href="#2-3-1-指定module参数" class="headerlink" title="2.3.1 指定module参数"></a>2.3.1 指定module参数</h4><p>  现在我们想往字典self._module_dict字典中添加新类。最容易想到方法就是下面这样：</p><pre><code>if __name__ == &#39;__main__&#39;:    backbones = Registry(&#39;backbone&#39;)    class MobileNet:        pass    backbones.register_module(module=MobileNet)    print(backbones)</code></pre><p> 即直接指定参数module=MobileNet。内部通过self._module_dict[name]=module_class完成注册。</p><h4 id="2-3-2-不指定module参数"><a href="#2-3-2-不指定module参数" class="headerlink" title="2.3.2 不指定module参数"></a>2.3.2 不指定module参数</h4><p> 上节提供方法完全可以，但是在利用mmdetection拓展新模型的时候，如果每次创建完一个类之后，然后通过上述方法注册，着实不方便。势必会影响mmdetection拓展性。而装饰器可以很方便给类拓展新功能，装饰器有机会我会单独出一篇文章，<br> 这里简单记住装饰器用法：funB = funA(funB)，即被装饰函数funB，经过装饰器funA的装饰，中间可能发生了一些其他事情，最终funA的return funB。<br> 首先看用法:比如我想注册ResNet。</p><pre><code>if __name__ == &#39;__main__&#39;:    backbones = Registry(&#39;backbone&#39;)    @backbones.register_module()    class ResNet:        pass    print(backbones)</code></pre><p> 这里内部实质上经过了下面函数：</p><pre><code>        def _register(cls):            self._register_module(                module_class=cls, module_name=name, force=force)            return cls</code></pre><p>在这个过程中，funB相当于cls。而_register函数相当于funA。中间往self._module_dict字典中注册了类cls。然后return cls。即funB。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> BEV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PETR_code_note</title>
      <link href="/2023/11/16/PETR-code-note/"/>
      <url>/2023/11/16/PETR-code-note/</url>
      
        <content type="html"><![CDATA[<h1 id="PETR-code-note"><a href="#PETR-code-note" class="headerlink" title="PETR code note"></a>PETR code note</h1><ol><li><p><code>cfg = Config.fromfile(args.config)</code></p><h1 id="从args更新读取的config文件，args优先级-gt-cfg优先级，args定义了cfg文件中没有定义的work-dir等参数-还有一部分需要覆盖cfg的参数"><a href="#从args更新读取的config文件，args优先级-gt-cfg优先级，args定义了cfg文件中没有定义的work-dir等参数-还有一部分需要覆盖cfg的参数" class="headerlink" title="从args更新读取的config文件，args优先级>cfg优先级，args定义了cfg文件中没有定义的work_dir等参数,还有一部分需要覆盖cfg的参数"></a>从args更新读取的config文件，args优先级&gt;cfg优先级，args定义了cfg文件中没有定义的work_dir等参数,还有一部分需要覆盖cfg的参数</h1></li></ol><ol><li><p>cfg.merge_from_dict()</p><p><strong>合并字典到配置</strong> 通过 <code>cfg.merge_from_dict</code> 函数接口可以实现对字典内容进行合并，典型用法如下：</p><pre><code class="lang-python">cfg_file = osp.join(data_path, 'config/a.py')cfg = Config.fromfile(cfg_file)input_options = {'item2.a': 1, 'item2.b': 0.1, 'item3': False}cfg.merge_from_dict(input_options)# 原始 a.py 内容为：item1 = [1, 2]item2 = {'a': 0}item3 = Trueitem4 = 'test'# 进行合并后, cfg 内容item1 = [1, 2]item2 = dict(a=1, b=0.1)item3 = Falseitem4 = 'test'</code></pre></li><li><p>```python<br>if cfg.plugin:</p><pre><code>import importlib</code></pre></li></ol><p>​       #将plugin批量导入模型环境</p><p>​       #plugin_dir=’projects/mmdet3d_plugin/‘</p><ol><li><p><code>torch.backends.cudnn.benchmark = True</code></p><p>对模型里的卷积层进行预先的优化，也就是在每一个卷积层中测试 cuDNN 提供的所有卷积实现算法，然后选择最快的那个。这样在模型启动的时候，只要额外多花一点点预处理时间，就可以较大幅度地减少训练时间。</p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -PETR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDetection整体构建流程二</title>
      <link href="/2023/11/15/MMDetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B%E4%BA%8C/"/>
      <url>/2023/11/15/MMDetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection-整体构建流程-二"><a href="#MMDetection-整体构建流程-二" class="headerlink" title="MMDetection 整体构建流程(二)"></a>MMDetection 整体构建流程(二)</h1><p>本文核心内容是<strong>按照抽象到具体方式，从多个层次进行训练和测试流程深入解析</strong>，从最抽象层讲起，到最后核心代码实现，希望帮助大家更容易理解 MMDetection 开源框架整体构建细节</p><h2 id="一、第一层整体抽象"><a href="#一、第一层整体抽象" class="headerlink" title="一、第一层整体抽象"></a>一、第一层整体抽象</h2><p><img src="https://pic2.zhimg.com/80/v2-2463639f7e39afd273fdeccbfa530d49_720w.jpg" alt=""></p><p>上图为 MMDetection 框架整体训练和测试抽象流程图。按照数据流过程，训练流程可以简单总结为：</p><ol><li>给定任何一个数据集，首先需要构建Dataset类，用于迭代输出数据</li><li>在迭代输出数据的时候需要通过数据pipeline对数据进行各种处理，最典型的处理流是训练中的数据增强操作，测试中的数据预处理等</li><li>通过Sampler采样器可以控制Dataset输出的数据顺序，最常用的是随机采样器RandomSampler。由于Dataset中输出的图片大小不一样，为了尽可能减少后续组成batch时pad的像素个数，MMDetection引入了分组采样器GroupSampler和DistributedGroupSampler，相当于在RandomSampler基础上额外新增了根据图片宽高比进行group功能</li><li>将Sampler和Dataset都输入给DataLoader，然后通过DataLoader输出已组成batch的数据，作为Model的输入</li><li>对于任何一个Model，为了方便处理数据流及分布式需求，MMDetection引入了两个Model的上层封装：单机版本MMDataParallel、分布式（单机多卡或多机多卡）版本MMDistributedDataParallel</li><li>Model运行后会输出loss及其他一些信息，会通过logger进行保存或者可视化</li><li>为了更好地解耦，方便地获取各个组件之间依赖和灵活扩展，MMDetection引入了Runner类进行全生命周期管理，并且通过Hook方便的获取、修改和拦截任何生命周期数据流，扩展非常便捷</li></ol><p>而测试流程就比较简单了，直接对 DataLoader 输出的数据进行前向推理即可，还原到最终原图尺度过程也是在 Model 中完成。</p><p>以上就是 MMDetection  框架整体训练和测试抽象流程，上图不仅仅反映了训练和测试数据流，而且还包括了模块和模块之间的调用关系。对于训练而言，最核心部分应该是  Runner，理解了 Runner 的运行流程，也就理解了整个 MMDetection 数据流。</p><h2 id="二、第二层模块抽象"><a href="#二、第二层模块抽象" class="headerlink" title="二、第二层模块抽象"></a>二、第二层模块抽象</h2><p>在总体把握了整个MMDetection框架训练和测试流程后，下个层次是每个模块内部抽象流程，主要包括pipeline、DataParallel、Model、Runner和Hooks。</p><h3 id="2-1-Pipeline"><a href="#2-1-Pipeline" class="headerlink" title="2.1 Pipeline"></a>2.1 Pipeline</h3><p>Pipeline 实际上由一系列按照插入顺序运行的数据处理模块组成，每个模块完成某个特定功能，例如 Resize，因为其流式顺序运行特性，故叫做 Pipeline。</p><p><img src="https://pic3.zhimg.com/80/v2-d7eb7e24335613da3da22da4ea93e132_720w.webp" alt=""></p><p>上图是一个非常典型的训练流程 Pipeline，每个类都接收字典输入，输出也是字典，顺序执行，其中绿色表示该类运行后新增字段，橙色表示对该字段可能会进行修改。如果进一步细分的话，不同算法的 Pipeline 都可以划分为如下部分：</p><ul><li><strong>图片和标签加载</strong>，通常用的类是 LoadImageFromFile 和 LoadAnnotations</li><li><strong>数据前处理</strong>，例如统一 Resize</li><li><strong>数据增强</strong>，典型的例如各种图片几何变换等，这部分是训练流程特有，测试阶段一般不采用(多尺度测试采用其他实现方式)</li><li><strong>数据收集</strong>，例如 Collect</li></ul><p>在 MMDetection 框架中，图片和标签加载和数据后处理流程一般是固定的，用户主要可能修改的是数据增强步骤，目前已经接入了第三方增强库 Albumentations，可以按照示例代码轻松构建属于你自己的数据增强 Pipeline。</p><p><strong>在构建自己的 Pipeline 时候一定要仔细检查你修改或者新增的字典 key 和 value，因为一旦你错误地覆盖或者修改原先字典里面的内容，代码也可能不会报错，如果出现 bug，则比较难排查</strong>。</p><h3 id="2-2-DataParallel-和-Model"><a href="#2-2-DataParallel-和-Model" class="headerlink" title="2.2 DataParallel 和 Model"></a>2.2 DataParallel 和 Model</h3><p>在 MMDetection 中 DataLoader 输出的内容不是 pytorch 能处理的标准格式，还包括了 DataContainer  对象，该对象的作用是包装不同类型的对象使之能按需组成 batch。在目标检测中，每张图片 gt bbox 个数是不一样的，如果想组成 batch tensor，要么你设置最大长度，要么你自己想办法组成 batch。而考虑到内存和效率，MMDetection 通过引入  DataContainer 模块来解决上述问题，但是随之带来的问题是 pytorch 无法解析 DataContainer 对象，故需要在  MMDetection 中自行处理。</p><p>解决办法其实非常多，MMDetection  选择了一种比较优雅的实现方式：MMDataParallel 和 MMDistributedDataParallel。具体来说，这两个类相比  PyTorch 自带的 DataParallel 和 DistributedDataParallel 区别是：</p><ul><li>可以处理 DataContainer 对象</li><li>额外实现了 <code>train_step()</code> 和 <code>val_step()</code> 两个函数，可以被 Runner 调用</li></ul><p>Model如下：</p><p><img src="https://pic4.zhimg.com/80/v2-0c8f69636320fb40d8a8cd994296bf87_720w.webp" alt=""></p><h3 id="2-3-Runner-和-Hooks"><a href="#2-3-Runner-和-Hooks" class="headerlink" title="2.3 Runner 和 Hooks"></a>2.3 Runner 和 Hooks</h3><p>对于任何一个目标检测算法，都需要包括优化器、学习率设置、权重保存等等组件才能构成完整训练流程，而这些组件是通用的。为了方便 OpenMMLab  体系下的所有框架复用，在 MMCV 框架中引入了 Runner 类来统一管理训练和验证流程，并且通过 Hooks  机制以一种非常灵活、解耦的方式来实现丰富扩展功能。</p><p>下面列出了在 MMDetection 几个非常重要的 hook 以及其作用的生命周期： </p><p><img src="https://pic4.zhimg.com/80/v2-5d614997aa85e1b841457094b7bc0cbb_720w.webp" alt=""></p><p>例如 CheckpointHook 在每个训练 epoch 完成后会被调用，从而实现保存权重功能。用户也可以将自己定制实现的 Hook 采用上述方式绘制，对理解整个流程或许有帮助。</p><h2 id="三、第三层代码抽象"><a href="#三、第三层代码抽象" class="headerlink" title="三、第三层代码抽象"></a>三、第三层代码抽象</h2><p>前面两层抽象分析流程，基本上把整个 MMDetection 的训练和测试流程分析完了，下面从具体代码层面进行抽象分析。</p><h3 id="3-1-训练和测试整体代码抽象流程"><a href="#3-1-训练和测试整体代码抽象流程" class="headerlink" title="3.1 训练和测试整体代码抽象流程"></a>3.1 训练和测试整体代码抽象流程</h3><p><img src="https://pic4.zhimg.com/80/v2-b03d43ed4b3dc4c02e68712e57023cff_720w.webp" alt=""></p><p>上图为训练和验证的和具体代码相关的整体抽象流程，对应到代码上，其核心代码如下：</p><pre><code class="lang-python">#=================== tools/train.py ==================# 1.初始化配置cfg = Config.fromfile(args.config)# 2.判断是否为分布式训练模式# 3.初始化 loggerlogger = get_root_logger(log_file=log_file, log_level=cfg.log_level)# 4.收集运行环境并且打印，方便排查硬件和软件相关问题env_info_dict = collect_env()# 5.初始化 modelmodel = build_detector(cfg.model, ...)# 6.初始化 datasets#=================== mmdet/apis/train.py ==================# 1.初始化 data_loaders ，内部会初始化 GroupSamplerdata_loader = DataLoader(dataset,...)# 2.基于是否使用分布式训练，初始化对应的 DataParallelif distributed:  model = MMDistributedDataParallel(...)else:  model = MMDataParallel(...)# 3.初始化 runnerrunner = EpochBasedRunner(...)# 4.注册必备 hookrunner.register_training_hooks(cfg.lr_config, optimizer_config,                               cfg.checkpoint_config, cfg.log_config,                               cfg.get(&#39;momentum_config&#39;, None))# 5.如果需要 val，则还需要注册 EvalHook           runner.register_hook(eval_hook(val_dataloader, **eval_cfg))# 6.注册用户自定义 hookrunner.register_hook(hook, priority=priority)# 7.权重恢复和加载if cfg.resume_from:    runner.resume(cfg.resume_from)elif cfg.load_from:    runner.load_checkpoint(cfg.load_from)# 8.运行，开始训练runner.run(data_loaders, cfg.workflow, cfg.total_epochs)</code></pre><p>上面的流程比较简单，一般大家比较难以理解的是 <code>runner.run</code> 内部逻辑，下小节进行详细分析，而对于测试逻辑由于比较简单，就不详细描述了，简单来说测试流程下不需要 runner，直接加载训练好的权重，然后进行 model 推理即可。</p><h3 id="3-2-Runner-训练和验证代码抽象"><a href="#3-2-Runner-训练和验证代码抽象" class="headerlink" title="3.2 Runner 训练和验证代码抽象"></a>3.2 Runner 训练和验证代码抽象</h3><p>runner 对象内部的 run 方式是一个通用方法，可以运行任何 workflow，目前常用的主要是 train 和 val。</p><ul><li>当配置为：workflow = [(‘train’, 1)]，表示仅仅进行 train workflow，也就是迭代训练</li><li>当配置为：workflow = [(‘train’, n),(‘val’, 1)]，表示先进行 n 个 epoch 的训练，然后再进行1个 epoch  的验证，然后循环往复,如果写成 [(‘val’, 1),(‘train’, n)] 表示先进行验证，然后才开始训练</li></ul><p>当进入对应的 workflow，则会调用 runner 里面的 train() 或者 val()，表示进行一次 epoch 迭代。其代码也非常简单，如下所示：</p><pre><code class="lang-python">def train(self, data_loader, **kwargs):    self.model.train()    self.mode = &#39;train&#39;    self.data_loader = data_loader    self.call_hook(&#39;before_train_epoch&#39;)    for i, data_batch in enumerate(self.data_loader):        self.call_hook(&#39;before_train_iter&#39;)        self.run_iter(data_batch, train_mode=True)        self.call_hook(&#39;after_train_iter&#39;)    self.call_hook(&#39;after_train_epoch&#39;)def val(self, data_loader, **kwargs):    self.model.eval()    self.mode = &#39;val&#39;    self.data_loader = data_loader    self.call_hook(&#39;before_val_epoch&#39;)    for i, data_batch in enumerate(self.data_loader):        self.call_hook(&#39;before_val_iter&#39;)        with torch.no_grad():            self.run_iter(data_batch, train_mode=False)        self.call_hook(&#39;after_val_iter&#39;)    self.call_hook(&#39;after_val_epoch&#39;)</code></pre><p>核心函数实际上是 self.run_iter()，如下：</p><pre><code class="lang-python">def run_iter(self, data_batch, train_mode, **kwargs):    if train_mode:        # 对于每次迭代，最终是调用如下函数        outputs = self.model.train_step(data_batch,...)    else:        # 对于每次迭代，最终是调用如下函数        outputs = self.model.val_step(data_batch,...)    if &#39;log_vars&#39; in outputs:        self.log_buffer.update(outputs[&#39;log_vars&#39;],...)    self.outputs = outputs</code></pre><p>上述 self.call_hook() 表示在不同生命周期调用所有已经注册进去的 hook，而字符串参数表示对应的生命周期。以 OptimizerHook 为例，其执行反向传播、梯度裁剪和参数更新等核心训练功能：</p><pre><code class="lang-python">@HOOKS.register_module()class OptimizerHook(Hook):    def __init__(self, grad_clip=None):        self.grad_clip = grad_clip    def after_train_iter(self, runner):        runner.optimizer.zero_grad()        runner.outputs[&#39;loss&#39;].backward()        if self.grad_clip is not None:            grad_norm = self.clip_grads(runner.model.parameters())        runner.optimizer.step()</code></pre><p>可以发现 OptimizerHook 注册到的生命周期是 after_train_iter，故在每次 train() 里面运行到 </p><p><code>self.call_hook(&#39;after</code><em>train</em><code>iter&#39;)</code> 时候就会被调用，其他 hook 也是同样运行逻辑。</p><h3 id="3-3-Model-训练和测试代码抽象"><a href="#3-3-Model-训练和测试代码抽象" class="headerlink" title="3.3 Model 训练和测试代码抽象"></a>3.3 Model 训练和测试代码抽象</h3><p>前面说个，训练和验证的时候实际上调用了 model 内部的 <code>train_step</code> 和 <code>val_step</code> 函数，<strong>理解了两个函数调用流程就理解了 MMDetection 训练和测试流程</strong>。</p><p>注意，由于 model 对象会被 DataParallel 类包裹，故实际上此时的 model，是指的 MMDataParallel 或者  MMDistributedDataParallel。以非分布式 train_step 流程为例，其内部完成调用流程图示如下：</p><p><img src="https://pic4.zhimg.com/80/v2-0d17b53f68286931803bf9d1dca10467_720w.webp" alt=""></p><h3 id="3-3-1-train-或者-val-流程"><a href="#3-3-1-train-或者-val-流程" class="headerlink" title="3.3.1 train 或者 val 流程"></a>3.3.1 train 或者 val 流程</h3><p><strong>(1) 调用 runner 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>在 runner 中调用 <code>train_step</code> 或者 <code>val_step</code>，代码如下：</p><pre><code class="lang-python">#=================== mmcv/runner/epoch_based_runner.py ==================if train_mode:    outputs = self.model.train_step(data_batch,...)else:    outputs = self.model.val_step(data_batch,...)</code></pre><p>实际上，首先会调用 DataParallel 中的 <code>train_step</code> 或者 <code>val_step</code> ，其具体调用流程为：</p><pre><code class="lang-python"># 非分布式训练#=================== mmcv/parallel/data_parallel.py/MMDataParallel ==================def train_step(self, *inputs, **kwargs):    if not self.device_ids:        inputs, kwargs = self.scatter(inputs, kwargs, [-1])        # 此时才是调用 model 本身的 train_step        return self.module.train_step(*inputs, **kwargs)    # 单 gpu 模式    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)    # 此时才是调用 model 本身的 train_step    return self.module.train_step(*inputs[0], **kwargs[0])# val_step 也是的一样逻辑def val_step(self, *inputs, **kwargs):    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)    # 此时才是调用 model 本身的 val_step    return self.module.val_step(*inputs[0], **kwargs[0])</code></pre><p>可以发现，在调用 model 本身的 train_step 前，需要额外调用 scatter 函数，前面说过该函数的作用是处理 DataContainer 格式数据，使其能够组成 batch，否则程序会报错。</p><p>如果是分布式训练，则调用的实际上是 <code>mmcv/parallel/distributed.py/MMDistributedDataParallel</code>，最终调用的依然是 model 本身的 <code>train_step</code> 或者 <code>val_step</code>。</p><p><strong>(2) 调用 model 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>其核心代码如下：</p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/BaseDetector ==================def train_step(self, data, optimizer):    # 调用本类自身的 forward 方法    losses = self(**data)    # 解析 loss    loss, log_vars = self._parse_losses(losses)    # 返回字典对象    outputs = dict(        loss=loss, log_vars=log_vars, num_samples=len(data[&#39;img_metas&#39;]))    return outputsdef forward(self, img, img_metas, return_loss=True, **kwargs):    if return_loss:        # 训练模式        return self.forward_train(img, img_metas, **kwargs)    else:        # 测试模式        return self.forward_test(img, img_metas, **kwargs)</code></pre><p><code>forward_train</code> 和 <code>forward_test</code> 需要在不同的算法子类中实现，输出是 Loss 或者 预测结果。</p><p><strong>(3) 调用子类中的 <code>forward_train</code> 方法</strong> </p><p>目前提供了两个具体子类，<code>TwoStageDetector</code> 和 <code>SingleStageDetector</code> ，用于实现 two-stage 和 single-stage 算法。</p><p>对于 <code>TwoStageDetector</code> 而言，其核心逻辑是：</p><pre><code class="lang-python">#============= mmdet/models/detectors/two_stage.py/TwoStageDetector ============def forward_train(...):    # 先进行 backbone+neck 的特征提取    x = self.extract_feat(img)    losses = dict()    # RPN forward and loss    if self.with_rpn:        # 训练 RPN        proposal_cfg = self.train_cfg.get(&#39;rpn_proposal&#39;,                                          self.test_cfg.rpn)        # 主要是调用 rpn_head 内部的 forward_train 方法        rpn_losses, proposal_list = self.rpn_head.forward_train(x,...)        losses.update(rpn_losses)    else:        proposal_list = proposals    # 第二阶段，主要是调用 roi_head 内部的 forward_train 方法    roi_losses = self.roi_head.forward_train(x, ...)    losses.update(roi_losses)    return losses</code></pre><p>对于 <code>SingleStageDetector</code> 而言，其核心逻辑是：</p><pre><code class="lang-python">#============= mmdet/models/detectors/single_stage.py/SingleStageDetector ============def forward_train(...):    super(SingleStageDetector, self).forward_train(img, img_metas)    # 先进行 backbone+neck 的特征提取    x = self.extract_feat(img)    # 主要是调用 bbox_head 内部的 forward_train 方法    losses = self.bbox_head.forward_train(x, ...)    return losses</code></pre><h3 id="3-3-2-test流程"><a href="#3-3-2-test流程" class="headerlink" title="3.3.2 test流程"></a>3.3.2 test流程</h3><p>由于没有 runner 对象，测试流程简单很多，下面简要概述：</p><ol><li><p>调用 MMDataParallel 或 MMDistributedDataParallel 中的 <code>forward</code> 方法</p></li><li><p>调用 base.py 中的 <code>forward</code> 方法</p></li><li><p>调用 base.py 中的 <code>self.forward_test</code> 方法</p></li><li><p>如果是单尺度测试，则会调用 TwoStageDetector 或 SingleStageDetector 中的 <code>simple_test</code> 方法，如果是多尺度测试，则调用 <code>aug_test</code> 方法</p></li><li><p>最终调用的是每个具体算法 Head 模块的  <code>simple_test</code> 或者 <code>aug_test</code> 方法</p></li></ol><h2 id="四、-总结"><a href="#四、-总结" class="headerlink" title="四、 总结"></a>四、 总结</h2><p>本文基于第一篇解读文章，详细地从三个层面全面解读了 MMDetection 框架，希望读者读完本文，能够对 MMDetection 框架设计思想、组件间关系和整体代码实现流程了然于心。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> BEV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmdetection3d</title>
      <link href="/2023/11/15/mmdetection3d/"/>
      <url>/2023/11/15/mmdetection3d/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection3D-整体框架介"><a href="#MMDetection3D-整体框架介" class="headerlink" title="MMDetection3D 整体框架介"></a>MMDetection3D 整体框架介</h1><p>[TOC]</p><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>由于3D本身数据的复杂性和MMDetection3D支持任务（电云D检测、单目3D检测、多模态3D检测和点云3D语义分割等）和场景（室内和外）的多样性，整个框架结构相对复杂，门槛高，这里对MMDetection3D整个框架进行整体的了解，包括设计流程，核心组件，数据集处理方法等。</p><p>整个框架的代码库目录结构如下：</p><pre><code class="lang-bash"># MMDetection3D 代码目录结构，展示主要部分 mmdetection3d    |    |- configs                    # 配置文件    |- data                       # 原始数据及预处理后数据文件    |- mmdet3d     |     |- ops                  # cuda 算子（即将迁移到 mmcv 中）    |     |- core                 # 核心组件    |     |- datasets             # 数据集相关代码    |     |- models               # 模型相关代码    |     |- utils                # 辅助工具    |     |- ...    |- tools    |     |- analysis_tools       # 分析工具，包括可视化、计算flops等    |     |- data_converter       # 各个数据集预处理转换脚本    |     |- create_data.py       # 数据预处理入口    |     |- train.py             # 训练脚本    |     |- test.py              # 测试脚本    |     |- ...                          |- ...</code></pre><h2 id="二、任务介绍"><a href="#二、任务介绍" class="headerlink" title="二、任务介绍"></a>二、任务介绍</h2><p>3D 目标检测按照输入数据模态划分可以分为：<strong>点云 3D 检测、纯视觉 3D 检测以及多模态 3D 检测（点云+图片）。</strong></p><p><img src="https://pic3.zhimg.com/80/v2-2a0bf86a79b2710a380e4f1ba0d5164a_720w.webp" alt=""></p><p><img src="https://pic3.zhimg.com/80/v2-42c8641edd26dc0441a6e7815f37220e_720w.webp" alt=""></p><p><img src="https://pic2.zhimg.com/80/v2-43f400129e178782740ac1a877b3e405_720w.webp" alt=""></p><p><img src="https://pic2.zhimg.com/80/v2-9c66063032e7f7ce4cd63ab01ef3a319_720w.webp" alt=""></p><p>除此之外，MMDetection3D还拓展到了点云3D语义分割领域，目前已经支持了室内点云语义分割，同时会在将来支持室外点云语义分割。</p><h2 id="三、算法模型支持"><a href="#三、算法模型支持" class="headerlink" title="三、算法模型支持"></a>三、算法模型支持</h2><p>所有模型相关代码位于mmdet3d/models下，MMDetection3D支持的各个方向的模型大体可以归类如下：</p><p><img src="https://pic4.zhimg.com/80/v2-efc56a48b8d6f69a23d89e85e739518b_720w.webp" alt=""></p><p>总体来说，由于MMDetection3D依赖于MMDetection和MMSegmentation，所以很多的模型及组件都是直接复用或继承而来。目前在MMDetection3D内，整体模型的构建方式会根据任务类型被划分为三种方式，具体如下：</p><p>点云3D检测（包含多模态3D检测）：</p><p><img src="https://pic2.zhimg.com/80/v2-9edad73af084acad23a0721454ef4b89_720w.webp" alt=""></p><p>对于点云3D检测（多模态3D检测），我们继承自MMDetection中的BaseDetector构建了适用于3D检测的Base3DDetector，再根据检测中的单价段和二阶段分别构造，需要注意的是不同于SingleStage3DDetector，为了尽可能的复用已有的代码组件，二阶段检测器TwoStage3DDetector同时继承自Base3DDetector和TwoStageDetector，图中只列出了部分支持的模型算法。</p><p>单目3D检测：</p><p><img src="https://pic4.zhimg.com/80/v2-d86ac9e6fcace16aa84df3771e62dba7_720w.webp" alt=""></p><p>对于单目3D检测，考虑到和2D检测输入数据的一致性，同事方便做2D检测的同学可以快速上手单目3D检测，我们继承自MMDetection中的SingleStageDetector构建了SingleStageMono3DDetector，目前所支持的单目3D检测算法都是基于该类构建的。</p><p>点云3D语义分割：</p><p><img src="https://pic1.zhimg.com/80/v2-9a01a3aecf662585eeb4af1fec1210b8_720w.webp" alt=""></p><p>对于点云 3D 语义分割，我们继承自 MMSegmentation 中的 <code>BaseSegmentor</code> 构建了适用于点云分割的 <code>Base3DSegmentor</code>，而目前所支持的点云分割算法都是遵循 <code>EncoderDecoder3D</code> 模式。 </p><h2 id="四、数据预处理"><a href="#四、数据预处理" class="headerlink" title="四、数据预处理"></a>四、数据预处理</h2><p>该部分对应于toos/create_data.py，各个数据集预处理脚本位于tools/data_converter目录下。由于3D数据集的多样性，MMDetection3D会对数据集做预处理。这里，我们从整体视角来看下数据预处理的文件生成过程：</p><p><img src="https://pic4.zhimg.com/80/v2-e1409ac7a44d062bbfe7814848f5611b_720w.webp" alt=""></p><p>在MMDetection3D中，不同的任务和不同的场景（室内、外）的数据预处理都会存在一定的区别，如上图所示，会产生不同的预处理后的文件，便于后续训练。</p><ol><li><p>对所有的任务和场景，统一用数据处理脚本转换后的pkl文件，该文件包含数据集的各种信息，包括数据集路径、calib信息和标注信息等，从而做到各个数据集内部格式尽可能的统一。</p></li><li><p>对于点云（多模态）3D检测，室内和室外数据集生成的文件是不一样的：</p><p>对于某些室外数据集，我们会借助pkl文件的信息进一步提取reduced_point_cloud和gt_database：前者是仅包含前方视野的点云文件，通常存在于kitti数据集处理过程中，因为kitti数据集仅包含前方视野的标注；后者则是包含在训练集数据集的每个3D边界框中的点云数据分别提取出来得到的各个物体的点云文件，常用来在数据增强时使用（copy-paster)。</p><p>对于室内数据集，由于点云较为密集，通常会进行点云的下采用处理，保存在points内。</p></li></ol><p>对于单目3D检测，整个模型构建的流程是遵循2D检测的，同样的在数据处理的过程中，在生成基本的pkl文件后，还需要将其抓换位coco标注格式的json文件，该过程中会对pkl的标注信息做相应处理，实际在该任务中，pkl文件用来提供data信息，json文件提供标注信息。</p><p>对于点云3D语义分割，目前MMDetection3D仅支持室内点云分割，相对于检测任务，如图所示需要生成额外的文件：instance_mask 包含每个点云的实例标签，semantic_mask包含每个点云的语义标签，seg_info包含额外的辅助训练的信息。</p><h2 id="五、模块抽象"><a href="#五、模块抽象" class="headerlink" title="五、模块抽象"></a>五、模块抽象</h2><p>和MMDetection一脉相承，整个MMDetection3D的模块内部抽象流程也主要包括Pipeline、DataParallel、Model、Runner和Hooks。</p><h3 id="5-1Pipeline"><a href="#5-1Pipeline" class="headerlink" title="5.1Pipeline"></a>5.1Pipeline</h3><p>具体在Pipeline方面由于数据模态的不同，所以在数据处理过程中包含不同的信息。</p><p><img src="https://pic4.zhimg.com/80/v2-7271a1fdfa1cfd93cced3fca4f540dd3_720w.webp" alt=""></p><p>上图展示了三个比较典型的3D检测Pipeline，流程自上而下分别是点云3D检测、多模态3D检测和单目3D检测，从上述的流程可以看出，pipeline其实是由一系列的按照插入顺序插入顺序进行的数据处理模块组成。MMDetection3D 对于点云 3D 检测提供了很多常用的 pipeline  模块，比如GlobalRotScaleTrans（点云的旋转缩放）、PointsRangeFilter /  ObjectRangeFilter（限定了点云和物体的范围）、PointShuffle（打乱点云数据）；而对于单目 3D 检测基本就是直接调用  MMDetection 的数据处理模块，比如 Resize （图片缩放）、Normalize （正则化）、Pad  （图片填充）；多模态检测则兼用两者。我们可以看到其实这些任务共享了部分的 pipeline 模块，比如 LoadAnnotations3D  （标签载入）、RandomFlip3D（会对点云和图片同时进行翻转）、DefaultFormatBundle3D（数据格式化）、Collect3D （选取需要用于训练的数据和标签），这些代码都在 <code>mmdet3d/datasets/pipeline</code> 目录下。</p><h3 id="5-2-Model"><a href="#5-2-Model" class="headerlink" title="5.2 Model"></a>5.2 Model</h3><p>在该部分我们按照任务类型分类，对于整个模型内部做抽象介绍。和2D检测类型，3D检测器通常也包含了几个核心组件：Backbone用于提取特征、Neck进行特征融合和增强、Head用于输出需要的结果。</p><ol><li>点云3D检测模型</li></ol><p>目前云目标检测按照对点云数据的处理方式，可以分为<strong>体素处理方法 (Voxel-based)</strong> 和<strong>原始点云处理方法 (Point-based)</strong>，这两种方法其实在构建模型的时候会有一定的区别，整体的模型构建按照下图流程所示： </p><p><img src="https://pic2.zhimg.com/80/v2-f464a0118006f4b4706d7f70cb432129_720w.webp" alt=""></p><ul><li><p>基于体素的模型通常需要 <code>Encoder</code> 来对点云体素化，如 <code>HardVFE</code> 和 <code>PointPillarScatter</code>等，采用的稀疏卷积或者 Pillars 的方法从点云中生成 2D 特征图，然后基本可以套用 2D 检测流程进行 3D 检测。</p></li><li><p>基于原始点云模型通常直接采用 3D Backbone (Pointnet / Pointnet++ 等)  提取点的特征，再针对提取到的点云特征采用 RoI 或者 Group 等方式回归 3D bounding  box。有关的具体内容我们会在后续的文章中针对典型的方法进行分析介绍.</p></li></ul><ol><li>单目3D检测模型</li></ol><p><img src="https://pic3.zhimg.com/80/v2-90d4d36dc288c41341bb80a0f546bf56_720w.webp" alt=""></p><p>由于单目 3D 检测的输入是图片，输出是 3D bounding box, 所以整体的检测流程和模型组成来说基本和 2D 检测保持一致。</p><ol><li>多模态3D检测模型</li></ol><p>多模态的检测模型从组成来看可以看成2D检测模型和点云检测模型的拼接。</p><ol><li>点云3D语义分割模型</li></ol><p><img src="https://pic1.zhimg.com/80/v2-8d879986dfa4ca933fc908fd0b99aac8_720w.webp" alt=""></p><p>MMDetection3D 内部支持的 3D 分割模型都是符合 <code>EncoderDecoder</code> 结构的，需要 <code>backbone</code> 来 encode feature, <code>decode_head</code> 用来预测每个点云的类别的进行分割，目前主要只支持室内场景的 3D 语义分割。</p><h2 id="六、训练和测试流程"><a href="#六、训练和测试流程" class="headerlink" title="六、训练和测试流程"></a>六、训练和测试流程</h2><p>首先我们训练和验证调用的是 <code>tools/train.py</code> 脚本，先进行 Dataset、Model 等相关类初始化，然后我们构建了一个 runner，最终模型的训练和验证过程是发生在 runner 内部的，而训练和验证的时候实际上是 runner 调用了 model 内部的 <code>train_step</code> 和 <code>val_step</code> 函数。 </p><h3 id="6-1train和val流程"><a href="#6-1train和val流程" class="headerlink" title="6.1train和val流程"></a>6.1train和val流程</h3><p><img src="https://pic3.zhimg.com/80/v2-a8c9de0156a19b7ddc84ab550ea3419a_720w.webp" alt=""></p><p><strong>(1) 调用 runner 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>在 runner 中调用 <code>train_step</code> 或者 <code>val_step</code>，代码如下： </p><pre><code class="lang-python">#=================== mmcv/runner/epoch_based_runner.py ================== if train_mode:     outputs = self.model.train_step(data_batch,...) else:     outputs = self.model.val_step(data_batch,...)</code></pre><p>实际上，首先会调用 DataParallel 中的 <code>train_step</code> 或者 <code>val_step</code> ，其具体调用流程为： </p><pre><code class="lang-python"># 非分布式训练 #=================== mmcv/parallel/data_parallel.py/MMDataParallel ================== def train_step(self, *inputs, **kwargs):     if not self.device_ids:         inputs, kwargs = self.scatter(inputs, kwargs, [-1])         # 此时才是调用 model 本身的 train_step         return self.module.train_step(*inputs, **kwargs)     # 单 gpu 模式     inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)     # 此时才是调用 model 本身的 train_step     return self.module.train_step(*inputs[0], **kwargs[0]) # val_step 也是的一样逻辑 def val_step(self, *inputs, **kwargs):     inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)     # 此时才是调用 model 本身的 val_step     return self.module.val_step(*inputs[0], **kwargs[0])</code></pre><p>可以发现，在调用 model 本身的 train_step 前，需要额外调用 scatter 函数，前面说过该函数的作用是处理 DataContainer 格式数据，使其能够组成 batch，否则程序会报错。 </p><p>如果是分布式训练，则调用的实际上是 <code>mmcv/parallel/distributed.py/MMDistributedDataParallel</code>，最终调用的依然是 model 本身的 <code>train_step</code> 或者 <code>val_step</code>。 </p><p><strong>(2) 调用 model 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>训练流程： </p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/BaseDetector ============= def train_step(self, data, optimizer):     # 调用本类自身的 forward 方法     losses = self(**data)     # 解析 loss     loss, log_vars = self._parse_losses(losses)     # 返回字典对象     outputs = dict(         loss=loss, log_vars=log_vars, num_samples=len(data[&#39;img_metas&#39;]))     return outputs #=================== mmdet/models/detectors/base.py/Base3DDetector =========== # Base3DDetector 主要是重写了 forward，改变了模型输入数据的类型，可同时传入点云数据和图片数据，从而满足多模态检测的需求 @auto_fp16(apply_to=(&#39;img&#39;, &#39;points&#39;)) def forward(self, return_loss=True, **kwargs):     if return_loss:         # 训练模式         return self.forward_train(**kwargs)     else:         # 测试模式         return self.forward_test(**kwargs)</code></pre><p><code>forward_train</code> 和 <code>forward_test</code> 需要在不同的算法子类中实现，输出是 Loss 或者 预测结果。 </p><p><strong>(3) 调用子类中的 <code>forward_train</code> 方法</strong> </p><p>PointPillars 采用的是 VoxelNet 检测器，核心逻辑还是比较通用的。 </p><pre><code class="lang-python">#============= mmdet/models/detectors/voxelnet.py/VoxelNet ============ def forward_train(self,                   points,                   img_metas,                   gt_bboxes_3d,                   gt_labels_3d,                   gt_bboxes_ignore=None):     # 先进行点云的特征提取       x = self.extract_feat(points, img_metas)     # 主要是调用 bbox_head 内部的 forward_train 方法，得到 head 输出     outs = self.bbox_head(x)     loss_inputs = outs + (gt_bboxes_3d, gt_labels_3d, img_metas)     # 将 head 部分的输出和数据的 label 送入计算 loss     losses = self.bbox_head.loss(         *loss_inputs, gt_bboxes_ignore=gt_bboxes_ignore)     return losses</code></pre><p><strong>(4) 调用 model 中的 <code>_parse_losses</code> 方法</strong></p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/BaseDetector ================== def _parse_losses(self, losses):     # 返回来的 losses 是一个dict, 我们需要对 loss 进行求和     log_vars = OrderedDict()     for loss_name, loss_value in losses.items():         if isinstance(loss_value, torch.Tensor):             log_vars[loss_name] = loss_value.mean()         elif isinstance(loss_value, list):             log_vars[loss_name] = sum(_loss.mean() for _loss in loss_value)         else:             raise TypeError(                 f&#39;&#123;loss_name&#125; is not a tensor or list of tensors&#39;)     loss = sum(_value for _key, _value in log_vars.items()                if &#39;loss&#39; in _key)     log_vars[&#39;loss&#39;] = loss     for loss_name, loss_value in log_vars.items():         # reduce loss when distributed training         if dist.is_available() and dist.is_initialized():             loss_value = loss_value.data.clone()             dist.all_reduce(loss_value.div_(dist.get_world_size()))         log_vars[loss_name] = loss_value.item()     return loss, log_vars</code></pre><h3 id="6-2-test流程"><a href="#6-2-test流程" class="headerlink" title="6.2 test流程"></a>6.2 test流程</h3><p><img src="https://pic1.zhimg.com/80/v2-b80193d8d2bd66015ebd5aedaa9c5b14_720w.webp" alt=""></p><p>test 流程如上图所示， 我们可以看见在 test 的时候流程相比 train / val 更为简单，没有调用 runner 对象。 </p><p><strong>(1) 调用 model 中的 <code>forward_test</code></strong> </p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/Base3DDetector =========== def forward_test(self, points, img_metas, img=None, **kwargs):     num_augs = len(points)     if num_augs != len(img_metas):         raise ValueError(             &#39;num of augmentations (&#123;&#125;) != num of image meta (&#123;&#125;)&#39;.format(                 len(points), len(img_metas)))     # 根据 points list 长度判断是 simple_test 还是 aug_test     if num_augs == 1:         img = [img] if img is None else img         return self.simple_test(points[0], img_metas[0], img[0], **kwargs)     else:         return self.aug_test(points, img_metas, img, **kwargs)</code></pre><p><strong>(2) 调用子类 的 <code>simple_test</code> 或 <code>aug_test</code></strong> </p><pre><code class="lang-python">#============= mmdet/models/detectors/voxelnet.py/VoxelNet ============ def simple_test(self, points, img_metas, imgs=None, rescale=False):     # 无数据增强测试     # 提取特征     x = self.extract_feat(points, img_metas)     # 调用 head      outs = self.bbox_head(x)     # 根据 head 输出结果生成 bboxes     bbox_list = self.bbox_head.get_bboxes(         *outs, img_metas, rescale=rescale)     # 对检测结果进行格式调整     bbox_results = [         bbox3d2result(bboxes, scores, labels)         for bboxes, scores, labels in bbox_list     ]     return bbox_results def aug_test(self, points, img_metas, imgs=None, rescale=False):     # 数据增强测试     feats = self.extract_feats(points, img_metas)     # 目前只支持单个 sample 的 aug_test     aug_bboxes = []     for x, img_meta in zip(feats, img_metas):         outs = self.bbox_head(x)         bbox_list = self.bbox_head.get_bboxes(             *outs, img_meta, rescale=rescale)         bbox_list = [             dict(boxes_3d=bboxes, scores_3d=scores, labels_3d=labels)             for bboxes, scores, labels in bbox_list         ]         aug_bboxes.append(bbox_list[0])     # 将增强后的 bboxes 进行 merge 合并操作     merged_bboxes = merge_aug_bboxes_3d(aug_bboxes, img_metas,                                         self.bbox_head.test_cfg)     return [merged_bboxes]</code></pre><p> 以上我们主要分析了整体的框架流程。</p>]]></content>
      
      
      
        <tags>
            
            <tag> BEV </tag>
            
            <tag> MMDetection3D </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmdetection整体构建流程</title>
      <link href="/2023/11/15/mmdetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/"/>
      <url>/2023/11/15/mmdetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection-整体构建流程"><a href="#MMDetection-整体构建流程" class="headerlink" title="MMDetection 整体构建流程"></a>MMDetection 整体构建流程</h1><h2 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、摘要</h2><p>众所周知，目标检测算法比较复杂，细节比较多，难以复现，而我们推出的 MMDetection 开源框架则希望解决上述问题。目前  MMdetection 已经复现了大部分主流和前沿模型，例如 Faster R-CNN 系列、Mask R-CNN 系列、YOLO  系列和比较新的 DETR 等等，模型库非常丰富，star 接近 13k，在学术研究和工业落地中应用非常广泛。</p><p>本文主要是从整体框架构建角度来解析，不会涉及到具体算法和代码，希望通过本文讲解：</p><ul><li>MMDetection 整体构建流程和思想</li><li>目标检测算法核心组件划分</li><li>目标检测核心组件功能</li></ul><h2 id="二、目标检测算法抽象流程"><a href="#二、目标检测算法抽象流程" class="headerlink" title="二、目标检测算法抽象流程"></a>二、目标检测算法抽象流程</h2><p>按照目前目标检测的发展，可以大概归纳为如下所示： </p><p><img src="https://pic1.zhimg.com/80/v2-23f3f33d5ed5792e7ad55e559a6798fc_720w.webp" alt="img"></p><p>注意上面仅仅写了几个典型算法而已，简单来说目标检测算法可以按照 3 个维度划分：</p><ul><li><strong>按照 stage 个数划分</strong>，常规是 one-stage 和 two-stage，但是实际上界限不是特别清晰，例如带 refine 阶段的算法  RepPoints，实际上可以认为是1.5 stage 算法，而 Cascade R-CNN  可以认为是多阶段算法，为了简单，上面图示没有划分如此细致</li><li><strong>按照是否需要预定义 anchor 划分</strong>，常规是 anchor-based 和 anchor-free，当然也有些算法是两者混合的</li><li><strong>按照是否采用了 transformer 结构划分</strong>，目前基于 transformer 结构的目标检测算法发展迅速，也引起了极大的关注，所以这里特意增加了这个类别的划分</li></ul><p>不管哪种划分方式，其实都可以分成若干固定模块，然后通过模块堆叠来构建整个检测算法体系。</p><h2 id="三、MMDetection整体构建流程和思想"><a href="#三、MMDetection整体构建流程和思想" class="headerlink" title="三、MMDetection整体构建流程和思想"></a>三、MMDetection整体构建流程和思想</h2><p>基于目前代码实现，所有目标检测算法都按照以下流程进行划分： </p><p><img src="https://pic1.zhimg.com/80/v2-7ecc8e5e19c59a3e6682c5e3cdc34918_720w.webp" alt="img"></p><p>上述流程对应 MMDetection 代码构建流程，理解每个组件的作用不仅仅对阅读算法源码有帮助，而且还能够快速理解新提出算法对应的改进部分。下面对每个模块进行详细解读。</p><h3 id="3-1-训练核心组件"><a href="#3-1-训练核心组件" class="headerlink" title="3.1 训练核心组件"></a>3.1 训练核心组件</h3><p>训练部分一般包括 9 个核心组件，总体流程是：</p><ol><li>任何一个 batch 的图片先输入到 backbone 中进行特征提取，典型的骨干网络是 ResNet</li><li>输出的单尺度或者多尺度特征图输入到 neck 模块中进行特征融合或者增强，典型的 neck 是 FPN</li><li>上述多尺度特征最终输入到 head 部分，一般都会包括分类和回归分支输出</li><li>在整个网络构建阶段都可以引入一些即插即用增强算子来增加提取提取能力，典型的例如 SPP、DCN 等等</li><li>目标检测 head 输出一般是特征图，对于分类任务存在严重的正负样本不平衡，可以通过正负样本属性分配和采样控制</li><li>为了方便收敛和平衡多分支，一般都会对 gt bbox 进行编码</li><li>最后一步是计算分类和回归 loss，进行训练</li><li>在训练过程中也包括非常多的 trick，例如优化器选择等，参数调节也非常关键</li></ol><p>注意上述 9 个组件不是每个算法都需要的，下面详细分析。</p><h4 id="3-1-1-Backbone"><a href="#3-1-1-Backbone" class="headerlink" title="3.1.1 Backbone"></a>3.1.1 Backbone</h4><p><img src="https://pic2.zhimg.com/80/v2-cdee2bd9f289d650ddbcbd748c4be0f9_720w.webp" alt="img"></p><p>backbone 作用主要是特征提取。目前 MMDetection 中已经集成了大部分骨架网络，具体见文件：<code>mmdet/models/backbones</code>，V2.7 已经实现的骨架如下：</p><pre><code class="lang-python">__all__ = [    &#39;RegNet&#39;, &#39;ResNet&#39;, &#39;ResNetV1d&#39;, &#39;ResNeXt&#39;, &#39;SSDVGG&#39;, &#39;HRNet&#39;, &#39;Res2Net&#39;,    &#39;HourglassNet&#39;, &#39;DetectoRS_ResNet&#39;, &#39;DetectoRS_ResNeXt&#39;, &#39;Darknet&#39;,    &#39;ResNeSt&#39;, &#39;TridentResNet&#39;]</code></pre><p>最常用的是 ResNet 系列、ResNetV1d 系列和 Res2Net 系列。如果你需要对骨架进行扩展，可以继承上述网络，然后通过注册器机制注册使用。一个典型用法为：</p><pre><code class="lang-python"># 骨架的预训练权重路径pretrained=&#39;torchvision://resnet50&#39;,backbone=dict(    type=&#39;ResNet&#39;, # 骨架类名，后面的参数都是该类的初始化参数    depth=50,    num_stages=4,    out_indices=(0, 1, 2, 3),    frozen_stages=1,    norm_cfg=dict(type=&#39;BN&#39;, requires_grad=True),     norm_eval=True,    style=&#39;pytorch&#39;),</code></pre><p>通过 MMCV 中的注册器机制，你可以通过 dict 形式的配置来实例化任何已经注册的类，非常方便和灵活。</p><h4 id="3-1-2-Neck"><a href="#3-1-2-Neck" class="headerlink" title="3.1.2 Neck"></a>3.1.2 Neck</h4><p><img src="https://pic1.zhimg.com/80/v2-f0975c00a32fa03a80860f9c09234bbc_720w.webp" alt="img"></p><p>neck 可以认为是 backbone 和 head 的连接层，主要负责对 backbone 的特征进行高效融合和增强，能够对输入的单尺度或者多尺度特征进行融合、增强输出等。具体见文件：<code>mmdet/models/necks</code>，V2.7 已经实现的 neck 如下：</p><pre><code class="lang-python">__all__ = [    &#39;FPN&#39;, &#39;BFP&#39;, &#39;ChannelMapper&#39;, &#39;HRFPN&#39;, &#39;NASFPN&#39;, &#39;FPN_CARAFE&#39;, &#39;PAFPN&#39;,    &#39;NASFCOS_FPN&#39;, &#39;RFP&#39;, &#39;YOLOV3Neck&#39;]</code></pre><p>最常用的应该是 FPN，一个典型用法是：</p><pre><code class="lang-python">neck=dict(    type=&#39;FPN&#39;,    in_channels=[256, 512, 1024, 2048], # 骨架多尺度特征图输出通道    out_channels=256, # 增强后通道输出    num_outs=5), # 输出num_outs个多尺度特征图</code></pre><h4 id="3-1-3-Head"><a href="#3-1-3-Head" class="headerlink" title="3.1.3 Head"></a>3.1.3 Head</h4><p><img src="https://pic2.zhimg.com/80/v2-fdd9a6232e62c75b143153dab8ba9bc1_720w.webp" alt="img"></p><p>目标检测算法输出一般包括分类和框坐标回归两个分支，不同算法 head 模块复杂程度不一样，灵活度比较高。在网络构建方面，理解目标检测算法主要是要理解 head 模块。</p><p>MMDetection 中 head 模块又划分为 two-stage 所需的 RoIHead 和 one-stage 所需的 DenseHead，也就是说所有的 one-stage 算法的 head 模块都在<code>mmdet/models/dense_heads</code>中，而 two-stage 算法还包括额外的<code>mmdet/models/roi_heads</code>。</p><p>目前 V2.7 中已经实现的 dense_heads 包括：</p><pre><code class="lang-python">__all__ = [    &#39;AnchorFreeHead&#39;, &#39;AnchorHead&#39;, &#39;GuidedAnchorHead&#39;, &#39;FeatureAdaption&#39;,    &#39;RPNHead&#39;, &#39;GARPNHead&#39;, &#39;RetinaHead&#39;, &#39;RetinaSepBNHead&#39;, &#39;GARetinaHead&#39;,    &#39;SSDHead&#39;, &#39;FCOSHead&#39;, &#39;RepPointsHead&#39;, &#39;FoveaHead&#39;,    &#39;FreeAnchorRetinaHead&#39;, &#39;ATSSHead&#39;, &#39;FSAFHead&#39;, &#39;NASFCOSHead&#39;,    &#39;PISARetinaHead&#39;, &#39;PISASSDHead&#39;, &#39;GFLHead&#39;, &#39;CornerHead&#39;, &#39;YOLACTHead&#39;,    &#39;YOLACTSegmHead&#39;, &#39;YOLACTProtonet&#39;, &#39;YOLOV3Head&#39;, &#39;PAAHead&#39;,    &#39;SABLRetinaHead&#39;, &#39;CentripetalHead&#39;, &#39;VFNetHead&#39;, &#39;TransformerHead&#39;]</code></pre><p>几乎每个算法都包括一个独立的 head，而 roi_heads 比较杂，就不列出了。</p><p>需要注意的是：<strong>two-stage 或者 mutli-stage 算法，会额外包括一个区域提取器 roi extractor，用于将不同大小的 RoI 特征图统一成相同大小</strong>。</p><p>虽然 head 部分的网络构建比较简单，但是由于正负样本属性定义、正负样本采样和 bbox 编解码模块都在 head 模块中进行组合调用，故 MMDetection <strong>中最复杂的模块就是 head</strong>。在最后的整体流程部分会对该模块进行详细分析。</p><h4 id="3-1-4-Enhance"><a href="#3-1-4-Enhance" class="headerlink" title="3.1.4 Enhance"></a>3.1.4 Enhance</h4><p><img src="https://pic3.zhimg.com/80/v2-65a706efe224f0b7ffc7f4fd7a65f2ca_720w.webp" alt="img"></p><p>enhance 是即插即用、能够对特征进行增强的模块，其具体代码可以通过 dict 形式注册到 backbone、neck 和 head  中，非常方便(目前还不完善)。常用的 enhance 模块是 SPP、ASPP、RFB、Dropout、Dropblock、DCN  和各种注意力模块 SeNet、Non_Local、CBA 等。目前 MMDetection 中部分模块支持 enhance 的接入，例如  ResNet 骨架中的 plugins。</p><h4 id="3-1-5-BBox-Assigner"><a href="#3-1-5-BBox-Assigner" class="headerlink" title="3.1.5 BBox Assigner"></a>3.1.5 BBox Assigner</h4><p>正负样本属性分配模块作用是进行正负样本定义或者正负样本分配（可能也包括忽略样本定义），正样本就是常说的前景样本（可以是任何类别），负样本就是背景样本。因为目标检测是一个同时进行分类和回归的问题，对于分类场景必然需要确定正负样本，否则无法训练。该模块至关重要，不同的正负样本分配策略会带来显著的性能差异，目前大部分目标检测算法都会对这个部分进行改进，至关重要。一些典型的分配策略如下：</p><p><img src="https://pic3.zhimg.com/80/v2-12bae70e2ea2e4afb05d0d8d3f38ca56_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/core/bbox/assigners</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;BaseAssigner&#39;, &#39;MaxIoUAssigner&#39;, &#39;ApproxMaxIoUAssigner&#39;,     &#39;PointAssigner&#39;, &#39;ATSSAssigner&#39;, &#39;CenterRegionAssigner&#39;, &#39;GridAssigner&#39;,    &#39;HungarianAssigner&#39;]</code></pre><h4 id="3-1-6-BBox-Sampler"><a href="#3-1-6-BBox-Sampler" class="headerlink" title="3.1.6 BBox Sampler"></a>3.1.6 BBox Sampler</h4><p>在确定每个样本的正负属性后，可能还需要进行样本平衡操作。本模块作用是对前面定义的正负样本不平衡进行采样，力争克服该问题。一般在目标检测中 gt bbox 都是非常少的，所以正负样本比是远远小于 1  的。而基于机器学习观点：在数据极度不平衡情况下进行分类会出现预测倾向于样本多的类别，出现过拟合，为了克服该问题，适当的正负样本采样策略是非常必要的，一些典型采样策略如下：</p><p><img src="https://pic4.zhimg.com/80/v2-91674a0710afadfd06a9ebd139f875fb_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/core/bbox/samplers</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;BaseSampler&#39;, &#39;PseudoSampler&#39;, &#39;RandomSampler&#39;,    &#39;InstanceBalancedPosSampler&#39;, &#39;IoUBalancedNegSampler&#39;, &#39;CombinedSampler&#39;,    &#39;OHEMSampler&#39;, &#39;SamplingResult&#39;, &#39;ScoreHLRSampler&#39;]</code></pre><h4 id="3-1-7-BBox-Encoder"><a href="#3-1-7-BBox-Encoder" class="headerlink" title="3.1.7 BBox Encoder"></a>3.1.7 BBox Encoder</h4><p>为了更好的收敛和平衡多个 loss，具体解决办法非常多，而 bbox 编解码策略也算其中一个，bbox 编码阶段对应的是对正样本的 gt bbox  采用某种编码变换（反操作就是 bbox 解码），最简单的编码是对 gt bbox  除以图片宽高进行归一化以平衡分类和回归分支，一些典型的编解码策略如下：</p><p><img src="https://pic4.zhimg.com/80/v2-1f8d5e5e45886423df474d168452f50b_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/core/bbox/coder</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;BaseBBoxCoder&#39;, &#39;PseudoBBoxCoder&#39;, &#39;DeltaXYWHBBoxCoder&#39;,    &#39;LegacyDeltaXYWHBBoxCoder&#39;, &#39;TBLRBBoxCoder&#39;, &#39;YOLOBBoxCoder&#39;,    &#39;BucketingBBoxCoder&#39;]</code></pre><h4 id="3-1-8-Loss"><a href="#3-1-8-Loss" class="headerlink" title="3.1.8 Loss"></a>3.1.8 Loss</h4><p>Loss 通常都分为分类和回归 loss，其对网络 head 输出的预测值和 bbox encoder 得到的 targets 进行梯度下降迭代训练。</p><p>loss 的设计也是各大算法重点改进对象，常用的 loss 如下：</p><p><img src="https://pic4.zhimg.com/80/v2-686b0b9ac6a82f9945ae454d18783227_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/models/losses</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;cross_entropy&#39;, &#39;binary_cross_entropy&#39;,    &#39;mask_cross_entropy&#39;, &#39;CrossEntropyLoss&#39;, &#39;sigmoid_focal_loss&#39;,    &#39;FocalLoss&#39;, &#39;smooth_l1_loss&#39;, &#39;SmoothL1Loss&#39;, &#39;balanced_l1_loss&#39;,    &#39;BalancedL1Loss&#39;, &#39;mse_loss&#39;, &#39;MSELoss&#39;, &#39;iou_loss&#39;, &#39;bounded_iou_loss&#39;,    &#39;IoULoss&#39;, &#39;BoundedIoULoss&#39;, &#39;GIoULoss&#39;, &#39;DIoULoss&#39;, &#39;CIoULoss&#39;, &#39;GHMC&#39;,    &#39;GHMR&#39;, &#39;reduce_loss&#39;, &#39;weight_reduce_loss&#39;, &#39;weighted_loss&#39;, &#39;L1Loss&#39;,    &#39;l1_loss&#39;, &#39;isr_p&#39;, &#39;carl_loss&#39;, &#39;AssociativeEmbeddingLoss&#39;,    &#39;GaussianFocalLoss&#39;, &#39;QualityFocalLoss&#39;, &#39;DistributionFocalLoss&#39;,    &#39;VarifocalLoss&#39;]</code></pre><p>可以看出 MMDetection 中已经实现了非常多的 loss，可以直接使用。</p><h4 id="3-1-9-Training-tricks"><a href="#3-1-9-Training-tricks" class="headerlink" title="3.1.9 Training tricks"></a>3.1.9 Training tricks</h4><p>训练技巧非常多，常说的调参很大一部分工作都是在设置这部分超参。这部分内容比较杂乱，很难做到完全统一，目前主流的 tricks 如下所示:</p><p><img src="https://pic3.zhimg.com/80/v2-569a12b6d4a20f8619a27b48d5b2fa42_720w.webp" alt="img"></p><p>MMDetection 目前这部分还会继续完善，也欢迎大家一起贡献。</p><h3 id="3-2-测试核心组件"><a href="#3-2-测试核心组件" class="headerlink" title="3.2 测试核心组件"></a>3.2 测试核心组件</h3><p>测试核心组件和训练非常类似，但是简单很多，除了必备的网络构建部分外( backbone、neck、head 和 enhance )，不需要正负样本定义、正负样本采样和 loss  计算三个最难的部分，但是其额外需要一个 bbox 后处理模块和测试 trick。</p><h4 id="3-2-1-BBox-Decoder"><a href="#3-2-1-BBox-Decoder" class="headerlink" title="3.2.1 BBox Decoder"></a>3.2.1 BBox Decoder</h4><p>训练时候进行了编码，那么对应的测试环节需要进行解码。根据编码的不同，解码也是不同的。举个简单例子：假设训练时候对宽高是直接除以图片宽高进行归一化的，那么解码过程也仅仅需要乘以图片宽高即可。其代码和 bbox encoder 放在一起，在<code>mmdet/core/bbox/coder</code>中。</p><h4 id="3-2-2-BBox-PostProcess"><a href="#3-2-2-BBox-PostProcess" class="headerlink" title="3.2.2 BBox PostProcess"></a>3.2.2 BBox PostProcess</h4><p>在得到原图尺度 bbox 后，由于可能会出现重叠 bbox 现象，故一般都需要进行后处理，最常用的后处理就是非极大值抑制以及其变种。</p><p>其对应的文件在<code>mmdet/core/post_processing</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;multiclass_nms&#39;, &#39;merge_aug_proposals&#39;, &#39;merge_aug_bboxes&#39;,    &#39;merge_aug_scores&#39;, &#39;merge_aug_masks&#39;, &#39;fast_nms&#39;]</code></pre><h4 id="3-2-3-Testing-tricks"><a href="#3-2-3-Testing-tricks" class="headerlink" title="3.2.3 Testing tricks"></a>3.2.3 Testing tricks</h4><p>为了提高检测性能，测试阶段也会采用 trick。这个阶段的 tricks 也非常多，难以完全统一，最典型的是多尺度测试以及各种模型集成手段，典型配置如下：</p><pre><code class="lang-python">dict(    type=&#39;MultiScaleFlipAug&#39;,    img_scale=(1333, 800),    flip=True,    transforms=[        dict(type=&#39;Resize&#39;, keep_ratio=True),        dict(type=&#39;RandomFlip&#39;),        dict(type=&#39;Normalize&#39;, **img_norm_cfg),        dict(type=&#39;Pad&#39;, size_divisor=32),        dict(type=&#39;ImageToTensor&#39;, keys=[&#39;img&#39;]),        dict(type=&#39;Collect&#39;, keys=[&#39;img&#39;]),    ])</code></pre><p><img src="https://pic3.zhimg.com/80/v2-16e307727f0c3e941ec72c21f214b982_720w.webp" alt="img"></p><h3 id="3-3-训练测试算法流程"><a href="#3-3-训练测试算法流程" class="headerlink" title="3.3 训练测试算法流程"></a>3.3 训练测试算法流程</h3><p>在分析完每个训练流程的各个核心组件后，为了方便大家理解整个算法构建，下面分析 MMDetection 是如何组合各个组件进行训练的，这里以 one-stage 检测器为例，two-stage 也比较类似。</p><pre><code class="lang-python">class SingleStageDetector(---):   def __init__(...):        # 构建骨架、neck和head        self.backbone = build_backbone(backbone)        if neck is not None:            self.neck = build_neck(neck)        self.bbox_head = build_head(bbox_head)  def forward_train(---):         # 先运行backbone+neck进行特征提取        x = self.extract_feat(img)        # 对head进行forward train，输出loss        losses = self.bbox_head.forward_train(x, img_metas, gt_bboxes,                                              gt_labels, gt_bboxes_ignore)        return losses  def simple_test(---):        # 先运行backbone+neck进行特征提取        x = self.extract_feat(img)        # head输出预测特征图        outs = self.bbox_head(x)        # bbox解码和还原        bbox_list = self.bbox_head.get_bboxes(            *outs, img_metas, rescale=rescale)        # 重组结果返回        bbox_results = [            bbox2result(det_bboxes, det_labels, self.bbox_head.num_classes)            for det_bboxes, det_labels in bbox_list        ]        return bbox_results</code></pre><p>以上就是整个检测器算法训练和测试最简逻辑，可以发现训练部分最核心的就是<code>bbox_head.forward_train</code>，测试部分最核心的是<code>bbox_head.get_bboxes</code>，下面单独简要分析。</p><h4 id="3-3-1-bbox-head-forward-train"><a href="#3-3-1-bbox-head-forward-train" class="headerlink" title="3.3.1 bbox_head.forward_train"></a>3.3.1 bbox_head.forward_train</h4><p>forward_train 是通用函数，如下所示：</p><pre><code class="lang-python">def forward_train(...):    # 调用每个head自身的forward方法    outs = self(x)    if gt_labels is None:        loss_inputs = outs + (gt_bboxes, img_metas)    else:        loss_inputs = outs + (gt_bboxes, gt_labels, img_metas)    # 计算每个head自身的loss方法    losses = self.loss(*loss_inputs, gt_bboxes_ignore=gt_bboxes_ignore)    # 返回    return losses</code></pre><p>对于不同的 head，虽然 forward 内容不一样，但是依然可以抽象为： <code>outs = self(x)</code></p><pre><code class="lang-python">def forward(self, feats):   # 多尺度特征图，一个一个迭代进行forward_single   return multi_apply(self.forward_single, feats)def forward_single(self, x):   # 运行各个head独特的head forward方法，得到预测图   ....   return cls_score, bbox_pred...</code></pre><p>而对于不同的 head，其 loss 计算部分也比较复杂，可以简单抽象为：<code>losses = self.loss(...)</code></p><pre><code class="lang-python">def loss(...):    # 1 生成anchor-base需要的anchor或者anchor-free需要的points    # 2 利用gt bbox对特征图或者anchor计算其正负和忽略样本属性    # 3 进行正负样本采样    # 4 对gt bbox进行bbox编码    # 5 loss计算，并返回    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox,...)</code></pre><h4 id="3-3-2-bbox-head-get-bboxes"><a href="#3-3-2-bbox-head-get-bboxes" class="headerlink" title="3.3.2 bbox_head.get_bboxes"></a>3.3.2 bbox_head.get_bboxes</h4><p>get_bboxes函数更加简单</p><pre><code class="lang-python">def get_bboxes(...):   # 1 生成anchor-base需要的anchor或者anchor-free需要的points   # 2 遍历每个输出层，遍历batch内部的每张图片，对每张图片先提取指定个数的预测结果，缓解后面后处理压力；对保留的位置进行bbox解码和还原到原图尺度   # 3 统一nms后处理   return det_bboxes, det_labels...</code></pre><h2 id="四、-总结"><a href="#四、-总结" class="headerlink" title="四、 总结"></a>四、 总结</h2><p>本文重点分析了一个目标检测器是如何通过多个核心组件堆叠而成，不涉及具体代码，大家只需要总体把握即可，其中最应该了解的是：<strong>任何一个目标检测算法都可以分成 n 个核心组件，组件和组件之间是隔离的，方便复用和设计</strong>。当面对一个新算法时候我们可以先分析其主要是改进了哪几个核心组件，然后就可以高效的掌握该算法。</p><p>最后附上总图： </p><p><img src="https://pic3.zhimg.com/80/v2-c4e6229a1fd42692d090108481be34a6_720w.webp" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> BEV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention:从NLP到CV再到BEV</title>
      <link href="/2023/11/09/Attention:%E4%BB%8ENLP%E5%88%B0CV%E5%86%8D%E5%88%B0BEV/"/>
      <url>/2023/11/09/Attention:%E4%BB%8ENLP%E5%88%B0CV%E5%86%8D%E5%88%B0BEV/</url>
      
        <content type="html"><![CDATA[<p>一、Transformer</p><p>Transformer源于17年谷歌的文章Attention Is All You Need“”</p><p><img src="https://picx.zhimg.com/80/v2-d44557c723b7b8ed46ea9affe4f2e926_720w.webp?source=2c26e567" style="zoom:67%;"></p><p>Transformer最开始应用于NLP领域的机器翻译任务。</p><p>它是一个编码器-解码器结构：编码器将原始语言的句子作为输入并生成基于注意力的表征，解码器则关注编码信息并以自回归方式生成翻译的句子。</p><p><img src="https://picx.zhimg.com/80/v2-f3374bc9c9556a7cdf076b48c64e4303_720w.webp?source=2c26e567" alt=""></p><p>Transformer中最重要的是Attention机制。</p><p>Attention（注意力）机制如果浅层的理解，跟他的名字非常匹配。他的核心逻辑就是「<strong>从关注全部到关注重点</strong>」。</p><p><img src="https://pic1.zhimg.com/80/v2-9e9e42cf4de1cfa1851c0bb7e7f0d8c4_720w.jpg" alt=""></p><p><strong>Attention机制的实质其实就是一个寻址（addressing）的过程</strong>，如下图所示：给定一个和任务相关的查询<strong>Query</strong>向量 <strong>q</strong>，通过计算与<strong>Key</strong>的注意力分布并附加在<strong>Value</strong>上，从而计算<strong>Attention Value</strong>，这个过程实际上是<strong>Attention机制缓解神经网络模型复杂度的体现</strong>：不需要将所有的N个输入信息都输入到神经网络进行计算，只需要从X中选择一些和任务相关的信息输入给神经网络。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3724c8a2bee76f326f78f18c5d3fa4da.webp?x-oss-process=image/format,png" alt=""></p><p>举个例子：</p><p><img src="https://pic2.zhimg.com/80/v2-f5cbf9efc7a017b02d00e946dda8360d_720w.webp" alt=""></p><p>图书管（source）里有很多书（value），为了方便查找，我们给书做了编号（key）。当我们想要了解漫威（query）的时候，我们就可以看看那些动漫、电影、甚至二战（美国队长）相关的书籍。</p><p>为了提高效率，并不是所有的书都会仔细看，针对漫威来说，动漫，电影相关的会看的仔细一些（权重高），但是二战的就只需要简单扫一下即可（权重低）。</p><p>当我们全部看完后就对漫威有一个全面的了解了。</p><p><strong>Attention 原理的3步分解：</strong></p><p>第一步： query 和 key 进行相似度计算，得到权值</p><p>第二步：将权值进行归一化，得到直接可用的权重</p><p>第三步：将权重和 value 进行加权求和</p><p><img src="https://img-blog.csdnimg.cn/6c2d4a4226944090bec7dad2b22c0caf.png" alt=""></p><p>self-attention</p><p>寻找一段文本内部不同部分之间的关系来构建这段文本的表征。</p><p><img src="https://pic2.zhimg.com/80/v2-cbc7e56ea862be44515d5f56e2f6ce71_720w.webp" alt=""></p><p>上图显示的就是当算法处理到红色字的表征时，它应该给文中其他文字的表征多大的注意力权重。</p><hr><p>Transformers目标检测，端到端的DETR</p><p><img src="https://pic1.zhimg.com/80/v2-772984ccd82a0e0a279ea6a09c3c34c0_720w.webp" alt=""></p><p>DETR摒弃了以往的生成Anchors和NMS环节，我们知道，生成Anchors即为生成一系列的框，再由CNN判断框内是否有目标及其对应的类别，而NMS则是将多余重复的框删减掉。而DETR将目标检测视为集合预测的问题，也即预测最终所需的各个目标的框及类别。直白点，就是希望通过向网络输入图片，让网络直接输出物体最终的框及其类别，这样便少了生成Anchors及NMS的环节。</p><p>这篇文章让网络生成固定数量N（原文N取100）个预测，每个预测都包含一个框及其类别。但不同于以往可能有多个预测是属于同一物体（也即得通过NMS来消除框），这里的预测，对于图片上的每个物体有且仅有一个框与之对应，而对于多于的预测，则直接归为背景类（no object）。</p><p>如上图，大概流程为，先将图片通过CNN提取特征，再通过transformer直接输出固定数量为N（原文中N取100，而N则是远大于一张图片中包含的物体数量）的预测框及其类别（不再有Anchors生成以及NMS环节）。而这N个框，每个框要么与物体唯一对应，要么直接归为背景类（no object）。假设我们现在有一张图片，图片上有2个物体，则最终预测的100个框中，将有2个为物体框，剩余的98个为背景框（不会输出）。</p><p><img src="https://pic4.zhimg.com/v2-3d43474df51c545ad6bafc19b3c8ccc3_r.jpg" alt=""></p><p>下图为最后一个Encoder Layer的attention可视化，Encoder已经分离了instances，简化了Decoder的对象提取和定位。</p><p><img src="https://pic3.zhimg.com/80/v2-dffe148c6e78f7b67cf6aa5c8bbbc316_720w.webp" alt=""></p><p>类似于可视化编码器注意力，作者在下图中可视化解码器注意力，用不同的颜色给每个预测对象的注意力图着色。观察到，解码器的attention相当局部，这意味着它主要关注对象的四肢，如头部或腿部。我们假设，在编码器通过全局关注分离实例之后，<strong>解码器只需要关注极端来提取类和对象边界。</strong></p><p><img src="https://pic1.zhimg.com/80/v2-6b80634bf88e496f035945ec25c40764_720w.webp" alt=""></p><p><strong>DETR模型弊端</strong></p><p>如果用10*10的特征图表示一张图片，即一张图片划分成100个Patch，那么就有100个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要100*100=10000次。</p><p>如果用100*100的特征图表示一张图片，即一张图片划分成10000个Patch，那么就有10000个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要10000*100000=1亿次。由此可见，每一个Patch的边长缩小10倍，计算量要增加一万倍。因为识别小物体有恰恰需要划分更小的Patch，因此DETR的小物体识别能力有限。<br>                                                      <img src="https://img-blog.csdnimg.cn/img_convert/065259c3a0e98a8e500c6f59db05fbab.png" style="zoom:36%;"></p><hr><p><strong>Transformer在BEV上的应用———BEVFormer</strong></p><p>其网络结构如下：</p><p><img src="https://pic2.zhimg.com/v2-65a11a98d73c1111bcc05e1f10848195_r.jpg" alt=""></p><p>Encoder模块包含了两个子模块：Temporal Self-Attention模块和Spatial Cross-Attention模块。</p><p>这两个模块都用到了一个组件———多尺度的可变性注意力模块，该模块是将Transformer的全局注意力变为局部注意力的一个非常关键的组件，用来减少训练时间，提高Transformer的收敛速度。</p><p>多尺度可变形注意力模块与Transformer中常见的先生成Attention Map，再计算加权和的方式不同；常规而言Attention Map = Query 和Key做内积运算，将Attention Map再和Value做加权；但是由于这种方式计算量开销会比较大，所以在Deformable DETR中用局部注意力机制代替了全局注意力机制，只对几个采样点进行采样，<strong>而采样点的位置对于参考点的偏移量和每个采样点在加权时的比重均是靠Query经过Linear层学习得到的。</strong></p><p>Temporal Self-Attention模块通过引入时序信息（History BEV）与当前时刻的BEV Query进行融合，提高BEV Query的建模能力。</p><p><img src="/home/haseka/Pictures/Spatial-Att.png" alt=""></p><p>Spatial Cross-Attention模块利用Temporal Self-Attention模块输出的<code>bev_query</code>，对主干网和Neck网络提取到的多尺度环视图像特征进行查询，生成BEV空间下的BEV Embedding特征</p><p><img src="/home/haseka/Pictures/bev_layout.png" alt=""></p><p>上述产生BEV特征的过程是用了当前输入到网络模型中除当前帧外，之前所有帧特征去迭代修正去获得pre_bev的特征；所以在利用decoder模块进行解码之前，需要对当前时刻环视的6张图片同样利用Backbone+Neck提取多尺度特征，再利用上述的 Temporal Self-Attention 模块和 Spatial Cross-Attention 模块的逻辑生成当前时刻的<code>bev_embedding</code>，然后将这部分特征送入到 Decoder 中进行 3D 目标检测。</p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention</title>
      <link href="/2023/11/09/Attention/"/>
      <url>/2023/11/09/Attention/</url>
      
        <content type="html"><![CDATA[<h2 id="一注意力机制attention">一、注意力机制：Attention</h2><h3 id="什么是注意力机制">1.1什么是注意力机制？</h3><p>我们先来看一张图片</p><p><img src="/home/haseka/Documents/hexo_blog/themes/butterfly/source/img/clannad.jpg"></p><p>那么，大家的目光是更多注意在美少女古河渚身上，还是花草风景身上呢？可能对于热爱动漫的人来说他会关注logo------CLANNAD1和主人公古河渚，对于喜欢花的人来说可能更关注樱花，对于喜欢制服的人来说可能更关注jk装......</p><p>再举几个例子：</p><ul><li>看人--&gt;看脸</li><li>看文章--&gt;看标题</li><li>看段落--&gt;看开头</li></ul><p><strong>注意力机制</strong>其实是源自于人对于外部信息的处理能力。由于每一时刻接受的信息都是无比庞大且复杂万分的，远远超过了人脑的处理能力，<font color="red">因此人在处理信息的时候，会将注意力放在需要关注的信息上，对于其他无关的外部信息进行过滤</font>，这种处理方式被称为注意力机制。</p><p>通俗而言，注意力对于人而言可以理解为“关注度”，对于没有感情的机器而言就是赋予多少权重（0-1间的小数），越重要的地方或者越相关的地方就赋予越高的权重。</p><hr><h3 id="如何运用注意力机制">1.2如何运用注意力机制？</h3><h4 id="querykey和value">1.2.1 Query、Key和Value</h4><p>首先，三者概念：</p><ul><li>查询（Query）：是指查询的范围，自主提示，即主观意识的特征向量</li><li>键（Key）：是被对比的项，非自主提示，即物体的突然出特征信息向量</li><li>值（Value）：是代表物体自身的特征向量，通常与Key成对出现</li></ul><p>注意力机制是通过Query与Key的注意力汇聚（给定一个Query，计算Query与Key的相关性，然后根据该相关性去找到最合适的Value）实现对Value的注意力权重分配，生成最终的输出结果。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3724c8a2bee76f326f78f18c5d3fa4da.webp?x-oss-process=image/format,png"></p><p>举例子而言：</p><ol type="1"><li>淘宝购物，输入关键词（男鞋），这个就是Query</li><li>搜素系统会根据这个关键词去查找一些列相关的Key（商品名、图片）</li><li>最后系统会将相应的Value（具体鞋子）返回给你</li></ol><p>上述例子中，Query，Key和Value的每个属性虽然在不同的空间，但其实它们是有一定的潜在关系，也就是说通过某种变换，可以使得三者的属性在一个相近的空间中。</p><hr><h4 id="注意力机制计算过程">1.2.2 注意力机制计算过程</h4><p>输入Query、Key、Value：</p><ul><li><p><strong>第一步：</strong>计算Query和Key间相似度（常见方法：点积、余弦相似度、MLP网络），得到注意力得分：</p><p>点积：<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="40.384ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 17849.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(990,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1868,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2213,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2511,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3040,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3491,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3836,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4197,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5076,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5867,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6439,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6905,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7356,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7846,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8290.7,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(9179.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(9645.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10462.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11129.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(12185.2,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(12976.2,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(13548.2,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(14014.2,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(14465.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(15177.4,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(15677.6,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(16566.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(17032.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span></p><p>Cosine 相似性： <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.238ex;" xmlns="http://www.w3.org/2000/svg" width="40.114ex" height="3.461ex" role="img" focusable="false" viewBox="0 -982.8 17730.5 1529.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(990,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1868,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2213,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2511,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3040,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3491,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3836,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4197,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5076,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5867,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6439,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6905,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7356,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7846,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8290.7,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(9179.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(9645.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10462.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11129.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(12185.2,0)"><g data-mml-node="mrow" transform="translate(927.1,485) scale(0.707)"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(791,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1363,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1829,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2280,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2770,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(3048,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(3937,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(4403,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-370.3) scale(0.707)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(1291,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1863,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(2329,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2780,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3270,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g></g><g data-mml-node="mo" transform="translate(3770,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mrow" transform="translate(4048,0)"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(1389,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(1855,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2672,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g></g></g><rect width="5305.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span></p><p>MLP网络<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="47.133ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 20832.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(990,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1868,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2213,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2511,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3040,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3491,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3836,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4197,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5076,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5867,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6439,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6905,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7356,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7846,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8290.7,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(9179.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(9645.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10462.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11129.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(12185.2,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(13236.2,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(13917.2,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(14668.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(15057.2,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(15848.2,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(16420.2,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(16886.2,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(17337.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(17827.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(18271.8,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(19160.8,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(19626.8,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(20443.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p></li><li><p><strong>第二步：</strong>对注意力得分进行缩放scale（除以维度的根号），再softmax()，一方面可以进行归一化，将原始计算分值整理成所有元素权重之和为1的概率分布；另一方面也可以通过softmax的内在机制更加突出重要元素的权重。一般采用如下公式计算：</p><p>​ <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.882ex;" xmlns="http://www.w3.org/2000/svg" width="32.339ex" height="4.152ex" role="img" focusable="false" viewBox="0 -1003.2 14294 1835"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1133.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2189.5,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(2834.5,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3319.5,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(3869.5,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4230.5,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5108.5,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5637.5,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6209.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6598.5,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(7243.5,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(7588.5,0)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(911,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(8793.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9460.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(10516,0)"><g data-mml-node="msup" transform="translate(1120.9,394) scale(0.707)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(990,0)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(911,-307.4)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-526.3) scale(0.707)"><g data-mml-node="munderover"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-287.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msup" transform="translate(2500.7,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,472.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(990,0)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(911,-307.4)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g><rect width="3537.9" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span></p></li><li><p><strong>第三步：</strong>根据权重系数对Value值进行加权求和，得到AttentionValue（此时的V是具有一些注意力信息的，更重要的信息更关注，不重要的信息被忽视了）</p><p>​ <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.777ex;" xmlns="http://www.w3.org/2000/svg" width="44.57ex" height="2.949ex" role="img" focusable="false" viewBox="0 -960 19699.9 1303.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(750,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1111,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1472,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1938,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2538,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(2899,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3244,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3729,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4329,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4718,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5509,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6081,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6547,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6998,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7488,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7932.7,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(8577.7,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(9062.7,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(9634.7,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(10085.7,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(10518.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(10984.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11651.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(12707.2,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msub" transform="translate(15160.5,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(16238.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(16738.9,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mi" transform="translate(17507.9,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(18036.9,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(18334.9,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(18906.9,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(499,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span></p></li></ul><p>这三个步可以用下图表示：</p><p><img src="https://img-blog.csdnimg.cn/6c2d4a4226944090bec7dad2b22c0caf.png"></p><hr><h2 id="二自注意力机制self-attention">二、自注意力机制：Self-Attention</h2><h3 id="什么是自注意力机制">2.1什么是自注意力机制</h3><p>自注意机制是注意力机制的一种，它要解决的实际问题是<font color="red">神经网络接收的输入是很多大小不一的向量，并且不同向量之间有一定的关系，但是实际训练的时候无法充分发挥这些输入之间的关系而导致模型训练结果效果极差。</font>比如，在语义分析中多个向量对应一个标签。</p><p>针对全连接神经网络对于多个相关的输入无法建立起相关性的这个问题，通过自注意力机制来解决，自注意力机制实际上是想让机器注意到<font color="red"><strong>整个输入中不同部分之间的相关性</strong></font>。</p><p>自注意力机制是注意力机制的变体，<font color="red">其减少了对外部信息的依赖，更擅长捕捉数据或特征的内部相关性。</font>自注意力机制的关键点在于，<font color="red">Q、K、V是同一个东西，或者三者来源于同一个X，三者同源。</font>通过X找到X里面的关键点，从而更关注X的关键信息，忽略X的不重要信息。<strong>不是输入语句与输出语句之间的注意力机制，而是输入语句内部元素之间或者输出语句内部元素之间发生的注意力机制。</strong></p><blockquote><p><font color="orange">注意力机制和自注意力机制的区别：</font></p><p>（1）注意力机制的Q和K是不同来源的，例如，在Encoder-Decoder模型中，K是Encoder中的元素，而Q是Decoder中的元素。在中译英模型中，Q是中文单词特征，而K则是英文单词特征。</p><p>（2）自注意力机制的Q和K则都是来自于同一组的元素，例如，在Encoder-Decoder模型中，Q和K都是Encoder中的元素，即Q和K都是中文特征，相互之间做注意力汇聚。也可以理解为同一句话中的词元或者同一张图像中不同的patch，这都是一组元素内部相互做注意力机制，因此，自注意力机制（self-attention）也被称为内部注意力机制（intra-attention）。</p></blockquote><hr><h3 id="如何运用自注意力机制">2.2如何运用自注意力机制</h3><p>大体上步骤和注意力机制是一样的。</p><p><strong>First：得到Q,K,V的值</strong></p><p>对于每一个向量x，分别乘上三个系数<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.408ex" height="2.37ex" role="img" focusable="false" viewBox="0 -853.7 5484.6 1047.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(1511.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1956.1,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mo" transform="translate(3510.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(3955.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g></g></g></svg></mjx-container></span>,得到的Q,K,V分别表示query，key和Value</p><p><img src="https://img-blog.csdnimg.cn/49fa756cd86b4d248baf53f91dec0521.jpeg"></p><p><strong>Second：Matmul</strong></p><p>利用得到的Q和K计算每两个向量之间的相关性，一般采用点积计算，为每个向量计算一个socre:sa:<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.084ex" height="2.009ex" role="img" focusable="false" viewBox="0 -694 5341 888"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(469,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(902,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1387,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1838,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(2581.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3637.6,0)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(4319.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(4820,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container></span></p><p><img src="https://img-blog.csdnimg.cn/9d4d3104ba0d4c82adb6662d74ef7234.jpeg"></p><p><strong>Third: Scale+Softmax</strong></p><p>将刚得到的相似度除以<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="0.036ex" height="0.036ex" role="img" focusable="false" viewBox="0 0 16 16"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"></g></g></svg></mjx-container>，再进行Softmax。经过Softmax的归一化后，每个值都是一个大于0且小于1的权重系数，且总和为1，这个结果可以被理解成一个权重矩阵。</p><p><img src="https://img-blog.csdnimg.cn/61cdd0e854ac45ef9314b962dc266e83.jpeg"></p><p><strong>Fourth：Matmul</strong></p><p>使用刚得到的权重矩阵，与V相乘，计算加权求和。</p><p><img src="https://img-blog.csdnimg.cn/9c6b21bb37334c8bbf1c6ee89d4b5ef9.jpeg"></p><p>以上是对ThinkingMachines这句话进行自注意力的全过程，最终得到z1和z2两个新向量。</p><p>其中z1表示的是thinking这个词向量的新的向量表示（通过thinking这个词向量，去查询和thinkingmachine这句话里面每个单词和thinking之间的相似度）。</p><p>也就是说新的z1依然是 thinking的词向量表示，只不过这个词向量的表示蕴含了 thinking machines 这句话对于thinking 而言哪个更重要的信息。</p><hr><h3 id="自注意力机制的问题">2.3 自注意力机制的问题</h3><p>自注意力机制的原理是筛选重要信息，过滤不重要信息，这就导致其有效信息的抓取能力会比CNN小一点。这是因为自注意力机制相比CNN，无法利用图像本身具有的尺度、平移不变形，以及图像的特征局部性这些先验知识，只能通过大量数据进行学习。<strong>这就导致自注意力机制只能在大数据的基础上才能有效地建立准确的全局关系，而在小数据的情况下，其效果不如CNN。</strong></p><hr><h2 id="三多头注意力机制multi-head-self-attention">三、多头注意力机制：Multi-HeadSelf-Attention</h2><h3 id="为什么用多头注意力机制">3.1为什么用多头注意力机制</h3><p>自注意力机制的缺陷：模型对当前未知的信息进行编码时，会过度将注意力集中于自身的位置，有效信息抓取能力会差一点，会有才有了多头注意力机制。</p><p>在实践中，当给定相同的查询、键和值的集合时，我们希望模型可以基于相同的注意力机制学习到不同的行为，然后将不同的行为作为知识组合起来，补货序列内各种范围的依赖关系（例如：短距离依赖和长距离依赖关系）。因此，<strong>允许注意力机制组合使用查询、键、值的不同子空间表示（representationsubspaces）可能是有益的。</strong></p><p>为此，与其使用单独一个注意力汇聚，我们可以用<strong>独立学习到的h组（一般h=8）不同的线性投影（linearprojections）</strong>来变换查询、键和值。然后，<strong>这h组变换后的查询、键和值将并行地送到注意力汇聚中。最后，将这h个注意力汇聚的输出拼接到一起，并通过另一个可学习的线性投影进行变换，以生成最终输出。</strong>这种设计被称为<font color="red"><strong>多头注意力（multi-headattention）。</strong></font></p><p><img src="https://img-blog.csdnimg.cn/75d93a626a7844a5aac1df5ff9ad4142.png" alt="f" style="zoom:50%;"></p><hr><h3 id="如何运用多头注意力机制">3.2如何运用多头注意力机制</h3><p><strong>First：定义多组W，生成多组Q,K,V</strong></p><p><img src="https://img-blog.csdnimg.cn/6e9d6d0b7a2d4f0c9121d26dedf01b5d.jpeg"></p><p><strong>Second：定义8组参数</strong></p><p>对应8个single head，对应8组<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.408ex" height="2.37ex" role="img" focusable="false" viewBox="0 -853.7 5484.6 1047.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(1511.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1956.1,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mo" transform="translate(3510.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(3955.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g></g></g></g></svg></mjx-container></span>,再分别进行self-attention，就得到了Z0-Z7</p><p><img src="https://img-blog.csdnimg.cn/238fda6a68af4151b9cdde8224b4612a.jpeg"></p><p><strong>Third：将多组输出拼接后乘以矩阵W0以降维</strong></p><p>首先在输出到下一层前，我们需要将Z0-Z7concat到一起，乘以矩阵W0做一次线性变换进行降维</p><p><img src="https://img-blog.csdnimg.cn/3d14d6a9722848a186bd336d01524ff3.jpeg"></p><p>完整流程如下：</p><p><img src="https://img-blog.csdnimg.cn/b2ac3cd2adb4403fb1e6c4d8bfe2f780.png"></p><p>【注意】对于上图中的第2）步，当前为第一层时，直接对输入词进行编码，生成词向量X；当前为后续层时，直接使用上一层输出。</p><hr><h3 id="代码实现多头注意力机制">3.3代码实现多头注意力机制</h3><p>在实现过程中，我们选择了缩放的“点－积”注意力作为每一个注意力头。为了避免计算成本和参数数量的显著增长，我们设置了<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="19.91ex" height="2.347ex" role="img" focusable="false" viewBox="0 -750 8800.2 1037.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(1189,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2244.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mo" transform="translate(3477,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(4532.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g><g data-mml-node="mo" transform="translate(5739.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(6795.3,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7724.2,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(8224.2,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g></g></svg></mjx-container></span>。值得注意的是，如果我们将查询、键和值的线性变换的输出数量设置为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="21.385ex" height="2.22ex" role="img" focusable="false" viewBox="0 -694 9452.2 981.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mi" transform="translate(911.3,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(1765,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2820.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mi" transform="translate(3775.2,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(4629,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(5684.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g><g data-mml-node="mi" transform="translate(6613.7,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(7467.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(8523.3,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></g></svg></mjx-container></span>，则可以并行计算h 头。在下面的实现中，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="2.102ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 928.9 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></g></svg></mjx-container></span>是通过参数num_hiddens 指定的。</p><pre class="python3"><code>import mathimport torchfrom torch import nnfrom d2l import torch as d2ldef transpose_qkv(X,num_heads):    # 输入 `X` 的形状: (`batch_size`, 查询或者“键－值”对的个数, `num_hiddens`).    # 输出 `X` 的形状: (`batch_size`, 查询或者“键－值”对的个数, `num_heads`,`num_hiddens` / `num_heads`)    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)    # 输出 `X` 的形状: (`batch_size`, `num_heads`, 查询或者“键－值”对的个数,`num_hiddens` / `num_heads`)    X = X.permute(0, 2, 1, 3)    # `output` 的形状: (`batch_size` * `num_heads`, 查询或者“键－值”对的个数,`num_hiddens` / `num_heads`)    return X.reshape(-1, X.shape[2], X.shape[3])def transpose_output(X,num_heads):    """逆转 `transpose_qkv` 函数的操作"""    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])    X = X.permute(0, 2, 1, 3)    return X.reshape(X.shape[0], X.shape[1], -1)class MultiHeadAttention(nn.Module):    def __init__(self,key_size,query_size,value_size,num_hiddens,                num_heads,dropout,bias=False,**kwargs):        super(MultiHeadAttention,self).__init__(**kwargs)        self.num_heads = num_heads        self.attention = d2l.DotProductAttention(dropout)        self.W_q = nn.Linear(query_size,num_hiddens,bias=bias) # 将输入映射为（batch_size,query_size/k-v size,num_hidden）大小的输出        self.W_k = nn.Linear(key_size,num_hiddens,bias=bias)        self.W_v = nn.Linear(value_size,num_hiddens,bias=bias)        self.W_o = nn.Linear(num_hiddens,num_hiddens,bias=bias)        def forward(self,queries,keys,values,valid_lens):        # `queries`, `keys`, or `values` 的形状:            # (`batch_size`, 查询或者“键－值”对的个数, `num_hiddens`)        # `valid_lens`　的形状:            # (`batch_size`,) or (`batch_size`, 查询的个数)        # 经过变换后，输出的 `queries`, `keys`, or `values`　的形状:            # (`batch_size` * `num_heads`, 查询或者“键－值”对的个数,`num_hiddens` / `num_heads`)        queries = transpose_qkv(self.W_q(queries), self.num_heads)         keys = transpose_qkv(self.W_k(keys), self.num_heads)        values = transpose_qkv(self.W_v(values), self.num_heads) # 将多个头的数据堆叠在一起，然后进行计算，从而不用多次计算        if valid_lens is not None:            valid_lens = torch.repeat_interleave(valid_lens,                                                repeats=self.num_heads,                                                dim=0)        output = self.attention(queries,keys,values,valid_lens) # output-&gt;(10,4,20)#         return output        output_concat = transpose_output(output,self.num_heads) # output_concat -&gt; (2,4,100)        return self.W_o(output_concat)</code></pre><p>让我们使用键和值相同的小栗子来测试我们编写的<code>MultiHeadAttention</code>类。多头注意力输出的形状是（batch_size、num_queries、num_hiddens）。</p><pre class="python3"><code># 线性变换的输出为100个，5个头num_hiddens, num_heads = 100, 5attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,num_hiddens, num_heads, 0.5)attention.eval()</code></pre><pre class="pyt"><code>MultiHeadAttention(  (attention): DotProductAttention(    (dropout): Dropout(p=0.5, inplace=False)  )  (W_q): Linear(in_features=100, out_features=100, bias=False)  (W_k): Linear(in_features=100, out_features=100, bias=False)  (W_v): Linear(in_features=100, out_features=100, bias=False)  (W_o): Linear(in_features=100, out_features=100, bias=False))</code></pre><div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>batch_size, num_queries, num_kvpairs, valid_lens <span class="op">=</span> <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, torch.tensor([<span class="dv">3</span>, <span class="dv">2</span>])</span><span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.ones((batch_size, num_queries, num_hiddens)) <span class="co"># query（2，4，100）</span></span><span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.ones((batch_size, num_kvpairs, num_hiddens)) <span class="co"># key和value （2，6，100）</span></span><span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> attention(X, Y, Y, valid_lens) <span class="co"># 输出大小与输入的query的大小相同</span></span><span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>output.shape</span></code></pre></div><pre class="pytho"><code>torch.Size([2, 4, 100])</code></pre>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BEVFormer</title>
      <link href="/2023/11/07/BEVFormer/"/>
      <url>/2023/11/07/BEVFormer/</url>
      
        <content type="html"><![CDATA[<p>BEVFormer是一个一个采用纯视觉做感知任务的算法模型，其通过提取环视相机采集到的图像特征，并将提取的环视特征通过模型学习的方式转换到BEV空间（模型去学习如何将特征从图像坐标系转化到BEV坐标系），从而实现3D目标检测和地图分割任务。</p><hr><p><strong>BEVFormer的Pipline</strong></p><p>BEVFormer的pipline分为下面几个部分：</p><ul><li>Backbone + Neck （ResNet-101-DCN+FPN）提取环视图像的多尺度特征；</li><li>Encoder模块（包括Temporal Self-Attention模块和SpatialCross-Attion模块）完成环视图像特征向BEV特征的建模；</li><li>Decoder模块完成3D目标检测的分类和定位任务；</li><li>正负样本的定义（采用Transformer 中常用的匈牙利匹配算法，Foacal Loss+ L1 loss的总损失最小）；</li><li>损失的计算（Focal Loss分类损失 + L1 Loss回归损失）；</li><li>反向传播，更新网络模型参数</li></ul><hr><p><strong>输入数据格式</strong></p><p>BEVFormer网络模型的输入是一个6维的张量：</p><p>（bs，queue，cam，C，H，W）</p><ul><li>bs：batch size大小；</li><li>queue：连续帧的个数；由于BEVFormer采用了时序信息的思想，可以从一定程度上缓解遮挡问题，所以输入到网络模型中的数据包含当前帧及之前几帧数据；</li><li>cam：每帧中包含的图像数量，对于nuScenes数据集而言，由于一辆车带有6个环视相机传感器，可以实现360°全场景的覆盖，所以一帧会包含6个环视相机拍摄到的6张环视图片；</li><li>C,H,W:图片的通道数、高度及宽度。</li></ul><p><img src="https://pic4.zhimg.com/80/v2-b2c6629cfc100aea30b58f676af2992f_720w.webp"></p><p>网络特征提取的目的是将每一帧对应的六张环视图像的特征提取出来，便于后续转换到BEV 特征空间，生成 BEV特征，在特征提取过程中，张量流的变换情况如下：</p><pre class="python3"><code># 输入图片信息 tensor: (bs, queue, cam, c, h, w)# 通过 for loop 方式一次获取单帧对应的六张环视图像# 送入到 Backbone + Neck 网络提取多尺度的图像特征for idx in range(tensor.size(1) - 1):  # 利用除当前帧之外的所有帧迭代计算 `prev_bev` 特征    single_frame = tensor[:, idx, :]   # (bs, cam, c, h, w)    # 将 bs * cam 看作是 batch size，将原张量 reshape 成 4 维的张量    # 待 Backbone + Neck 网络提取多尺度特征后，再把 bs * cam 的维度再拆成 bs，cam    single_frame = single_frame.reshape(bs * cam, c, h, w)    feats = Backbone(FPN(single_frame))     """ feats 是一个多尺度的特征列表 """    [0]: (bs, cam, 256, h / 8, w / 8)    [1]: (bs, cam, 256, h / 16, w / 16)    [2]: (bs, cam, 256, h / 32, w / 32)    [3]: (bs, cam, 256, h / 64, w / 64)</code></pre><hr><p><strong>Encoder模块</strong></p><p>Encoder模块是为了生成BEV特征，其网络结构如下：</p><p><img src="https://pic2.zhimg.com/v2-65a11a98d73c1111bcc05e1f10848195_r.jpg"></p><p>Encoder模块包含了两个子模块：Temporal Self-Attention模块和SpatialCross-Attention模块。</p><p>这两个模块都用到了一个组件------多尺度的可变性注意力模块，该模块是将Transformer的全局注意力变为局部注意力的一个非常关键的组件，用来减少训练时间，提高Transformer的收敛速度。</p><p>多尺度可变形注意力模块与Transformer中常见的先生成AttentionMap，再计算加权和的方式不同；常规而言Attention Map = Query和Key做内积运算，将AttentionMap再和Value做加权；但是由于这种方式计算量开销会比较大，所以在DeformableDETR中用局部注意力机制代替了全局注意力机制，只对几个采样点进行采样，<strong>而采样点的位置对于参考点的偏移量和每个采样点在加权时的比重均是靠Query经过Linear层学习得到的。</strong></p><p><strong>Temporal Self-Attention模块</strong></p><p><strong>功能：</strong>通过引入时序信息（History BEV）与当前时刻的BEVQuery进行融合，提高BEV Query的建模能力。</p><p><img src="/home/haseka/Pictures/Spatial-Att.png"></p><p>对于TemporalSelf-Attention模块而言，需要bev_query、bev_pos、prev_bev、ref_point、value等参数。</p><ul><li><p><strong>bev_query：</strong>一个完全<strong>learnableparameter</strong>，通过nn.Embedding()函数得到，形状shape =（200*200，256）；200，200分别代表BEV特征平面的长和宽；</p><ul><li>History BEV <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex;" xmlns="http://www.w3.org/2000/svg" width="4.527ex" height="2.016ex" role="img" focusable="false" viewBox="0 -683 2000.9 891"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container> 与当前BEV Queries <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.483ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1097.3 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></g></svg></mjx-container>会首先进行Self-Attention，前者为后者BEV Queries提供先验，提前优化了该BEVQueries，方便之后与图像空间上的多尺度特征进行Cross-Attention，这样既融合了时序特征又融合了空间特征，并最终生产BEV特征。</li></ul></li><li><p><strong>bev_pose：</strong>一个完全<strong>learnableparameter</strong>，与2D检测中常见的正余弦编码方式不同，是把不同的grid位置映射到一个高维的向量空间，shape=（bs，256，200，200），代码如下：</p><pre class="python3"><code>""" bev_pose 的生成过程 """# w, h 分别代表 bev 特征的空间尺寸 200 * 200x = torch.arange(w, device=mask.device)y = torch.arange(h, device=mask.device)# self.col_embed 和 self.row_embed 分别是两个 Linear 层，将(200, )的坐标向高维空间做映射x_embed = self.col_embed(x)  # (200, 128)y_embed = self.row_embed(y)  # (200, 128)# pos shape: (bs, 256, 200, 200)pos = torch.cat((x_embed.unsqueeze(0).repeat(h, 1, 1), y_embed.unsqueeze(1).repeat(1, w, 1)), dim=-1).permute(2, 0, 1).unsqueeze(0).repeat(mask.shape[0], 1, 1, 1)</code></pre></li><li><p><strong>ref_point：</strong>该参数根据当前TemporalSelf-Attention模块是否有pre_bev特征输入而言，会对应不同的情况，之所以会出现不同，是考虑到了前后时刻BEV特征存在不对齐的问题，BEV特征不对齐主要表现在以下两个方面：</p><ul><li><p>车自身是不断运动的</p><p>上一刻和当前时刻，由于车身的不断运动，两个时刻的BEV特征在空间上是不对齐的；针对这一问题，为了实现两个特征的空间对齐，需要用到can_bus数据中有关车身自身旋转角度和偏移的信息，从而对上一时刻的BEV特征与当前时刻的BEV特征在空间上实现特征对齐；</p></li><li><p>车周围的物体也在一定范围内运动</p><p>针对车周围的物体可能在不同时刻也有移动，这部分的特征对齐就是靠网络自身的注意力模块去学习实现修正了。</p></li></ul><p>综上，对于TemporalSelf-Attention模块没有输入pre_bev（第一帧没有前一时刻的BEV特征）的情况，其<code>ref_point = ref_2d</code>；对于存在输入pre_bev的情况，其<code>ref_point = ref_2d +shift</code>;</p><p>涉及到的<code>ref_2d</code>、<code>shift</code>参数，核心代码如下：</p><pre class="text"><code>"""shift 参数的生成""" # obtain rotation angle and shift with ego motion delta_x = kwargs['img_metas'][0]['can_bus'][0] delta_y = kwargs['img_metas'][0]['can_bus'][1] ego_angle = kwargs['img_metas'][0]['can_bus'][-2] / np.pi * 180 rotation_angle = kwargs['img_metas'][0]['can_bus'][-1] grid_length_y = grid_length[0] grid_length_x = grid_length[1] translation_length = np.sqrt(delta_x ** 2 + delta_y ** 2) translation_angle = np.arctan2(delta_y, delta_x) / np.pi * 180 if translation_angle &lt; 0:     translation_angle += 360 bev_angle = ego_angle - translation_angle shift_y = translation_length * \     np.cos(bev_angle / 180 * np.pi) / grid_length_y / bev_h shift_x = translation_length * \     np.sin(bev_angle / 180 * np.pi) / grid_length_x / bev_w shift_y = shift_y * self.use_shift shift_x = shift_x * self.use_shift shift = bev_queries.new_tensor([shift_x, shift_y])  # shape (2,) # 通过`旋转`和`平移`变换实现 BEV 特征的对齐，对于平移部分是通过对参考点加上偏移量`shift`体现的if prev_bev is not None:    if prev_bev.shape[1] == bev_h * bev_w:        prev_bev = prev_bev.permute(1, 0, 2)    if self.rotate_prev_bev:        num_prev_bev = prev_bev.size(1)        prev_bev = prev_bev.reshape(bev_h, bev_w, -1).permute(2, 0, 1)  # sequence -&gt; grid        prev_bev = rotate(prev_bev, rotation_angle, center=self.rotate_center)        prev_bev = prev_bev.permute(1, 2, 0).reshape(bev_h * bev_w, num_prev_bev, -1)"""ref_2d 参数的生成，常规的 2D 网格生成的规则坐标点"""ref_y, ref_x = torch.meshgrid(torch.linspace(0.5, H - 0.5, H, dtype=dtype, device=device),                              torch.linspace(0.5, W - 0.5, W, dtype=dtype, device=device))ref_y = ref_y.reshape(-1)[None] / Href_x = ref_x.reshape(-1)[None] / Wref_2d = torch.stack((ref_x, ref_y), -1)ref_2d = ref_2d.repeat(bs, 1, 1).unsqueeze(2)</code></pre></li><li><p><strong>value:</strong>该参数就是对应着bev_query去查询的特征；</p><p>对于 Temporal Self-Attention 模块输入包含<code>prev_bev</code>时，<code>value = [prev_bev，bev_query]</code>，对应的参考点<code>ref_point = [ref_2d + shift，ref_2d]</code>；如果输入不包含<code>prev_bev</code>时，<code>value =  [bev_query，bev_query]</code>，对应的参考点<code>ref_point = [ref_2d，ref_2d]</code>。</p><p>内部参数：Offset、weights、Sample Location。</p><p>参数<code>Offset</code>的计算是同时考虑了<code>value[0]</code>和<code>bev_query</code>的信息，在映射空间的维度上进行了concat，并基于concat 后的特征，去计算<code>Offset</code>以及<code>attention weights</code>，涉及到的核心代码如下：</p><pre class="python3"><code>""" bev_query 按照通道维度进行 concat """query = torch.cat([value[0:1], query], -1)  # (bs, 40000, 512)""" value 经过 Linear 做映射 """value = self.value_proj(value)""" offsets 以及 attention weights 的生成过程 """# sampling_offsets: shape = (bs, num_query, 8, 1, 4, 2)# 对 query 进行维度映射得到采样点的偏移量sampling_offsets = self.sampling_offsets(query).view(bs, num_query, self.num_heads, self.num_levels, self.num_points, 2)# 对 query 进行维度映射得到注意力权重attention_weights = self.attention_weights(query).view(bs, num_query, self.num_heads, self.num_levels * self.num_points)  attention_weights = attention_weights.softmax(-1)# attention_weights: shape = (bs, num_query, 8, 1, 4)attention_weights = attention_weights.view(bs, num_query, self.num_heads, self.num_levels, self.num_points) """ sample location 的生成过程 通过代码可以观察到两点：1. 通过 query 学到的 sampling_offsets 偏移量是一个绝对量，不是相对量，所以需要做 normalize；2. 最终生成的 sampling_locations 是一个相对量；"""offset_normalizer = torch.stack([spatial_shapes[..., 1], spatial_shapes[..., 0]], -1)sampling_locations = reference_points[:, :, None, :, None, :] \                + sampling_offsets / offset_normalizer[None, None, None, :, None, :] </code></pre></li><li><p>输出bev_query</p><p>至此，Temporal Self-Attention 模块的逻辑到此结束，将生成的 bev_query送入到后面的 Spatial Cross-Attention 模块中。</p><pre class="python3"><code>""" 各个参数的 shape 情况 1. value: (2，40000，8，32） # 2: 代表前一时刻的 BEV 特征和后一时刻的 BEV 特征，两个特征在计算的过程中是互不干扰的，                             # 40000: 代表 bev_query 200 * 200 空间大小的每个位置                             # 8: 代表8个头，# 32: 每个头表示为 32 维的特征2. spatial_shapes: (200, 200) # 方便将归一化的 sampling_locations 反归一化3. level_start_index: 0 # BEV 特征只有一层4. sampling_locations: (2, 40000, 8, 1, 4, 2)5. attention_weights: (2, 40000, 8, 1, 4)6. output: (2, 40000, 8, 32)"""output = MultiScaleDeformableAttnFunction.apply(value,                                                 spatial_shapes,                                                 level_start_index,                                                 sampling_locations,                                                attention_weights,                                                 self.im2col_step)""" 最后将前一时刻的 bev_query 与当前时刻的 bev_query 做平均output = output.permute(1, 2, 0)output = (output[..., :bs] + output[..., bs:])/self.num_bev_queue</code></pre></li></ul><p><strong>Spatial Cross-Attention模块</strong></p><ul><li><p>功能</p><p>利用TemporalSelf-Attention模块输出的<code>bev_query</code>，对主干网和Neck网络提取到的多尺度环视图像特征进行查询，生成BEV空间下的BEVEmbedding特征；</p></li><li><p>代码实现</p><p>对于Spatial Cross-Attention模块而言，与TemporalSelf-Attention模块需要的参数很类似，但是不需要bev_pos参数，只需要bev_query、ref_point、value（就是concat到一起的多尺度特征），不需要bev_pose；</p></li><li><p>参数bev_query</p><p>bev_query参数来自于Temporal Self-Attention模块的输出</p></li><li><p>参数value</p><p>对于Transformer而言，由于其本身是处理文本序列的模型，而文本序列都是一组组一维的数据，所以将前面提取到的多尺度特征做flatten()处理，将所有层的特征汇聚到一起，方便之后做查询，相应代码如下：</p><pre class="python3"><code>""" 首先将多尺度的特征每一层都进行 flatten() """for lvl, feat in enumerate(mlvl_feats):    bs, num_cam, c, h, w = feat.shape    spatial_shape = (h, w)    feat = feat.flatten(3).permute(1, 0, 3, 2)      if self.use_cams_embeds:        feat = feat + self.cams_embeds[:, None, None, :].to(feat.dtype)        feat = feat + self.level_embeds[None, None, lvl:lvl + 1, :].to(feat.dtype)        spatial_shapes.append(spatial_shape)        feat_flatten.append(feat)""" 对每个 camera 的所有层级特征进行汇聚 """feat_flatten = torch.cat(feat_flatten, 2)  # (cam, bs, sum(h*w), 256)spatial_shapes = torch.as_tensor(spatial_shapes, dtype=torch.long, device=bev_pos.device)# 计算每层特征的起始索引位置level_start_index = torch.cat((spatial_shapes.new_zeros((1,)), spatial_shapes.prod(1).cumsum(0)[:-1]))# 维度变换feat_flatten = feat_flatten.permute(0, 2, 1, 3)  # (num_cam, sum(H*W), bs, embed_dims)</code></pre></li><li><p>ref_point</p><p>ref_3d是基于BEV空间产生的三维空间规则网格点，同时在z轴方向上人为的选择了4个坐标点。这里使用z轴，并在z轴上采样的物体意义可能是为了提取每个BEV位置处不同高度的特征，为了更好的获取在BEV空间下的（x,y）处的特征，将（x,y）的坐标进行lift，从而将BEV坐标系下的三维点映射回图像平面后可以去查询并融合更加准确的特征。</p><p>而在映射过程中，由于每个参考点映射回图像坐标系后，不会落到6个图像上，只可能落在其中的某些图像的某些位置上，所以只对这些参考点附近的位置进行采样，可以提高模型的收敛速度。</p><p><img src="https://pic1.zhimg.com/80/v2-503ed0236461349bf35fef572f4dc70c_720w.webp"></p><p>ref_3d参数生成、3D坐标向图像平面转换等过程的核心代码如下，真正用在SpatialCross-Attention模块的参考点事下面代码中的reference_points_cam：</p><pre class="text"><code>""" ref_3d 坐标生成 """zs = torch.linspace(0.5, Z - 0.5, num_points_in_pillar, dtype=dtype, device=device).view(-1, 1, 1).expand(num_points_in_pillar, H, W) / Zxs = torch.linspace(0.5, W - 0.5, W, dtype=dtype, device=device).view(1, 1, W).expand(num_points_in_pillar, H, W) / Wys = torch.linspace(0.5, H - 0.5, H, dtype=dtype, device=device).view(1, H, 1).expand(num_points_in_pillar, H, W) / Href_3d = torch.stack((xs, ys, zs), -1)  # (4, 200, 200, 3)  (level, bev_h, bev_w, 3) 3代表 x,y,z 坐标值ref_3d = ref_3d.permute(0, 3, 1, 2).flatten(2).permute(0, 2, 1)  # (4, 200 * 200, 3)ref_3d = ref_3d[None].repeat(bs, 1, 1, 1)  # (1, 4, 200 * 200, 3)""" BEV 空间下的三维坐标点向图像空间转换的过程代码中的`lidar2img`需要有两点需要注意1. BEV 坐标系 这里指 lidar 坐标系2. 这里提到的`lidar2img`是经过坐标变换的，一般分成三步   第一步：lidar 坐标系 -&gt; ego vehicle 坐标系   第二步：ego vehicle 坐标系 -&gt; camera 坐标系   第三部：camera 坐标系 通过相机内参 得到像素坐标系   以上这三步用到的所有平移和旋转矩阵都合并到了一起，形成了 `lidar2img` 旋转平移矩阵同时需要注意：再与`lidar2img`矩阵乘完，还需要经过下面两步坐标系转换，才是得到了三维坐标点在二维图像平面上的点"""# (level, bs, cam, num_query, 4)坐标系转换第一步：reference_points_cam = torch.matmul(lidar2img.to(torch.float32), reference_points.to(torch.float32)).squeeze(-1)  eps = 1e-5bev_mask = (reference_points_cam[..., 2:3] &gt; eps)  # (level, bs, cam, num_query, 1)坐标系转换第二步：reference_points_cam = reference_points_cam[..., 0:2] / torch.maximum(reference_points_cam[..., 2:3], torch.ones_like(reference_points_cam[..., 2:3]) * eps)# reference_points_cam = (bs, cam = 6, 40000, level = 4, xy = 2)reference_points_cam[..., 0] /= img_metas[0]['img_shape'][0][1]  # 坐标归一化reference_points_cam[..., 1] /= img_metas[0]['img_shape'][0][0]  # 坐标归一化# bev_mask 用于评判某一 三维坐标点 是否落在了 二维坐标平面上# bev_mask = (bs, cam = 6, 40000, level = 4)bev_mask = (bev_mask &amp; (reference_points_cam[..., 1:2] &gt; 0.0)                     &amp; (reference_points_cam[..., 1:2] &lt; 1.0)                     &amp; (reference_points_cam[..., 0:1] &lt; 1.0)                     &amp; (reference_points_cam[..., 0:1] &gt; 0.0))</code></pre><p><strong>注意：</strong>上述得到的bev_query和reference_points_cam并不是直接用在SpatialCross-Attention模块中，而是选择有用部分进行使用（减少模型的计算量，提高训练过程的收敛速度）</p><p>之前也有提到，并不是 BEV坐标系下的每个三维坐标都会映射到环视相机的所有图像上，而只会映射到其中的某几张图片上，所以使用所有来自Temporal Self-Attention模块的所有<code>bev_query</code>会消耗很大的计算量，所以这里是对<code>bev_query</code>进行了重新的整合，涉及的核心代码如下：</p><pre class="python3"><code>indexes = []# 根据每张图片对应的`bev_mask`结果，获取有效query的indexfor i, mask_per_img in enumerate(bev_mask):    index_query_per_img = mask_per_img[0].sum(-1).nonzero().squeeze(-1)    indexes.append(index_query_per_img)queries_rebatch = query.new_zeros([bs * self.num_cams, max_len, self.embed_dims])reference_points_rebatch = reference_points_cam.new_zeros([bs * self.num_cams, max_len, D, 2]) for i, reference_points_per_img in enumerate(reference_points_cam):    for j in range(bs):        index_query_per_img = indexes[i]        # 重新整合 `bev_query` 特征，记作 `query_rebatch        queries_rebatch[j * self.num_cams + i, :len(index_query_per_img)] = query[j, index_query_per_img]        # 重新整合 `reference_point`采样位置，记作`reference_points_rebatch`        reference_points_rebatch[j * self.num_cams + i, :len(index_query_per_img)] = reference_points_per_img[j, index_query_per_img]</code></pre><p>与产生query_rebatch原因相同，获取映射到二维图像后的有效位置，对原有的reference_points进行重新整合reference_points_rebatch。</p><pre class="python3"><code>""" 获取 sampling_offsets，依旧是对 query 做 Linear 做维度的映射，但是需要注意的是这里的 query 指代的是上面提到的 `quries_rebatch` """ # sample 8 points for single ref point in each level.# sampling_offsets: shape = (bs, max_len, 8, 4, 8, 2)sampling_offsets = self.sampling_offsets(query).view(bs, num_query, self.num_heads, self.num_levels, self.num_points, 2)attention_weights = self.attention_weights(query).view(bs, num_query, self.num_heads, self.num_levels * self.num_points)attention_weights = attention_weights.softmax(-1)# attention_weights: shape = (bs, max_len, 8, 4, 8)attention_weights = attention_weights.view(bs, num_query,                                           self.num_heads,                                           self.num_levels,                                           self.num_points)""" 生成 sampling location """offset_normalizer = torch.stack([spatial_shapes[..., 1], spatial_shapes[..., 0]], -1)reference_points = reference_points[:, :, None, None, None, :, :]sampling_offsets = sampling_offsets / offset_normalizer[None, None, None, :, None, :]sampling_locations = reference_points + sampling_offsets</code></pre></li><li><p>输出bev_embedding</p><p>将上述处理好的参数，送入多尺度可变形注意力模块中生成bev_embedding特征：</p><pre class="python3"><code>"""1. value: shape = (cam = 6, sum(h_i * w_i) = 30825, head = 8, dim = 32)2. spatial_shapes = ([[116, 200], [58, 100], [29,  50], [15,  25]])3. level_start_index= [0, 23200, 29000, 30450]4. sampling_locations = (cam, max_len, 8, 4, 8, 2)5. attention_weights = (cam, max_len, 8, 4, 8)6. output = (cam, max_len, 8, 32)"""output = MultiScaleDeformableAttnFunction.apply(value, spatial_shapes, level_start_index, sampling_locations,                attention_weights, self.im2col_step)"""最后再将六个环视相机查询到的特征整合到一起，再求一个平均值 """for i, index_query_per_img in enumerate(indexes):    for j in range(bs):  # slots: (bs, 40000, 256)        slots[j, index_query_per_img] += queries[j * self.num_cams + i, :len(index_query_per_img)]count = bev_mask.sum(-1) &gt; 0count = count.permute(1, 2, 0).sum(-1)count = torch.clamp(count, min=1.0)slots = slots / count[..., None]  # maybe normalize.slots = self.output_proj(slots)</code></pre><p>以上就是 Spatial Cross-Attention 模块的整体逻辑。</p><p>将 Temporal Self-Attetion 模块和 Spatial Cross-Attention模块堆叠在一起，并重复六次，最终得到的 <code>BEV Embedding</code>特征作为下游 3D 目标检测和道路分割任务的 BEV 空间特征。</p></li></ul><hr><p>Decoder模块</p><p>上述产生BEV特征的过程是用了当前输入到网络模型中除当前帧外，之前所有帧特征去迭代修正去获得pre_bev的特征；所以在利用decoder模块进行解码之前，需要对当前时刻环视的6张图片同样利用Backbone+Neck提取多尺度特征，再利用上述的Temporal Self-Attention 模块和 Spatial Cross-Attention模块的逻辑生成当前时刻的<code>bev_embedding</code>，然后将这部分特征送入到Decoder 中进行 3D 目标检测。</p><p>如何获取预测框和分类得分</p><ul><li><p>query、query_pos</p><p>query和query_pos都是可学习的。模型直接用 nn.Embedding()生成一组（900，512）维的张量。然后将 512维的张量分成两组，分别构成了<code>query = (900，256)</code>和<code>query_pos = (900，256)</code>。</p></li><li><p>reference_points</p><p>对于多尺度可变形注意力模块需要参考点，但在预测过程中无参考点，这需要网络学习出来，网络靠query_pos学习到的，代码如下：</p><pre class="text"><code>reference_points = self.reference_points(query_pos)  # (bs, 900, 3)  3 代表 (x, y, z) 坐标reference_points = reference_points.sigmoid()  # absolute -&gt; relativeinit_reference_out = reference_points </code></pre></li><li><p>Decoder逻辑</p><p>在获取到需要用到的<code>query</code>、<code>query_pos</code>、<code>reference_points</code>参数后，后面的逻辑有些类似Deformabe DETR 的 Decoder 过程，简单概括如下几点：</p><p>利用<code>query</code>和<code>query_pos</code>去做常规的Self-Attention 运算更新<code>query</code>；</p><p>利用 Self-Attention 得到的 query，之前获得的<code>bev_embedding</code>作为value，<code>query_pos</code>，由query生成的<code>reference_points</code>（虽然生成的x，y，z参考点位置，但是BEV Embedding 是二维的，所以参考点只选择了前两维）仿照 DeformableAttention Module 的 pipeline 做可变形注意力；</p><p>可变形注意力核心代码如下：</p><pre class="text"><code>""" 由 query 生成 sampling_offsets 和 attention_weights """sampling_offsets = self.sampling_offsets(query).view(            bs, num_query, self.num_heads, self.num_levels, self.num_points, 2)  # (bs, 900, 8, 1, 4, 2)attention_weights = self.attention_weights(query).view(            bs, num_query, self.num_heads, self.num_levels * self.num_points)  # (bs, 900, 8, 4)attention_weights = attention_weights.softmax(-1)attention_weights = attention_weights.view(bs, num_query,                                                   self.num_heads,                                                   self.num_levels,                                                   self.num_points)  # (bs, 900, 8, 1, 4)""" sampling_offsets 和 reference_points 得到 sampling_locations """offset_normalizer = torch.stack(                [spatial_shapes[..., 1], spatial_shapes[..., 0]], -1)sampling_locations = reference_points[:, :, None, :, None, :] \                + sampling_offsets \                / offset_normalizer[None, None, None, :, None, :]""" 多尺度可变形注意力模块 """# value: shape = (bs, 40000, 8, 32)# spatial_shapes = (200, 200)# level_start_index = 0# sampling_locations = (bs, 900, 8, 1, 4, 2)# attention_weights = (bs, 900, 8, 1, 4)# output = (bs, 900, 256)output = MultiScaleDeformableAttnFunction.apply(value, spatial_shapes, level_start_index, sampling_locations,                attention_weights, self.im2col_step)</code></pre><p>在获得查询到的特征后，会利用回归分支（FFN网络）对提取的特征计算回归结果，预测 10 个输出；</p><p>我的理解这 10个维度的含义为：[xc，yc，w，l，zc，h，rot.sin()，rot.cos()，vx，vy]；[预测框中心位置的x方向偏移，预测框中心位置的y方向偏移，预测框的宽，预测框的长，预测框中心位置的z方向偏移，预测框的高，旋转角的正弦值，旋转角的余弦值，x方向速度，y方向速度]；</p><p>然后根据预测的偏移量，对参考点的位置进行更新，为级联的下一个 Decoder提高精修过的参考点位置，核心代码如下：</p><pre class="python3"><code>if reg_branches is not None:  # update the reference point.    tmp = reg_branches[lid](output)  # (bs, 900, 256) -&gt; (bs, 900, 10) 回归分支的预测输出    assert reference_points.shape[-1] == 3    new_reference_points = torch.zeros_like(reference_points)    # 预测出来的偏移量是绝对量    new_reference_points[..., :2] = tmp[..., :2] + inverse_sigmoid(reference_points[..., :2])  # 框中心处的 x, y 坐标    new_reference_points[..., 2:3] = tmp[..., 4:5] + inverse_sigmoid(reference_points[..., 2:3])  # 框中心处的 z 坐标    # 参考点坐标是一个归一化的坐标    new_reference_points = new_reference_points.sigmoid()    reference_points = new_reference_points.detach()""" 最后将每层 Decoder 产生的特征 = (bs, 900, 256)，以及参考点坐标 = (bs, 900, 3) 保存下来。"""if self.return_intermediate:    intermediate.append(output)    intermediate_reference_points.append(reference_points)</code></pre><p>然后将层级的 <code>bev_embedding</code>特征以及参考点通过 for loop的形式，一次计算每个 Decoder 层的分类和回归结果：</p><pre class="text"><code>bev_embed, hs, init_reference, inter_references = outputshs = hs.permute(0, 2, 1, 3)  # (decoder_level, bs, 900, 256)outputs_classes = []outputs_coords = []for lvl in range(hs.shape[0]):    if lvl == 0:        reference = init_reference    else:        reference = inter_references[lvl - 1]    reference = inverse_sigmoid(reference)    outputs_class = self.cls_branches[lvl](hs[lvl])  # (bs, 900, num_classes)    tmp = self.reg_branches[lvl](hs[lvl])  # (bs, 900, 10)    assert reference.shape[-1] == 3    tmp[..., 0:2] += reference[..., 0:2]  # (x, y)    tmp[..., 0:2] = tmp[..., 0:2].sigmoid()    tmp[..., 4:5] += reference[..., 2:3]    tmp[..., 4:5] = tmp[..., 4:5].sigmoid()    tmp[..., 0:1] = (tmp[..., 0:1] * (self.pc_range[3] - self.pc_range[0]) + self.pc_range[0])    tmp[..., 1:2] = (tmp[..., 1:2] * (self.pc_range[4] - self.pc_range[1]) + self.pc_range[1])    tmp[..., 4:5] = (tmp[..., 4:5] * (self.pc_range[5] - self.pc_range[2]) + self.pc_range[2])    outputs_coord = tmp    outputs_classes.append(outputs_class)    outputs_coords.append(outputs_coord) </code></pre></li></ul><hr><p><strong>正负样本的定义</strong></p><p>正负样本的定义用到的就是匈牙利匹配算法，分类损失和类似回归损失的总损失和最小；</p><p>分类损失的计算代码如下：</p><pre class="text"><code>cls_pred = cls_pred.sigmoid()  # calculate the neg_cost and pos_cost by focal loss.neg_cost = -(1 - cls_pred + self.eps).log() * (1 - self.alpha) * cls_pred.pow(self.gamma)pos_cost = -(cls_pred + self.eps).log() * self.alpha * (1 - cls_pred).pow(self.gamma)cls_cost = pos_cost[:, gt_labels] - neg_cost[:, gt_labels]cls_cost = cls_cost * self.weight</code></pre><p>类回归损失的计算代码如下：</p><p>这里介绍一下，gt_box 的表示方式，gt_box 的维度是九维的，分别是[xc，yc，zc，w，l，h，rot，vx，vy]；而预测结果框的维度是十维的，所以要对gt_box 的维度进行转换，转换为的维度表示为[xc，yc，w，l，cz，h，rot.sin()，rot.cos()，vx，vy]</p><p>对应代码如下：</p><pre class="text"><code>cx = bboxes[..., 0:1]cy = bboxes[..., 1:2]cz = bboxes[..., 2:3]w = bboxes[..., 3:4].log()l = bboxes[..., 4:5].log()h = bboxes[..., 5:6].log()rot = bboxes[..., 6:7]vx = bboxes[..., 7:8] vy = bboxes[..., 8:9]normalized_bboxes = torch.cat((cx, cy, w, l, cz, h, rot.sin(), rot.cos(), vx, vy), dim=-1)</code></pre><p>计算类回归损失（L1 Loss）</p><p>这里有一点需要注意的是，在正负样本定义中计算 L1 Loss的时候，只对前预测框和真值框的前 8 维计算损失</p><pre class="text"><code>self.reg_cost(bbox_pred[:, :8], normalized_gt_bboxes[:, :8])</code></pre>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -BEVFormer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>视觉BEV综述</title>
      <link href="/2023/11/06/%E8%A7%86%E8%A7%89BEV%E7%BB%BC%E8%BF%B0/"/>
      <url>/2023/11/06/%E8%A7%86%E8%A7%89BEV%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="感知bev综述">感知BEV综述</h1><h3 id="什么是bev">什么是BEV</h3><p>BEV的意思是鸟瞰图，也就是我们会将环视摄像机，激光雷达，甚至是毫米波雷达的数据，经过特征提取之后，统统通过视角变换，转换到鸟瞰图这种场景下，然后会在这些场景下，做一些多传感器数据融合就很方便了，之后我们就可以接各种任务头，做3D目标检测，车道线检测，语义分割，障碍物检测等等，都是可以的。</p><p>对于低成本的自动驾驶系统，以视觉为中心的BEV感知是一个长期的挑战，因为摄像头通常放置在自车上，与地面平行，面向外部。图像在与BEV正交的透视图（PV）中获取，并且两个视图之间的变换是不适定问题。最早工作[用单应矩阵以物理和数学方式将平坦地面从PV转换为BEV。多年来，这种方法一直占据主导地位，直到平地硬约束无法满足复杂真实场景的自主驾驶要求。随着计算机视觉中数据驱动方法的发展，近年来出现了许多基于深度学习的方法，通过求解PV-BEV变换来促进以视觉为中心的BEV感知。</p><h3 id="bev方法">BEV方法</h3><p>基于视图变换，当前BEV视觉感知工作可分为两大类：基于几何的变换和基于网络的变换。如图1所示：</p><p><imgsrc="https://pic1.zhimg.com/v2-1bccea29938448e33a091e958698199c_r.jpg" /></p><p>前者充分利用摄像头的物理原理以可解释的方式迁移视图。除了经典的基于homograph的方法外，通过显式或隐式深度估计将2-D特征提升到3-D空间是主要的解决方案。对于图像的每个像素，都存在一条来自摄影机的光线，该光线会遇到现实世界中的目标。不直接将像素映射到BEV，另一种方法是计算每个像素的深度分布，利用该分布将2D特征提升到3D，然后通过降维从3D获得BEV表示。</p><p>这些方法对深度采用不同的假设，例如精确值、射线上的均匀分布或射线上的类分布。深度监督来自于最终的显示深度值或任务监督。对于后者，其方法采用神经网络作为PV到BEV的视图投影。深度神经网络充当一个负责的映射函数，以不同的模式、维度、表示等将输入转换为输出。简单的想法是使用编码器-解码器（VE-D）或MLP将PV特征投影到BEV。上述方法在某种程度上采用了自下而上（bottom-up）的策略，以前向的凡是处理转换。另一种方法是采用自顶向下（top-down）的策略，通过交叉注意力机制直接构造BEVquery并搜索前视图像上的相应特征。为了匹配不同的下游任务，各种方法提出稀疏、密集或混合query。</p><p>3-D目标检测是3-D感知的核心任务之一。根据不同的输入数据模式，该任务可以分为：基于图像、基于激光雷达和基于多模态的3-D检测。</p><p>基于图像的3D检测设置需要模型预测仅给定多个图像的目标类别和3-D边框。以前的工作通常直接从透视图特征进行预测，这个过程虽然简单，但在实践中对多视图摄像头数据进行复杂的后处理，难以利用来自多个视图和时间连续帧的立体视觉线索。因此，最近基于BEV的方法进入视野。</p><p>将透视图转化为BEV的一个传统而直接的解决方案是，利用二者之间的自然集合投影关系，称之为几何方法。根据如何弥合这两个视图间的差距，以前的工作可分为两组：基于homograpgh的方法和基于深度的方法。</p><h4 id="基于homograph的方法">基于homograph的方法</h4><p>3-D空间中的点可以通过透视映射变换到图像空间，而将图像像素投影到3-D空间的逆问题是病态的。逆透视映射（IPM），基于逆映射点位于水平面的夫君爱约束，解决数学上不可能的映射问题。单应矩阵可以从相机的内外参物理地导出。一些方法用CNN提取PV图形的语义特征，并估计图像中的垂直消失点和地平面消失线，以确定单应矩阵。</p><p>由于IPM严重依赖于平坦地面假设，这些给予IPM的方法通常无法准确检测地平面上方的目标，如建筑物、车辆和行人。</p><p><strong>总结：</strong>基于homograph方法主要基于PV和BEV之间平地面的物理映射，具有良好的可解释性。IPM在下游感知任务的图像投影或特征投影中起作用。为了减少地平面以上区域的失真，充分探索语义信息，并广泛使用GAN来提高BEV特征的质量。由于从PV到BEV的实际转换是不适定的，IPM的硬假设解决来部分问题。PV整个特征图的有效BEV映射仍有待解决。</p><h4 id="基于深度预测的方法">基于深度预测的方法</h4><p>基于深度的PV-BEV方法自然建立在显示3D表示上。基于所使用的表示，这些方法可以分为两种类型：基于点的方法和基于体素的方法。</p><ul><li>基于点的视图转换</li></ul><p>基于点的方法直接使用深度估计将像素转换为点云，在连续3-D空间中散播。其更直接，更容易集成单目深度估计和基于激光雷达的3D检测成熟经验。</p><ul><li>基于体素的视图变换</li></ul><p>与基于激光雷达的3-D检测方法类似，纯摄像头方法也有两种常见的选择来表示变换后的3-D特征和几何。与分布在连续3-D空间中的点云相比，体素通过离散3-D空间来构造用于特征变换的均匀结构，为3-D场景理解提供来更有效的表示。</p><p>具体而言，该方案通常使用深度引导直接在相应位置的3D位置散射2D特征（而不是点）。先前的工作将2D特征图与相应的预测深度分布进行外积（outerproduct）来实现这一目标。早期的工作假设分布是均匀的，即沿射线的所有特征都相同，如OFT。这项工作建立了一个内部表示，以确定图像中哪些特征与正交BEV上的位置相关。在定义的均匀间隔3-D格上，它构建3-D体素特征图，并在投影的相应图像特征图区域累积特征来填充体素。然后，沿垂直轴对体素特征求和获得正交特征图，然后深度卷积神经网络提取BEV特征用于3-D目标检测。<strong>对于图像的每个像素，网络对分配的3D点预测相同的表示，即预测沿深度的均匀表示。</strong>这类方法通常不需要深度监督，并且可以在视图转换之后以端到端方式学习网络中的深度或3D位置信息。</p><p>相反，另一种范式会明确预测深度分布，并以此仔细构建3D特征，LSS代表了这种方法。其预测深度上的类分布（categoricaldistribution）和上下文向量，其外积确定透视光线每个点的特征，更好地接近真实深度分布。此外，它将来自所有摄像头的预测融合到场景的一个结合表征中，对标定误差更有鲁棒性。BEVDet遵循这一LSS范式，提出了一种从BEV进行全摄像头多视图的3D检测框架。而新版本BEVDet4D展示了基于多摄像头3D检测的时域线索。具体而言，保留前一帧的中间BEV特征，并将其与前帧生产的特征连接。</p><ul><li>深度监督</li></ul><p>当使用预测深度分布来提升2-D特征时，该分布精度非常重要。CaDDN用经典方法对激光雷达点投影的稀疏深度图进行插值，并以此监督深度分布的预测。其他不用深度标签的方法，只能从稀疏实例标注中学习此类3D位置或深度信息，仅靠网络学习，要困难得多。除了将深度监督纳入检测框架之外，DD3D和MV-FCOS3D++指出，深度估计和单目3D检测的预训练可以显著增强2D主干的表征学习。</p><ul><li>与基于IPM的方法相结合</li></ul><p>PanopticSeg利用这两个方法的优点，提出一种用于全景分割的densetransformer模块，其包括一个用IPM的flattransformer，然后误差校正，生成平面BEV特征，还有一个用3-D体格（volumetrilattice）建模中间3D空间的vertical transformer。</p><ul><li>多视图聚合做立体匹配</li></ul><p>除了单目深度估计外，立体匹配还可以在纯摄像头感知中预测更精确的深度信息。它依赖于适当多视图设置自然形成的基线。相比之下，在双目情况下的深度估计中具有更重要的优点。</p><p>基于深度的视图变换方法通常基于显式3-D表示、量化体素或连续3-D空间的点云散射。基于体素的方法使用均匀的深度向量或明确预测的深度分布将2D特征提升到3D体素空间，并执行几乎BEV的感知。相反，基于点的方法将深度预测转化为伪激光雷达表示，然后用定义网络进行3-D检测。如下表显式了3-D检测的结果：</p><p><imgsrc="https://pic4.zhimg.com/80/v2-1a79417fd7b3a648bc32a239516a4a9b_720w.webp" /></p><p>下图是基于深度的方法时间顺序概述：</p><p><imgsrc="https://pic4.zhimg.com/80/v2-dc857d960de7bb1eb157a672367a9c1b_720w.webp" /></p><p><strong>总而言之：</strong></p><p>1.早期的方法通常第一步用伪激光雷达表示，在第二步直接用3D检测器；然而，由于难以进行可推广的端到端训练，而面临着模型复杂度和性能低的问题。</p><p>2.由于计算效率和灵活性，最近的方法更加关注基于体素的方法。这种表示已广泛应用于不同任务的纯摄像头方法中。</p><p>3.深度监督对于这种基于深度的方法很重要，因为准确的深度分布可以为特征PV转换为BEV时提供基本线索。</p><p>4.如DfM、BEVDet4D和MV-FCOS3D++所分析的，在时域建模中此类方法是一个有希望的方向。</p><p>基于几何的方法明确建立在摄像头投影过程的物理原理上，将视图pV转换为BEV，这是一种可解释的解决方案。另一种选择是以<strong>数据驱动</strong>的方式对视图进行建模，有效地利用摄像头几何结构，其中神经网络充当PV和BEV之间的映射函数。为了涵盖单应性等复杂变幻，<strong>MLP</strong>和<strong>transformer</strong>是基于<strong>网络方法</strong>的两个合适选择。</p><h4 id="基于mlp的视图转换">基于MLP的视图转换</h4><p>多层感知器（MLP）在某种程度上可以看为一个复杂的映射函数，其将输入映射到具有不同模态、维度或表示的输出。摆脱标定摄像机设置包含的继承感应偏差，一些方法倾向于利用MLP学习摄像机标定的隐式表示，实现在两个不同视图（PV和BEV）之间转换。</p><p>基于MLP的方法忽略了标定摄像机的几何先验，并利用MLP作为通用映射函数来建模从PV到BEV的转换。虽然MLP在理论上是一种通用的近似器，但由于缺乏深度信息、遮挡等原因，这使得基于MLP的方法无法利用重叠区域带来的几何潜力。</p><p>总之，基于MLP的方法更多地关注单个图像的情况，而多视图融合还没有得到充分的研究。</p><h4 id="基于transformer的视图转换">基于Transformer的视图转换</h4><p>Transformer解决方案，无需明确利用摄像头模型。基于MLP和基于Transformer的张量映射之间有三个主要区别：</p><p>1）由于加权矩阵在推理过程中是固定的，因此MLP学习的映射不依赖于数据，相反，Transformer中的交叉注意与数据相关，其中加权矩阵与输入数据相关。此数据相关属性使Transformer更有表现力。</p><p>2）交叉注意是置换不变的，需要位置编码来区分输入顺序；MLP对排列自然敏感。</p><p>3）基于Transformer的方法采用自顶向下的策略，通过构造query并通过注意机制搜索相应的图像特征，而不是像基于MLP的方法那样以前向方式处理视图变换。</p><p>根据Transformer解码器中可学习slots（称为query）的粒度，将这些方法分为三类：基于稀疏query的方法、基于密集query的方法和基于混合query的方法。</p><h5 id="基于稀疏query的方法">基于稀疏query的方法</h5><p>对于基于稀疏查询的方法，查询嵌入使网络能够直接产生稀疏感知结果，而无需显式执行图像特征的密集变换。</p><p>DETR3D侧重与多摄像机输入的3D检测，并用基于几何的特征采样过程代替交叉注意。它首先从可学习的稀疏查询中预测3-D参考点，然后使用标定矩阵将参考点投影到图像平面上，最后对相应的多视图多尺度图像特征进行采样，进行端到端的3-D边框预测。为了缓解DETR3D中复杂的特征采样过程，PETR将摄像机参数导出的3-D位置嵌入编码到2-D多视图特征中，这样稀疏查询可以直接与交叉注意中位置-觉察图像特征进行交互，实现更简单、更优雅的框架。下图为PETR3D与PETR比较：</p><p><imgsrc="https://pic3.zhimg.com/80/v2-69dfa7b7a47ab07cda1888787f838006_720w.webp" /></p><p>PETRv2将3D位置嵌入扩展到时域来利用时域信息。</p><h5 id="基于密集query的方法">基于密集query的方法</h5><p>对于基于密集查询的方法，每个查询都预先分配3D空间或BEV空间的空间位置。查询数目有光栅化空间的空间分辨率决定，通常大于基于稀疏查询的方法。密集BEV表示可以密集查询与多个下游任务图像特征之间的交互来实现。</p><h5 id="基于混合query的方法">基于混合query的方法</h5><p>基于稀疏查询的方法适用于以目标为中心的任务，但无法导出显示密集BEV表示，不适用于密集感知任务，如BEV分割。因此，PETRv2中设计了一种混合查询策略，其中处理稀疏目标查询外，还提出了一种密集分割查询，每个分割查询分割特定的patch。</p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 -综述 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -综述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DETR代码解读</title>
      <link href="/2023/11/02/DETR%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
      <url>/2023/11/02/DETR%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="detr代码解析">DETR代码解析</h1><h2 id="一源代码">一、源代码</h2><p><code>https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/detr</code></p><h2 id="二代码解析">二、代码解析</h2><h3 id="前言">1.前言</h3><ul><li><p><strong>二维位置编码：</strong></p><p>构造位置矩阵x_embed、y_embed，这里用python函数cumsum，对一个矩阵的元素进行累加，那么累加以后最后一个元素就是对所以累加元素的和，省去了求和的步骤，直接用这个和做归一化，对应x_embed[:,:,-1:]和y_embed[:,-1:,:]。</p></li><li><p><strong>代码中一些变量的shape：</strong></p><p>tensor_list的类型是NestedTensor,内部自动附加mask，用于表示动态shape，是pytorch新特性，全是false。</p><p>x:(b,c,H,W)</p><p>mask: (b,H,W)，全是False。</p><p>not_mask：(b,H,W)，全是True。</p><p>首先出现的y_embed：(b,H,W)，具体是1,1,1,1,......,2,2,2,2,......,3,3,3,3,......</p><p>首先出现的x_embed：(b,H,W)，具体是1,2,3,4,......,1,2,3,4,......,1,2,3,4,......</p><p>self.num_pos_feats = 128</p><p>首先出现的dim_t = [0,1,2,3,......,127]</p><p>pos_x：(b,H,W,128)</p><p>pos_y：(b,H,W,128)</p><p>flatten后面的数字是指：flatten()方法应从哪个轴开始展开操作。</p><p>torch.stack((pos_y[:,:,:,0::2].sin(),pos_y[:,:,:,0::2].cos()),dim=4)</p><p>这一步执行完后变成(b,H,W,2,64)通过flatten()方法从第3个轴开始展平，变为：(b,H,W,128)</p><p>toch.cat((pos_y,pos_x),dim=3)之后变为(b,H,W,256)，最后permute为(b,256,H,W)。</p><p>PositionEmbeddingSine类继承nn.Module类。</p></li></ul><h3 id="位置编码">2.位置编码</h3><pre class="python3"><code>class PositionEmbeddingSine(nn.Module):    def forward(self, tensor_list: NestedTensor):#输入是b,c,h,w#tensor_list的类型是NestedTensor，内部自动附加了mask，#用于表示动态shape，是pytorch中tensor新特性https://github.com/pytorch/nestedtensor        x = tensor_list.tensors# 附加的mask，shape是b,h,w 全是false        mask = tensor_list.mask        assert mask is not None        not_mask = ~mask# 因为图像是2d的，所以位置编码也分为x,y方向# 1 1 1 1 ..  2 2 2 2... 3 3 3...        y_embed = not_mask.cumsum(1, dtype=torch.float32)# 1 2 3 4 ... 1 2 3 4...        x_embed = not_mask.cumsum(2, dtype=torch.float32)        if self.normalize:            eps = 1e-6            y_embed = y_embed / (y_embed[:, -1:, :] + eps) * self.scale            x_embed = x_embed / (x_embed[:, :, -1:] + eps) * self.scale# num_pos_feats = 128# 0~127 self.num_pos_feats=128,因为前面输入向量是256，编码是一半sin，一半cos        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device)        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)# 输出shape=b,h,w,128        pos_x = x_embed[:, :, :, None] / dim_t        pos_y = y_embed[:, :, :, None] / dim_t        pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)        pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)# 每个特征图的xy位置都编码成256的向量，其中前128是y方向编码，而128是x方向编码        return pos# b,n=256,h,w</code></pre><p>作者定义了一种数据结构：NestedTensor，里面打包存放了两个变量：x和mask。x是张量数据，mask是x数据是否是padding填充的。mask数据如下图所示：</p><p><imgsrc="/home/haseka/Documents/hexo_blog/themes/butterfly/source/img/detr_code/mask.png" /></p><p>而not_mask则是对mask取反说明featuremap某个(x,y)是否是真实值，未用padding，如下：</p><p><img src="/home/haseka/Pictures/not_mask.png" /></p><p>之后对图像进行编码，因为不是一维编码，是二维编码，需要考虑x，y方向上的编码，这里使用cumsum()求累加和的方法来进行编码，x和y经cumsum()后的结果如下：</p><p><imgsrc="/home/haseka/Documents/hexo_blog/source/img/detr_code/y_embed.png" /><img src="/home/haseka/Pictures/x_embed.png" /></p><p>并进行归一化后，得到对应的x、y编码，最终通过cat()操作将两个128维向量合成256维向量，作为最终编码pos返回。</p><h3 id="backbone">3.backbone</h3><pre class="python3"><code>class BackboneBase(nn.Module):    def __init__(self, backbone: nn.Module, train_backbone: bool, num_channels: int, return_interm_layers: bool):        super().__init__()        for name, parameter in backbone.named_parameters():            if not train_backbone or &#39;layer2&#39; not in name and &#39;layer3&#39; not in name and &#39;layer4&#39; not in name:                parameter.requires_grad_(False)        if return_interm_layers:            return_layers = &#123;&quot;layer1&quot;: &quot;0&quot;, &quot;layer2&quot;: &quot;1&quot;, &quot;layer3&quot;: &quot;2&quot;, &quot;layer4&quot;: &quot;3&quot;&#125;        else:            return_layers = &#123;&#39;layer4&#39;: &quot;0&quot;&#125;#作用的模型：定义BackboneBase时传入的nn.Moduleclass的backbone，返回的layer：来自bool变量return_interm_layers        self.body = IntermediateLayerGetter(backbone, return_layers=return_layers)        self.num_channels = num_channels    def forward(self, tensor_list: NestedTensor):#BackboneBase的输入是一个NestedTensor#xs中间层的输出，        xs = self.body(tensor_list.tensors)        out: Dict[str, NestedTensor] = &#123;&#125;        for name, x in xs.items():            m = tensor_list.mask            assert m is not None#F.interpolate上下采样，调整mask的size#to(torch.bool)  把mask转化为Bool型变量            mask = F.interpolate(m[None].float(), size=x.shape[-2:]).to(torch.bool)[0]            out[name] = NestedTensor(x, mask)        return outclass Backbone(BackboneBase):    &quot;&quot;&quot;ResNet backbone with frozen BatchNorm.&quot;&quot;&quot;    def __init__(self, name: str,                 train_backbone: bool,                 return_interm_layers: bool,                 dilation: bool):#根据name选择backbone, num_channels, return_interm_layers等，传入BackboneBase初始化        backbone = getattr(torchvision.models, name)(            replace_stride_with_dilation=[False, False, dilation],            pretrained=is_main_process(), norm_layer=FrozenBatchNorm2d)        num_channels = 512 if name in (&#39;resnet18&#39;, &#39;resnet34&#39;) else 2048        super().__init__(backbone, train_backbone, num_channels, return_interm_layers)</code></pre><p>本文采取Resnt作为backbone。</p><pre class="python3"><code>class Joiner(nn.Sequential):    def __init__(self, backbone, position_embedding):        super().__init__(backbone, position_embedding)    def forward(self, tensor_list: NestedTensor):        xs = self[0](tensor_list)        out: List[NestedTensor] = []        pos = []        for name, x in xs.items():            out.append(x)            # position encoding            pos.append(self[1](x).to(x.tensors.dtype))        return out, posdef build_backbone(args):#position_embedding是个nn.module    position_embedding = build_position_encoding(args)    train_backbone = args.lr_backbone &gt; 0    return_interm_layers = args.masks#backbone是个nn.module    backbone = Backbone(args.backbone, train_backbone, return_interm_layers, args.dilation)#nn.Sequential在一起    model = Joiner(backbone, position_embedding)    model.num_channels = backbone.num_channels    return model</code></pre><p><strong>把Backbone和之前的PositionEmbeddingSine连在一起：</strong>Backbone完以后输出(b,c,h,w)，再经过PositionEmbeddingSine输出(b,H,W,256)。</p><h3 id="transformer">4.Transformer</h3><h4 id="encoder">encoder</h4><pre class="python3"><code>class TransformerEncoderLayer(nn.Module):    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,                 activation=&quot;relu&quot;, normalize_before=False):        super().__init__()        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)        # Implementation of Feedforward model        self.linear1 = nn.Linear(d_model, dim_feedforward)        self.dropout = nn.Dropout(dropout)        self.linear2 = nn.Linear(dim_feedforward, d_model)        self.norm1 = nn.LayerNorm(d_model)        self.norm2 = nn.LayerNorm(d_model)        self.dropout1 = nn.Dropout(dropout)        self.dropout2 = nn.Dropout(dropout)        self.activation = _get_activation_fn(activation)        self.normalize_before = normalize_before    def with_pos_embed(self, tensor, pos: Optional[Tensor]):        return tensor if pos is None else tensor + pos    def forward_post(self,                     src,                     src_mask: Optional[Tensor] = None,                     src_key_padding_mask: Optional[Tensor] = None,                     pos: Optional[Tensor] = None):    # 和标准做法有点不一样，src加上位置编码得到q和k，但是v依然还是src，    # 也就是v和qk不一样        q = k = self.with_pos_embed(src, pos)        src2 = self.self_attn(q, k, value=src, attn_mask=src_mask,                              key_padding_mask=src_key_padding_mask)[0]#Add and Norm        src = src + self.dropout1(src2)        src = self.norm1(src)#FFN        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))#Add and Norm        src = src + self.dropout2(src2)        src = self.norm2(src)        return src    def forward_pre(self, src,                    src_mask: Optional[Tensor] = None,                    src_key_padding_mask: Optional[Tensor] = None,                    pos: Optional[Tensor] = None):        src2 = self.norm1(src)        q = k = self.with_pos_embed(src2, pos)        src2 = self.self_attn(q, k, value=src2, attn_mask=src_mask,                              key_padding_mask=src_key_padding_mask)[0]        src = src + self.dropout1(src2)        src2 = self.norm2(src)        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))        src = src + self.dropout2(src2)        return src    def forward(self, src,                src_mask: Optional[Tensor] = None,                src_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None):        if self.normalize_before:            return self.forward_pre(src, src_mask, src_key_padding_mask, pos)        return self.forward_post(src, src_mask, src_key_padding_mask, pos)</code></pre><p><strong>有了一个EncoderLayer的定义，再看Transformer的整个Encoder：</strong></p><pre class="python3"><code>class TransformerEncoder(nn.Module):    def __init__(self, encoder_layer, num_layers, norm=None):        super().__init__()        # 编码器copy6份        self.layers = _get_clones(encoder_layer, num_layers)        self.num_layers = num_layers        self.norm = norm    def forward(self, src,                mask: Optional[Tensor] = None,                src_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None):        # 内部包括6个编码器，顺序运行        # src是图像特征输入，shape=hxw,b,256        output = src        for layer in self.layers:            # 第一个编码器输入来自图像特征，后面的编码器输入来自前一个编码器输出            output = layer(output, src_mask=mask,                           src_key_padding_mask=src_key_padding_mask, pos=pos)        return output</code></pre><h4 id="decoder">Decoder</h4><pre class="python3"><code>class TransformerDecoderLayer(nn.Module):    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,                 activation=&quot;relu&quot;, normalize_before=False):        super().__init__()        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)        # Implementation of Feedforward model        self.linear1 = nn.Linear(d_model, dim_feedforward)        self.dropout = nn.Dropout(dropout)        self.linear2 = nn.Linear(dim_feedforward, d_model)        self.norm1 = nn.LayerNorm(d_model)        self.norm2 = nn.LayerNorm(d_model)        self.norm3 = nn.LayerNorm(d_model)        self.dropout1 = nn.Dropout(dropout)        self.dropout2 = nn.Dropout(dropout)        self.dropout3 = nn.Dropout(dropout)        self.activation = _get_activation_fn(activation)        self.normalize_before = normalize_before    def with_pos_embed(self, tensor, pos: Optional[Tensor]):        return tensor if pos is None else tensor + pos            def forward_post(self, tgt, memory,                     tgt_mask: Optional[Tensor] = None,                     memory_mask: Optional[Tensor] = None,                     tgt_key_padding_mask: Optional[Tensor] = None,                     memory_key_padding_mask: Optional[Tensor] = None,                     pos: Optional[Tensor] = None,                     query_pos: Optional[Tensor] = None):                     #query,key的输入是object queries(query_pos) + Decoder的输入(tgt),shape都是(100,b,256)#value的输入是Decoder的输入(tgt),shape = (100,b,256)        q = k = self.with_pos_embed(tgt, query_pos)#Multi-head self-attention        tgt2 = self.self_attn(q, k, value=tgt, attn_mask=tgt_mask,                              key_padding_mask=tgt_key_padding_mask)[0]#Add and Norm        tgt = tgt + self.dropout1(tgt2)        tgt = self.norm1(tgt)#query的输入是上一个attention的输出(tgt) + object queries(query_pos)#key的输入是Encoder的位置编码(pos) + Encoder的输出(memory)#value的输入是Encoder的输出(memory)        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),                                   key=self.with_pos_embed(memory, pos),                                   value=memory, attn_mask=memory_mask,                                   key_padding_mask=memory_key_padding_mask)[0]#Add and Norm        tgt = tgt + self.dropout2(tgt2)        tgt = self.norm2(tgt)#FFN        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))        tgt = tgt + self.dropout3(tgt2)        tgt = self.norm3(tgt)        return tgt    def forward_pre(self, tgt, memory,                    tgt_mask: Optional[Tensor] = None,                    memory_mask: Optional[Tensor] = None,                    tgt_key_padding_mask: Optional[Tensor] = None,                    memory_key_padding_mask: Optional[Tensor] = None,                    pos: Optional[Tensor] = None,                    query_pos: Optional[Tensor] = None):        tgt2 = self.norm1(tgt)        q = k = self.with_pos_embed(tgt2, query_pos)        tgt2 = self.self_attn(q, k, value=tgt2, attn_mask=tgt_mask,                              key_padding_mask=tgt_key_padding_mask)[0]        tgt = tgt + self.dropout1(tgt2)        tgt2 = self.norm2(tgt)        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),                                   key=self.with_pos_embed(memory, pos),                                   value=memory, attn_mask=memory_mask,                                   key_padding_mask=memory_key_padding_mask)[0]        tgt = tgt + self.dropout2(tgt2)        tgt2 = self.norm3(tgt)        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))        tgt = tgt + self.dropout3(tgt2)        return tgt    def forward(self, tgt, memory,                tgt_mask: Optional[Tensor] = None,                memory_mask: Optional[Tensor] = None,                tgt_key_padding_mask: Optional[Tensor] = None,                memory_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None,                query_pos: Optional[Tensor] = None):        if self.normalize_before:            return self.forward_pre(tgt, memory, tgt_mask, memory_mask,                                    tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)        return self.forward_post(tgt, memory, tgt_mask, memory_mask,                                 tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)</code></pre><p><strong>有了一个Decoder def with_pos_embed(self, tensor, pos:Optional[Tensor]): return tensor if pos is None else tensor + posLayer的定义，再看Transformer的整个Decoder：</strong></p><pre class="python3"><code>class TransformerDecoder(nn.Module):#值得注意的是：在使用TransformerDecoder时需要传入的参数有：# tgt：Decoder的输入，memory：Encoder的输出，pos：Encoder的位置编码的输出，query_pos：Object Queries，一堆mask    def forward(self, tgt, memory,                tgt_mask: Optional[Tensor] = None,                memory_mask: Optional[Tensor] = None,                tgt_key_padding_mask: Optional[Tensor] = None,                memory_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None,                query_pos: Optional[Tensor] = None):        output = tgt# Decoder输入的tgt:(100, b, 256)        intermediate = []        for layer in self.layers:            output = layer(output, memory, tgt_mask=tgt_mask,                           memory_mask=memory_mask,                           tgt_key_padding_mask=tgt_key_padding_mask,                           memory_key_padding_mask=memory_key_padding_mask,                           pos=pos, query_pos=query_pos)            if self.return_intermediate:                intermediate.append(self.norm(output))        if self.norm is not None:            output = self.norm(output)            if self.return_intermediate:                intermediate.pop()                intermediate.append(output)        if self.return_intermediate:            return torch.stack(intermediate)        return output.unsqueeze(0)</code></pre><h3 id="ffn">5.FFN</h3><pre class="python3"><code>class MLP(nn.Module):    &quot;&quot;&quot; Very simple multi-layer perceptron (also called FFN)&quot;&quot;&quot;    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):        super().__init__()        self.num_layers = num_layers        h = [hidden_dim] * (num_layers - 1)        self.layers = nn.ModuleList(nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim]))    def forward(self, x):        for i, layer in enumerate(self.layers):            x = F.relu(layer(x)) if i &lt; self.num_layers - 1 else layer(x)        return x</code></pre><p><strong>匈牙利匹配HungarianMatcher类：</strong><strong>这个类的目的是计算从targets到predictions的一种最优排列。</strong>predictions比targets的数量多，但我们要进行1-to-1matching，所以多的predictions将与 匹配。这个函数整体在构建(13)式，cost_class，cost_bbox，cost_giou，对应的就是(13)式中的几个损失函数，它们的维度都是(b,100,m)。m包含了这个batch内部所有的GT Bounding Box。</p><pre class="python3"><code># pred_logits:[b,100,92]# pred_boxes:[b,100,4]# targets是个长度为b的list，其中的每个元素是个字典，共包含：labels-长度为(m,)的Tensor，元素是标签；boxes-长度为(m,4)的Tensor，元素是Bounding Box。# detr分类输出，num_queries=100，shape是(b,100,92)        bs, num_queries = outputs[&quot;pred_logits&quot;].shape[:2]        # We flatten to compute the cost matrices in a batch        out_prob = outputs[&quot;pred_logits&quot;].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes] = [100b, 92]        out_bbox = outputs[&quot;pred_boxes&quot;].flatten(0, 1)  # [batch_size * num_queries, 4] = [100b, 4]# 准备分类target shape=(m,)里面存储的是类别索引，m包括了整个batch内部的所有gt bbox        # Also concat the target labels and boxes        tgt_ids = torch.cat([v[&quot;labels&quot;] for v in targets])# (m,)[3,6,7,9,5,9,3]# 准备bbox target shape=(m,4)，已经归一化了        tgt_bbox = torch.cat([v[&quot;boxes&quot;] for v in targets])# (m,4)#(100b,92)-&gt;(100b, m)，对于每个预测结果，把目前gt里面有的所有类别值提取出来，其余值不需要参与匹配#对应上述公式，类似于nll loss，但是更加简单        # Compute the classification cost. Contrary to the loss, we don&#39;t use the NLL,        # but approximate it in 1 - proba[target class].        # The 1 is a constant that doesn&#39;t change the matching, it can be ommitted.#行：取每一行；列：只取tgt_ids对应的m列        cost_class = -out_prob[:, tgt_ids]# (100b, m)        # Compute the L1 cost between boxes, 计算out_bbox和tgt_bbox两两之间的l1距离 (100b, m)        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)# (100b, m)        # Compute the giou cost betwen boxes, 额外多计算一个giou loss (100b, m)        cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))#得到最终的广义距离(100b, m)，距离越小越可能是最优匹配        # Final cost matrix        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou#(100b, m)--&gt; (b, 100, m)        C = C.view(bs, num_queries, -1).cpu()#计算每个batch内部有多少物体，后续计算时候按照单张图片进行匹配，没必要batch级别匹配,徒增计算        sizes = [len(v[&quot;boxes&quot;]) for v in targets]#匈牙利最优匹配，返回匹配索引#enumerate(C.split(sizes, -1))]：(b,100,image1,image2,image3,...)        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]           return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]</code></pre><p>在得到匹配关系后算loss就水到渠成了。loss_labels计算分类损失，loss_boxes计算回归损失，包含L_1 loss,iou_loss。</p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -DETR -code </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DETR_Start</title>
      <link href="/2023/11/01/DETR%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/11/01/DETR%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<center><head>    DETR原理解读    </head> </center><h6 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a>原理解读</h6><hr><p> DETR任务是Object detection，用到的工具是transformers，特点是End-to-end。而目标检测的任务是要预测一系列的Bounding Box的坐标及Label，当下大多数检测器通过定义一些proposal或者anchor，将问题构建成一个分类及回归问题来间接完成这个任务。DETR的工作则是将transfoemers运用到目标检测领域，取代了现在模型需要手工设计的工作，并且取得了不错的结果。    DETR是第一个使用端到端的方法解决检测问题，解决的方法是检测问题视为一个set prediction 问题，如下图所示：</p><p>​    <img src="https://pic1.zhimg.com/v2-772984ccd82a0e0a279ea6a09c3c34c0_r.jpg" alt=""></p><h6 id=""><a href="#" class="headerlink" title=" "></a> </h6><p>     网络的主要组成：CNN和Transformer。</p><p>DETR工作两个关键部分：</p><ul><li>用transformer的encoder-decoder架构一次性生成N个box prediction。(N是一个事先设定的、远远大于image中object个数的一个整数)</li><li>设计了bipartite matching loss，基于预测的box和ground truthboxes的二分图匹配计算loss大小，从而使得预测的box位置和类别更接近于ground truth。</li></ul><p>DETR整体结构可以分为4个部分：(如下图所示)</p><ul><li><p>backbone</p></li><li><p>encoder</p></li><li><p>decoder</p></li><li><p>FFN</p><p><img src="https://pic4.zhimg.com/80/v2-3d43474df51c545ad6bafc19b3c8ccc3_720w.webp" alt=""></p></li></ul><ol><li><p><strong>backbone:</strong> CNN backbone处理 <script type="math/tex">x_i \in B \times 3 \times H_0 \times W_0</script>维的图像，把它转换为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="12.511ex" height="2.413ex" role="img" focusable="false" viewBox="0 -861.5 5530 1066.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(827.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1772.6,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(2297,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(3075,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container>维的feature map。</p></li><li><p><strong>encoder：</strong> encoder的输入是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="12.511ex" height="2.413ex" role="img" focusable="false" viewBox="0 -861.5 5530 1066.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(827.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1772.6,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(2297,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(3075,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的feature map，接下来一次进行下面过程：</p><ul><li><strong>通道数压缩:</strong> 通过1*1卷积处理，将channels数量从C压缩到d，即得到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="12.923ex" height="2.306ex" role="img" focusable="false" viewBox="0 -853.7 5711.8 1019.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mn" transform="translate(498,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1179.3,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2124.1,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2057,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2835,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的新feature map。</li><li><strong>转化为序列化数据：</strong> 将空间的维度（高和宽）压缩为一个维度，即把<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="12.923ex" height="2.306ex" role="img" focusable="false" viewBox="0 -853.7 5711.8 1019.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mn" transform="translate(498,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1179.3,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2124.1,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2057,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2835,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的新feature map通过reshape成（HW，B，256）维的feature map。</li><li><strong>位置编码：</strong> 在得到$z<em>0 \in R^{B\times d \times W}$ 维的feature map后，正式输入encoder之前，需要进行<strong>Positional Encoding</strong>。因为在<em>_self-attention中需要有表示位置的信息，但是transformer encoder这个结构本身无法体现出位置信息</em></em>。所以我们需要对<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="12.923ex" height="2.306ex" role="img" focusable="false" viewBox="0 -853.7 5711.8 1019.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mn" transform="translate(498,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1179.3,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2124.1,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2057,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2835,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的feature map做positional encoding。</li></ul><p>原版本Transformer与Vision Transformer中Positional Encoding表达式为：</p><script type="math/tex; mode=display">PE_{(pos,2i)} = sin(pos / 10000^{2i/d}),  PE_{(pos,2i+1)} = cos(pos / 10000^{2i/d})</script><p>其中，d就是d*HW维的feature map的第一维，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="13.838ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6116.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(988,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(1734.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2679.6,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(2957.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3457.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3902.2,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(4790.2,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(5838.2,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container>。表示token在sequence中的位置，sequence的长度是HW，例如第一个token的pos=0。</p><p>2i和2i+1表示了Positional Encoding的维度，i的取值范围为[0,…,d/2）。所以当pos为1时，Positional Encoding可以写为：</p><script type="math/tex; mode=display">PE(1) = [sin(1/10000^{(0/256)}),cos(1/10000^{(0/256)}),sin(1/10000^{(2/256)}),cos(1/10000^{(2/256)}),...]</script><p>式子中，d=256。</p><p><strong>不同点1：因为Transformer原版中只需要考虑x方向的位置编码，而DETR需要考虑xy方向的位置编码（图像特征是2-D特征），考虑xy方向进行同时编码</strong>Positional Enconding的输出张量：(B,d,H,W),d = 256,其中d代表位置编码长度，H,W代表张量位置。意思为，这个特征图上的任意一个点(H1,W1)有个位置编码，这个编码的长度为256，其中，前128维代表H1的位置编码，后128维代表W1的位置编码。</p><script type="math/tex; mode=display">PE_{(pos_x,2i) = sin(pos_x/10000^{2i/128})}</script><script type="math/tex; mode=display">PE_{(pos_x,2i+1) = cos(pos_x/10000^{2i/128})}</script><script type="math/tex; mode=display">PE_{(pos_y,2i) = sin(pos_y/10000^{2i/128})}</script><script type="math/tex; mode=display">PE_{(pos_y,2i+1) = cos(pos_y/10000^{2i/128})}</script><p>任意一个位置<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="43.195ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 19092.3 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(1377,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(2333.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2778.1,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(3281.1,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(3766.1,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4664.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5053.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5498.3,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(6001.3,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(6486.3,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(7720.5,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(8665.3,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(8943.3,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(9443.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(9888,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(10776,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(11824,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(12102,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(12546.6,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(13049.6,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(13534.6,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(14710.9,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(15655.7,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(15933.7,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(16433.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(16878.3,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(17766.3,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(18814.3,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container> 的Positional Encoding，通过公式(3)(4)可以得到128维向量，代表 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="4.399ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 1944.5 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(988,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container> 的位置编码，通过带入<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="4.268ex" height="1.667ex" role="img" focusable="false" viewBox="0 -442 1886.5 737"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(988,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>带入公式(5)(6)可以得到一个128维向量，代表<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="4.268ex" height="1.667ex" role="img" focusable="false" viewBox="0 -442 1886.5 737"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(988,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>的位置编码，将这两个128维的向量拼接起来，可以得到一个256维的向量，代表<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="11.434ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 5053.6 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(1377,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(2333.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2778.1,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(3281.1,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(3766.1,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4664.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>的位置编码。</p></li></ol><p>   计算所有位置的编码后就可以得到(256,H,W)的张量，代表这个batch的位置编码。编码矩阵的维度是(B,256,H,W)，也把其序列化为维度为(HW,B,256)维的张量。准备与<strong>(HW,B,256)维的feature map相加输入Encoder</strong>。</p><p>   <img src="https://pic1.zhimg.com/80/v2-89d23b461169c6ab25ea64389fe8d86c_720w.webp" alt=""></p><p>   <strong>不同点2：原版Transformer只在Encoder之前使用了Positional Encoding，并且只在输入上进行Positional Encoding，再把输入经过transformation matrix变为Query，Key和Value这几个张量。但DETR在Encoder的每一个Multi-head Self-attention之前都使用了Positional Encoding，且只对Query和Key使用，即：只把维度维(HW,B,256)维的位置编码与维度为(HW,B,256)维的Query和Key相加，而不与Value相加</strong>。</p><p>   下图为DETR的transformer的结构详解：</p><p>   <img src="https://pic3.zhimg.com/v2-c158521c7a602382dfa4d85243672df2_r.jpg" alt=""></p><p>   <img src="https://pic4.zhimg.com/v2-1719966a223d98ad48f98c2e4d71add7_r.jpg" alt=""></p><p>   除了Positonal Encoding设置不一样之外，Encoder其他结构一致。每个Encoder Layer包含一个multi-head self-attention的module和一个前馈网络。</p><p>   Encoder最终输出的是(HW,b,256)维的编码矩阵Embedding，并将其输入Decoder。</p><p>   <strong>与原始transformer编码器不同之处：</strong></p><ul><li><p>输入编码器的位置需要考虑2-D空间位置。</p></li><li><p>位置编码向量需要加入每个Encoder Layer中。</p></li><li><p>在编码器内部位置编码仅作用于Query和Key，即只与Query和Key相加，Value不做处理。</p></li></ul><ol><li><p>decoder：</p><p>DETR的Decoder与原版Transformer的也不太一样：原版的decoder最后一个框output probability，代表一次只产生一个单词的softmax，并由此得到这个单词的预测结果。即：<strong>predicts the output sequence one element at a time</strong>。</p></li></ol><p>   不同的是，DETR的transformer decoder是一次性处理全部的object queries，即一次性输出全部的predictions，即：<strong>decodes the N objects in parallel at each decoder layer</strong>。</p><p>   DETR的Decoder主要有两个输入：</p><ol><li>Transformer Encoder 输入的Embedding与position encoding之和。</li><li><p>Object queries。</p><p>其中，Embedding即使上文提到的(HW,b,256)的编码矩阵。</p></li></ol><p>   <strong>Object queries</strong>是一个维度维(100,b,256)的张量，数据类型是nn.Embedding，该张量可学习。<strong>Object queries</strong>矩阵内部通过学习建模了100个物体之间的全局关系（例如：房间里桌子旁一般放椅子），推理时可以利用该全局注意力更好的进行解码预测输出。</p><p>   Decoder的输入初始被初始为维度为(100,b,256)维的全部元素为0的张量，和<strong>Object queries</strong>相加后一起充当<strong>multi-head self-attention的Query和Key。multi-head self-attention的Value为Decoder的输入(全0张量)</strong>。</p><p>   而到了Decoder的multi-head attention时，它的Key和Value来自Encoder的输出张量，维度为(hw,b,256)，    其中Key值还进行位置编码。Query值一部分来自第一个Add and Norm的输出，维度为(100,b,256)的张量，另一部分来自Object queries，充当可学习的位置编码。所以，multi-head attention的Key和Value的维度为(hw,b,256)，而Query的维度为(100,b,256)。</p><p>   每个Decoder的输出维度为(1,b,100,256)，送入后面的前馈网络。</p><p>   故而：Object queries充当的其实是位置编码的作用，只不过它是可学习的位置编码。所以，归纳得：</p><p>   <img src="https://pic1.zhimg.com/v2-6b9de32f5e1174eb3ecfecc2f0335d48_r.jpg" alt=""></p><p>   <strong>损失函数部分解读：</strong></p><p>   Decoder输出维度(b,100,256)的张量，送到2个前馈网络FFN得到class和Bounding Box。他们会得到N=100个预测目标，包括类别和Bounding Box(100远大于图中目标总数)。计算loss时回归分支仅计算物体位置，背景集合忽略。所以DETR输出张量的维度为<strong>分类分支(b,100,class+1)</strong>和<strong>回归分支(b,100,4)</strong>。其中，4是指每个预测目标归一化的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="11.735ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 5186.9 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1309.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1754.1,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2616.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3061.3,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(3777.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4221.9,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(4797.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。归一化就是出一图片宽高进行归一化。</p><p>   <strong>question: 预测框和真值如何一一对应————-如何知道第47个预测框对应图片里的狗的?</strong></p><p>   DETR: 目标检测任务就是输出无序集合，如何将GT Bounding Box计算loss？</p><p>   一幅图，若第i个物体的真值表达为$y<em>i = (c_i,b_i)<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="9.05ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 4000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">其</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>c_i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="16.285ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 7198 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">表</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">示</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">它</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(4000,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(4433,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(4731,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5260,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(5729,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(6198,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>b_i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="29.805ex" height="2.161ex" role="img" focusable="false" viewBox="0 -750 13174 955"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">表</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">示</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">它</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(4000,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(4759,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(5244,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5816,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6416,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(6936,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7281,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7881,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(8358,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(9117,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(9602,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(10174,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">。</text></g></g><g data-mml-node="mi" transform="translate(11174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">定</text></g><g data-mml-node="mi" transform="translate(12174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">义</text></g></g></g></svg></mjx-container>\hat{y} = {\hat{y_i}}^N</em>{i=1}$ 为网络输出的N个预测值。</p><p>   由匈牙利算法，可以找到每个真指对应的预测值：</p><script type="math/tex; mode=display">   \hat{\sigma} = arg \underset{\sigma\in\textstyle \sum_{N}^{}}{min}  \sum_{i}^{N}L_{match}(y_i,\hat{y_{\sigma(i)}}),</script><p>   对于某一个真值$y<em>i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="40.724ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 18000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">假</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">设</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">已</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">经</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">找</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">到</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">了</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">这</text></g><g data-mml-node="mi" transform="translate(9000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">个</text></g><g data-mml-node="mi" transform="translate(10000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text></g><g data-mml-node="mi" transform="translate(11000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">值</text></g><g data-mml-node="mi" transform="translate(12000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">对</text></g><g data-mml-node="mi" transform="translate(13000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">应</text></g><g data-mml-node="mi" transform="translate(14000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(15000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">预</text></g><g data-mml-node="mi" transform="translate(16000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">测</text></g><g data-mml-node="mi" transform="translate(17000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">值</text></g></g></g></svg></mjx-container>\hat{y</em>{\sigma(i)}}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="6.787ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 3000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">这</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">里</text></g></g></g></svg></mjx-container>\textstyle \sum<em>{N}^{}$表示所有可能的排列，代表<strong>从真值索引到预测值索引的所有的映射</strong>，然后用$L</em>{match}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="6.787ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 3000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">小</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">化</text></g></g></g></svg></mjx-container>y<em>i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 1000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">和</text></g></g></g></svg></mjx-container>\hat{y</em>{\sigma(i)}}$的距离。</p><script type="math/tex; mode=display">   L_{match} = -l_{\{c_i\ne\emptyset \}}\hat{p}_{\sigma(i)}(c_i) + l_{\{c_i\ne\emptyset \}}L_{box}(b_i,\hat{b}_{\sigma{(i)}})</script><p>   意思为：假设当前从真值索引到预测值索引的所有映射为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1ex" role="img" focusable="false" viewBox="0 -431 571 442"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g></g></g></svg></mjx-container>，对于图片中的每个真值ℹ，先找到对应的预测值<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.833ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1694 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(571,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container>,再看分类网络的结果$\hat{p}<em>{\sigma(i)}(c_i)<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="10.056ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 4444.7 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">取</text></g><g data-mml-node="mi" transform="translate(1444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">反</text></g><g data-mml-node="mi" transform="translate(2444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">作</text></g><g data-mml-node="mi" transform="translate(3444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">为</text></g></g></g></svg></mjx-container>L</em>{match}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="35.068ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 15500 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">第</text></g><g data-mml-node="mn" transform="translate(2000,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(2500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">部</text></g><g data-mml-node="mi" transform="translate(3500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4500,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">。</text></g></g><g data-mml-node="mi" transform="translate(5500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">再</text></g><g data-mml-node="mi" transform="translate(6500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">计</text></g><g data-mml-node="mi" transform="translate(7500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">算</text></g><g data-mml-node="mi" transform="translate(8500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">回</text></g><g data-mml-node="mi" transform="translate(9500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">归</text></g><g data-mml-node="mi" transform="translate(10500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">网</text></g><g data-mml-node="mi" transform="translate(11500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">络</text></g><g data-mml-node="mi" transform="translate(12500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(13500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">结</text></g><g data-mml-node="mi" transform="translate(14500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">果</text></g></g></g></svg></mjx-container>\hat{b}<em>{\sigma{(i)}}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="34.33ex" height="2.161ex" role="img" focusable="false" viewBox="0 -750 15174 955"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">与</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">直</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">值</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(4000,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(4759,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(5244,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5816,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6416,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(6936,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7281,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7881,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(8358,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(9117,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(9602,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(10174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(11174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">差</text></g><g data-mml-node="mi" transform="translate(12174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">异</text></g><g data-mml-node="mi" transform="translate(13174,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(14174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">即</text></g></g></g></svg></mjx-container>L</em>{box}(b<em>i,\hat{b}</em>{\sigma{(i)}})<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="4.525ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 2000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">作</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">为</text></g></g></g></svg></mjx-container>L_{match}$的第2部分。</p><p>   所以，可使$L<em>{match}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="11.312ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 5000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">小</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">排</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">列</text></g></g></g></svg></mjx-container>\hat{\sigma}$就是我们要找的排列，即：<em>_对于每个真值ℹ来说，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.833ex" height="2.398ex" role="img" focusable="false" viewBox="0 -810 1694 1060"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(285.5,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(571,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(960,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1305,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>就是这个真值所对应的预测值的索引</em></em>。</p><p>   接下来，使用上步得到的排列<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1.857ex" role="img" focusable="false" viewBox="0 -810 571 821"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(285.5,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g></g></g></svg></mjx-container>，计算匈牙利损失：</p><script type="math/tex; mode=display">   L_{Hungarian}(y,\hat{y}) = \sum_{i=1}^{N}[-log\hat{p}_{\hat{\sigma}(i)}(c_i) + L_{box}(b_i,\hat{b}_{\sigma{(i)}})]</script><p>   其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.106ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1814.8 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(914,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></g></svg></mjx-container>具体为：</p><script type="math/tex; mode=display">   L_{box}(b_i,\hat{b}_{\sigma{(i)}}) = \lambda_{iou}(b_i,\hat{b}_{\sigma(i)}) + \lambda_{L1}\left \| b_i - \hat{b}_{\sigma(i)}) \right \|_1, where    \lambda_{iou},\lambda_{L1} \in R</script><p>   常用的L1 loss对于大小Bounding  Box会有不同的标度，即使它们的相对误差相似。为缓解该问题，这里使用L1 loss和广义loU损耗<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="3.971ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1755.4 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(830,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></mjx-container>的线性组合，它是比列不变的。</p><p>   <strong>DETR的End-to-End的原理概括</strong></p><ul><li><p><strong>DETR如何训练?</strong></p><p>训练集李的任意一张图片，假设第1张图片，通过模型产生100个预测框Predict Bounding Box，假设这张图片有3个GT Bounding Box，它们分别是Cat,Monkey,Pig。</p><p>​                               <script type="math/tex">(label_{Cat} = 1,label_{Monkey} = 19,label_{Pig} = 80)</script></p><p>问题是：如何知道这100个预测框哪个对应Cat，哪个对应Monkey，哪个对应Pig？</p><p>首先建立一个(100,3)的矩阵，矩阵元素即为公式(7)所得结果。举个例子：比如左上角(1,1)号元素的含义是：第1个预测框对应Cat(label = 1)的情况下的$L<em>{match}$值。我们用<strong>scipy.optimize</strong>这个库中的<strong>linear_sum_assignment</strong>函数找到最优匹配，这个过程称之为：<em>_”匈牙利算法(Hungarian Algorithm)”</em></em>。</p><p>假设<strong>linear_sum_assignment</strong>结果是：第16个预测框对应Cat，第39个预测框对应Monkey，第88个预测框对应Pig。接下来，会将第16、39、88个预测框挑出来安装公式(9)计算这个图片的Loss。最后，将所有的图片都按照这个模式去训练模型。</p></li></ul><ul><li><p><strong>训练完如何用?</strong></p><p>训练完，你的模型学习到了一种能力，即：<strong>模型产生的100个预测框，它指导某个预测框该对应什么Object</strong>，例如，模型学习到：第1个预测框对应Cat(label=1)，第2个预测框对应Dog(label=11)，第3个预测框对应Mouse(label=32)，第4-100个预测框对应……</p></li></ul><ul><li><p><strong>为什么训练完后，模型学习到了一种能力，即：模型产生的100个预测框，它指导某个预测框该对应什么Object？</strong></p><p>前文提到Object queries，它是一个维度为(100,b,256)维的张量，初始化元素维全0。实现方式是<strong>nn.Embedding(num_queries,hidden_dim)</strong>，这里num<em>queries=100，hidden<em>dim=256，它是可以训练的。这里的b指batch size，对于但章图片而言，假设Object queries是一个维度为(100,256)维的张量。在训练完模型后，这个张量也训练完成了，那</em></em>此时的Object queries代表什么呢?</p><p>可以把此时的<strong>Object queries看成100个格子，每个格子都是256维的向量</strong>。训练完成后，这100个格子里<strong>注入了不同Object的位置信息和类别信息</strong>。例如：第一个格子里的这256维的向量代表着Cat这种Object的位置信息，这种信息是通过训练，考虑所有图片的某个位置附近的Cat编码特征，属于和位置有关的全局Car统计信息。</p><p>测试时，倘若图片中有Cat，Monkey，Pig三种物体，该图片会输入到编码器中进行特征编码，假设特征没有丢失，Decoder的<strong>Key</strong>和 <strong>Value</strong>就是编码器输出的编码向量，而<strong>Query</strong>就是Object queries，就是我们的100个格子。</p><p><strong>Query可以看作代表不同Object的信息，而Key和Value可以看作代表图像的全局信息</strong>。</p><p>通过注意力模块，将<strong>Query</strong>和<strong>Key</strong>计算，然后加权<strong>Value</strong>得到解码器输出。对于第1个格子的<strong>Query</strong>会和<strong>Key</strong>中的所有向量进行计算，目的是查找某个位置附近有没有Cat,如果有那么该特征就会加权输出，若没有，输出信息就不会有Cat。</p><p>整个过程计算完成后就可以把编码向量中的Cat，Monkey，Pig的编码嵌入信息提取出来，容纳后后面接上FFN进行分类和回归就比较容易，因为特征已经对齐了。</p><p>总而言之，Object queries在训练过程中，对于N个格子会压缩入对应的位置和类别相关统计信息，在测试阶段就可以利用<strong>Query区和某个图像的编码特征Key，Value</strong>计算，<strong>若图片中刚好有Query想找的特征，比如Cat，则这个特征就能提取出来，最后通过2个FFN进行分类和回归</strong>。Object queries作用非常类似Faster R-CNN中的anchor，这个anchor是可学习的，由于维度比较高，故可以表征的东西丰富，训练时间相应也会越长。</p></li></ul><p><strong>Experiments：</strong></p><p><strong>1.性能对比：</strong></p><p>​       <img src="https://pic4.zhimg.com/80/v2-a82446719e7ebd58ac2b3680bd096b6b_720w.webp" alt=""></p><p><strong>2.编码器层数对比:</strong></p><p><img src="https://pic2.zhimg.com/80/v2-35d68162e148aa1457e7f91d135cfdf1_720w.webp" alt=""></p><p>实验发现，编码器层数越多越好，最后选择6层。</p><p>下图为最后一个Encoder Layer的attention可视化，Encoder已经分离了instances，简化了Decoder的对象提取和定位。</p><p><img src="https://pic3.zhimg.com/80/v2-dffe148c6e78f7b67cf6aa5c8bbbc316_720w.webp" alt=""></p><p><strong>3.解码器层数对比:</strong></p><p><img src="https://pic4.zhimg.com/80/v2-87f7c11d6b088af0d0351e3e4808e4b7_720w.webp" alt=""></p><p>可以发现，性能随着解码器层数的增加而提升。下图为Decoder Layer的attention可视化：</p><p><img src="https://pic1.zhimg.com/80/v2-6b80634bf88e496f035945ec25c40764_720w.webp" alt=""></p><p>类似于可视化编码器注意力，作者用不同颜色给每个预测对象的注意力图着色。</p><p><strong>Final: Question:</strong></p><p><strong>Q:</strong> 如果他的N个object query在训练完之后，每个都有了自己对应的目标，比如cat\monkey\pig等，但是如果测试图中，有好多同一目标该怎么办？这时候的输出(N，class+1)与(N,4)该怎么输出多个同一目标？</p><p><strong>A:</strong> N个object query在训练完之后，每个都有了自己对应的目标”只是一种便于理解的方式，实际上也可能是多个query都能找到同样类型的object。比如第49,65个query都可以对应Cat。但anyway，还是query个数多一点比较好，像Deformable DETR就用了N=300。</p><p><strong>Q</strong>:<strong>残差链接用途</strong></p><p><strong>A：</strong>残差链接减小了梯度消失的影响，加入残差链接，就能保证层次很深的模型不会出现梯度消失的现象。</p><p><strong>Q:encoder的输出如何作为decoder的输入</strong></p><p><strong>A：</strong>根据transformer的整体架构图可以看出，decoder的第二层是一个多头注意力（Multi-Head Attention）。既然是多头注意力了，那么一定会涉及到Q、K、V三个矩阵。从上图中还可以看出，K、V矩阵是由encoder部分的输出作为decoder的输入的。刚才提到，encoder最后一层的输出是Zn。那么如何把Zn这一个矩阵变成K、V两个矩阵呢？很简单，和注意力机制内部一样，初始化一个新的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="4.106ex" height="1.964ex" role="img" focusable="false" viewBox="0 -846 1814.8 868"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g></g></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.914ex" height="1.964ex" role="img" focusable="false" viewBox="0 -846 1730 868"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></g></g></svg></mjx-container>​权重矩阵，用Zn去乘这两个矩阵就可以了。总结一下，假如该transformer的编码部分有6层encoder，每层encoder有8个“头”，那么编码部分一共初始化了多少个<img src="https://latex.csdn.net/eq?W%5E%7BQ%7D" alt="W^{Q}">、<img src="https://latex.csdn.net/eq?W%5E%7BK%7D" alt="W^{K}">、<img src="https://latex.csdn.net/eq?W%5E%7BV%7D" alt="W^{V}">权重矩阵？</p><blockquote><p><img src="https://latex.csdn.net/eq?W%5E%7BK%7D" alt="W^{K}">、<img src="https://latex.csdn.net/eq?W%5E%7BV%7D" alt="W^{V}">都是6×8+1个，<img src="https://latex.csdn.net/eq?W%5E%7BQ%7D" alt="W^{Q}">有6×8个。</p></blockquote><p><strong>DETR模型弊端</strong></p><p>如果用10*10的特征图表示一张图片，即一张图片划分成100个Patch，那么就有100个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要100*100=10000次。</p><p>如果用100*100的特征图表示一张图片，即一张图片划分成10000个Patch，那么就有10000个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要10000*100000=1亿次。由此可见，每一个Patch的边长缩小10倍，计算量要增加一万倍。因为识别小物体有恰恰需要划分更小的Patch，因此DETR的小物体识别能力有限。<br>                                                      <img src="https://img-blog.csdnimg.cn/img_convert/065259c3a0e98a8e500c6f59db05fbab.png" style="zoom:36%;"></p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -DETR </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
