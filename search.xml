<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>mmd3d数据提取、模型搭建过程</title>
      <link href="/2023/11/17/mmd3d%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E3%80%81%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B/"/>
      <url>/2023/11/17/mmd3d%E6%95%B0%E6%8D%AE%E6%8F%90%E5%8F%96%E3%80%81%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="熟悉mmdetection3d数据提取、模型搭建过程"><a href="#熟悉mmdetection3d数据提取、模型搭建过程" class="headerlink" title="熟悉mmdetection3d数据提取、模型搭建过程"></a>熟悉mmdetection3d数据提取、模型搭建过程</h1><h3 id="1、读取配置文件"><a href="#1、读取配置文件" class="headerlink" title="1、读取配置文件"></a>1、读取配置文件</h3><h4 id="1-1-mmdetection3d配置文件的组成"><a href="#1-1-mmdetection3d配置文件的组成" class="headerlink" title="1.1 mmdetection3d配置文件的组成"></a>1.1 mmdetection3d配置文件的组成</h4><p>配置文件存放于mmdetection3d/config目录下，其中<strong><em>base</em>目录为mmdetection3d自带的基础配置，即原始配置，从<em>base</em></strong>目录的组成来看，mmdetection3d将配置文件分为四种，分别是：<strong>数据集 (dataset)，模型 (model)，训练策略 (schedule) 和运行时的默认设置 (default runtime)</strong></p><p>下面基于一个配置文件的部分内容，解释一下该怎么看</p><pre><code># configs/centerpoint/centerpoint_01voxel_second_secfpn_4x8_cyclic_20e_nus.py_base_ = [    &#39;../_base_/datasets/nus-3d.py&#39;,    &#39;../_base_/models/centerpoint_01voxel_second_secfpn_nus.py&#39;, # 继承了这个模型的基础文件    &#39;../_base_/schedules/cyclic_20e.py&#39;, &#39;../_base_/default_runtime.py&#39;]model = dict(    pts_voxel_layer=dict(point_cloud_range=point_cloud_range),    pts_bbox_head=dict(bbox_coder=dict(pc_range=point_cloud_range[:2])),    # model training and testing settings    train_cfg=dict(pts=dict(point_cloud_range=point_cloud_range)),    test_cfg=dict(pts=dict(pc_range=point_cloud_range[:2])))</code></pre><p>可以看出，在centerpoint_01voxel_second_secfpn_4x8_cyclic_20e_nus.py这个文件中，model部分只有一小段内容，这是因为继承了centerpoint_01voxel_second_secfpn_nus.py，只是在继承文件的基础上来修改或添加某些特定字段</p><p>为了方便说明，来一份简化版的配置文件</p><pre><code># configs/_base_/models/centerpoint_01voxel_second_secfpn_nus.pymodel = dict(    type=&#39;CenterPoint&#39;,    pts_voxel_layer=dict(         max_num_points=10, voxel_size=voxel_size, max_voxels=(90000, 120000)),    pts_voxel_encoder=dict(type=&#39;HardSimpleVFE&#39;, num_features=5),    pts_middle_encoder=dict(),    pts_backbone=dict(),    pts_neck=dict(),    pts_bbox_head=dict(),    # model training and testing settings    train_cfg=dict(),    test_cfg=dict())</code></pre><p>为了查看具体网络是怎么实现的，我们首先从model最开始出发，根据配置文件，第一个字段为type，上述例子中使用了CenterPoint，我们需要在mmdetection3d/mmdet3d/models/detectors/<strong>init</strong>.py中，找到CenterPoint，看一下是从哪里引入的，如下图所示，这样一来，我们找到了实现网络的具体位置，路径为:mmdetection3d/mmdet3d/models/detectors/centerpoint.py<br><img src="https://img-blog.csdnimg.cn/55d1efc693924069b6d35942f7fcf8b4.png#pic_center" alt=""></p><p><img src="https://img-blog.csdnimg.cn/20908a38ed224a8c845697489d6aa152.png" alt=""></p><p>再往下走，有一句：python pts_voxel_layer=dict( max_num_points=10, voxel_size=voxel_size, max_voxels=(90000, 120000)),</p><p>我们在mmdetection3d/mmdet3d/models/detectors/centerpoint.py中的<strong>init</strong>方法中，找到对应初始化字段pts_voxel_layer</p><p><img src="https://img-blog.csdnimg.cn/3be861f1d1d04d4ea6f9ecaf059545b9.png#pic_center" alt=""></p><p>但是我们在此发现，这里并没有使用这个字段，这是因为CenterPoint类继承了MVXTwoStageDetector类，我们顺藤摸瓜，查看MVXTwoStageDetector类，发现这个类使用了pts_voxel_layer字段，并且给出了使用过程。Voxelization(**pts_voxel_layer)为封装好的一个体素化函数，它返回一组能表示体素的参数，这里我们不关心具体实现。另外，根据上图可以看出，init方法里所有的字段与配置文件中的字段是对应着顺下来的，也就是说，我们可以从centerpoint类里顺藤摸瓜，找到所有配置的具体实现<br><img src="https://img-blog.csdnimg.cn/b4f7508106fb4a21b1f29856de870e56.png#pic_center" alt=""></p><p>至此，第一行分析完毕，再往下走，是一句<code>pts_voxel_encoder=dict(type=&#39;HardSimpleVFE&#39;, num_features=5)</code>，分析方法与上面相同。</p><h4 id="1-2-使用base配置文件构建自己的配置文件"><a href="#1-2-使用base配置文件构建自己的配置文件" class="headerlink" title="1.2 使用base配置文件构建自己的配置文件"></a>1.2 使用base配置文件构建自己的配置文件</h4><p>这部分我们继承基础配置文件，构建一个简单的配置文件，以便接下来使用</p><ol><li>首先，我们在configs目录下创建一个文件夹，用于保存自己的配置文件，并新建一个my_config.py文件</li><li>在新建的配置文件中，写入以下内容</li></ol><pre><code>_base_ = [    &#39;../_base_/datasets/nus-3d-mini.py&#39;, # 这里我继承了基础文件中的nus-3d.py构建了一个mini版本，主要就是修改了一下数据集路径    &#39;../_base_/schedules/schedule_2x.py&#39;,    &#39;../_base_/default_runtime.py&#39;,]voxel_size = [0.1, 0.1, 0.1]norm_cfg = NoneDOUBLE_FLIP = False# 为了简单演示，这里只实现了体素构造层和编码层model = dict(    type=&quot;MY_MODEL&quot;,    voxel_layer=dict(        max_num_points=32,        point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],        voxel_size=voxel_size,        max_voxels=(16000, 40000)),    voxel_encoder=dict(        type=&#39;VoxelFeatureExtractorV3&#39;,        num_input_features=4    ),    train_cfg=dict(),    test_cfg=dict())data = dict(    samples_per_gpu=1,    workers_per_gpu=4)</code></pre><p>1.3 根据配置文件搭建网络</p><p>接下来要做的，是根据我们配置文件中的model部分，开始搭建网络，具体步骤如下：</p><ul><li>在mmdet3d/models/detectors目录下，创建一个py文件，这里取名为my_model.py</li><li>构造一个类，类名要和配置文件中的type一致，当然也可以在注册的时候用import … as …来替换:</li></ul><pre><code>from ..builder import DETECTORS # 引入构造器@DETECTORS.register_module() # 注册，这一句必须要有class MY_MODEL():    def __init__(self):        pass</code></pre><ul><li><strong>在mmdet3d/models/detectors/<em>*init*</em>.py中注册</strong>：</li></ul><p><img src="https://img-blog.csdnimg.cn/04a4d3ce9a854208a7531fe0d9af7eac.png#pic_center" alt=""></p><ul><li>在此例中，便于理解，我们就不继承任何文件了，仅写出初始化方法</li><li>接下来要做的，是要在init方法中定义相关参数并给出相应实现</li></ul><pre><code>from mmcv.ops import Voxelization # 引入mmcv中的体素化方法from .. import builder    # 引入构造器from ..builder import DETECTORS@DETECTORS.register_module()class my_model():    def __init__(self, voxel_layer, voxel_encoder, train_cfg, test_cfg):        self.voxel_layer = Voxelization(**voxel_layer) # 这一层是mmcv自带的，在3.4中会再介绍一下        self.voxel_encoder = builder.build_voxel_encoder(voxel_encoder) # 这里表示这个层是需要我们自己构造的</code></pre><ul><li>再一步，是实现我们的voxel_encoder层，我们在<strong>mmdet3d/models/voxel_encoders</strong>目录下，新建一个文件也好，直接写在现有文件里也行，这里我写在了voxel_encoder.py文件下</li></ul><pre><code>@VOXEL_ENCODERS.register_module() # 注册为体素编码层class VoxelFeatureExtractorV3(nn.Module):    def __init__(            self, num_input_features=4, norm_cfg=None, name=&quot;VoxelFeatureExtractorV3&quot;    ):        super(VoxelFeatureExtractorV3, self).__init__()        self.name = name        self.num_input_features = num_input_features    def forward(self, features, num_voxels, coors=None):        &quot;&quot;&quot;            features: 输入的体素            num_voxels: 体素数目        &quot;&quot;&quot;        points_mean = features[:, :, : self.num_input_features].sum(            dim=1, keepdim=False        ) / num_voxels.type_as(features).view(-1, 1)        return points_mean.contiguous()</code></pre><ul><li><p>再一步，是在mmdet3d/models/voxel<em>encoders/<em>_init</em></em>.py文件中，引入写好的VoxelFeatureExtractorV3，这样，我们就能在配置文件中，使用voxel_encoder=dict(type=’VoxelFeatureExtractorV3’, num_input_features=4)来调用我们的体素编码模块了</p><p><img src="https://img-blog.csdnimg.cn/2a4c35e92d0f4166a656f5b6de878aa9.png#pic_center" alt=""></p><h3 id="2、构建模型"><a href="#2、构建模型" class="headerlink" title="2、构建模型"></a>2、构建模型</h3><pre><code>此部分，我们使用jupyter notebook逐步、分解的从数据抓取开始，演示一下数据在我们搭建的网络中的运行流程</code></pre><h4 id="2-1-读取配置文件"><a href="#2-1-读取配置文件" class="headerlink" title="2.1 读取配置文件"></a>2.1 读取配置文件</h4><p>在真正的训练过程中，是通过传入的参数，根据配置文件路径导入整个参数的，相关代码位于tools/train.py。这里为简便期间，我们直接使用路径读取配置文件</p><pre><code># 读取配置文件from mmcv import Configconfig_file = &quot;/home/wistful/work/mmdetection3d/configs/my_config/my_config.py&quot;cfg = Config.fromfile(config_file)print(&quot;cfg type:&quot;,type(cfg))print(&quot;cfg.model type:&quot;,type(cfg.model))cfg.model  # 打印模型部分</code></pre><p><img src="https://img-blog.csdnimg.cn/27d9011ca29a4803a285a7d6cfb7edf6.png" alt=""></p></li></ul><p>可以看出，打印出来的模型结构，与我们配置文件中的一样。其中，cfg和cfg.model等等的数据类型在此就不介绍了</p><h4 id="2-2-读取数据"><a href="#2-2-读取数据" class="headerlink" title="2.2 读取数据"></a>2.2 读取数据</h4><pre><code># 取数据from mmdet3d.datasets import build_datasetdatasets = [build_dataset(cfg.data.train)]print(&quot;datastes type:&quot;, type(datasets))print(&quot;datastes[0] type&quot;, type(datasets[0]))print(&quot;datastes[0][0] type&quot;, type(datasets[0][0]))datasets[0][0].keys()</code></pre><p><img src="https://img-blog.csdnimg.cn/ae951ca5367d4446b5f3cab978c2783b.png" alt=""></p><p>这里，就不再解释相关内容了，只需要明白datasets为一个长度1的列表，datasets[0]为一个nuscenes数据集类型，datasets[0][i]是nuscenes数据集的所有内容，每一项包含了四部分内容：‘img_metas’, ‘points’, ‘gt_bboxes_3d’, ‘gt_labels_3d’</p><p>实际上，在真正训练或测试过程中，还需要一个data_loader迭代器，方便我们去多线程地读取数据，并且可以实现batch以及shuffle的读取等，mmdet已经帮我们实现了，这里我们由于只需要一条数据模拟一下流程，就不构造data_loader了</p><h4 id="2-3-构造模型"><a href="#2-3-构造模型" class="headerlink" title="2.3 构造模型"></a>2.3 构造模型</h4><pre><code># 构建模型from mmdet3d.models import build_modelmodel = build_model(    cfg.model,    train_cfg=cfg.get(&#39;train_cfg&#39;),    test_cfg=cfg.get(&#39;test_cfg&#39;))model</code></pre><p><img src="https://img-blog.csdnimg.cn/b172c33b34034c738e94a42552c79c2b.png#pic_center" alt=""></p><h3 id="3、运行流程"><a href="#3、运行流程" class="headerlink" title="3、运行流程"></a>3、运行流程</h3><h4 id="3-1-voxel-layer：点云-gt-体素"><a href="#3-1-voxel-layer：点云-gt-体素" class="headerlink" title="3.1 voxel_layer：点云 -&gt; 体素"></a>3.1 voxel_layer：点云 -&gt; 体素</h4><pre><code># 示例文件配置中，第一步是voxel_layer层，将点云编码为体素voxel_layer = model.voxel_layer# 取点云数据points = datasets[0][0].get(&#39;points&#39;).data# 将点云数据送入 voxel_layervoxels_out, coors_out, num_points_per_voxel_out = voxel_layer(points)</code></pre><p>上述代码中，voxel_layer(points)执行的是self.voxel_layer = Voxelization(**voxel_layer)，Voxelization的输入输出大家可以去具体看一下</p><p>我们再使用voxel_layer.parameters打印一下参数，得到下面输出：<br><img src="https://img-blog.csdnimg.cn/08999b11c0d444cd996ae7f2dbc8402d.png#pic_center" alt=""></p><p>现在再来回想一下我们自定义的配置文件，这里再放一下：</p><pre><code>voxel_size = [0.1, 0.1, 0.1]model = dict(    type=&quot;MY_MODEL&quot;,    voxel_layer=dict(        max_num_points=32,        point_cloud_range=[0, -39.68, -3, 69.12, 39.68, 1],        voxel_size=voxel_size,        max_voxels=(16000, 40000)),    voxel_encoder=dict(        type=&#39;VoxelFeatureExtractorV3&#39;,        num_input_features=4    ),    train_cfg=dict(),    test_cfg=dict())</code></pre><p>可以看出，voxel_layer层传入的参数是我们配置文件中的内容，根据前面提到过的Voxelization的输入输出，可以看到，forward部分只缺一个points input，即点云。在本节刚开始的代码块中，voxels_out, coors_out, num_points_per_voxel_out = voxel_layer(points)执行的便是将点云转换为体素操作，我们输出前后形状来看一下：<br><img src="https://img-blog.csdnimg.cn/7703fb82834b472a8116af8b2130bc1d.png#pic_center" alt=""></p><p>即将自定范围内的点云，按照自定体素大小[0.1,0.1,0.1]，每块体素最多保留32个点，最终将32242个点，转换为了6051个体素，每个体素包含的点不一样，但都记录下来了。<br>3.2 voxel_encoder：体素编码</p><p>这一层，主要是将上一层(voxel_layer)的输出进行encoder，往上翻到1.3，我们给出了相应实现，这里实现较为简单，即求每个体素中的平均点。我们现在这里记一下实现中的forward函数：def forward(self, features, num_voxels, coors=None)</p><p>我们先打印一下这一层的参数<br><img src="https://img-blog.csdnimg.cn/d27ce630aa214c45a2e050f4453dc2d8.png" alt=""></p><p>发现没有输出，这是因为我们没有定义相关方法，我们在VoxelFeatureExtractorV3类中加一个方法：</p><pre><code>    def __repr__(self):        s = self.__class__.__name__ + &#39;(&#39;        s += &#39;num_input_features=&#39; + str(self.num_input_features)        s += &#39;)&#39;        return s</code></pre><p>再次执行就有输出了，参数也是与配置文件相同。下面代码将上一层的输出传递到这一层</p><p>```import torch<br>import torch</p><p>voxel_encoder = model.voxel_encoder<br>print(voxel_encoder.parameters)<br>voxel_encoder_inputs = voxels_out  # 将上一层的输出作为输入<br>num_voxels = torch.tensor(voxels_out.shape[0])  # 这里只用一条数据作为演示，所以要转一下tensor<br>voxel_encoder_result = voxel_encoder(voxel_encoder_inputs, num_voxels)<br>print(“voxel_encoder output shape:”, voxel_encoder_result.shape)<br>```</p><p><img src="https://img-blog.csdnimg.cn/d6f781b6c7d245fb80ef3215cb0fb6ea.png#pic_center" alt=""></p><p>我们的配置文件和网络只给出了两个基础层的定义和实现，剩下的几层（neck、backbone…）都大同小异，都是这么个流程，完整的流程还会有损失函数的计算、反向更新等等，这一步是写在模型的forward里，此篇就不再详解了</p>]]></content>
      
      
      
        <tags>
            
            <tag> mmd3d </tag>
            
            <tag> 数据提取 </tag>
            
            <tag> 模型搭建 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/importlib/"/>
      <url>/2023/11/17/importlib/</url>
      
        <content type="html"><![CDATA[<h1 id="python-importlib-用法小结"><a href="#python-importlib-用法小结" class="headerlink" title="python importlib 用法小结"></a>python importlib 用法小结</h1><p>在使用Python的时候，大部分时候引入包，都是通过<code>import</code>  语句，比如</p><pre><code class="lang-python">import numpy as np</code></pre><p>有时候为了更复杂的需求，我们需要用<strong>程序化</strong>的方式来引入包 (Programmatic Importing), 比如根据输入不同，选择执行两个不同包里面的同名函数，这时候就需要用到<code>importlib</code>这个库了。这里先从一个简单例子开始，逐渐深入地讲一下这个库的用法。 </p><h3 id="import-module用法"><a href="#import-module用法" class="headerlink" title="import_module用法"></a>import_module用法</h3><p><code>importlib</code> 是Python3.1增加的系统库，其中最常用的函数是其中的<code>import_module</code> ，功能是用程序语句的方式替代<code>import</code> 语句，用法如下：</p><pre><code class="lang-python">import importlib# 与 import time 效果一样time = importlib.import_module(&#39;time&#39;)print(time.time())# 与 import os.path as path 效果一样path = importlib.import_module(&#39;os.path&#39;)path.join(&#39;a&#39;, &#39;b&#39;)  # results: &#39;a/b&#39;# 相对引入, 一级目录，与 import os.path as path 效果一样path = importlib.import_module(&#39;.path&#39;, package=&#39;os&#39;)path.join(&#39;a&#39;, &#39;b&#39;)  # results: &#39;a/b&#39;# 相对引入，二级目录，与 import os.path as path 效果一样path = importlib.import_module(&#39;..path&#39;, package=&#39;os.time&#39;)path.join(&#39;a&#39;, &#39;b&#39;)  # results: &#39;a/b&#39;</code></pre><p>注意最后的例子中，相对引入时需要在前面增加<code>.</code> </p><p>或者<code>..</code> 来表示相对目录，如果直接使用<code>importlib.import_module(&#39;path&#39;, package=&#39;os&#39;)</code> 会报错。</p><p>如果光看这几个例子的话，貌似跟<code>import</code> 没什么区别，而且语句变得更复杂了，有点多此一举的感觉。</p><p>其实不是的，<strong>个人认为，<code>importlib</code></strong> <strong>的强大之处是将<code>import</code></strong> <strong>语句中写死的字面值改成了<code>import_module</code></strong> <strong>函数中的参数，因此可以通过修改参数在外部用变量来控制实际import的包或者模块，大大地增加了灵活性。</strong> 下面会举一个稍微实用一些的例子。</p><h3 id="一个实际例子"><a href="#一个实际例子" class="headerlink" title="一个实际例子"></a>一个实际例子</h3><p>假设我们在设计一个深度学习工具库，里面包含了N个网络模型（ResNet50, HRNet, MobileNet等等），每个模型的实现都有一个<code>load_model</code> 的函数。由于计算设备的性能不同，需要调用的网络结构也会变化，我们需要根据外部传入的参数来判断实际load哪一个模型。</p><p>虽然采用<code>import</code> 语句+<code>if-else</code> 判断也能完成这个需求，举例实现如下:</p><pre><code class="lang-python">def run(model_name, input):    if model_name == &#39;resnet_50&#39;:        from resnet_50.model import load_model    elif model_name == &#39;hrnet&#39;:        from hrnet.model import load_model    elif model_name == &#39;moblienet&#39;:        from mobilenet.model import load_model    model = load_model()    output = model(input)    return output</code></pre><p>这种写法存在下面的两个问题：  </p><ol><li><p>写法很冗余, N个模型的话需要添加2N条语句  </p></li><li><p>新增模型时需要修改调用处的代码，添加对应的<code>import</code>语句，不符合模块化的要求。</p></li></ol><p>这时候采用<code>importlib</code> 就能比较简洁地解决这个问题:</p><pre><code class="lang-python">import importlibdef run(model_name, input):    load_model = importlib.import_module(&#39;load_model&#39;, package=&#39;&#123;&#125;.model&#39;.format(model_name))    model = load_model()    output = model(input)    return output</code></pre><p>可以看到在这种场景下<code>importlib</code> 确实能大大简化代码。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd-custom_imports/"/>
      <url>/2023/11/17/mmd-custom_imports/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV-自定义"><a href="#MMCV-自定义" class="headerlink" title="MMCV  自定义"></a>MMCV  自定义</h1><p>假设想要添加<code>MyOptimizer</code>的新优化器，有<code>a</code>，<code>b</code>，<code>c</code>三个参数，需要创建一个新的路径 <code>mmdet/core/optimizer</code>。然后在config文件中应用一个新的优化器 <code>mmdet/core/optimizer/my_optimizer.py</code>：</p><pre><code class="lang-python">from .registry import OPTIMIZERSfrom torch.optim import Optimizer@OPTIMIZERS.register_module()class MyOptimizer(Optimizer):    def __init__(self, a, b, c)</code></pre><h4 id="1-2-2-将新的优化器添加到注册器中"><a href="#1-2-2-将新的优化器添加到注册器中" class="headerlink" title="1.2.2 将新的优化器添加到注册器中"></a>1.2.2 将新的优化器添加到注册器中</h4><p>上边定义完成的模块想要在config文件中使用，就必须import到一个明明空间中，两种方法，实现这个工作：</p><ul><li><p>直接在<code>__init__.py</code>文件中，导入，在<code>mmdet/core/optimizer/__init__.py</code>中</p><pre><code class="lang-python">from .my_optimizer import MyOptimizer</code></pre></li><li><p>在config文件中实现</p><pre><code class="lang-python">custom_imports = dict(imports=[&#39;mmdet.core.optimizer.my_optimizer&#39;], allow_failed_imports=False)</code></pre></li></ul><p>该模块<code>mmdet.core.optimizer.my_optimizer</code>将在程序开始时导入，然后自动注册<code>MyOptimizer</code>这个类。请注意，仅应该导入包含<code>MyOptimizer</code>的包。 <code>mmdet.core.optimizer.my_optimizer.MyOptimizer</code> <strong>无法</strong>直接导入。</p><p>实际上，使用这种导入的方式，使用者可以直接使用不同的文件路径结构，只要模块的路径在<code>PYTHONPATH</code>中可以找到即可。</p><h4 id="1-2-3-在config文件中指定优化器"><a href="#1-2-3-在config文件中指定优化器" class="headerlink" title="1.2.3 在config文件中指定优化器"></a>1.2.3 在config文件中指定优化器</h4><p>在config文件中的<code>optimizer</code>字段中使用<code>MyOptimizer</code>：</p><pre><code class="lang-python"># 原始的优化器使用方法optimizer = dict(type=&#39;SGD&#39;, lr=0.02, momentum=0.9, weight_decay=0.0001)# 自定义优化器使用方法optimizer = dict(type=&#39;MyOptimizer&#39;, a=a_value, b=b_value, c=c_value）</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd-hook/"/>
      <url>/2023/11/17/mmd-hook/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV核心组件：Hook"><a href="#MMCV核心组件：Hook" class="headerlink" title="MMCV核心组件：Hook"></a>MMCV核心组件：Hook</h1><h2 id="0-摘要"><a href="#0-摘要" class="headerlink" title="0 摘要"></a>0 摘要</h2><p>Hook 机制在 OpenMMLab 系列框架中应用非常广泛，结合 Runner 类可以实现对训练过程的整个生命周期进行管理。同时内置了多种 Hook，通过注册的形式注入 Runner 中实现了丰富的扩展功能，例如模型权重保存、日志记录等等。</p><h2 id="1-Hook-通俗理解"><a href="#1-Hook-通俗理解" class="headerlink" title="1 Hook 通俗理解"></a>1 Hook 通俗理解</h2><h3 id="（1）Hook是什么"><a href="#（1）Hook是什么" class="headerlink" title="（1）Hook是什么"></a>（1）Hook是什么</h3><p>在wiki百科中的定义如下：</p><p><code>钩子编程（hooking），也称作“挂钩”，是计算机程序设计语，指通过拦截软件模块间的函数调用、消息传递、事件传递来修改或扩展操作系统、应用程序或其他软件组件的行为的各种技术。处理被拦截的函数调用、事件、消息的代码，被称为（钩子hook）</code></p><p>简而言之，就是能改变程序执行流程的一种技术统称。</p><h3 id="（2）Hook用途"><a href="#（2）Hook用途" class="headerlink" title="（2）Hook用途"></a>（2）Hook用途</h3><p>Hook 技术应用非常广泛，可以随便找一个简单例子来说明其用途。在软件编程的设计模式中，有一种设计模式叫做观察者设计模式，该设计模式实现的功能是：对于被观察者的一举一动，观察者都能够立即观测到，其内部实现机制可以简单通过 hook 机制实现，下面具体说明。</p><p>假设气象台可以提供两种对外服务：各大城市未来五天的天气情况和是否会出现地质灾害，你下个月由于要出差想知道深圳未来五天的天气情况，很简单，只需要订阅该气象台发布的其中一个天气预报服务即可，然后每天早上八点你手机会自动收到气象台发布的天气情况，注意：你不需要每时每刻关注气象台是否有发布天气情况，而是等它通知即可，如果不想再收到天气预报了，那么取消订阅即可。</p><p>这是非常典型的观察者设计模式：<strong>被观察者(气象台)对外提供注册机制，观察者可以通过插入和移除 Hook 实现订阅和取消订阅消息的功能，无论观察者有没有注册 Hook,都不会影响被观察者发布消息</strong>，伪代码如下：</p><pre><code class="lang-python">class 气象台():    def __init__():       self.天气预报服务=&#39;&#39;       self.是否存在地质灾害服务=&#39;&#39;       self.天气预报_hooks=[]       self.是否存在地质灾害_hooks=[]    def 订阅天气预报服务(hook_fn)        self.天气预报_hooks.append(hook_fn)     def 取消订阅天气预报服务(hook_fn)：       del self.天气预报_hooks[hook_fn]    def 订阅是否存在地质灾害服务(hook_fn)        self.是否存在地质灾害_hooks.append(hook_fn)     def 取消订阅是否存在地质灾害服务(hook_fn)：       del self.是否存在地质灾害_hooks[hook_fn]    # 每天早上8点，气象台自动调用    def 发布消息():      天气预报信息=获取天气信息()      是否存在地质灾害信息=获取是否存在地质灾害信息()      for hook in self.天气预报_hooks:            hook(天气预报信息)      for hook in self.是否存在地质灾害_hooks:            hook(是否存在地质灾害信息)</code></pre><p>针对个人用户气象台伪代码如下所示：</p><pre><code class="lang-python">def 天气预报信息_hook(str):    print(str)    我收到消息了，天气预报内容是strif __name__ == &#39;__main__&#39;:    # 实例化   气象台实例=气象台()   # 注册 hook   气象台实例.订阅天气预报服务(天气预报信息_hook)   # 接收消息，此时我就能够自动收到消息了   气象台实例.发布消息()   # 不打算再订阅了   气象台实例.取消订阅天气预报服务(天气预报信息_hook)</code></pre><p>注意，实际上气象台实例不需要我们自己实例化，发布消息也不是我们控制的，这些都是被观察者自己的事情，个人用户只需要订阅和取消订阅即可。</p><p><strong>在 python 中由于函数是一等公民，实现 hook 机制其实只需要传入一个函数即可，在该函数中我们可以获取到内部信息，可以修改或者访问该内容，从而实现一些类似黑科技一般的功能</strong>。</p><h3 id="（3）Hook如何用"><a href="#（3）Hook如何用" class="headerlink" title="（3）Hook如何用"></a>（3）Hook如何用</h3><p>在 python 中要实现 hook 机制，非常简单，传入一个函数即可，如下是一个简单的 hook，该 hook 的功能是打印内部变量</p><pre><code class="lang-python">def hook(d):   print(d)def add(a,b,c,hook_fn=None)：   sum1=a+b   if hook_fn is not None:       hook_fn(sum1)    return sum1+c# 调用add(1,2,3,hook)</code></pre>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_build_from_cfg/"/>
      <url>/2023/11/17/mmd3d_build_from_cfg/</url>
      
        <content type="html"><![CDATA[<h1 id="build-from-cfg"><a href="#build-from-cfg" class="headerlink" title="build_from_cfg()"></a>build_from_cfg()</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p> 本篇主要介绍mmdetection如何构建目标检测模型的。在读本文之前，建议读者先阅读mmcv之Config类介绍。该系列文章以构建FasterRcnn为具体例子。当然，本文不会详细介绍如何构建FasterRcnn，仅仅介绍mmdetection是如何建立目标检测模型的。</p><h3 id="1、总体流程"><a href="#1、总体流程" class="headerlink" title="1、总体流程"></a>1、总体流程</h3><p><img src="https://img-blog.csdnimg.cn/20210226165323994.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>我这里简单介绍下流程：“模型配置字典”以字典形式存储着实例化类的信息。而检测器注册类里面存储了目标检测类(FasterRcnn,Yolo,ssd等，里面存储着是类，不是实例）。而函数build_from_cfg则是根据模型配置字典中type字段FasterRcnn来从 检测器注册类 中提取出FasterRcnn类。然后完成实例化。<br> 本篇文章分配顺序如下：</p><ul><li><p>介绍“模型配置字典”和“检测器注册类”；</p></li><li><p>介绍build_from_cfg；</p></li><li><p>实例化faster_rcnn。</p></li></ul><h3 id="2、模型配置字典和检测器注册类"><a href="#2、模型配置字典和检测器注册类" class="headerlink" title="2、模型配置字典和检测器注册类"></a>2、模型配置字典和检测器注册类</h3><h4 id="2-1-模型配置字典"><a href="#2-1-模型配置字典" class="headerlink" title="2.1.模型配置字典"></a>2.1.模型配置字典</h4><p> 这里放张FasterRcnn的配置字典。关于这个字典怎么生成的请转<a href="https://blog.csdn.net/wulele2/article/details/113870217">mmdet之Config类介绍</a>。</p><p><img src="https://img-blog.csdnimg.cn/20210227103744125.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>这里注意下‘type’字段。type字段是用来辨别采用何种检测器/backbone等等（比如FasterRcnn,ResNet,FPN）。</p><h4 id="2-2-检测器注册类"><a href="#2-2-检测器注册类" class="headerlink" title="2.2.检测器注册类"></a>2.2.检测器注册类</h4><p> 注册器是mmdetection中一大特色，要讲清需要很大篇幅，后续我会单独出一篇博文介绍。这里只需明白注册器就是一个字典，里面存储了各个类。比如检测器注册器类，里面存储着（FasterRcnn类、SSD类、Yolo类）。这里贴下注册器类：</p><p><img src="https://img-blog.csdnimg.cn/20210227104650126.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>从上图可以看出，注册器Registry里面包括了多种检测器类。</p><h3 id="3、build-from-cfg函数介绍"><a href="#3、build-from-cfg函数介绍" class="headerlink" title="3、build_from_cfg函数介绍"></a>3、build_from_cfg函数介绍</h3><p> 在弄懂了模型配置字典和注册器类之后，build_from_cfg就是根据模型配置字典中的 type字段 来从注册器类中索引出 对应的 类 完成初始化。举个例子，type为FasterRcnn，则就从Registry中提取出FasterRcnn类。贴下代码：</p><pre><code>def build_from_cfg(cfg, registry, default_args=None):    args = cfg.copy()    obj_type = args.pop(&#39;type&#39;)            # 从配置文件中索引出type字段对应的obj    if isinstance(obj_type, str):        obj_cls = registry.get(obj_type)   # 根据字段从Registry中索引出类        if obj_cls is None:            raise KeyError(                f&#39;&#123;obj_type&#125; is not in the &#123;registry.name&#125; registry&#39;)    elif inspect.isclass(obj_type):        obj_cls = obj_type    else:        raise TypeError(            f&#39;type must be a str or valid type, but got &#123;type(obj_type)&#125;&#39;)    return obj_cls(**args)                 # 完成类的初始化</code></pre><p>这里比较难以理解最后一行代码：<strong>obj_cls(args)</strong> 。其实作用就是用模型配置字典中参数完成类的初始化。这里贴下FasterRcnn初始化代码：</p><pre><code>@DETECTORS.register_module()class TwoStageDetector(BaseDetector):    def __init__(self,                 backbone,                 neck=None,                 rpn_head=None,                 roi_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        super(TwoStageDetector, self).__init__()</code></pre><p>就是用模型配置字典中剩下的字段完成上述参数的初始化。<br>  这是类继承关系图:</p><p><img src="https://img-blog.csdnimg.cn/20210227125122257.png#pic_center" alt=""></p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> Registry </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_model/"/>
      <url>/2023/11/17/mmd3d_model/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV核心组件：Hook"><a href="#MMCV核心组件：Hook" class="headerlink" title="MMCV核心组件：Hook"></a>MMCV核心组件：Hook</h1><h2 id="0-摘要"><a href="#0-摘要" class="headerlink" title="0 摘要"></a>0 摘要</h2>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_registry_builder/"/>
      <url>/2023/11/17/mmd3d_registry_builder/</url>
      
        <content type="html"><![CDATA[<h1 id="MMD3D：模型之registry-py和builder-py解读"><a href="#MMD3D：模型之registry-py和builder-py解读" class="headerlink" title="MMD3D：模型之registry.py和builder.py解读"></a>MMD3D：模型之registry.py和builder.py解读</h1><h3 id="1-引言："><a href="#1-引言：" class="headerlink" title="1.引言："></a>1.引言：</h3><p>本篇文章主要就是讲一下，搭建模型的思路，以及registry.py和builder.py中各个函数块的作用。</p><p>注：builder.py是在mmdet/models文件夹下，是用来创建BACKBONES、NECKS、ROI_EXTRACTORS、SHARED_HEADS、HEADS、LOSSES、DETECTORS的模型的。而关于build_dataset()（在mmdet/datasets/builder.py中），在后面讲到数据集的时候再来讲它。</p><p>在mmdet/utils文件夹下的registry.py为主要的实现过程，后面详细讲解。</p><p>先来看在mmdet/models文件夹下的registry.py，较简单，代码如下：</p><pre><code class="lang-python3"># -*- coding: utf-8 -*-  from mmdet.utils import RegistryBACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;) #类的实例化，Registry是一个类，传入的是一个字符串。该字符串为Registry类的name属性值</code></pre><p>举个例子：DETECTORS为注册表Registry的实例化对象，DETECTORS.name = ‘detector’，Registry类的定义在mmdet/utils/文件中。</p><blockquote><p>所以，根据上面代码，我们就应该知道了，不止一个名为DETECTORS的注册表Registry，后面还会有名为NECKS、ROI_EXTRACTORS 、SHARED_HEADS 、HEADS 、LOSSES  的注册表，这些注册表下的_module_dict属性，则是用来存对应的相同类对象的，举个例子：比如DETECTORS的_module_dict下就有可能有：Faster R-CNN、Cascade R-CNN、FPN、HTC等常见的检测器，到这或许你就明白了注册表的作用咯。</p></blockquote><p>而在mmdet/utils/Registry.py中，有一个类Registry的定义和一个方法：build_from_cfg()的实现。</p><p>build_from_cfg()方法的作用是从  congfig/py配置文件中获取字典数据，创建module（其实也就是一个class类），然后将这个module添加到之前创建的注册表Registry的属性_module_dict中（这是一个字典，key为类名，value为具体的类），返回值是一个实例化后的类对象。</p><p>所以，可以这样理解，从config/py配置文件中，将字典提取出来，然后为其映射成一个类，放进Registry对象的_module_dict属性中。（具体看下面的代码）</p><h3 id="2-Registry-py文件"><a href="#2-Registry-py文件" class="headerlink" title="2.Registry.py文件"></a>2.Registry.py文件</h3><p>以下代码分三部分</p><h4 id="2-1Part-one："><a href="#2-1Part-one：" class="headerlink" title="2.1Part one："></a><strong>2.1Part one：</strong></h4><p><strong>inspect</strong>模块是针对模块，类，方法，功能等对象提供些有用的方法。例如可以帮助我们检查类的内容，检查方法的代码，提取和格式化方法的参数等。</p><pre><code class="lang-python3"># -*- coding: utf-8 -*-  import inspectimport mmcv</code></pre><h4 id="2-2Part-two："><a href="#2-2Part-two：" class="headerlink" title="2.2Part two："></a><strong>2.2Part two：</strong></h4><p>通过前面第一段的代码段，我们知道DETECTORS = Registry(‘detector’)</p><p>detector是干什么的 ？？？</p><p>其实，DETECTORS = Registry(‘detector’) 只是注册了一个对象名为DETECTORS  ，属性name为detector的对象。然后用属性_module_dict  来保存config配置文件中的对应的字典数据所对应的class类（看第三部分代码）。请看如下类Registry的定义代码：</p><pre><code class="lang-python3">class Registry(object):    def __init__(self, name):        #此处的self，是个对象（Object），是当前类的实例，name即为传进来的&#39;detector&#39;值        self._name = name        self._module_dict = dict()  #定义的属性，是一个字典    def __repr__(self):    #返回一个可以用来表示对象的可打印字符串，可以理解为java中的toString()。        format_str = self.__class__.__name__ + &#39;(name=&#123;&#125;, items=&#123;&#125;)&#39;.format(            self._name, list(self._module_dict.keys()))        return format_str    @property                        #把方法变成属性，通过self.name 就能获得name的值。    def name(self):        return self._name         #因为没有定义它的setter方法，所以是个只读属性，不能通过 self.name = newname进行修改。    @property    def module_dict(self):         #同上，通过self.module_dict可以获取属性_module_dict，也是只读的        return self._module_dict    def get(self, key):        #普通方法，获取字典中指定key的value，_module_dict是一个字典，然后就可以通过self.get(key),获取value值        return self._module_dict.get(key, None)    def _register_module(self, module_class):          #关键的一个方法，作用就是Register a module.         #在model文件夹下的py文件中，里面的class定义上面都会出现 @DETECTORS.register_module，意思就是将类当做形参，                #将类送入了方法register_module()中执行。@的具体用法看后面解释。        &quot;&quot;&quot;Register a module.        Args:            module (:obj:`nn.Module`): Module to be registered.        &quot;&quot;&quot;        if not inspect.isclass(module_class):          #判断是否为类，是类的话，就为True，跳过判断            raise TypeError(&#39;module must be a class, but got &#123;&#125;&#39;.format(                type(module_class)))        module_name = module_class.__name__           #获取类名        if module_name in self._module_dict:          #看该类是否已经登记在属性_module_dict中            raise KeyError(&#39;&#123;&#125; is already registered in &#123;&#125;&#39;.format(                module_name, self.name))        self._module_dict[module_name] = module_class #在module中dict新增key和value。key为类名，value为类对象    def register_module(self, cls):                   #对上面的方法，修改了名字，添加了返回值，即返回类本身        self._register_module(cls)        return cls</code></pre><p><strong>note：</strong></p><p><strong>@的含义：</strong><br>Python当解释器读到@的这样的修饰符之后，会先解析@后的内容，直接就把@下一行的函数或者类作为@后边的函数的参数，然后将返回值赋值给下一行修饰的函数对象。<br>在网上看到一个这样的例子：</p><pre><code class="lang-python3">def a(x):    if x==2:        return 4    return 6def b(x):    if x==1:        return 2    return 3@a@bdef c():    return 1</code></pre><p>python会按照自下而上的顺序把各自的函数结果作为下一个函数（上面的函数）的形参输入，也就是a(b(c()))。</p><h4 id="2-3-Part-three："><a href="#2-3-Part-three：" class="headerlink" title="2.3 Part three："></a>2.3 Part three：</h4><p>以下我们通过配置文件<code>cascade_rcnn_r50_fpn_1x.py</code>进行讲解 build 模型的过程。<br>在train中，最先执行Registry的是DETECTORS，传入的参数是配置文件中的model字典。</p><pre><code class="lang-python3">#在 train.py中 model = build_detector(        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)#在builder.py中def build_detector(cfg, train_cfg=None, test_cfg=None):    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))</code></pre><p>所以，后面出现的参数cfg，指的就是配置文件中的model字典。下面是model字典的部分代码：</p><pre><code class="lang-python3"># model settingsmodel = dict(    type=&#39;CascadeRCNN&#39;,    num_stages=3,    pretrained=&#39;torchvision://resnet50&#39;,    backbone=dict(        type=&#39;ResNet&#39;,        depth=50,        num_stages=4,        out_indices=(0, 1, 2, 3),        frozen_stages=1,        style=&#39;pytorch&#39;),    neck=dict(        type=&#39;FPN&#39;,        in_channels=[256, 512, 1024, 2048],        out_channels=256,        num_outs=5),    rpn_head=dict(        type=&#39;RPNHead&#39;,        in_channels=256,        feat_channels=256,        anchor_scales=[8],        anchor_ratios=[0.5, 1.0, 2.0],        anchor_strides=[4, 8, 16, 32, 64],        target_means=[.0, .0, .0, .0],        target_stds=[1.0, 1.0, 1.0, 1.0],        loss_cls=dict(            type=&#39;CrossEntropyLoss&#39;, use_sigmoid=True, loss_weight=1.0),        loss_bbox=dict(type=&#39;SmoothL1Loss&#39;, beta=1.0 / 9.0, loss_weight=1.0)),</code></pre><p>我们继续往下看</p><p>先看build_from_cfg()方法的参数：</p><p><strong>Args:</strong></p><ul><li>cfg (dict): Config dict. It should at least contain the key  “type”.这个cfg就是py配置文件中的字典。在py配置文件中，基本上dict都会有一个key为”type”，当然也有不是的，不是的，这一步就不会执行，也就不会为他创建module。也就是这边创建成module的dict，都必须有key为”type”才可以创建（这里，我们主要讲的是注册表DETECTORS，所以此时cfg对应的是配置文件中的model字典，看上面截图）。举个例子：比如type=’CascadeRCNN’，后面我们会知道，这个value为”CascadeRCNN”的，其实就是models文件夹中某py文件中的类名，他们通过@DETECTORS.register_module，将类名当做形参，传入register_module。并保存下来。</li><li>registry (:obj:Registry): The registry to search the type from.</li><li>default_args (dict, optional): Default initialization arguments.</li></ul><pre><code class="lang-python3">def build_from_cfg(cfg, registry, default_args=None):    &quot;&quot;&quot;Build a module from config dict.    Args:        cfg (dict): Config dict. It should at least contain the key &quot;type&quot;.        registry (:obj:`Registry`): The registry to search the type from.        default_args (dict, optional): Default initialization arguments.    Returns:        obj: The constructed object.    &quot;&quot;&quot;    assert isinstance(cfg, dict) and &#39;type&#39; in cfg    assert isinstance(default_args, dict) or default_args is None #两个是断言，相当于判断，否的话抛出异常。    args = cfg.copy()                        #args相当于temp中间变量，是个字典。    obj_type = args.pop(&#39;type&#39;)             #字典的pop作用：移除序列中key为‘type’的元素，并且返回该元素的值    if mmcv.is_str(obj_type):                        obj_type = registry.get(obj_type)    #获取obj_type的value。        #如果obj_type已经注册到注册表registry中，即在属性_module_dict中，则obj_type 不为None        if obj_type is None:            raise KeyError(&#39;&#123;&#125; is not in the &#123;&#125; registry&#39;.format(                obj_type, registry.name))    elif not inspect.isclass(obj_type):             raise TypeError(&#39;type must be a str or valid type, but got &#123;&#125;&#39;.format(            type(obj_type)))    if default_args is not None:        for name, value in default_args.items():#items()返回字典的键值对用于遍历            args.setdefault(name, value)            #将default_args的键值对加入到args中，将模型和训练配置进行整合，然后送入类中返回    return obj_type(**args)</code></pre><p>obj_type(<em>*args)，</em>  *args是将字典unpack得到各个元素，分别与形参匹配送入函数中；看上面model的截图，所以这边，其实就是将除了’type’的所有字段，当做形参，送入了名为CascadeRCNN()的类中（type =’ CascadeRCNN’）。所以字典里的key就是类中的属性？继续看下面。</p><p>根据Cascade R-CNN的例子，我们在models/detectors找cascade_rcnn的py文件。</p><p>参考里面的参数时，直接打开对应的cascade_rcnn配置文件，在init中，里面的参数则</p><p>对应了配置文件中的字典名。下面两个截图分别是配置文件cascade_rcnn.py和model/detectors/cascade_rcnn.py中的类定义。</p><p><strong>configs/cascade_rcnn.py：</strong></p><pre><code class="lang-python3"># model settingsmodel = dict(    type=&#39;CascadeRCNN&#39;,    num_stages=3,    pretrained=&#39;torchvision://resnet50&#39;,    backbone=dict(        type=&#39;ResNet&#39;,        depth=50,        num_stages=4,        out_indices=(0, 1, 2, 3),        frozen_stages=1,        style=&#39;pytorch&#39;),    neck=dict(        type=&#39;FPN&#39;,        in_channels=[256, 512, 1024, 2048],        out_channels=256,        num_outs=5),    rpn_head=dict(        type=&#39;RPNHead&#39;,</code></pre><p><strong>model/detectors/cascade_rcnn.py：</strong></p><pre><code class="lang-text">@DETECTORS.register_moduleclass CascadeRCNN(BaseDetector, RPNTestMixin):    def __init__(self,                 num_stages,                 backbone,                 neck=None,                 shared_head=None,                 rpn_head=None,                 bbox_roi_extractor=None,                 bbox_head=None,                 mask_roi_extractor=None,                 mask_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        assert bbox_roi_extractor is not None        assert bbox_head is not None        super(CascadeRCNN, self).__init__()</code></pre><p>注意的是，在py配置文件中，好多py文件中都有type = ‘CascadeRCNN’，所以有些参数和属性对不上很正常（毕竟已经设置为None了），因为这个参数可能是其他的cascade R-CNN里面的字典。</p><p>所以，我们在训练时，测试时，就要给出配置文件，配置文件可以不同，但相同type</p><p>detector等文件是相同的，毕竟已经将数据和实现完全的分离了。</p><p>注意：无论训练/检测，都会build DETECTORS；</p><h4 id="2-4-builder-py文件"><a href="#2-4-builder-py文件" class="headerlink" title="2.4 builder.py文件"></a>2.4 builder.py文件</h4><p>builder文件较为简单，因为train.py中，只出现了build_detector()，所以我们先记住里面的两个方法：build_detector和build()。</p><ul><li>build_detector：是创建一个detector，方法里调用了build()方法（所有的build_xx都是直接调用build方法，所以看懂这一个也就看懂所有了）。</li><li>build()：则是调用的Registry.py文件中的build_from_cfg()方法，这个方法我们已经在上面讲过了。</li></ul><p>import：</p><pre><code class="lang-python3"># -*- coding: utf-8 -*-  from torch import nnfrom mmdet.utils import build_from_cfg#此处不会在执行registry而是直接进行sys.modules查询得到from .registry import (BACKBONES, NECKS, ROI_EXTRACTORS, SHARED_HEADS, HEADS,                       LOSSES, DETECTORS)#上面的registry是在models文件夹下，registry类的具体实现是在mmdet/utils文件夹下</code></pre><p>只需要看一下build()的两个参数：cfg, registry</p><p>build_detector()在train.py中的调用，我们就可以知道，cfg是py配置文件中的字典， 以registry是DETECTORS为例，cfg就是model字典  （后面注册表为BACKBONES、NECKS等时，就是配置文件中的其他的字典了，不是model） 。</p><p>build()方法中，主干是一个判断结构，其实就是判断传进来的cfg是字典列表还是单独的字典，来分情况处理。（以注册表DETECTORS为例，是一个单独的字典）</p><ul><li>字典列表的话：挨个调用build_from_cfg()，将其加到注册表的_module_dict中，然后再返回return nn.Sequential(*modules)，这个地方的作用，有待博主继续研究一下下？？？</li><li>字典的话：直接调用build_from_cfg()，将其添加到注册表DETECTORS中（以DETECTORS为例）。</li></ul><pre><code class="lang-python3">def build(cfg, registry, default_args=None):    if isinstance(cfg, list):        modules = [            build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg            #build_from_cfg()返回值是一个带形参的类，返回时也就完成了实例化的过程。        ]        #所以modules就是一个class类的列表        return nn.Sequential(*modules)        #nn.Sequential 一个有序的容器，神经网络模块将按照在传入构造器的顺序依次被添加到计算图中执行，同时以神经网络模块为元素的有序字典也可以作为传入参数    else:        return build_from_cfg(cfg, registry, default_args) #Config dictdef build_detector(cfg, train_cfg=None, test_cfg=None):    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))    #DETECTORS = Registry(&#39;detector&#39;)，创建一个名为DETECTORS的注册表Registry。def build_backbone(cfg):    return build(cfg, BACKBONES)def build_neck(cfg):    return build(cfg, NECKS)def build_roi_extractor(cfg):    return build(cfg, ROI_EXTRACTORS)def build_shared_head(cfg):    return build(cfg, SHARED_HEADS)def build_head(cfg):    return build(cfg, HEADS)def build_loss(cfg):    return build(cfg, LOSSES)</code></pre><p>后面的几个build_XXXXX()的方法也就跟build_detector()相同咯。</p><p>还是以注册表DETECTORS为例，配置文件为cascade_rcnn_r50_fpn_1x.py来讲解：在model文件夹下的cascade_rcnn.py文件中，有类Cascade_RCNN()的定义，在配置文件中，对应的key被传入类中当做属性，这些属性被初始化的时候，调用对应的build_XXXXX()，由此创建它们对应的注册表。</p><p>再以NECK为例，调用build_neck(cfg)；然后执行build(cfg,  NECKS)，这一步，形参用到NECKS，所以在Registry中，又多了一个名为NECKS的注册表了。然后将配置文件中，字典名为neck的，然后生成一个类(类名是neck字典中的type的值，该类在models/necks文件夹下)，同时将该类添加到了注册表NECKS的_module_dict中。</p><pre><code class="lang-python3">#在model/detectors/cascade_rcnn.py中if neck is not None:            self.neck = builder.build_neck(neck)#再builder.py中def build_neck(cfg):    return build(cfg, NECKS)#在configs/cascade_rcnn_r50_fpn_1x.py中neck=dict(        type=&#39;FPN&#39;,        in_channels=[256, 512, 1024, 2048],        out_channels=256,        num_outs=5),</code></pre><p>到这，NECK的注册和数据读入，相信大家已经很清楚了，其他的注册表也是类似的。</p><h3 id="3-总结："><a href="#3-总结：" class="headerlink" title="3.总结："></a>3.总结：</h3><p><strong>搭建模型思路：</strong></p><ul><li>首先，创建一个名为DETECTORS的注册表Registry。这个注册表有属性name=’detector’，和属性_module_dict。_module_dict 是一个字典，专门用来存各个对象名和对应的对象。</li><li>其次，读取py配置文件，py配置文件是个字典，（字典里还有字典，这里面的字典，也是后面来创建模型的，道理是一样的）。根据key为’type’的字典，创建module，对于的value为其module名，然后再models文件夹下中，已经存在了这些module的类。将字典中的其他数据，作为形参，实例化这些类。并保存这些module到属性_module_dict中。</li><li>到这，配置文件的数据，里面的字典（含有type的字典）对应着一个类，type为类名，其他字段则为其属性（其他字段也可能是个字典，后面也有可能要再为它们搭建模型哦）。由此完成模型的搭建。</li></ul><p>这是搭建模型的一个思路，虽然讲得篇幅很大，有点乱乱的感觉，但是看懂后，就会发现很简单。</p><p><strong>mmdetection搭建模型用途：</strong></p><p>mmdetection将配置文件中，字典名为：backbone、neck、roi_extractor、shared_head、head、loss、detector的字典，全部实例化成注册表（Registry），然后这些字典里的type，都被实例化成对应的类（module），并添加到注册表的属性_module_dict中，其他的字段，则为这个类的属性，由此完成模型的建立，实际上，就是将配置文件的字典数据保存到类（module）中，以便后面读取数据，加载数据。</p><h3 id="Problem："><a href="#Problem：" class="headerlink" title="Problem："></a>Problem：</h3><p><strong>Importance：</strong></p><p><strong>总体讲的通俗易懂，但是有一点疑问。文中多次出现类似于”通过build实例化模块类，然后把实例存入model_dict”的表述。但是，结合我目前掌握的相关知识，我的理解是，模块类的注册是通过register_module方法，把模块类加入到model_dict，然后bulid方法根据cfg提供的type类名，从Register类中通过get方法从model_dict获取模块类，然后利用cfg提供的参数对模块类进行实例化</strong></p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_train_see/"/>
      <url>/2023/11/17/mmd3d_train_see/</url>
      
        <content type="html"><![CDATA[<h1 id="MMCV核心组件：Hook"><a href="#MMCV核心组件：Hook" class="headerlink" title="MMCV核心组件：Hook"></a>MMCV核心组件：Hook</h1><h2 id="0-摘要"><a href="#0-摘要" class="headerlink" title="0 摘要"></a>0 摘要</h2>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> hook </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmd_hook</title>
      <link href="/2023/11/17/mmd3d_%E6%B3%A8%E5%86%8C%E6%A8%A1%E5%9E%8B/"/>
      <url>/2023/11/17/mmd3d_%E6%B3%A8%E5%86%8C%E6%A8%A1%E5%9E%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection3D-注册模型"><a href="#MMDetection3D-注册模型" class="headerlink" title="MMDetection3D:注册模型"></a>MMDetection3D:注册模型</h1><p>train.py的开头中，已经开始注册必要的模块了 </p><pre><code>from mmcv import Configfrom mmdet import __version__from mmdet.datasets import build_datasetfrom mmdet.apis import (train_detector, init_dist, get_root_logger,                        set_random_seed)from mmdet.models import build_detector</code></pre><p>看mmdet文件夹下的<strong>init</strong>.py，以及datasets , apis , models 下的<strong>init</strong>.py文件，发现：<br> mmdet.<strong>init</strong>py:</p><pre><code>from .backbones import *  # noqa: F401,F403 from .necks import *  #    noqa: F401,F403 from .roi_extractors import *  # noqa: F401,F403 from    .anchor_heads import *  # noqa: F401,F403 from .shared_heads import *    # noqa: F401,F403 from .bbox_heads import *  # noqa: F401,F403 from .mask_heads import *  # noqa: F401,F403 from .losses import *  #    noqa: F401,F403 from .detectors import *  # noqa: F401,F403 from    .registry import (BACKBONES, NECKS, ROI_EXTRACTORS, SHARED_HEADS,    HEADS,                      LOSSES, DETECTORS) from .builder import (build_backbone, build_neck, build_roi_extractor,                     build_shared_head, build_head, build_loss,                     build_detector)       __all__ = [    &#39;BACKBONES&#39;, &#39;NECKS&#39;, &#39;ROI_EXTRACTORS&#39;, &#39;SHARED_HEADS&#39;, &#39;HEADS&#39;, &#39;LOSSES&#39;,    &#39;DETECTORS&#39;, &#39;build_backbone&#39;, &#39;build_neck&#39;, &#39;build_roi_extractor&#39;,    &#39;build_shared_head&#39;, &#39;build_head&#39;, &#39;build_loss&#39;, &#39;build_detector&#39; ]</code></pre><p>这个文件，第一行，导入了backbone.<em><em>init</em></em>.py，看一下里面内容：<br> mmdet.models.backbones.<em><em>init</em></em>.py</p><pre><code>from .resnet import ResNet, make_res_layerfrom .resnext import ResNeXtfrom .ssd_vgg import SSDVGGfrom .hrnet import HRNet__all__ = [&#39;ResNet&#39;, &#39;make_res_layer&#39;, &#39;ResNeXt&#39;, &#39;SSDVGG&#39;, &#39;HRNet&#39;]</code></pre><p>这里又导入了resnet，resnext等几个卷积神经网络，那么以resnet为例，看一下里面都有啥<br> mmdet.models.backbones.resnet.py<br> 第13.14行：</p><pre><code>from ..registry import BACKBONESfrom ..utils import build_conv_layer, build_norm_layer</code></pre><p>其中又从registry中导入BACKBONES，那么再来看看registry和他的BACKBONES<br> mmdet.registry.py:</p><pre><code>from mmdet.utils import RegistryBACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;)</code></pre><p>那么这个Registry又是何方神圣？意欲何为？看看去<br> mmdet.utils.<em><em>init</em></em>.py:</p><pre><code>from .registry import Registry, build_from_cfg__all__ = [&#39;Registry&#39;, &#39;build_from_cfg&#39;]</code></pre><p>顺藤摸瓜，找到registry.py<br> mmdet.utils.registry.py<br> 代码稍长，分两段看吧。只看主要代码，能帮助理解其机制的代码，删除部分不影响理解的代码，全文都是。<br> Registry:</p><pre><code>import inspectimport mmcvclass Registry(object):    def __init__(self, name):        self._name = name        self._module_dict = dict()    def __repr__(self):        format_str = self.__class__.__name__ + &#39;(name=&#123;&#125;, items=&#123;&#125;)&#39;.format(            self._name, list(self._module_dict.keys()))        return format_str    @property    def name(self):        return self._name    @property    def module_dict(self):        return self._module_dict    def get(self, key):        return self._module_dict.get(key, None)    def _register_module(self, module_class):        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, but got &#123;&#125;&#39;.format(                type(module_class)))        module_name = module_class.__name__        if module_name in self._module_dict:            raise KeyError(&#39;&#123;&#125; is already registered in &#123;&#125;&#39;.format(                module_name, self.name))        self._module_dict[module_name] = module_class    def register_module(self, cls):        self._register_module(cls)        return cls</code></pre><p>这段代码呢，生成了一个字典，里面包含了模块名字，以后模块都要挂在这个名字下。此时我们反过头来再看registry.py中的代码，其实是生成了各个主要部分，并向外提供了接口。<br> 这段代码到现在，暂时没有了下文，我们再来看build_from_cfg函数：</p><pre><code>def build_from_cfg(cfg, registry, default_args=None):    &quot;&quot;&quot;Build a module from config dict.    Args:        cfg (dict): Config dict. It should at least contain the key &quot;type&quot;.        registry (:obj:`Registry`): The registry to search the type from.        default_args (dict, optional): Default initialization arguments.    Returns:        obj: The constructed object.    &quot;&quot;&quot;    assert isinstance(cfg, dict) and &#39;type&#39; in cfg    assert isinstance(default_args, dict) or default_args is None    args = cfg.copy()    obj_type = args.pop(&#39;type&#39;)    if mmcv.is_str(obj_type):        obj_type = registry.get(obj_type)        if obj_type is None:            raise KeyError(&#39;&#123;&#125; is not in the &#123;&#125; registry&#39;.format(                obj_type, registry.name))    elif not inspect.isclass(obj_type):        raise TypeError(&#39;type must be a str or valid type, but got &#123;&#125;&#39;.format(            type(obj_type)))    if default_args is not None:        for name, value in default_args.items():            args.setdefault(name, value)    return obj_type(**args)</code></pre><p>这段代码比较难弄，尤其是最后哪行。我们来分析一波吧，既然难懂，就先来看他在那里被调用的吧。回到tools.train.py：</p><pre><code>...def parse_args():    ...    parser.add_argument(&#39;config&#39;, help=&#39;train config file path&#39;)...def main():    args = parse_args()    cfg = Config.fromfile(args.config)    ...    model = build_detector(        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)    ...</code></pre><p>因为其有个cfg参数，而这build_detector是用到了cfg，可以算个线索（如果你使用IDE的话，可以看看build_from_cfg是被谁引用的，顺藤摸瓜，推荐）。再来看build_detector,文章第一个代码段train.py最后一行引入进来，在mmet.models里，而mmet.models.<strong>init</strong>py中，有</p><pre><code>from .builder import (build_backbone, build_neck, build_roi_extractor,                      build_shared_head, build_head, build_loss,                      build_detector)</code></pre><p>我们来看这build_detector具体内容吧mmet.models.builder.py:</p><pre><code>from torch import nnfrom mmdet.utils import build_from_cfgfrom .registry import (BACKBONES, NECKS, ROI_EXTRACTORS, SHARED_HEADS, HEADS,                       LOSSES, DETECTORS)def build(cfg, registry, default_args=None):    if isinstance(cfg, list):        modules = [            build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg        ]        return nn.Sequential(*modules)    else:        return build_from_cfg(cfg, registry, default_args)def build_backbone(cfg):    return build(cfg, BACKBONES)def build_neck(cfg):    return build(cfg, NECKS)def build_roi_extractor(cfg):    return build(cfg, ROI_EXTRACTORS)def build_shared_head(cfg):    return build(cfg, SHARED_HEADS)def build_head(cfg):    return build(cfg, HEADS)def build_loss(cfg):    return build(cfg, LOSSES)def build_detector(cfg, train_cfg=None, test_cfg=None):    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))</code></pre><p>看到参数又传到build里，而cfg是个dict类型，所以又到了build_from_cfg,此刻我们来分析build_from_cfg：</p><pre><code>def build_from_cfg(cfg, registry, default_args=None):    ...    args = cfg.copy()    obj_type = args.pop(&#39;type&#39;)    ...    return obj_type(**args)</code></pre><p>再在你的配置文件里看到这个obj_type：<br> configs.faster_rcnn_r50_fpn_1x.py:</p><pre><code>model = dict(    type=&#39;FasterRCNN&#39;,</code></pre><p>其实也就是执行了FasterRCNN(),那么，FasterRCNN又是从何而来呢？<br> 答：在mmdet.models.<em><em>init里，可以看到`from .detectors import \</em>`这行代码，再来瞧瞧mmdet.models.detectors.</em>*init**.py：</p><pre><code>from .base import BaseDetectorfrom .single_stage import SingleStageDetectorfrom .two_stage import TwoStageDetectorfrom .rpn import RPNfrom .fast_rcnn import FastRCNNfrom .faster_rcnn import FasterRCNNfrom .mask_rcnn import MaskRCNNfrom .cascade_rcnn import CascadeRCNNfrom .htc import HybridTaskCascadefrom .retinanet import RetinaNetfrom .fcos import FCOSfrom .grid_rcnn import GridRCNNfrom .mask_scoring_rcnn import MaskScoringRCNN__all__ = [    &#39;BaseDetector&#39;, &#39;SingleStageDetector&#39;, &#39;TwoStageDetector&#39;, &#39;RPN&#39;,    &#39;FastRCNN&#39;, &#39;FasterRCNN&#39;, &#39;MaskRCNN&#39;, &#39;CascadeRCNN&#39;, &#39;HybridTaskCascade&#39;,    &#39;RetinaNet&#39;, &#39;FCOS&#39;, &#39;GridRCNN&#39;, &#39;MaskScoringRCNN&#39;]</code></pre><p>可以看到这里注册了一大堆的模型，取出faster_rcnn来看，在mmdet.models.detectors.faster_rcnn.py里：</p><pre><code>from .two_stage import TwoStageDetectorfrom ..registry import DETECTORS@DETECTORS.register_moduleclass FasterRCNN(TwoStageDetector):    def __init__(self,                 backbone,                 rpn_head,                 bbox_roi_extractor,                 bbox_head,                 train_cfg,                 test_cfg,                 neck=None,                 shared_head=None,                 pretrained=None):        super(FasterRCNN, self).__init__(            backbone=backbone,            neck=neck,            shared_head=shared_head,            rpn_head=rpn_head,            bbox_roi_extractor=bbox_roi_extractor,            bbox_head=bbox_head,            train_cfg=train_cfg,            test_cfg=test_cfg,            pretrained=pretrained)</code></pre><p>看到这里以TwoStageDetector作为其父类，看TwoStageDetector：</p><pre><code>import torchimport torch.nn as nnfrom .base import BaseDetectorfrom .test_mixins import RPNTestMixin, BBoxTestMixin, MaskTestMixinfrom .. import builderfrom ..registry import DETECTORSfrom mmdet.core import bbox2roi, bbox2result, build_assigner, build_sampler@DETECTORS.register_moduleclass TwoStageDetector(BaseDetector, RPNTestMixin, BBoxTestMixin,                       MaskTestMixin):    def __init__(self,                 backbone,                 neck=None,                 shared_head=None,                 rpn_head=None,                 bbox_roi_extractor=None,                 bbox_head=None,                 mask_roi_extractor=None,                 mask_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        super(TwoStageDetector, self).__init__()        self.backbone = builder.build_backbone(backbone)        if neck is not None:            self.neck = builder.build_neck(neck)        if shared_head is not None:            self.shared_head = builder.build_shared_head(shared_head)        if rpn_head is not None:            self.rpn_head = builder.build_head(rpn_head)        if bbox_head is not None:            self.bbox_roi_extractor = builder.build_roi_extractor(                bbox_roi_extractor)            self.bbox_head = builder.build_head(bbox_head)        if mask_head is not None:            if mask_roi_extractor is not None:                self.mask_roi_extractor = builder.build_roi_extractor(                    mask_roi_extractor)                self.share_roi_extractor = False            else:                self.share_roi_extractor = True                self.mask_roi_extractor = self.bbox_roi_extractor            self.mask_head = builder.build_head(mask_head)        self.train_cfg = train_cfg        self.test_cfg = test_cfg        self.init_weights(pretrained=pretrained)    @property    def with_rpn(self):        return hasattr(self, &#39;rpn_head&#39;) and self.rpn_head is not None</code></pre><p>可以看到，在这里形成了整个模型。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> registry model </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Registry</title>
      <link href="/2023/11/16/Registry/"/>
      <url>/2023/11/16/Registry/</url>
      
        <content type="html"><![CDATA[<h1 id="Registry"><a href="#Registry" class="headerlink" title="Registry"></a>Registry</h1><p>Registry 类可以提供一种完全相似的对外装饰函数来管理构建不同的组件，例如 backbones、head 和 necks  等等，Registry 类内部其实维护的是一个全局 key-value 对。通过 Registry  类，用户可以通过字符串方式实例化任何想要的模块。</p><p>Registry 类最大好处是：<strong>解耦性强、可扩展性强，代码更易理解</strong>。</p><p>回到 Registry 类本身，有如下几种用法：</p><pre><code># 0. 先构建一个全局的 CATS 注册器类CATS = mmcv.Registry(&#39;cat&#39;)# 通过装饰器方式作用在想要加入注册器的具体类中#===============================================================# 1. 不需要传入任何参数，此时默认实例化的配置字符串是 str (类名)@CATS.register_module()class BritishShorthair:    pass# 类实例化CATS.get(&#39;BritishShorthair&#39;)(**args)#==============================================================# 2.传入指定 str，实例化时候只需要传入对应相同 str 即可@CATS.register_module(name=&#39;Siamese&#39;)class SiameseCat:    pass# 类实例化CATS.get(&#39;Siamese&#39;)(**args)#===============================================================# 3.如果出现同名 Registry Key，可以选择报错或者强制覆盖# 如果指定了 force=True，那么不会报错# 此时 Registry 的 Key 中，Siamese2Cat 类会覆盖 SiameseCat 类# 否则会报错@CATS.register_module(name=&#39;Siamese&#39;,force=True)class Siamese2Cat:    pass# 类实例化CATS.get(&#39;Siamese&#39;)(**args)#==============================================================# 4. 可以直接注册类class Munchkin:    passCATS.register_module(Munchkin)# 类实例化CATS.get(&#39;Munchkin&#39;)(**args)</code></pre><p><strong>(1) 最简实现</strong></p><pre><code class="lang-python"># 方便起见，此处并未使用类方式构建，而是直接采用全局变量_module_dict = dict()# 定义装饰器函数def register_module(name):    def _register(cls):        _module_dict[name] = cls        return cls    return _register# 装饰器用法@register_module(&#39;one_class&#39;)class OneTest(object):    pass@register_module(&#39;two_class&#39;)class TwoTest(object):    pass</code></pre><p>进行简单测试：</p><pre><code class="lang-python">if __name__ == &#39;__main__&#39;:    # 通过注册类名实现自动实例化功能    one_test = _module_dict[&#39;one_class&#39;]()    print(one_test)# 输出&lt;__main__.OneTest object at 0x7f1d7c5acee0&gt;</code></pre><p>可以发现只要将所定义的简单装饰器函数作用到类名上，然后内部采用 <code>_module_dict</code> 保存信息即可</p><p><strong>(2) 实现无需传入参数，自动根据类名初始化类</strong></p><pre><code class="lang-python">_module_dict = dict()def register_module(module_name=None):    def _register(cls):        name = module_name        # 如果 module_name 没有给，则自动获取        if module_name is None:            name = cls.__name__        _module_dict[name] = cls        return cls    return _register@register_module(&#39;one_class&#39;)class OneTest(object):    pass@register_module()class TwoTest(object):    pass</code></pre><p>进行简单测试：</p><pre><code class="lang-python">if __name__ == &#39;__main__&#39;:    one_test = _module_dict[&#39;one_class&#39;]    # 方便起见，此处仅仅打印了类对象，而没有实例化。如果要实例化，只需要 one_test() 即可    print(one_test)    two_test = _module_dict[&#39;TwoTest&#39;]    print(two_test)# 输出&lt;class &#39;__main__.OneTest &#39;&gt;&lt;class &#39;__main__.TwoTest&#39;&gt;</code></pre><h3 id="Registry-类实现"><a href="#Registry-类实现" class="headerlink" title="Registry 类实现"></a>Registry 类实现</h3><p>基于上面的理解，此时再来看 MMCV 实现就会非常简单了，核心逻辑如下：</p><pre><code class="lang-python">class Registry:    def __init__(self, name):        # 可实现注册类细分功能        self._name = name         # 内部核心内容，维护所有的已经注册好的 class        self._module_dict = dict()    def _register_module(self, module_class, module_name=None, force=False):        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, &#39;                            f&#39;but got &#123;type(module_class)&#125;&#39;)        if module_name is None:            module_name = module_class.__name__        if not force and module_name in self._module_dict:            raise KeyError(f&#39;&#123;module_name&#125; is already registered &#39;                           f&#39;in &#123;self.name&#125;&#39;)        # 最核心代码        self._module_dict[module_name] = module_class    # 装饰器函数    def register_module(self, name=None, force=False, module=None):        if module is not None:            # 如果已经是 module，那就知道 增加到字典中即可            self._register_module(                module_class=module, module_name=name, force=force)            return module        # 最标准用法        # use it as a decorator: @x.register_module()        def _register(cls):            self._register_module(                module_class=cls, module_name=name, force=force)            return cls        return _register</code></pre><p>在 MMCV 中所有的类实例化都是通过 <code>build_from_cfg</code> 函数实现，做的事情非常简单，就是给定 <code>module_name</code>，然后从 <code>self._module_dict</code> 提取即可。</p><pre><code class="lang-python">def build_from_cfg(cfg, registry, default_args=None):    args = cfg.copy()    if default_args is not None:        for name, value in default_args.items():            args.setdefault(name, value)    obj_type = args.pop(&#39;type&#39;) # 注册 str 类名    if is_str(obj_type):        # 相当于 self._module_dict[obj_type]        obj_cls = registry.get(obj_type)        if obj_cls is None:            raise KeyError(                f&#39;&#123;obj_type&#125; is not in the &#123;registry.name&#125; registry&#39;)    # 如果已经实例化了，那就直接返回    elif inspect.isclass(obj_type):        obj_cls = obj_type    else:        raise TypeError(            f&#39;type must be a str or valid type, but got &#123;type(obj_type)&#125;&#39;)    # 最终初始化对于类，并且返回，就完成了一个类的实例化过程    return obj_cls(**args)</code></pre><p>一个完整的使用例子如下：</p><pre><code class="lang-python">CONVERTERS = Registry(&#39;converter&#39;)@CONVERTERS.register_module()class Converter1(object):    def __init__(self, a, b):        self.a = a        self.b = bconverter_cfg = dict(type=&#39;Converter1&#39;, a=a_value, b=b_value)converter = build_from_cfg(converter_cfg,CONVERTERS)</code></pre><p>​       </p><hr><h1 id="mmdetection模型构建及Registry注册器机制"><a href="#mmdetection模型构建及Registry注册器机制" class="headerlink" title="mmdetection模型构建及Registry注册器机制"></a>mmdetection模型构建及Registry注册器机制</h1><p>mmdetection封装的很好，很方便使用，比如我想训练的话只需如下的一条指令。在train.py中，通过build_detector来构建模型，</p><pre><code>python tools/train.py  configs/pascal_voc/faster_rcnn_r50_fpn_1x_voc0712.py</code></pre><p>build_detector的定义如下，最后通过build_from_cfg来构建模型，这里看到了让人困惑的Registry.</p><pre><code>from mmdet.cv_core.utils import Registry, build_from_cfgfrom torch import nnBACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;)def build(cfg, registry, default_args=None):    &quot;&quot;&quot;Build a module.    Args:        cfg (dict, list[dict]): The config of modules, is is either a dict            or a list of configs.        registry (:obj:`Registry`): A registry the module belongs to.        default_args (dict, optional): Default arguments to build the module.            Defaults to None.    Returns:        nn.Module: A built nn module.    &quot;&quot;&quot;    if isinstance(cfg, list):        modules = [            build_from_cfg(cfg_, registry, default_args) for cfg_ in cfg        ]        return nn.Sequential(*modules)    else:        return build_from_cfg(cfg, registry, default_args)def build_detector(cfg, train_cfg=None, test_cfg=None):    &quot;&quot;&quot;Build detector.&quot;&quot;&quot;    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg)</code></pre><h2 id="一、Registry是干什么的"><a href="#一、Registry是干什么的" class="headerlink" title="一、Registry是干什么的"></a>一、Registry是干什么的</h2><p>Registry完成了从字符串到类的映射，这样模型信息、训练时的参数信息，只需要写入到一个配置文件里，然后使用注册器来实例化即可。</p><h2 id="二、如何实现"><a href="#二、如何实现" class="headerlink" title="二、如何实现"></a>二、如何实现</h2><p> 通过装饰器来实现。在mmcv/mmcv/registry.py中，我们看到了Registry类。其中完成字符串到类的映射，实际上就是下面的成员函数来实现的，核心代码就一句，将要注册的类添加到字典里，key为类的名字（字符串）。下面通过一个小例子，</p><pre><code>def _register_module(self, module_class, module_name=None, force=False):        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, &#39;                            f&#39;but got &#123;type(module_class)&#125;&#39;)        if module_name is None:            module_name = module_class.__name__        if not force and module_name in self._module_dict:            raise KeyError(f&#39;&#123;module_name&#125; is already registered &#39;                           f&#39;in &#123;self.name&#125;&#39;)        self._module_dict[module_name] = module_class</code></pre><p> 来看看它的构建过程。在导入下面这个文件时，首先创建FRUIT实例，接着通过装饰器（这里是用成员函数装饰类）来注册Apple类，调用register_module，然后调用_register（注意：参数cls即为类Apple），最后调用_register_module完成Apple的添加。完成后，FRUIT就有了个字典成员：[‘Apple’]=APPle。在build_from_cfg中，传入模型参数，即可通过FRUIT构建Apple的实例化对象。</p><pre><code>class Registry():    def __init__(self, name):        self._name = name        self._module_dict = dict()    def _register_module(self, module_class, module_name, force):        self._module_dict[module_name] = module_class        print(&#39;self._module_dict&#39;,self._module_dict)    def register_module(self, name=None, force=False, module=None):        print(&#39;register module ...&#39;)        def _register(cls):            print(&#39;cls &#39;, cls)            self._register_module(                module_class=cls, module_name=name, force=force)            return cls        return _registerFRUIT = Registry(&#39;fruit&#39;)@FRUIT.register_module()class Apple():    def __init__(self, name):        self.name = name</code></pre><p>运行结果：</p><pre><code>register module ...cls  &lt;class &#39;__main__.Apple&#39;&gt;self._module_dict &#123;None: &lt;class &#39;__main__.Apple&#39;&gt;&#125;</code></pre><h2 id="三、Registry在mmdetection中是如何构建模型的"><a href="#三、Registry在mmdetection中是如何构建模型的" class="headerlink" title="三、Registry在mmdetection中是如何构建模型的"></a>三、Registry在mmdetection中是如何构建模型的</h2><p> 我们来看一下构建模型的流程：</p><p>​        1、在train.py中通过build_detector构建模型，其中cfg.model, cfg.train_cfg如下，包括模型信息和训练信息。</p><pre><code>model = build_detector(        cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)</code></pre><p><img src="https://s2.51cto.com/images/blog/202112/30151824_61cd5d40bbd4586669.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp/resize,m_fixed,w_1184" alt=""></p><p> 2、最关键的部分来了。首先通过build_detector构建模型， 其中传入的DETECTORS是Registry的实例，在该实例中，包含了所有已经实现的检测器，如图。那么它是在哪里实现添加这些检测的类的呢？</p><pre><code>def build_detector(cfg, train_cfg=None, test_cfg=None):    &quot;&quot;&quot;Build detector.&quot;&quot;&quot;    return build(cfg, DETECTORS, dict(train_cfg=train_cfg, test_cfg=test_cfg))</code></pre><p><img src="https://s2.51cto.com/images/blog/202112/30151825_61cd5d410366b83654.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp/resize,m_fixed,w_1184" alt=""></p><p>  看了前面那个小例子我们就能猜到，一定是在这些检测类上，用Registry对其进行了注册，看看faster rcnn的实现，证明了我们的猜想。这样只要</p><p>在定义这些类时，对其进行注册，那么就会自动加入到DETECTORS这个实例的成员字典里，非常的巧妙。当我们想实例化某个检测网络时，传入其字符名称即可。</p><p><img src="https://s2.51cto.com/images/blog/202112/30151825_61cd5d4138de211806.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=/format,webp/resize,m_fixed,w_1184" alt=""></p><p> 既然都看到这里了，就进一步看看网络时如何继续构建的吧。mmdetection将网络分成了几个部分，backbone，head，neck等。在TwoStageDetector（</p><p>faster rcnn的基类）中，可以看到分别构建了这几个部分。head, neck, loss等，同样是通过Registry来注册实现的。最后就是将这几个部分组合起来即可。</p><pre><code>@DETECTORS.register_module()class TwoStageDetector(BaseDetector):    &quot;&quot;&quot;Base class for two-stage detectors.    Two-stage detectors typically consisting of a region proposal network and a    task-specific regression head.    &quot;&quot;&quot;    def __init__(self,                 backbone,                 neck=None,                 rpn_head=None,                 roi_head=None,                 train_cfg=None,                 test_cfg=None,                 pretrained=None):        super(TwoStageDetector, self).__init__()        self.backbone = build_backbone(backbone)        if neck is not None:            self.neck = build_neck(neck)        if rpn_head is not None:            rpn_train_cfg = train_cfg.rpn if train_cfg is not None else None            rpn_head_ = rpn_head.copy()            rpn_head_.update(train_cfg=rpn_train_cfg, test_cfg=test_cfg.rpn)            self.rpn_head = build_head(rpn_head_)        if roi_head is not None:            # update train and test cfg here for now            # TODO: refactor assigner &amp; sampler            rcnn_train_cfg = train_cfg.rcnn if train_cfg is not None else None            roi_head.update(train_cfg=rcnn_train_cfg)            roi_head.update(test_cfg=test_cfg.rcnn)            self.roi_head = build_head(roi_head)        self.train_cfg = train_cfg        self.test_cfg = test_cfg        self.init_weights(pretrained=pretrained)</code></pre><hr><h1 id="简单理解mmdetection中的registry类"><a href="#简单理解mmdetection中的registry类" class="headerlink" title="简单理解mmdetection中的registry类"></a>简单理解mmdetection中的registry类</h1><h3 id="注册器类-Registry"><a href="#注册器类-Registry" class="headerlink" title="注册器类(Registry)"></a>注册器类(Registry)</h3><p>在mmdetection中，将会使用该类构建9个注册类实例，其实就是对类做一个划分管理。Python 装饰器的特性就是 被装饰对象（比如 ResNet 类）被定义的时候就立刻运行，从而将 ResNet 注册进 BACKBONES。</p><p>比如，backbone 作为一族（vgg,resnet等）</p><p><strong>文件：mmdet\models\registry.py</strong></p><pre><code class="lang-python">BACKBONES = Registry(&#39;backbone&#39;)NECKS = Registry(&#39;neck&#39;)ROI_EXTRACTORS = Registry(&#39;roi_extractor&#39;)SHARED_HEADS = Registry(&#39;shared_head&#39;)HEADS = Registry(&#39;head&#39;)LOSSES = Registry(&#39;loss&#39;)DETECTORS = Registry(&#39;detector&#39;)</code></pre><p><strong>文件：mmdet\datasets\registry.py</strong></p><pre><code class="lang-python">DATASETS = Registry(&#39;dataset&#39;)PIPELINES = Registry(&#39;pipeline&#39;)</code></pre><p>每一个实例，都是存放属于这一簇的类，将来通过get key方式获取，key 来自于config文件.</p><p>mmdetection在构建模型的过程中，一直是通过key 去查找对应的类（在注册器中），找到对应的类，然后实例化，最终将配置描述的模型，构建出来.</p><p>举个栗子：</p><pre><code class="lang-python">key = &#39;vgg&#39;VGG = BACKBONES.get(key)key = &#39;bce&#39;BCE = LOSSES .get(key)</code></pre><h3 id="Registry-类"><a href="#Registry-类" class="headerlink" title="Registry 类"></a>Registry 类</h3><pre><code class="lang-python">#!/usr/bin/python3# -*- coding: utf-8 -*-import inspectclass Registry(object):    def __init__(self, name):        self._name = name        self._module_dict = dict()    def __repr__(self):        format_str = self.__class__.__name__ + &#39;(name=&#123;&#125;, items=&#123;&#125;)&#39;.format(            self._name, list(self._module_dict.keys()))        return format_str    @property    def name(self):        return self._name    @property    def module_dict(self):        return self._module_dict    def get(self, key):        return self._module_dict.get(key, None)    def _register_module(self, module_class):        &quot;&quot;&quot;Register a module.        Args:            module (:obj:`nn.Module`): Module to be registered.        &quot;&quot;&quot;        if not inspect.isclass(module_class):            raise TypeError(&#39;module must be a class, but got &#123;&#125;&#39;.format(                type(module_class)))        module_name = module_class.__name__        if module_name in self._module_dict:            raise KeyError(&#39;&#123;&#125; is already registered in &#123;&#125;&#39;.format(                module_name, self.name))        self._module_dict[module_name] = module_class    def register_module(self, cls):        self._register_module(cls)        return cls</code></pre><h3 id="举个栗子："><a href="#举个栗子：" class="headerlink" title="举个栗子："></a>举个栗子：</h3><p>在mmdetection的代码中，将一个类注册（插入）到（某一个）注册器里面，是直接写在类的声明上方.</p><pre><code class="lang-python">ANIMAL = Registry(&#39;animal&#39;)@ANIMAL.register_moduleclass Dog(object):    def __init__(self):        pass    def run(self):        print(&#39;running dog&#39;)# ANIMAL.register_module(Dog)dog = ANIMAL.get(&#39;Dog&#39;)d = dog()d.run()</code></pre><p>等价写法：</p><pre><code class="lang-python">ANIMAL = Registry(&#39;animal&#39;)class Dog(object):    def __init__(self):        pass    def run(self):        print(&#39;running dog&#39;)ANIMAL.register_module(Dog)dog = ANIMAL.get(&#39;Dog&#39;)d = dog()d.run(）</code></pre><p>两者输出结果皆为：</p><p><code>running dog</code></p><hr><h1 id="mmcv之Registry类解读-增删改查"><a href="#mmcv之Registry类解读-增删改查" class="headerlink" title="mmcv之Registry类解读(增删改查)"></a>mmcv之Registry类解读(增删改查)</h1><h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><p> 本文主要介绍mmcv的Registry类。建议读者先配置下mmcv环境：mmcv源码安装。我相信读者大多数对于Registry类有点儿迷，主要涉及python中装饰器的知识。因此，本文尽量做到面面俱到，会简要介绍一部分装饰器的用法。</p><h3 id="1、Registry作用"><a href="#1、Registry作用" class="headerlink" title="1、Registry作用"></a>1、Registry作用</h3><p> Registry类可以简单理解为一个字典，举个例子，在mmdetection中，比如说创建了名为dataset的注册器对象，则注册器dataset中包含(CocoDataset类，VOCDataset类，Lvis类)；同理，detector注册器对象中包含(FasterRcnn类，SSD类，YOLO类等)。因此，Registry对象完全可以理解为一个字典，里面存储着同系列的类。</p><h3 id="2、源码分析"><a href="#2、源码分析" class="headerlink" title="2、源码分析"></a>2、源码分析</h3><p> Registry虽说是一个字典，但是得实现增删改查的功能。增即往字典中添加新的类；查即查询字典中是否有这个类。那么在Registry类中如何实现这些功能呢？</p><h4 id="2-1-初始化部分"><a href="#2-1-初始化部分" class="headerlink" title="2.1.初始化部分"></a>2.1.初始化部分</h4><pre><code>class Registry:    &quot;&quot;&quot;A registry to map strings to classes.Args:    name (str): Registry name.&quot;&quot;&quot;def __init__(self, name):    self._name = name    self._module_dict = dict()def __len__(self):    return len(self._module_dict)def __contains__(self, key):    return self.get(key) is not Nonedef __repr__(self):    format_str = self.__class__.__name__ + \                 f&#39;(name=&#123;self._name&#125;, &#39; \                 f&#39;items=&#123;self._module_dict&#125;)&#39;    return format_str</code></pre><p>这部分比较简单，就是传入了一个name并内部定义了一个self._module_dict字典。</p><h4 id="2-2-查"><a href="#2-2-查" class="headerlink" title="2.2.查"></a>2.2.查</h4><p> 查找self._module_dict存在一个某个类 实现也比较简单：</p><pre><code>def get(self, key):    return self._module_dict.get(key, None)</code></pre><p> 主要借助get方法，若有key则返回对应的value；若无key则返回None。</p><h4 id="2-3-增"><a href="#2-3-增" class="headerlink" title="2.3.增"></a>2.3.增</h4><p> 增的方法mmdetection中提供了两种方式，区别是方法_register_module()是否指定了module参数：</p><p><img src="https://img-blog.csdnimg.cn/20210227202037668.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3d1bGVsZTI=,size_16,color_FFFFFF,t_70#pic_center" alt=""></p><p>该函数主要往self._module_dict中添加类。注意，往字典里面添加的是类。以下代码包含了上图中两种方式。这里我截取了核心代码：</p><pre><code>def _register_module(self, module_class, module_name=None, force=False):    if module_name is None:        module_name = module_class.__name__    if isinstance(module_name, str):        module_name = [module_name]    self._module_dict[name] = module_classdef register_module(self, name=None, force=False, module=None):    # 若指定module，则执行if语句，执行完后完成module类添加    if module is not None:        self._register_module(            module_class=module, module_name=name, force=force)        return module    # 若没有指定module，则执行_register函数。    def _register(cls):        self._register_module(            module_class=cls, module_name=name, force=force)        return cls    return _register</code></pre><p> 我将分两小节来介绍这两种方式。</p><h4 id="2-3-1-指定module参数"><a href="#2-3-1-指定module参数" class="headerlink" title="2.3.1 指定module参数"></a>2.3.1 指定module参数</h4><p>  现在我们想往字典self._module_dict字典中添加新类。最容易想到方法就是下面这样：</p><pre><code>if __name__ == &#39;__main__&#39;:    backbones = Registry(&#39;backbone&#39;)    class MobileNet:        pass    backbones.register_module(module=MobileNet)    print(backbones)</code></pre><p> 即直接指定参数module=MobileNet。内部通过self._module_dict[name]=module_class完成注册。</p><h4 id="2-3-2-不指定module参数"><a href="#2-3-2-不指定module参数" class="headerlink" title="2.3.2 不指定module参数"></a>2.3.2 不指定module参数</h4><p> 上节提供方法完全可以，但是在利用mmdetection拓展新模型的时候，如果每次创建完一个类之后，然后通过上述方法注册，着实不方便。势必会影响mmdetection拓展性。而装饰器可以很方便给类拓展新功能，装饰器有机会我会单独出一篇文章，<br> 这里简单记住装饰器用法：funB = funA(funB)，即被装饰函数funB，经过装饰器funA的装饰，中间可能发生了一些其他事情，最终funA的return funB。<br> 首先看用法:比如我想注册ResNet。</p><pre><code>if __name__ == &#39;__main__&#39;:    backbones = Registry(&#39;backbone&#39;)    @backbones.register_module()    class ResNet:        pass    print(backbones)</code></pre><p> 这里内部实质上经过了下面函数：</p><pre><code>        def _register(cls):            self._register_module(                module_class=cls, module_name=name, force=force)            return cls</code></pre><p>在这个过程中，funB相当于cls。而_register函数相当于funA。中间往self._module_dict字典中注册了类cls。然后return cls。即funB。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> BEV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>PETR_code_note</title>
      <link href="/2023/11/16/PETR-code-note/"/>
      <url>/2023/11/16/PETR-code-note/</url>
      
        <content type="html"><![CDATA[<h1 id="PETR-code-note"><a href="#PETR-code-note" class="headerlink" title="PETR code note"></a>PETR code note</h1><ol><li><p><code>cfg = Config.fromfile(args.config)</code></p><h1 id="从args更新读取的config文件，args优先级-gt-cfg优先级，args定义了cfg文件中没有定义的work-dir等参数-还有一部分需要覆盖cfg的参数"><a href="#从args更新读取的config文件，args优先级-gt-cfg优先级，args定义了cfg文件中没有定义的work-dir等参数-还有一部分需要覆盖cfg的参数" class="headerlink" title="从args更新读取的config文件，args优先级>cfg优先级，args定义了cfg文件中没有定义的work_dir等参数,还有一部分需要覆盖cfg的参数"></a>从args更新读取的config文件，args优先级&gt;cfg优先级，args定义了cfg文件中没有定义的work_dir等参数,还有一部分需要覆盖cfg的参数</h1></li></ol><ol><li><p>cfg.merge_from_dict()</p><p><strong>合并字典到配置</strong> 通过 <code>cfg.merge_from_dict</code> 函数接口可以实现对字典内容进行合并，典型用法如下：</p><pre><code class="lang-python">cfg_file = osp.join(data_path, 'config/a.py')cfg = Config.fromfile(cfg_file)input_options = {'item2.a': 1, 'item2.b': 0.1, 'item3': False}cfg.merge_from_dict(input_options)# 原始 a.py 内容为：item1 = [1, 2]item2 = {'a': 0}item3 = Trueitem4 = 'test'# 进行合并后, cfg 内容item1 = [1, 2]item2 = dict(a=1, b=0.1)item3 = Falseitem4 = 'test'</code></pre></li><li><p>```python<br>if cfg.plugin:</p><pre><code>import importlib</code></pre></li></ol><p>​       #将plugin批量导入模型环境</p><p>​       #plugin_dir=’projects/mmdet3d_plugin/‘</p><ol><li><p><code>torch.backends.cudnn.benchmark = True</code></p><p>对模型里的卷积层进行预先的优化，也就是在每一个卷积层中测试 cuDNN 提供的所有卷积实现算法，然后选择最快的那个。这样在模型启动的时候，只要额外多花一点点预处理时间，就可以较大幅度地减少训练时间。</p></li><li></li></ol>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -PETR </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MMDetection整体构建流程二</title>
      <link href="/2023/11/15/MMDetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B%E4%BA%8C/"/>
      <url>/2023/11/15/MMDetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B%E4%BA%8C/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection-整体构建流程-二"><a href="#MMDetection-整体构建流程-二" class="headerlink" title="MMDetection 整体构建流程(二)"></a>MMDetection 整体构建流程(二)</h1><p>本文核心内容是<strong>按照抽象到具体方式，从多个层次进行训练和测试流程深入解析</strong>，从最抽象层讲起，到最后核心代码实现，希望帮助大家更容易理解 MMDetection 开源框架整体构建细节</p><h2 id="一、第一层整体抽象"><a href="#一、第一层整体抽象" class="headerlink" title="一、第一层整体抽象"></a>一、第一层整体抽象</h2><p><img src="https://pic2.zhimg.com/80/v2-2463639f7e39afd273fdeccbfa530d49_720w.jpg" alt=""></p><p>上图为 MMDetection 框架整体训练和测试抽象流程图。按照数据流过程，训练流程可以简单总结为：</p><ol><li>给定任何一个数据集，首先需要构建Dataset类，用于迭代输出数据</li><li>在迭代输出数据的时候需要通过数据pipeline对数据进行各种处理，最典型的处理流是训练中的数据增强操作，测试中的数据预处理等</li><li>通过Sampler采样器可以控制Dataset输出的数据顺序，最常用的是随机采样器RandomSampler。由于Dataset中输出的图片大小不一样，为了尽可能减少后续组成batch时pad的像素个数，MMDetection引入了分组采样器GroupSampler和DistributedGroupSampler，相当于在RandomSampler基础上额外新增了根据图片宽高比进行group功能</li><li>将Sampler和Dataset都输入给DataLoader，然后通过DataLoader输出已组成batch的数据，作为Model的输入</li><li>对于任何一个Model，为了方便处理数据流及分布式需求，MMDetection引入了两个Model的上层封装：单机版本MMDataParallel、分布式（单机多卡或多机多卡）版本MMDistributedDataParallel</li><li>Model运行后会输出loss及其他一些信息，会通过logger进行保存或者可视化</li><li>为了更好地解耦，方便地获取各个组件之间依赖和灵活扩展，MMDetection引入了Runner类进行全生命周期管理，并且通过Hook方便的获取、修改和拦截任何生命周期数据流，扩展非常便捷</li></ol><p>而测试流程就比较简单了，直接对 DataLoader 输出的数据进行前向推理即可，还原到最终原图尺度过程也是在 Model 中完成。</p><p>以上就是 MMDetection  框架整体训练和测试抽象流程，上图不仅仅反映了训练和测试数据流，而且还包括了模块和模块之间的调用关系。对于训练而言，最核心部分应该是  Runner，理解了 Runner 的运行流程，也就理解了整个 MMDetection 数据流。</p><h2 id="二、第二层模块抽象"><a href="#二、第二层模块抽象" class="headerlink" title="二、第二层模块抽象"></a>二、第二层模块抽象</h2><p>在总体把握了整个MMDetection框架训练和测试流程后，下个层次是每个模块内部抽象流程，主要包括pipeline、DataParallel、Model、Runner和Hooks。</p><h3 id="2-1-Pipeline"><a href="#2-1-Pipeline" class="headerlink" title="2.1 Pipeline"></a>2.1 Pipeline</h3><p>Pipeline 实际上由一系列按照插入顺序运行的数据处理模块组成，每个模块完成某个特定功能，例如 Resize，因为其流式顺序运行特性，故叫做 Pipeline。</p><p><img src="https://pic3.zhimg.com/80/v2-d7eb7e24335613da3da22da4ea93e132_720w.webp" alt=""></p><p>上图是一个非常典型的训练流程 Pipeline，每个类都接收字典输入，输出也是字典，顺序执行，其中绿色表示该类运行后新增字段，橙色表示对该字段可能会进行修改。如果进一步细分的话，不同算法的 Pipeline 都可以划分为如下部分：</p><ul><li><strong>图片和标签加载</strong>，通常用的类是 LoadImageFromFile 和 LoadAnnotations</li><li><strong>数据前处理</strong>，例如统一 Resize</li><li><strong>数据增强</strong>，典型的例如各种图片几何变换等，这部分是训练流程特有，测试阶段一般不采用(多尺度测试采用其他实现方式)</li><li><strong>数据收集</strong>，例如 Collect</li></ul><p>在 MMDetection 框架中，图片和标签加载和数据后处理流程一般是固定的，用户主要可能修改的是数据增强步骤，目前已经接入了第三方增强库 Albumentations，可以按照示例代码轻松构建属于你自己的数据增强 Pipeline。</p><p><strong>在构建自己的 Pipeline 时候一定要仔细检查你修改或者新增的字典 key 和 value，因为一旦你错误地覆盖或者修改原先字典里面的内容，代码也可能不会报错，如果出现 bug，则比较难排查</strong>。</p><h3 id="2-2-DataParallel-和-Model"><a href="#2-2-DataParallel-和-Model" class="headerlink" title="2.2 DataParallel 和 Model"></a>2.2 DataParallel 和 Model</h3><p>在 MMDetection 中 DataLoader 输出的内容不是 pytorch 能处理的标准格式，还包括了 DataContainer  对象，该对象的作用是包装不同类型的对象使之能按需组成 batch。在目标检测中，每张图片 gt bbox 个数是不一样的，如果想组成 batch tensor，要么你设置最大长度，要么你自己想办法组成 batch。而考虑到内存和效率，MMDetection 通过引入  DataContainer 模块来解决上述问题，但是随之带来的问题是 pytorch 无法解析 DataContainer 对象，故需要在  MMDetection 中自行处理。</p><p>解决办法其实非常多，MMDetection  选择了一种比较优雅的实现方式：MMDataParallel 和 MMDistributedDataParallel。具体来说，这两个类相比  PyTorch 自带的 DataParallel 和 DistributedDataParallel 区别是：</p><ul><li>可以处理 DataContainer 对象</li><li>额外实现了 <code>train_step()</code> 和 <code>val_step()</code> 两个函数，可以被 Runner 调用</li></ul><p>Model如下：</p><p><img src="https://pic4.zhimg.com/80/v2-0c8f69636320fb40d8a8cd994296bf87_720w.webp" alt=""></p><h3 id="2-3-Runner-和-Hooks"><a href="#2-3-Runner-和-Hooks" class="headerlink" title="2.3 Runner 和 Hooks"></a>2.3 Runner 和 Hooks</h3><p>对于任何一个目标检测算法，都需要包括优化器、学习率设置、权重保存等等组件才能构成完整训练流程，而这些组件是通用的。为了方便 OpenMMLab  体系下的所有框架复用，在 MMCV 框架中引入了 Runner 类来统一管理训练和验证流程，并且通过 Hooks  机制以一种非常灵活、解耦的方式来实现丰富扩展功能。</p><p>下面列出了在 MMDetection 几个非常重要的 hook 以及其作用的生命周期： </p><p><img src="https://pic4.zhimg.com/80/v2-5d614997aa85e1b841457094b7bc0cbb_720w.webp" alt=""></p><p>例如 CheckpointHook 在每个训练 epoch 完成后会被调用，从而实现保存权重功能。用户也可以将自己定制实现的 Hook 采用上述方式绘制，对理解整个流程或许有帮助。</p><h2 id="三、第三层代码抽象"><a href="#三、第三层代码抽象" class="headerlink" title="三、第三层代码抽象"></a>三、第三层代码抽象</h2><p>前面两层抽象分析流程，基本上把整个 MMDetection 的训练和测试流程分析完了，下面从具体代码层面进行抽象分析。</p><h3 id="3-1-训练和测试整体代码抽象流程"><a href="#3-1-训练和测试整体代码抽象流程" class="headerlink" title="3.1 训练和测试整体代码抽象流程"></a>3.1 训练和测试整体代码抽象流程</h3><p><img src="https://pic4.zhimg.com/80/v2-b03d43ed4b3dc4c02e68712e57023cff_720w.webp" alt=""></p><p>上图为训练和验证的和具体代码相关的整体抽象流程，对应到代码上，其核心代码如下：</p><pre><code class="lang-python">#=================== tools/train.py ==================# 1.初始化配置cfg = Config.fromfile(args.config)# 2.判断是否为分布式训练模式# 3.初始化 loggerlogger = get_root_logger(log_file=log_file, log_level=cfg.log_level)# 4.收集运行环境并且打印，方便排查硬件和软件相关问题env_info_dict = collect_env()# 5.初始化 modelmodel = build_detector(cfg.model, ...)# 6.初始化 datasets#=================== mmdet/apis/train.py ==================# 1.初始化 data_loaders ，内部会初始化 GroupSamplerdata_loader = DataLoader(dataset,...)# 2.基于是否使用分布式训练，初始化对应的 DataParallelif distributed:  model = MMDistributedDataParallel(...)else:  model = MMDataParallel(...)# 3.初始化 runnerrunner = EpochBasedRunner(...)# 4.注册必备 hookrunner.register_training_hooks(cfg.lr_config, optimizer_config,                               cfg.checkpoint_config, cfg.log_config,                               cfg.get(&#39;momentum_config&#39;, None))# 5.如果需要 val，则还需要注册 EvalHook           runner.register_hook(eval_hook(val_dataloader, **eval_cfg))# 6.注册用户自定义 hookrunner.register_hook(hook, priority=priority)# 7.权重恢复和加载if cfg.resume_from:    runner.resume(cfg.resume_from)elif cfg.load_from:    runner.load_checkpoint(cfg.load_from)# 8.运行，开始训练runner.run(data_loaders, cfg.workflow, cfg.total_epochs)</code></pre><p>上面的流程比较简单，一般大家比较难以理解的是 <code>runner.run</code> 内部逻辑，下小节进行详细分析，而对于测试逻辑由于比较简单，就不详细描述了，简单来说测试流程下不需要 runner，直接加载训练好的权重，然后进行 model 推理即可。</p><h3 id="3-2-Runner-训练和验证代码抽象"><a href="#3-2-Runner-训练和验证代码抽象" class="headerlink" title="3.2 Runner 训练和验证代码抽象"></a>3.2 Runner 训练和验证代码抽象</h3><p>runner 对象内部的 run 方式是一个通用方法，可以运行任何 workflow，目前常用的主要是 train 和 val。</p><ul><li>当配置为：workflow = [(‘train’, 1)]，表示仅仅进行 train workflow，也就是迭代训练</li><li>当配置为：workflow = [(‘train’, n),(‘val’, 1)]，表示先进行 n 个 epoch 的训练，然后再进行1个 epoch  的验证，然后循环往复,如果写成 [(‘val’, 1),(‘train’, n)] 表示先进行验证，然后才开始训练</li></ul><p>当进入对应的 workflow，则会调用 runner 里面的 train() 或者 val()，表示进行一次 epoch 迭代。其代码也非常简单，如下所示：</p><pre><code class="lang-python">def train(self, data_loader, **kwargs):    self.model.train()    self.mode = &#39;train&#39;    self.data_loader = data_loader    self.call_hook(&#39;before_train_epoch&#39;)    for i, data_batch in enumerate(self.data_loader):        self.call_hook(&#39;before_train_iter&#39;)        self.run_iter(data_batch, train_mode=True)        self.call_hook(&#39;after_train_iter&#39;)    self.call_hook(&#39;after_train_epoch&#39;)def val(self, data_loader, **kwargs):    self.model.eval()    self.mode = &#39;val&#39;    self.data_loader = data_loader    self.call_hook(&#39;before_val_epoch&#39;)    for i, data_batch in enumerate(self.data_loader):        self.call_hook(&#39;before_val_iter&#39;)        with torch.no_grad():            self.run_iter(data_batch, train_mode=False)        self.call_hook(&#39;after_val_iter&#39;)    self.call_hook(&#39;after_val_epoch&#39;)</code></pre><p>核心函数实际上是 self.run_iter()，如下：</p><pre><code class="lang-python">def run_iter(self, data_batch, train_mode, **kwargs):    if train_mode:        # 对于每次迭代，最终是调用如下函数        outputs = self.model.train_step(data_batch,...)    else:        # 对于每次迭代，最终是调用如下函数        outputs = self.model.val_step(data_batch,...)    if &#39;log_vars&#39; in outputs:        self.log_buffer.update(outputs[&#39;log_vars&#39;],...)    self.outputs = outputs</code></pre><p>上述 self.call_hook() 表示在不同生命周期调用所有已经注册进去的 hook，而字符串参数表示对应的生命周期。以 OptimizerHook 为例，其执行反向传播、梯度裁剪和参数更新等核心训练功能：</p><pre><code class="lang-python">@HOOKS.register_module()class OptimizerHook(Hook):    def __init__(self, grad_clip=None):        self.grad_clip = grad_clip    def after_train_iter(self, runner):        runner.optimizer.zero_grad()        runner.outputs[&#39;loss&#39;].backward()        if self.grad_clip is not None:            grad_norm = self.clip_grads(runner.model.parameters())        runner.optimizer.step()</code></pre><p>可以发现 OptimizerHook 注册到的生命周期是 after_train_iter，故在每次 train() 里面运行到 </p><p><code>self.call_hook(&#39;after</code><em>train</em><code>iter&#39;)</code> 时候就会被调用，其他 hook 也是同样运行逻辑。</p><h3 id="3-3-Model-训练和测试代码抽象"><a href="#3-3-Model-训练和测试代码抽象" class="headerlink" title="3.3 Model 训练和测试代码抽象"></a>3.3 Model 训练和测试代码抽象</h3><p>前面说个，训练和验证的时候实际上调用了 model 内部的 <code>train_step</code> 和 <code>val_step</code> 函数，<strong>理解了两个函数调用流程就理解了 MMDetection 训练和测试流程</strong>。</p><p>注意，由于 model 对象会被 DataParallel 类包裹，故实际上此时的 model，是指的 MMDataParallel 或者  MMDistributedDataParallel。以非分布式 train_step 流程为例，其内部完成调用流程图示如下：</p><p><img src="https://pic4.zhimg.com/80/v2-0d17b53f68286931803bf9d1dca10467_720w.webp" alt=""></p><h3 id="3-3-1-train-或者-val-流程"><a href="#3-3-1-train-或者-val-流程" class="headerlink" title="3.3.1 train 或者 val 流程"></a>3.3.1 train 或者 val 流程</h3><p><strong>(1) 调用 runner 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>在 runner 中调用 <code>train_step</code> 或者 <code>val_step</code>，代码如下：</p><pre><code class="lang-python">#=================== mmcv/runner/epoch_based_runner.py ==================if train_mode:    outputs = self.model.train_step(data_batch,...)else:    outputs = self.model.val_step(data_batch,...)</code></pre><p>实际上，首先会调用 DataParallel 中的 <code>train_step</code> 或者 <code>val_step</code> ，其具体调用流程为：</p><pre><code class="lang-python"># 非分布式训练#=================== mmcv/parallel/data_parallel.py/MMDataParallel ==================def train_step(self, *inputs, **kwargs):    if not self.device_ids:        inputs, kwargs = self.scatter(inputs, kwargs, [-1])        # 此时才是调用 model 本身的 train_step        return self.module.train_step(*inputs, **kwargs)    # 单 gpu 模式    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)    # 此时才是调用 model 本身的 train_step    return self.module.train_step(*inputs[0], **kwargs[0])# val_step 也是的一样逻辑def val_step(self, *inputs, **kwargs):    inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)    # 此时才是调用 model 本身的 val_step    return self.module.val_step(*inputs[0], **kwargs[0])</code></pre><p>可以发现，在调用 model 本身的 train_step 前，需要额外调用 scatter 函数，前面说过该函数的作用是处理 DataContainer 格式数据，使其能够组成 batch，否则程序会报错。</p><p>如果是分布式训练，则调用的实际上是 <code>mmcv/parallel/distributed.py/MMDistributedDataParallel</code>，最终调用的依然是 model 本身的 <code>train_step</code> 或者 <code>val_step</code>。</p><p><strong>(2) 调用 model 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>其核心代码如下：</p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/BaseDetector ==================def train_step(self, data, optimizer):    # 调用本类自身的 forward 方法    losses = self(**data)    # 解析 loss    loss, log_vars = self._parse_losses(losses)    # 返回字典对象    outputs = dict(        loss=loss, log_vars=log_vars, num_samples=len(data[&#39;img_metas&#39;]))    return outputsdef forward(self, img, img_metas, return_loss=True, **kwargs):    if return_loss:        # 训练模式        return self.forward_train(img, img_metas, **kwargs)    else:        # 测试模式        return self.forward_test(img, img_metas, **kwargs)</code></pre><p><code>forward_train</code> 和 <code>forward_test</code> 需要在不同的算法子类中实现，输出是 Loss 或者 预测结果。</p><p><strong>(3) 调用子类中的 <code>forward_train</code> 方法</strong> </p><p>目前提供了两个具体子类，<code>TwoStageDetector</code> 和 <code>SingleStageDetector</code> ，用于实现 two-stage 和 single-stage 算法。</p><p>对于 <code>TwoStageDetector</code> 而言，其核心逻辑是：</p><pre><code class="lang-python">#============= mmdet/models/detectors/two_stage.py/TwoStageDetector ============def forward_train(...):    # 先进行 backbone+neck 的特征提取    x = self.extract_feat(img)    losses = dict()    # RPN forward and loss    if self.with_rpn:        # 训练 RPN        proposal_cfg = self.train_cfg.get(&#39;rpn_proposal&#39;,                                          self.test_cfg.rpn)        # 主要是调用 rpn_head 内部的 forward_train 方法        rpn_losses, proposal_list = self.rpn_head.forward_train(x,...)        losses.update(rpn_losses)    else:        proposal_list = proposals    # 第二阶段，主要是调用 roi_head 内部的 forward_train 方法    roi_losses = self.roi_head.forward_train(x, ...)    losses.update(roi_losses)    return losses</code></pre><p>对于 <code>SingleStageDetector</code> 而言，其核心逻辑是：</p><pre><code class="lang-python">#============= mmdet/models/detectors/single_stage.py/SingleStageDetector ============def forward_train(...):    super(SingleStageDetector, self).forward_train(img, img_metas)    # 先进行 backbone+neck 的特征提取    x = self.extract_feat(img)    # 主要是调用 bbox_head 内部的 forward_train 方法    losses = self.bbox_head.forward_train(x, ...)    return losses</code></pre><h3 id="3-3-2-test流程"><a href="#3-3-2-test流程" class="headerlink" title="3.3.2 test流程"></a>3.3.2 test流程</h3><p>由于没有 runner 对象，测试流程简单很多，下面简要概述：</p><ol><li><p>调用 MMDataParallel 或 MMDistributedDataParallel 中的 <code>forward</code> 方法</p></li><li><p>调用 base.py 中的 <code>forward</code> 方法</p></li><li><p>调用 base.py 中的 <code>self.forward_test</code> 方法</p></li><li><p>如果是单尺度测试，则会调用 TwoStageDetector 或 SingleStageDetector 中的 <code>simple_test</code> 方法，如果是多尺度测试，则调用 <code>aug_test</code> 方法</p></li><li><p>最终调用的是每个具体算法 Head 模块的  <code>simple_test</code> 或者 <code>aug_test</code> 方法</p></li></ol><h2 id="四、-总结"><a href="#四、-总结" class="headerlink" title="四、 总结"></a>四、 总结</h2><p>本文基于第一篇解读文章，详细地从三个层面全面解读了 MMDetection 框架，希望读者读完本文，能够对 MMDetection 框架设计思想、组件间关系和整体代码实现流程了然于心。</p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> BEV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmdetection3d</title>
      <link href="/2023/11/15/mmdetection3d/"/>
      <url>/2023/11/15/mmdetection3d/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection3D-整体框架介"><a href="#MMDetection3D-整体框架介" class="headerlink" title="MMDetection3D 整体框架介"></a>MMDetection3D 整体框架介</h1><p>[TOC]</p><h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><p>由于3D本身数据的复杂性和MMDetection3D支持任务（电云D检测、单目3D检测、多模态3D检测和点云3D语义分割等）和场景（室内和外）的多样性，整个框架结构相对复杂，门槛高，这里对MMDetection3D整个框架进行整体的了解，包括设计流程，核心组件，数据集处理方法等。</p><p>整个框架的代码库目录结构如下：</p><pre><code class="lang-bash"># MMDetection3D 代码目录结构，展示主要部分 mmdetection3d    |    |- configs                    # 配置文件    |- data                       # 原始数据及预处理后数据文件    |- mmdet3d     |     |- ops                  # cuda 算子（即将迁移到 mmcv 中）    |     |- core                 # 核心组件    |     |- datasets             # 数据集相关代码    |     |- models               # 模型相关代码    |     |- utils                # 辅助工具    |     |- ...    |- tools    |     |- analysis_tools       # 分析工具，包括可视化、计算flops等    |     |- data_converter       # 各个数据集预处理转换脚本    |     |- create_data.py       # 数据预处理入口    |     |- train.py             # 训练脚本    |     |- test.py              # 测试脚本    |     |- ...                          |- ...</code></pre><h2 id="二、任务介绍"><a href="#二、任务介绍" class="headerlink" title="二、任务介绍"></a>二、任务介绍</h2><p>3D 目标检测按照输入数据模态划分可以分为：<strong>点云 3D 检测、纯视觉 3D 检测以及多模态 3D 检测（点云+图片）。</strong></p><p><img src="https://pic3.zhimg.com/80/v2-2a0bf86a79b2710a380e4f1ba0d5164a_720w.webp" alt=""></p><p><img src="https://pic3.zhimg.com/80/v2-42c8641edd26dc0441a6e7815f37220e_720w.webp" alt=""></p><p><img src="https://pic2.zhimg.com/80/v2-43f400129e178782740ac1a877b3e405_720w.webp" alt=""></p><p><img src="https://pic2.zhimg.com/80/v2-9c66063032e7f7ce4cd63ab01ef3a319_720w.webp" alt=""></p><p>除此之外，MMDetection3D还拓展到了点云3D语义分割领域，目前已经支持了室内点云语义分割，同时会在将来支持室外点云语义分割。</p><h2 id="三、算法模型支持"><a href="#三、算法模型支持" class="headerlink" title="三、算法模型支持"></a>三、算法模型支持</h2><p>所有模型相关代码位于mmdet3d/models下，MMDetection3D支持的各个方向的模型大体可以归类如下：</p><p><img src="https://pic4.zhimg.com/80/v2-efc56a48b8d6f69a23d89e85e739518b_720w.webp" alt=""></p><p>总体来说，由于MMDetection3D依赖于MMDetection和MMSegmentation，所以很多的模型及组件都是直接复用或继承而来。目前在MMDetection3D内，整体模型的构建方式会根据任务类型被划分为三种方式，具体如下：</p><p>点云3D检测（包含多模态3D检测）：</p><p><img src="https://pic2.zhimg.com/80/v2-9edad73af084acad23a0721454ef4b89_720w.webp" alt=""></p><p>对于点云3D检测（多模态3D检测），我们继承自MMDetection中的BaseDetector构建了适用于3D检测的Base3DDetector，再根据检测中的单价段和二阶段分别构造，需要注意的是不同于SingleStage3DDetector，为了尽可能的复用已有的代码组件，二阶段检测器TwoStage3DDetector同时继承自Base3DDetector和TwoStageDetector，图中只列出了部分支持的模型算法。</p><p>单目3D检测：</p><p><img src="https://pic4.zhimg.com/80/v2-d86ac9e6fcace16aa84df3771e62dba7_720w.webp" alt=""></p><p>对于单目3D检测，考虑到和2D检测输入数据的一致性，同事方便做2D检测的同学可以快速上手单目3D检测，我们继承自MMDetection中的SingleStageDetector构建了SingleStageMono3DDetector，目前所支持的单目3D检测算法都是基于该类构建的。</p><p>点云3D语义分割：</p><p><img src="https://pic1.zhimg.com/80/v2-9a01a3aecf662585eeb4af1fec1210b8_720w.webp" alt=""></p><p>对于点云 3D 语义分割，我们继承自 MMSegmentation 中的 <code>BaseSegmentor</code> 构建了适用于点云分割的 <code>Base3DSegmentor</code>，而目前所支持的点云分割算法都是遵循 <code>EncoderDecoder3D</code> 模式。 </p><h2 id="四、数据预处理"><a href="#四、数据预处理" class="headerlink" title="四、数据预处理"></a>四、数据预处理</h2><p>该部分对应于toos/create_data.py，各个数据集预处理脚本位于tools/data_converter目录下。由于3D数据集的多样性，MMDetection3D会对数据集做预处理。这里，我们从整体视角来看下数据预处理的文件生成过程：</p><p><img src="https://pic4.zhimg.com/80/v2-e1409ac7a44d062bbfe7814848f5611b_720w.webp" alt=""></p><p>在MMDetection3D中，不同的任务和不同的场景（室内、外）的数据预处理都会存在一定的区别，如上图所示，会产生不同的预处理后的文件，便于后续训练。</p><ol><li><p>对所有的任务和场景，统一用数据处理脚本转换后的pkl文件，该文件包含数据集的各种信息，包括数据集路径、calib信息和标注信息等，从而做到各个数据集内部格式尽可能的统一。</p></li><li><p>对于点云（多模态）3D检测，室内和室外数据集生成的文件是不一样的：</p><p>对于某些室外数据集，我们会借助pkl文件的信息进一步提取reduced_point_cloud和gt_database：前者是仅包含前方视野的点云文件，通常存在于kitti数据集处理过程中，因为kitti数据集仅包含前方视野的标注；后者则是包含在训练集数据集的每个3D边界框中的点云数据分别提取出来得到的各个物体的点云文件，常用来在数据增强时使用（copy-paster)。</p><p>对于室内数据集，由于点云较为密集，通常会进行点云的下采用处理，保存在points内。</p></li></ol><p>对于单目3D检测，整个模型构建的流程是遵循2D检测的，同样的在数据处理的过程中，在生成基本的pkl文件后，还需要将其抓换位coco标注格式的json文件，该过程中会对pkl的标注信息做相应处理，实际在该任务中，pkl文件用来提供data信息，json文件提供标注信息。</p><p>对于点云3D语义分割，目前MMDetection3D仅支持室内点云分割，相对于检测任务，如图所示需要生成额外的文件：instance_mask 包含每个点云的实例标签，semantic_mask包含每个点云的语义标签，seg_info包含额外的辅助训练的信息。</p><h2 id="五、模块抽象"><a href="#五、模块抽象" class="headerlink" title="五、模块抽象"></a>五、模块抽象</h2><p>和MMDetection一脉相承，整个MMDetection3D的模块内部抽象流程也主要包括Pipeline、DataParallel、Model、Runner和Hooks。</p><h3 id="5-1Pipeline"><a href="#5-1Pipeline" class="headerlink" title="5.1Pipeline"></a>5.1Pipeline</h3><p>具体在Pipeline方面由于数据模态的不同，所以在数据处理过程中包含不同的信息。</p><p><img src="https://pic4.zhimg.com/80/v2-7271a1fdfa1cfd93cced3fca4f540dd3_720w.webp" alt=""></p><p>上图展示了三个比较典型的3D检测Pipeline，流程自上而下分别是点云3D检测、多模态3D检测和单目3D检测，从上述的流程可以看出，pipeline其实是由一系列的按照插入顺序插入顺序进行的数据处理模块组成。MMDetection3D 对于点云 3D 检测提供了很多常用的 pipeline  模块，比如GlobalRotScaleTrans（点云的旋转缩放）、PointsRangeFilter /  ObjectRangeFilter（限定了点云和物体的范围）、PointShuffle（打乱点云数据）；而对于单目 3D 检测基本就是直接调用  MMDetection 的数据处理模块，比如 Resize （图片缩放）、Normalize （正则化）、Pad  （图片填充）；多模态检测则兼用两者。我们可以看到其实这些任务共享了部分的 pipeline 模块，比如 LoadAnnotations3D  （标签载入）、RandomFlip3D（会对点云和图片同时进行翻转）、DefaultFormatBundle3D（数据格式化）、Collect3D （选取需要用于训练的数据和标签），这些代码都在 <code>mmdet3d/datasets/pipeline</code> 目录下。</p><h3 id="5-2-Model"><a href="#5-2-Model" class="headerlink" title="5.2 Model"></a>5.2 Model</h3><p>在该部分我们按照任务类型分类，对于整个模型内部做抽象介绍。和2D检测类型，3D检测器通常也包含了几个核心组件：Backbone用于提取特征、Neck进行特征融合和增强、Head用于输出需要的结果。</p><ol><li>点云3D检测模型</li></ol><p>目前云目标检测按照对点云数据的处理方式，可以分为<strong>体素处理方法 (Voxel-based)</strong> 和<strong>原始点云处理方法 (Point-based)</strong>，这两种方法其实在构建模型的时候会有一定的区别，整体的模型构建按照下图流程所示： </p><p><img src="https://pic2.zhimg.com/80/v2-f464a0118006f4b4706d7f70cb432129_720w.webp" alt=""></p><ul><li><p>基于体素的模型通常需要 <code>Encoder</code> 来对点云体素化，如 <code>HardVFE</code> 和 <code>PointPillarScatter</code>等，采用的稀疏卷积或者 Pillars 的方法从点云中生成 2D 特征图，然后基本可以套用 2D 检测流程进行 3D 检测。</p></li><li><p>基于原始点云模型通常直接采用 3D Backbone (Pointnet / Pointnet++ 等)  提取点的特征，再针对提取到的点云特征采用 RoI 或者 Group 等方式回归 3D bounding  box。有关的具体内容我们会在后续的文章中针对典型的方法进行分析介绍.</p></li></ul><ol><li>单目3D检测模型</li></ol><p><img src="https://pic3.zhimg.com/80/v2-90d4d36dc288c41341bb80a0f546bf56_720w.webp" alt=""></p><p>由于单目 3D 检测的输入是图片，输出是 3D bounding box, 所以整体的检测流程和模型组成来说基本和 2D 检测保持一致。</p><ol><li>多模态3D检测模型</li></ol><p>多模态的检测模型从组成来看可以看成2D检测模型和点云检测模型的拼接。</p><ol><li>点云3D语义分割模型</li></ol><p><img src="https://pic1.zhimg.com/80/v2-8d879986dfa4ca933fc908fd0b99aac8_720w.webp" alt=""></p><p>MMDetection3D 内部支持的 3D 分割模型都是符合 <code>EncoderDecoder</code> 结构的，需要 <code>backbone</code> 来 encode feature, <code>decode_head</code> 用来预测每个点云的类别的进行分割，目前主要只支持室内场景的 3D 语义分割。</p><h2 id="六、训练和测试流程"><a href="#六、训练和测试流程" class="headerlink" title="六、训练和测试流程"></a>六、训练和测试流程</h2><p>首先我们训练和验证调用的是 <code>tools/train.py</code> 脚本，先进行 Dataset、Model 等相关类初始化，然后我们构建了一个 runner，最终模型的训练和验证过程是发生在 runner 内部的，而训练和验证的时候实际上是 runner 调用了 model 内部的 <code>train_step</code> 和 <code>val_step</code> 函数。 </p><h3 id="6-1train和val流程"><a href="#6-1train和val流程" class="headerlink" title="6.1train和val流程"></a>6.1train和val流程</h3><p><img src="https://pic3.zhimg.com/80/v2-a8c9de0156a19b7ddc84ab550ea3419a_720w.webp" alt=""></p><p><strong>(1) 调用 runner 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>在 runner 中调用 <code>train_step</code> 或者 <code>val_step</code>，代码如下： </p><pre><code class="lang-python">#=================== mmcv/runner/epoch_based_runner.py ================== if train_mode:     outputs = self.model.train_step(data_batch,...) else:     outputs = self.model.val_step(data_batch,...)</code></pre><p>实际上，首先会调用 DataParallel 中的 <code>train_step</code> 或者 <code>val_step</code> ，其具体调用流程为： </p><pre><code class="lang-python"># 非分布式训练 #=================== mmcv/parallel/data_parallel.py/MMDataParallel ================== def train_step(self, *inputs, **kwargs):     if not self.device_ids:         inputs, kwargs = self.scatter(inputs, kwargs, [-1])         # 此时才是调用 model 本身的 train_step         return self.module.train_step(*inputs, **kwargs)     # 单 gpu 模式     inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)     # 此时才是调用 model 本身的 train_step     return self.module.train_step(*inputs[0], **kwargs[0]) # val_step 也是的一样逻辑 def val_step(self, *inputs, **kwargs):     inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)     # 此时才是调用 model 本身的 val_step     return self.module.val_step(*inputs[0], **kwargs[0])</code></pre><p>可以发现，在调用 model 本身的 train_step 前，需要额外调用 scatter 函数，前面说过该函数的作用是处理 DataContainer 格式数据，使其能够组成 batch，否则程序会报错。 </p><p>如果是分布式训练，则调用的实际上是 <code>mmcv/parallel/distributed.py/MMDistributedDataParallel</code>，最终调用的依然是 model 本身的 <code>train_step</code> 或者 <code>val_step</code>。 </p><p><strong>(2) 调用 model 中的 <code>train_step</code> 或者 <code>val_step</code></strong> </p><p>训练流程： </p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/BaseDetector ============= def train_step(self, data, optimizer):     # 调用本类自身的 forward 方法     losses = self(**data)     # 解析 loss     loss, log_vars = self._parse_losses(losses)     # 返回字典对象     outputs = dict(         loss=loss, log_vars=log_vars, num_samples=len(data[&#39;img_metas&#39;]))     return outputs #=================== mmdet/models/detectors/base.py/Base3DDetector =========== # Base3DDetector 主要是重写了 forward，改变了模型输入数据的类型，可同时传入点云数据和图片数据，从而满足多模态检测的需求 @auto_fp16(apply_to=(&#39;img&#39;, &#39;points&#39;)) def forward(self, return_loss=True, **kwargs):     if return_loss:         # 训练模式         return self.forward_train(**kwargs)     else:         # 测试模式         return self.forward_test(**kwargs)</code></pre><p><code>forward_train</code> 和 <code>forward_test</code> 需要在不同的算法子类中实现，输出是 Loss 或者 预测结果。 </p><p><strong>(3) 调用子类中的 <code>forward_train</code> 方法</strong> </p><p>PointPillars 采用的是 VoxelNet 检测器，核心逻辑还是比较通用的。 </p><pre><code class="lang-python">#============= mmdet/models/detectors/voxelnet.py/VoxelNet ============ def forward_train(self,                   points,                   img_metas,                   gt_bboxes_3d,                   gt_labels_3d,                   gt_bboxes_ignore=None):     # 先进行点云的特征提取       x = self.extract_feat(points, img_metas)     # 主要是调用 bbox_head 内部的 forward_train 方法，得到 head 输出     outs = self.bbox_head(x)     loss_inputs = outs + (gt_bboxes_3d, gt_labels_3d, img_metas)     # 将 head 部分的输出和数据的 label 送入计算 loss     losses = self.bbox_head.loss(         *loss_inputs, gt_bboxes_ignore=gt_bboxes_ignore)     return losses</code></pre><p><strong>(4) 调用 model 中的 <code>_parse_losses</code> 方法</strong></p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/BaseDetector ================== def _parse_losses(self, losses):     # 返回来的 losses 是一个dict, 我们需要对 loss 进行求和     log_vars = OrderedDict()     for loss_name, loss_value in losses.items():         if isinstance(loss_value, torch.Tensor):             log_vars[loss_name] = loss_value.mean()         elif isinstance(loss_value, list):             log_vars[loss_name] = sum(_loss.mean() for _loss in loss_value)         else:             raise TypeError(                 f&#39;&#123;loss_name&#125; is not a tensor or list of tensors&#39;)     loss = sum(_value for _key, _value in log_vars.items()                if &#39;loss&#39; in _key)     log_vars[&#39;loss&#39;] = loss     for loss_name, loss_value in log_vars.items():         # reduce loss when distributed training         if dist.is_available() and dist.is_initialized():             loss_value = loss_value.data.clone()             dist.all_reduce(loss_value.div_(dist.get_world_size()))         log_vars[loss_name] = loss_value.item()     return loss, log_vars</code></pre><h3 id="6-2-test流程"><a href="#6-2-test流程" class="headerlink" title="6.2 test流程"></a>6.2 test流程</h3><p><img src="https://pic1.zhimg.com/80/v2-b80193d8d2bd66015ebd5aedaa9c5b14_720w.webp" alt=""></p><p>test 流程如上图所示， 我们可以看见在 test 的时候流程相比 train / val 更为简单，没有调用 runner 对象。 </p><p><strong>(1) 调用 model 中的 <code>forward_test</code></strong> </p><pre><code class="lang-python">#=================== mmdet/models/detectors/base.py/Base3DDetector =========== def forward_test(self, points, img_metas, img=None, **kwargs):     num_augs = len(points)     if num_augs != len(img_metas):         raise ValueError(             &#39;num of augmentations (&#123;&#125;) != num of image meta (&#123;&#125;)&#39;.format(                 len(points), len(img_metas)))     # 根据 points list 长度判断是 simple_test 还是 aug_test     if num_augs == 1:         img = [img] if img is None else img         return self.simple_test(points[0], img_metas[0], img[0], **kwargs)     else:         return self.aug_test(points, img_metas, img, **kwargs)</code></pre><p><strong>(2) 调用子类 的 <code>simple_test</code> 或 <code>aug_test</code></strong> </p><pre><code class="lang-python">#============= mmdet/models/detectors/voxelnet.py/VoxelNet ============ def simple_test(self, points, img_metas, imgs=None, rescale=False):     # 无数据增强测试     # 提取特征     x = self.extract_feat(points, img_metas)     # 调用 head      outs = self.bbox_head(x)     # 根据 head 输出结果生成 bboxes     bbox_list = self.bbox_head.get_bboxes(         *outs, img_metas, rescale=rescale)     # 对检测结果进行格式调整     bbox_results = [         bbox3d2result(bboxes, scores, labels)         for bboxes, scores, labels in bbox_list     ]     return bbox_results def aug_test(self, points, img_metas, imgs=None, rescale=False):     # 数据增强测试     feats = self.extract_feats(points, img_metas)     # 目前只支持单个 sample 的 aug_test     aug_bboxes = []     for x, img_meta in zip(feats, img_metas):         outs = self.bbox_head(x)         bbox_list = self.bbox_head.get_bboxes(             *outs, img_meta, rescale=rescale)         bbox_list = [             dict(boxes_3d=bboxes, scores_3d=scores, labels_3d=labels)             for bboxes, scores, labels in bbox_list         ]         aug_bboxes.append(bbox_list[0])     # 将增强后的 bboxes 进行 merge 合并操作     merged_bboxes = merge_aug_bboxes_3d(aug_bboxes, img_metas,                                         self.bbox_head.test_cfg)     return [merged_bboxes]</code></pre><p> 以上我们主要分析了整体的框架流程。</p>]]></content>
      
      
      
        <tags>
            
            <tag> BEV </tag>
            
            <tag> MMDetection3D </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>mmdetection整体构建流程</title>
      <link href="/2023/11/15/mmdetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/"/>
      <url>/2023/11/15/mmdetection%E6%95%B4%E4%BD%93%E6%9E%84%E5%BB%BA%E6%B5%81%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="MMDetection-整体构建流程"><a href="#MMDetection-整体构建流程" class="headerlink" title="MMDetection 整体构建流程"></a>MMDetection 整体构建流程</h1><h2 id="一、摘要"><a href="#一、摘要" class="headerlink" title="一、摘要"></a>一、摘要</h2><p>众所周知，目标检测算法比较复杂，细节比较多，难以复现，而我们推出的 MMDetection 开源框架则希望解决上述问题。目前  MMdetection 已经复现了大部分主流和前沿模型，例如 Faster R-CNN 系列、Mask R-CNN 系列、YOLO  系列和比较新的 DETR 等等，模型库非常丰富，star 接近 13k，在学术研究和工业落地中应用非常广泛。</p><p>本文主要是从整体框架构建角度来解析，不会涉及到具体算法和代码，希望通过本文讲解：</p><ul><li>MMDetection 整体构建流程和思想</li><li>目标检测算法核心组件划分</li><li>目标检测核心组件功能</li></ul><h2 id="二、目标检测算法抽象流程"><a href="#二、目标检测算法抽象流程" class="headerlink" title="二、目标检测算法抽象流程"></a>二、目标检测算法抽象流程</h2><p>按照目前目标检测的发展，可以大概归纳为如下所示： </p><p><img src="https://pic1.zhimg.com/80/v2-23f3f33d5ed5792e7ad55e559a6798fc_720w.webp" alt="img"></p><p>注意上面仅仅写了几个典型算法而已，简单来说目标检测算法可以按照 3 个维度划分：</p><ul><li><strong>按照 stage 个数划分</strong>，常规是 one-stage 和 two-stage，但是实际上界限不是特别清晰，例如带 refine 阶段的算法  RepPoints，实际上可以认为是1.5 stage 算法，而 Cascade R-CNN  可以认为是多阶段算法，为了简单，上面图示没有划分如此细致</li><li><strong>按照是否需要预定义 anchor 划分</strong>，常规是 anchor-based 和 anchor-free，当然也有些算法是两者混合的</li><li><strong>按照是否采用了 transformer 结构划分</strong>，目前基于 transformer 结构的目标检测算法发展迅速，也引起了极大的关注，所以这里特意增加了这个类别的划分</li></ul><p>不管哪种划分方式，其实都可以分成若干固定模块，然后通过模块堆叠来构建整个检测算法体系。</p><h2 id="三、MMDetection整体构建流程和思想"><a href="#三、MMDetection整体构建流程和思想" class="headerlink" title="三、MMDetection整体构建流程和思想"></a>三、MMDetection整体构建流程和思想</h2><p>基于目前代码实现，所有目标检测算法都按照以下流程进行划分： </p><p><img src="https://pic1.zhimg.com/80/v2-7ecc8e5e19c59a3e6682c5e3cdc34918_720w.webp" alt="img"></p><p>上述流程对应 MMDetection 代码构建流程，理解每个组件的作用不仅仅对阅读算法源码有帮助，而且还能够快速理解新提出算法对应的改进部分。下面对每个模块进行详细解读。</p><h3 id="3-1-训练核心组件"><a href="#3-1-训练核心组件" class="headerlink" title="3.1 训练核心组件"></a>3.1 训练核心组件</h3><p>训练部分一般包括 9 个核心组件，总体流程是：</p><ol><li>任何一个 batch 的图片先输入到 backbone 中进行特征提取，典型的骨干网络是 ResNet</li><li>输出的单尺度或者多尺度特征图输入到 neck 模块中进行特征融合或者增强，典型的 neck 是 FPN</li><li>上述多尺度特征最终输入到 head 部分，一般都会包括分类和回归分支输出</li><li>在整个网络构建阶段都可以引入一些即插即用增强算子来增加提取提取能力，典型的例如 SPP、DCN 等等</li><li>目标检测 head 输出一般是特征图，对于分类任务存在严重的正负样本不平衡，可以通过正负样本属性分配和采样控制</li><li>为了方便收敛和平衡多分支，一般都会对 gt bbox 进行编码</li><li>最后一步是计算分类和回归 loss，进行训练</li><li>在训练过程中也包括非常多的 trick，例如优化器选择等，参数调节也非常关键</li></ol><p>注意上述 9 个组件不是每个算法都需要的，下面详细分析。</p><h4 id="3-1-1-Backbone"><a href="#3-1-1-Backbone" class="headerlink" title="3.1.1 Backbone"></a>3.1.1 Backbone</h4><p><img src="https://pic2.zhimg.com/80/v2-cdee2bd9f289d650ddbcbd748c4be0f9_720w.webp" alt="img"></p><p>backbone 作用主要是特征提取。目前 MMDetection 中已经集成了大部分骨架网络，具体见文件：<code>mmdet/models/backbones</code>，V2.7 已经实现的骨架如下：</p><pre><code class="lang-python">__all__ = [    &#39;RegNet&#39;, &#39;ResNet&#39;, &#39;ResNetV1d&#39;, &#39;ResNeXt&#39;, &#39;SSDVGG&#39;, &#39;HRNet&#39;, &#39;Res2Net&#39;,    &#39;HourglassNet&#39;, &#39;DetectoRS_ResNet&#39;, &#39;DetectoRS_ResNeXt&#39;, &#39;Darknet&#39;,    &#39;ResNeSt&#39;, &#39;TridentResNet&#39;]</code></pre><p>最常用的是 ResNet 系列、ResNetV1d 系列和 Res2Net 系列。如果你需要对骨架进行扩展，可以继承上述网络，然后通过注册器机制注册使用。一个典型用法为：</p><pre><code class="lang-python"># 骨架的预训练权重路径pretrained=&#39;torchvision://resnet50&#39;,backbone=dict(    type=&#39;ResNet&#39;, # 骨架类名，后面的参数都是该类的初始化参数    depth=50,    num_stages=4,    out_indices=(0, 1, 2, 3),    frozen_stages=1,    norm_cfg=dict(type=&#39;BN&#39;, requires_grad=True),     norm_eval=True,    style=&#39;pytorch&#39;),</code></pre><p>通过 MMCV 中的注册器机制，你可以通过 dict 形式的配置来实例化任何已经注册的类，非常方便和灵活。</p><h4 id="3-1-2-Neck"><a href="#3-1-2-Neck" class="headerlink" title="3.1.2 Neck"></a>3.1.2 Neck</h4><p><img src="https://pic1.zhimg.com/80/v2-f0975c00a32fa03a80860f9c09234bbc_720w.webp" alt="img"></p><p>neck 可以认为是 backbone 和 head 的连接层，主要负责对 backbone 的特征进行高效融合和增强，能够对输入的单尺度或者多尺度特征进行融合、增强输出等。具体见文件：<code>mmdet/models/necks</code>，V2.7 已经实现的 neck 如下：</p><pre><code class="lang-python">__all__ = [    &#39;FPN&#39;, &#39;BFP&#39;, &#39;ChannelMapper&#39;, &#39;HRFPN&#39;, &#39;NASFPN&#39;, &#39;FPN_CARAFE&#39;, &#39;PAFPN&#39;,    &#39;NASFCOS_FPN&#39;, &#39;RFP&#39;, &#39;YOLOV3Neck&#39;]</code></pre><p>最常用的应该是 FPN，一个典型用法是：</p><pre><code class="lang-python">neck=dict(    type=&#39;FPN&#39;,    in_channels=[256, 512, 1024, 2048], # 骨架多尺度特征图输出通道    out_channels=256, # 增强后通道输出    num_outs=5), # 输出num_outs个多尺度特征图</code></pre><h4 id="3-1-3-Head"><a href="#3-1-3-Head" class="headerlink" title="3.1.3 Head"></a>3.1.3 Head</h4><p><img src="https://pic2.zhimg.com/80/v2-fdd9a6232e62c75b143153dab8ba9bc1_720w.webp" alt="img"></p><p>目标检测算法输出一般包括分类和框坐标回归两个分支，不同算法 head 模块复杂程度不一样，灵活度比较高。在网络构建方面，理解目标检测算法主要是要理解 head 模块。</p><p>MMDetection 中 head 模块又划分为 two-stage 所需的 RoIHead 和 one-stage 所需的 DenseHead，也就是说所有的 one-stage 算法的 head 模块都在<code>mmdet/models/dense_heads</code>中，而 two-stage 算法还包括额外的<code>mmdet/models/roi_heads</code>。</p><p>目前 V2.7 中已经实现的 dense_heads 包括：</p><pre><code class="lang-python">__all__ = [    &#39;AnchorFreeHead&#39;, &#39;AnchorHead&#39;, &#39;GuidedAnchorHead&#39;, &#39;FeatureAdaption&#39;,    &#39;RPNHead&#39;, &#39;GARPNHead&#39;, &#39;RetinaHead&#39;, &#39;RetinaSepBNHead&#39;, &#39;GARetinaHead&#39;,    &#39;SSDHead&#39;, &#39;FCOSHead&#39;, &#39;RepPointsHead&#39;, &#39;FoveaHead&#39;,    &#39;FreeAnchorRetinaHead&#39;, &#39;ATSSHead&#39;, &#39;FSAFHead&#39;, &#39;NASFCOSHead&#39;,    &#39;PISARetinaHead&#39;, &#39;PISASSDHead&#39;, &#39;GFLHead&#39;, &#39;CornerHead&#39;, &#39;YOLACTHead&#39;,    &#39;YOLACTSegmHead&#39;, &#39;YOLACTProtonet&#39;, &#39;YOLOV3Head&#39;, &#39;PAAHead&#39;,    &#39;SABLRetinaHead&#39;, &#39;CentripetalHead&#39;, &#39;VFNetHead&#39;, &#39;TransformerHead&#39;]</code></pre><p>几乎每个算法都包括一个独立的 head，而 roi_heads 比较杂，就不列出了。</p><p>需要注意的是：<strong>two-stage 或者 mutli-stage 算法，会额外包括一个区域提取器 roi extractor，用于将不同大小的 RoI 特征图统一成相同大小</strong>。</p><p>虽然 head 部分的网络构建比较简单，但是由于正负样本属性定义、正负样本采样和 bbox 编解码模块都在 head 模块中进行组合调用，故 MMDetection <strong>中最复杂的模块就是 head</strong>。在最后的整体流程部分会对该模块进行详细分析。</p><h4 id="3-1-4-Enhance"><a href="#3-1-4-Enhance" class="headerlink" title="3.1.4 Enhance"></a>3.1.4 Enhance</h4><p><img src="https://pic3.zhimg.com/80/v2-65a706efe224f0b7ffc7f4fd7a65f2ca_720w.webp" alt="img"></p><p>enhance 是即插即用、能够对特征进行增强的模块，其具体代码可以通过 dict 形式注册到 backbone、neck 和 head  中，非常方便(目前还不完善)。常用的 enhance 模块是 SPP、ASPP、RFB、Dropout、Dropblock、DCN  和各种注意力模块 SeNet、Non_Local、CBA 等。目前 MMDetection 中部分模块支持 enhance 的接入，例如  ResNet 骨架中的 plugins。</p><h4 id="3-1-5-BBox-Assigner"><a href="#3-1-5-BBox-Assigner" class="headerlink" title="3.1.5 BBox Assigner"></a>3.1.5 BBox Assigner</h4><p>正负样本属性分配模块作用是进行正负样本定义或者正负样本分配（可能也包括忽略样本定义），正样本就是常说的前景样本（可以是任何类别），负样本就是背景样本。因为目标检测是一个同时进行分类和回归的问题，对于分类场景必然需要确定正负样本，否则无法训练。该模块至关重要，不同的正负样本分配策略会带来显著的性能差异，目前大部分目标检测算法都会对这个部分进行改进，至关重要。一些典型的分配策略如下：</p><p><img src="https://pic3.zhimg.com/80/v2-12bae70e2ea2e4afb05d0d8d3f38ca56_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/core/bbox/assigners</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;BaseAssigner&#39;, &#39;MaxIoUAssigner&#39;, &#39;ApproxMaxIoUAssigner&#39;,     &#39;PointAssigner&#39;, &#39;ATSSAssigner&#39;, &#39;CenterRegionAssigner&#39;, &#39;GridAssigner&#39;,    &#39;HungarianAssigner&#39;]</code></pre><h4 id="3-1-6-BBox-Sampler"><a href="#3-1-6-BBox-Sampler" class="headerlink" title="3.1.6 BBox Sampler"></a>3.1.6 BBox Sampler</h4><p>在确定每个样本的正负属性后，可能还需要进行样本平衡操作。本模块作用是对前面定义的正负样本不平衡进行采样，力争克服该问题。一般在目标检测中 gt bbox 都是非常少的，所以正负样本比是远远小于 1  的。而基于机器学习观点：在数据极度不平衡情况下进行分类会出现预测倾向于样本多的类别，出现过拟合，为了克服该问题，适当的正负样本采样策略是非常必要的，一些典型采样策略如下：</p><p><img src="https://pic4.zhimg.com/80/v2-91674a0710afadfd06a9ebd139f875fb_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/core/bbox/samplers</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;BaseSampler&#39;, &#39;PseudoSampler&#39;, &#39;RandomSampler&#39;,    &#39;InstanceBalancedPosSampler&#39;, &#39;IoUBalancedNegSampler&#39;, &#39;CombinedSampler&#39;,    &#39;OHEMSampler&#39;, &#39;SamplingResult&#39;, &#39;ScoreHLRSampler&#39;]</code></pre><h4 id="3-1-7-BBox-Encoder"><a href="#3-1-7-BBox-Encoder" class="headerlink" title="3.1.7 BBox Encoder"></a>3.1.7 BBox Encoder</h4><p>为了更好的收敛和平衡多个 loss，具体解决办法非常多，而 bbox 编解码策略也算其中一个，bbox 编码阶段对应的是对正样本的 gt bbox  采用某种编码变换（反操作就是 bbox 解码），最简单的编码是对 gt bbox  除以图片宽高进行归一化以平衡分类和回归分支，一些典型的编解码策略如下：</p><p><img src="https://pic4.zhimg.com/80/v2-1f8d5e5e45886423df474d168452f50b_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/core/bbox/coder</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;BaseBBoxCoder&#39;, &#39;PseudoBBoxCoder&#39;, &#39;DeltaXYWHBBoxCoder&#39;,    &#39;LegacyDeltaXYWHBBoxCoder&#39;, &#39;TBLRBBoxCoder&#39;, &#39;YOLOBBoxCoder&#39;,    &#39;BucketingBBoxCoder&#39;]</code></pre><h4 id="3-1-8-Loss"><a href="#3-1-8-Loss" class="headerlink" title="3.1.8 Loss"></a>3.1.8 Loss</h4><p>Loss 通常都分为分类和回归 loss，其对网络 head 输出的预测值和 bbox encoder 得到的 targets 进行梯度下降迭代训练。</p><p>loss 的设计也是各大算法重点改进对象，常用的 loss 如下：</p><p><img src="https://pic4.zhimg.com/80/v2-686b0b9ac6a82f9945ae454d18783227_720w.webp" alt="img"></p><p>对应的代码在<code>mmdet/models/losses</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;cross_entropy&#39;, &#39;binary_cross_entropy&#39;,    &#39;mask_cross_entropy&#39;, &#39;CrossEntropyLoss&#39;, &#39;sigmoid_focal_loss&#39;,    &#39;FocalLoss&#39;, &#39;smooth_l1_loss&#39;, &#39;SmoothL1Loss&#39;, &#39;balanced_l1_loss&#39;,    &#39;BalancedL1Loss&#39;, &#39;mse_loss&#39;, &#39;MSELoss&#39;, &#39;iou_loss&#39;, &#39;bounded_iou_loss&#39;,    &#39;IoULoss&#39;, &#39;BoundedIoULoss&#39;, &#39;GIoULoss&#39;, &#39;DIoULoss&#39;, &#39;CIoULoss&#39;, &#39;GHMC&#39;,    &#39;GHMR&#39;, &#39;reduce_loss&#39;, &#39;weight_reduce_loss&#39;, &#39;weighted_loss&#39;, &#39;L1Loss&#39;,    &#39;l1_loss&#39;, &#39;isr_p&#39;, &#39;carl_loss&#39;, &#39;AssociativeEmbeddingLoss&#39;,    &#39;GaussianFocalLoss&#39;, &#39;QualityFocalLoss&#39;, &#39;DistributionFocalLoss&#39;,    &#39;VarifocalLoss&#39;]</code></pre><p>可以看出 MMDetection 中已经实现了非常多的 loss，可以直接使用。</p><h4 id="3-1-9-Training-tricks"><a href="#3-1-9-Training-tricks" class="headerlink" title="3.1.9 Training tricks"></a>3.1.9 Training tricks</h4><p>训练技巧非常多，常说的调参很大一部分工作都是在设置这部分超参。这部分内容比较杂乱，很难做到完全统一，目前主流的 tricks 如下所示:</p><p><img src="https://pic3.zhimg.com/80/v2-569a12b6d4a20f8619a27b48d5b2fa42_720w.webp" alt="img"></p><p>MMDetection 目前这部分还会继续完善，也欢迎大家一起贡献。</p><h3 id="3-2-测试核心组件"><a href="#3-2-测试核心组件" class="headerlink" title="3.2 测试核心组件"></a>3.2 测试核心组件</h3><p>测试核心组件和训练非常类似，但是简单很多，除了必备的网络构建部分外( backbone、neck、head 和 enhance )，不需要正负样本定义、正负样本采样和 loss  计算三个最难的部分，但是其额外需要一个 bbox 后处理模块和测试 trick。</p><h4 id="3-2-1-BBox-Decoder"><a href="#3-2-1-BBox-Decoder" class="headerlink" title="3.2.1 BBox Decoder"></a>3.2.1 BBox Decoder</h4><p>训练时候进行了编码，那么对应的测试环节需要进行解码。根据编码的不同，解码也是不同的。举个简单例子：假设训练时候对宽高是直接除以图片宽高进行归一化的，那么解码过程也仅仅需要乘以图片宽高即可。其代码和 bbox encoder 放在一起，在<code>mmdet/core/bbox/coder</code>中。</p><h4 id="3-2-2-BBox-PostProcess"><a href="#3-2-2-BBox-PostProcess" class="headerlink" title="3.2.2 BBox PostProcess"></a>3.2.2 BBox PostProcess</h4><p>在得到原图尺度 bbox 后，由于可能会出现重叠 bbox 现象，故一般都需要进行后处理，最常用的后处理就是非极大值抑制以及其变种。</p><p>其对应的文件在<code>mmdet/core/post_processing</code>中，V2.7 主要包括：</p><pre><code class="lang-python">__all__ = [    &#39;multiclass_nms&#39;, &#39;merge_aug_proposals&#39;, &#39;merge_aug_bboxes&#39;,    &#39;merge_aug_scores&#39;, &#39;merge_aug_masks&#39;, &#39;fast_nms&#39;]</code></pre><h4 id="3-2-3-Testing-tricks"><a href="#3-2-3-Testing-tricks" class="headerlink" title="3.2.3 Testing tricks"></a>3.2.3 Testing tricks</h4><p>为了提高检测性能，测试阶段也会采用 trick。这个阶段的 tricks 也非常多，难以完全统一，最典型的是多尺度测试以及各种模型集成手段，典型配置如下：</p><pre><code class="lang-python">dict(    type=&#39;MultiScaleFlipAug&#39;,    img_scale=(1333, 800),    flip=True,    transforms=[        dict(type=&#39;Resize&#39;, keep_ratio=True),        dict(type=&#39;RandomFlip&#39;),        dict(type=&#39;Normalize&#39;, **img_norm_cfg),        dict(type=&#39;Pad&#39;, size_divisor=32),        dict(type=&#39;ImageToTensor&#39;, keys=[&#39;img&#39;]),        dict(type=&#39;Collect&#39;, keys=[&#39;img&#39;]),    ])</code></pre><p><img src="https://pic3.zhimg.com/80/v2-16e307727f0c3e941ec72c21f214b982_720w.webp" alt="img"></p><h3 id="3-3-训练测试算法流程"><a href="#3-3-训练测试算法流程" class="headerlink" title="3.3 训练测试算法流程"></a>3.3 训练测试算法流程</h3><p>在分析完每个训练流程的各个核心组件后，为了方便大家理解整个算法构建，下面分析 MMDetection 是如何组合各个组件进行训练的，这里以 one-stage 检测器为例，two-stage 也比较类似。</p><pre><code class="lang-python">class SingleStageDetector(---):   def __init__(...):        # 构建骨架、neck和head        self.backbone = build_backbone(backbone)        if neck is not None:            self.neck = build_neck(neck)        self.bbox_head = build_head(bbox_head)  def forward_train(---):         # 先运行backbone+neck进行特征提取        x = self.extract_feat(img)        # 对head进行forward train，输出loss        losses = self.bbox_head.forward_train(x, img_metas, gt_bboxes,                                              gt_labels, gt_bboxes_ignore)        return losses  def simple_test(---):        # 先运行backbone+neck进行特征提取        x = self.extract_feat(img)        # head输出预测特征图        outs = self.bbox_head(x)        # bbox解码和还原        bbox_list = self.bbox_head.get_bboxes(            *outs, img_metas, rescale=rescale)        # 重组结果返回        bbox_results = [            bbox2result(det_bboxes, det_labels, self.bbox_head.num_classes)            for det_bboxes, det_labels in bbox_list        ]        return bbox_results</code></pre><p>以上就是整个检测器算法训练和测试最简逻辑，可以发现训练部分最核心的就是<code>bbox_head.forward_train</code>，测试部分最核心的是<code>bbox_head.get_bboxes</code>，下面单独简要分析。</p><h4 id="3-3-1-bbox-head-forward-train"><a href="#3-3-1-bbox-head-forward-train" class="headerlink" title="3.3.1 bbox_head.forward_train"></a>3.3.1 bbox_head.forward_train</h4><p>forward_train 是通用函数，如下所示：</p><pre><code class="lang-python">def forward_train(...):    # 调用每个head自身的forward方法    outs = self(x)    if gt_labels is None:        loss_inputs = outs + (gt_bboxes, img_metas)    else:        loss_inputs = outs + (gt_bboxes, gt_labels, img_metas)    # 计算每个head自身的loss方法    losses = self.loss(*loss_inputs, gt_bboxes_ignore=gt_bboxes_ignore)    # 返回    return losses</code></pre><p>对于不同的 head，虽然 forward 内容不一样，但是依然可以抽象为： <code>outs = self(x)</code></p><pre><code class="lang-python">def forward(self, feats):   # 多尺度特征图，一个一个迭代进行forward_single   return multi_apply(self.forward_single, feats)def forward_single(self, x):   # 运行各个head独特的head forward方法，得到预测图   ....   return cls_score, bbox_pred...</code></pre><p>而对于不同的 head，其 loss 计算部分也比较复杂，可以简单抽象为：<code>losses = self.loss(...)</code></p><pre><code class="lang-python">def loss(...):    # 1 生成anchor-base需要的anchor或者anchor-free需要的points    # 2 利用gt bbox对特征图或者anchor计算其正负和忽略样本属性    # 3 进行正负样本采样    # 4 对gt bbox进行bbox编码    # 5 loss计算，并返回    return dict(loss_cls=losses_cls, loss_bbox=losses_bbox,...)</code></pre><h4 id="3-3-2-bbox-head-get-bboxes"><a href="#3-3-2-bbox-head-get-bboxes" class="headerlink" title="3.3.2 bbox_head.get_bboxes"></a>3.3.2 bbox_head.get_bboxes</h4><p>get_bboxes函数更加简单</p><pre><code class="lang-python">def get_bboxes(...):   # 1 生成anchor-base需要的anchor或者anchor-free需要的points   # 2 遍历每个输出层，遍历batch内部的每张图片，对每张图片先提取指定个数的预测结果，缓解后面后处理压力；对保留的位置进行bbox解码和还原到原图尺度   # 3 统一nms后处理   return det_bboxes, det_labels...</code></pre><h2 id="四、-总结"><a href="#四、-总结" class="headerlink" title="四、 总结"></a>四、 总结</h2><p>本文重点分析了一个目标检测器是如何通过多个核心组件堆叠而成，不涉及具体代码，大家只需要总体把握即可，其中最应该了解的是：<strong>任何一个目标检测算法都可以分成 n 个核心组件，组件和组件之间是隔离的，方便复用和设计</strong>。当面对一个新算法时候我们可以先分析其主要是改进了哪几个核心组件，然后就可以高效的掌握该算法。</p><p>最后附上总图： </p><p><img src="https://pic3.zhimg.com/80/v2-c4e6229a1fd42692d090108481be34a6_720w.webp" alt="img"></p>]]></content>
      
      
      
        <tags>
            
            <tag> MMDetection </tag>
            
            <tag> BEV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention:从NLP到CV再到BEV</title>
      <link href="/2023/11/09/Attention:%E4%BB%8ENLP%E5%88%B0CV%E5%86%8D%E5%88%B0BEV/"/>
      <url>/2023/11/09/Attention:%E4%BB%8ENLP%E5%88%B0CV%E5%86%8D%E5%88%B0BEV/</url>
      
        <content type="html"><![CDATA[<p>一、Transformer</p><p>Transformer源于17年谷歌的文章Attention Is All You Need“”</p><p><img src="https://picx.zhimg.com/80/v2-d44557c723b7b8ed46ea9affe4f2e926_720w.webp?source=2c26e567" style="zoom:67%;"></p><p>Transformer最开始应用于NLP领域的机器翻译任务。</p><p>它是一个编码器-解码器结构：编码器将原始语言的句子作为输入并生成基于注意力的表征，解码器则关注编码信息并以自回归方式生成翻译的句子。</p><p><img src="https://picx.zhimg.com/80/v2-f3374bc9c9556a7cdf076b48c64e4303_720w.webp?source=2c26e567" alt=""></p><p>Transformer中最重要的是Attention机制。</p><p>Attention（注意力）机制如果浅层的理解，跟他的名字非常匹配。他的核心逻辑就是「<strong>从关注全部到关注重点</strong>」。</p><p><img src="https://pic1.zhimg.com/80/v2-9e9e42cf4de1cfa1851c0bb7e7f0d8c4_720w.jpg" alt=""></p><p><strong>Attention机制的实质其实就是一个寻址（addressing）的过程</strong>，如下图所示：给定一个和任务相关的查询<strong>Query</strong>向量 <strong>q</strong>，通过计算与<strong>Key</strong>的注意力分布并附加在<strong>Value</strong>上，从而计算<strong>Attention Value</strong>，这个过程实际上是<strong>Attention机制缓解神经网络模型复杂度的体现</strong>：不需要将所有的N个输入信息都输入到神经网络进行计算，只需要从X中选择一些和任务相关的信息输入给神经网络。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3724c8a2bee76f326f78f18c5d3fa4da.webp?x-oss-process=image/format,png" alt=""></p><p>举个例子：</p><p><img src="https://pic2.zhimg.com/80/v2-f5cbf9efc7a017b02d00e946dda8360d_720w.webp" alt=""></p><p>图书管（source）里有很多书（value），为了方便查找，我们给书做了编号（key）。当我们想要了解漫威（query）的时候，我们就可以看看那些动漫、电影、甚至二战（美国队长）相关的书籍。</p><p>为了提高效率，并不是所有的书都会仔细看，针对漫威来说，动漫，电影相关的会看的仔细一些（权重高），但是二战的就只需要简单扫一下即可（权重低）。</p><p>当我们全部看完后就对漫威有一个全面的了解了。</p><p><strong>Attention 原理的3步分解：</strong></p><p>第一步： query 和 key 进行相似度计算，得到权值</p><p>第二步：将权值进行归一化，得到直接可用的权重</p><p>第三步：将权重和 value 进行加权求和</p><p><img src="https://img-blog.csdnimg.cn/6c2d4a4226944090bec7dad2b22c0caf.png" alt=""></p><p>self-attention</p><p>寻找一段文本内部不同部分之间的关系来构建这段文本的表征。</p><p><img src="https://pic2.zhimg.com/80/v2-cbc7e56ea862be44515d5f56e2f6ce71_720w.webp" alt=""></p><p>上图显示的就是当算法处理到红色字的表征时，它应该给文中其他文字的表征多大的注意力权重。</p><hr><p>Transformers目标检测，端到端的DETR</p><p><img src="https://pic1.zhimg.com/80/v2-772984ccd82a0e0a279ea6a09c3c34c0_720w.webp" alt=""></p><p>DETR摒弃了以往的生成Anchors和NMS环节，我们知道，生成Anchors即为生成一系列的框，再由CNN判断框内是否有目标及其对应的类别，而NMS则是将多余重复的框删减掉。而DETR将目标检测视为集合预测的问题，也即预测最终所需的各个目标的框及类别。直白点，就是希望通过向网络输入图片，让网络直接输出物体最终的框及其类别，这样便少了生成Anchors及NMS的环节。</p><p>这篇文章让网络生成固定数量N（原文N取100）个预测，每个预测都包含一个框及其类别。但不同于以往可能有多个预测是属于同一物体（也即得通过NMS来消除框），这里的预测，对于图片上的每个物体有且仅有一个框与之对应，而对于多于的预测，则直接归为背景类（no object）。</p><p>如上图，大概流程为，先将图片通过CNN提取特征，再通过transformer直接输出固定数量为N（原文中N取100，而N则是远大于一张图片中包含的物体数量）的预测框及其类别（不再有Anchors生成以及NMS环节）。而这N个框，每个框要么与物体唯一对应，要么直接归为背景类（no object）。假设我们现在有一张图片，图片上有2个物体，则最终预测的100个框中，将有2个为物体框，剩余的98个为背景框（不会输出）。</p><p><img src="https://pic4.zhimg.com/v2-3d43474df51c545ad6bafc19b3c8ccc3_r.jpg" alt=""></p><p>下图为最后一个Encoder Layer的attention可视化，Encoder已经分离了instances，简化了Decoder的对象提取和定位。</p><p><img src="https://pic3.zhimg.com/80/v2-dffe148c6e78f7b67cf6aa5c8bbbc316_720w.webp" alt=""></p><p>类似于可视化编码器注意力，作者在下图中可视化解码器注意力，用不同的颜色给每个预测对象的注意力图着色。观察到，解码器的attention相当局部，这意味着它主要关注对象的四肢，如头部或腿部。我们假设，在编码器通过全局关注分离实例之后，<strong>解码器只需要关注极端来提取类和对象边界。</strong></p><p><img src="https://pic1.zhimg.com/80/v2-6b80634bf88e496f035945ec25c40764_720w.webp" alt=""></p><p><strong>DETR模型弊端</strong></p><p>如果用10*10的特征图表示一张图片，即一张图片划分成100个Patch，那么就有100个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要100*100=10000次。</p><p>如果用100*100的特征图表示一张图片，即一张图片划分成10000个Patch，那么就有10000个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要10000*100000=1亿次。由此可见，每一个Patch的边长缩小10倍，计算量要增加一万倍。因为识别小物体有恰恰需要划分更小的Patch，因此DETR的小物体识别能力有限。<br>                                                      <img src="https://img-blog.csdnimg.cn/img_convert/065259c3a0e98a8e500c6f59db05fbab.png" style="zoom:36%;"></p><hr><p><strong>Transformer在BEV上的应用———BEVFormer</strong></p><p>其网络结构如下：</p><p><img src="https://pic2.zhimg.com/v2-65a11a98d73c1111bcc05e1f10848195_r.jpg" alt=""></p><p>Encoder模块包含了两个子模块：Temporal Self-Attention模块和Spatial Cross-Attention模块。</p><p>这两个模块都用到了一个组件———多尺度的可变性注意力模块，该模块是将Transformer的全局注意力变为局部注意力的一个非常关键的组件，用来减少训练时间，提高Transformer的收敛速度。</p><p>多尺度可变形注意力模块与Transformer中常见的先生成Attention Map，再计算加权和的方式不同；常规而言Attention Map = Query 和Key做内积运算，将Attention Map再和Value做加权；但是由于这种方式计算量开销会比较大，所以在Deformable DETR中用局部注意力机制代替了全局注意力机制，只对几个采样点进行采样，<strong>而采样点的位置对于参考点的偏移量和每个采样点在加权时的比重均是靠Query经过Linear层学习得到的。</strong></p><p>Temporal Self-Attention模块通过引入时序信息（History BEV）与当前时刻的BEV Query进行融合，提高BEV Query的建模能力。</p><p><img src="/home/haseka/Pictures/Spatial-Att.png" alt=""></p><p>Spatial Cross-Attention模块利用Temporal Self-Attention模块输出的<code>bev_query</code>，对主干网和Neck网络提取到的多尺度环视图像特征进行查询，生成BEV空间下的BEV Embedding特征</p><p><img src="/home/haseka/Pictures/bev_layout.png" alt=""></p><p>上述产生BEV特征的过程是用了当前输入到网络模型中除当前帧外，之前所有帧特征去迭代修正去获得pre_bev的特征；所以在利用decoder模块进行解码之前，需要对当前时刻环视的6张图片同样利用Backbone+Neck提取多尺度特征，再利用上述的 Temporal Self-Attention 模块和 Spatial Cross-Attention 模块的逻辑生成当前时刻的<code>bev_embedding</code>，然后将这部分特征送入到 Decoder 中进行 3D 目标检测。</p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Attention</title>
      <link href="/2023/11/09/Attention/"/>
      <url>/2023/11/09/Attention/</url>
      
        <content type="html"><![CDATA[<h2 id="一注意力机制attention">一、注意力机制：Attention</h2><h3 id="什么是注意力机制">1.1什么是注意力机制？</h3><p>我们先来看一张图片</p><p><img src="/home/haseka/Documents/hexo_blog/themes/butterfly/source/img/clannad.jpg"></p><p>那么，大家的目光是更多注意在美少女古河渚身上，还是花草风景身上呢？可能对于热爱动漫的人来说他会关注logo------CLANNAD1和主人公古河渚，对于喜欢花的人来说可能更关注樱花，对于喜欢制服的人来说可能更关注jk装......</p><p>再举几个例子：</p><ul><li>看人--&gt;看脸</li><li>看文章--&gt;看标题</li><li>看段落--&gt;看开头</li></ul><p><strong>注意力机制</strong>其实是源自于人对于外部信息的处理能力。由于每一时刻接受的信息都是无比庞大且复杂万分的，远远超过了人脑的处理能力，<font color="red">因此人在处理信息的时候，会将注意力放在需要关注的信息上，对于其他无关的外部信息进行过滤</font>，这种处理方式被称为注意力机制。</p><p>通俗而言，注意力对于人而言可以理解为“关注度”，对于没有感情的机器而言就是赋予多少权重（0-1间的小数），越重要的地方或者越相关的地方就赋予越高的权重。</p><hr><h3 id="如何运用注意力机制">1.2如何运用注意力机制？</h3><h4 id="querykey和value">1.2.1 Query、Key和Value</h4><p>首先，三者概念：</p><ul><li>查询（Query）：是指查询的范围，自主提示，即主观意识的特征向量</li><li>键（Key）：是被对比的项，非自主提示，即物体的突然出特征信息向量</li><li>值（Value）：是代表物体自身的特征向量，通常与Key成对出现</li></ul><p>注意力机制是通过Query与Key的注意力汇聚（给定一个Query，计算Query与Key的相关性，然后根据该相关性去找到最合适的Value）实现对Value的注意力权重分配，生成最终的输出结果。</p><p><img src="https://img-blog.csdnimg.cn/img_convert/3724c8a2bee76f326f78f18c5d3fa4da.webp?x-oss-process=image/format,png"></p><p>举例子而言：</p><ol type="1"><li>淘宝购物，输入关键词（男鞋），这个就是Query</li><li>搜素系统会根据这个关键词去查找一些列相关的Key（商品名、图片）</li><li>最后系统会将相应的Value（具体鞋子）返回给你</li></ol><p>上述例子中，Query，Key和Value的每个属性虽然在不同的空间，但其实它们是有一定的潜在关系，也就是说通过某种变换，可以使得三者的属性在一个相近的空间中。</p><hr><h4 id="注意力机制计算过程">1.2.2 注意力机制计算过程</h4><p>输入Query、Key、Value：</p><ul><li><p><strong>第一步：</strong>计算Query和Key间相似度（常见方法：点积、余弦相似度、MLP网络），得到注意力得分：</p><p>点积：<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="40.384ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 17849.6 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(990,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1868,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2213,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2511,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3040,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3491,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3836,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4197,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5076,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5867,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6439,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6905,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7356,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7846,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8290.7,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(9179.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(9645.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10462.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11129.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(12185.2,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(12976.2,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(13548.2,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(14014.2,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(14465.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(15177.4,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(15677.6,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(16566.6,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(17032.6,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span></p><p>Cosine 相似性： <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.238ex;" xmlns="http://www.w3.org/2000/svg" width="40.114ex" height="3.461ex" role="img" focusable="false" viewBox="0 -982.8 17730.5 1529.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(990,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1868,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2213,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2511,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3040,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3491,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3836,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4197,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5076,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5867,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6439,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6905,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7356,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7846,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8290.7,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(9179.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(9645.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10462.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11129.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(12185.2,0)"><g data-mml-node="mrow" transform="translate(927.1,485) scale(0.707)"><g data-mml-node="mi"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(791,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1363,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1829,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2280,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(2770,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(3048,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(3937,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(4403,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g><g data-mml-node="mrow" transform="translate(220,-370.3) scale(0.707)"><g data-mml-node="mrow"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(1291,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1863,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(2329,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2780,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(3270,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g></g><g data-mml-node="mo" transform="translate(3770,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mrow" transform="translate(4048,0)"><g data-mml-node="mo"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(1389,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(1855,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2672,0)"><path data-c="2225" d="M133 736Q138 750 153 750Q164 750 170 739Q172 735 172 250T170 -239Q164 -250 152 -250Q144 -250 138 -244L137 -243Q133 -241 133 -179T132 250Q132 731 133 736ZM329 739Q334 750 346 750Q353 750 361 744L362 743Q366 741 366 679T367 250T367 -178T362 -243L361 -244Q355 -250 347 -250Q335 -250 329 -239Q327 -235 327 250T329 739Z"></path></g></g></g><rect width="5305.3" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span></p><p>MLP网络<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="47.133ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 20832.8 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(990,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1868,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2213,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(2511,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(3040,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3491,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3836,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4197,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4687,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(5076,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5867,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6439,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6905,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7356,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7846,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(8290.7,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(9179.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(9645.7,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(10462.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11129.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(12185.2,0)"><path data-c="1D440" d="M289 629Q289 635 232 637Q208 637 201 638T194 648Q194 649 196 659Q197 662 198 666T199 671T201 676T203 679T207 681T212 683T220 683T232 684Q238 684 262 684T307 683Q386 683 398 683T414 678Q415 674 451 396L487 117L510 154Q534 190 574 254T662 394Q837 673 839 675Q840 676 842 678T846 681L852 683H948Q965 683 988 683T1017 684Q1051 684 1051 673Q1051 668 1048 656T1045 643Q1041 637 1008 637Q968 636 957 634T939 623Q936 618 867 340T797 59Q797 55 798 54T805 50T822 48T855 46H886Q892 37 892 35Q892 19 885 5Q880 0 869 0Q864 0 828 1T736 2Q675 2 644 2T609 1Q592 1 592 11Q592 13 594 25Q598 41 602 43T625 46Q652 46 685 49Q699 52 704 61Q706 65 742 207T813 490T848 631L654 322Q458 10 453 5Q451 4 449 3Q444 0 433 0Q418 0 415 7Q413 11 374 317L335 624L267 354Q200 88 200 79Q206 46 272 46H282Q288 41 289 37T286 19Q282 3 278 1Q274 0 267 0Q265 0 255 0T221 1T157 2Q127 2 95 1T58 0Q43 0 39 2T35 11Q35 13 38 25T43 40Q45 46 65 46Q135 46 154 86Q158 92 223 354T289 629Z"></path></g><g data-mml-node="mi" transform="translate(13236.2,0)"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(13917.2,0)"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(14668.2,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(15057.2,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(15848.2,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(16420.2,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(16886.2,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(17337.2,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(17827.2,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(18271.8,0)"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g><g data-mml-node="mi" transform="translate(19160.8,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="msub" transform="translate(19626.8,0)"><g data-mml-node="mi"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(523,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(20443.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></span></p></li><li><p><strong>第二步：</strong>对注意力得分进行缩放scale（除以维度的根号），再softmax()，一方面可以进行归一化，将原始计算分值整理成所有元素权重之和为1的概率分布；另一方面也可以通过softmax的内在机制更加突出重要元素的权重。一般采用如下公式计算：</p><p>​ <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -1.882ex;" xmlns="http://www.w3.org/2000/svg" width="32.339ex" height="4.152ex" role="img" focusable="false" viewBox="0 -1003.2 14294 1835"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(1133.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(2189.5,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(2834.5,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3319.5,0)"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mi" transform="translate(3869.5,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(4230.5,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5108.5,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5637.5,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mo" transform="translate(6209.5,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6598.5,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(7243.5,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(7588.5,0)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(911,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(8793.5,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(9460.2,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(10516,0)"><g data-mml-node="msup" transform="translate(1120.9,394) scale(0.707)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(990,0)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(911,-307.4)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g><g data-mml-node="mrow" transform="translate(220,-526.3) scale(0.707)"><g data-mml-node="munderover"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-287.7) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g><g data-mml-node="mo" transform="translate(412,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1190,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msup" transform="translate(2500.7,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="TeXAtom" transform="translate(499,472.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(645,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(990,0)"><g data-mml-node="mi"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(911,-307.4)"><path data-c="1D457" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path></g></g></g></g></g><rect width="3537.9" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container></span></p></li><li><p><strong>第三步：</strong>根据权重系数对Value值进行加权求和，得到AttentionValue（此时的V是具有一些注意力信息的，更重要的信息更关注，不重要的信息被忽视了）</p><p>​ <span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.777ex;" xmlns="http://www.w3.org/2000/svg" width="44.57ex" height="2.949ex" role="img" focusable="false" viewBox="0 -960 19699.9 1303.4"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D434" d="M208 74Q208 50 254 46Q272 46 272 35Q272 34 270 22Q267 8 264 4T251 0Q249 0 239 0T205 1T141 2Q70 2 50 0H42Q35 7 35 11Q37 38 48 46H62Q132 49 164 96Q170 102 345 401T523 704Q530 716 547 716H555H572Q578 707 578 706L606 383Q634 60 636 57Q641 46 701 46Q726 46 726 36Q726 34 723 22Q720 7 718 4T704 0Q701 0 690 0T651 1T578 2Q484 2 455 0H443Q437 6 437 9T439 27Q443 40 445 43L449 46H469Q523 49 533 63L521 213H283L249 155Q208 86 208 74ZM516 260Q516 271 504 416T490 562L463 519Q447 492 400 412L310 260L413 259Q516 259 516 260Z"></path></g><g data-mml-node="mi" transform="translate(750,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1111,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(1472,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(1938,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(2538,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mi" transform="translate(2899,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(3244,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(3729,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(4329,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(4718,0)"><path data-c="1D444" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path></g><g data-mml-node="mi" transform="translate(5509,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6081,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(6547,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6998,0)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(7488,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(7932.7,0)"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z"></path></g><g data-mml-node="mi" transform="translate(8577.7,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(9062.7,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(9634.7,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(10085.7,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(10518.7,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(10984.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(11651.4,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="munderover" transform="translate(12707.2,0)"><g data-mml-node="mo"><path data-c="2211" d="M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1089,477.1) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(714,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g><g data-mml-node="TeXAtom" transform="translate(1089,-285.4) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(345,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1123,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g><g data-mml-node="msub" transform="translate(15160.5,0)"><g data-mml-node="mi"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(562,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(16238.7,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(16738.9,0)"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g><g data-mml-node="mi" transform="translate(17507.9,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(18036.9,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(18334.9,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="msub" transform="translate(18906.9,0)"><g data-mml-node="mi"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(499,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container></span></p></li></ul><p>这三个步可以用下图表示：</p><p><img src="https://img-blog.csdnimg.cn/6c2d4a4226944090bec7dad2b22c0caf.png"></p><hr><h2 id="二自注意力机制self-attention">二、自注意力机制：Self-Attention</h2><h3 id="什么是自注意力机制">2.1什么是自注意力机制</h3><p>自注意机制是注意力机制的一种，它要解决的实际问题是<font color="red">神经网络接收的输入是很多大小不一的向量，并且不同向量之间有一定的关系，但是实际训练的时候无法充分发挥这些输入之间的关系而导致模型训练结果效果极差。</font>比如，在语义分析中多个向量对应一个标签。</p><p>针对全连接神经网络对于多个相关的输入无法建立起相关性的这个问题，通过自注意力机制来解决，自注意力机制实际上是想让机器注意到<font color="red"><strong>整个输入中不同部分之间的相关性</strong></font>。</p><p>自注意力机制是注意力机制的变体，<font color="red">其减少了对外部信息的依赖，更擅长捕捉数据或特征的内部相关性。</font>自注意力机制的关键点在于，<font color="red">Q、K、V是同一个东西，或者三者来源于同一个X，三者同源。</font>通过X找到X里面的关键点，从而更关注X的关键信息，忽略X的不重要信息。<strong>不是输入语句与输出语句之间的注意力机制，而是输入语句内部元素之间或者输出语句内部元素之间发生的注意力机制。</strong></p><blockquote><p><font color="orange">注意力机制和自注意力机制的区别：</font></p><p>（1）注意力机制的Q和K是不同来源的，例如，在Encoder-Decoder模型中，K是Encoder中的元素，而Q是Decoder中的元素。在中译英模型中，Q是中文单词特征，而K则是英文单词特征。</p><p>（2）自注意力机制的Q和K则都是来自于同一组的元素，例如，在Encoder-Decoder模型中，Q和K都是Encoder中的元素，即Q和K都是中文特征，相互之间做注意力汇聚。也可以理解为同一句话中的词元或者同一张图像中不同的patch，这都是一组元素内部相互做注意力机制，因此，自注意力机制（self-attention）也被称为内部注意力机制（intra-attention）。</p></blockquote><hr><h3 id="如何运用自注意力机制">2.2如何运用自注意力机制</h3><p>大体上步骤和注意力机制是一样的。</p><p><strong>First：得到Q,K,V的值</strong></p><p>对于每一个向量x，分别乘上三个系数<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.408ex" height="2.37ex" role="img" focusable="false" viewBox="0 -853.7 5484.6 1047.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(1511.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1956.1,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mo" transform="translate(3510.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(3955.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g></g></g></svg></mjx-container></span>,得到的Q,K,V分别表示query，key和Value</p><p><img src="https://img-blog.csdnimg.cn/49fa756cd86b4d248baf53f91dec0521.jpeg"></p><p><strong>Second：Matmul</strong></p><p>利用得到的Q和K计算每两个向量之间的相关性，一般采用点积计算，为每个向量计算一个socre:sa:<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.084ex" height="2.009ex" role="img" focusable="false" viewBox="0 -694 5341 888"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(469,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(902,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(1387,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(1838,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mo" transform="translate(2581.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(3637.6,0)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(4319.8,0)"><path data-c="22C5" d="M78 250Q78 274 95 292T138 310Q162 310 180 294T199 251Q199 226 182 208T139 190T96 207T78 250Z"></path></g><g data-mml-node="mi" transform="translate(4820,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g></g></svg></mjx-container></span></p><p><img src="https://img-blog.csdnimg.cn/9d4d3104ba0d4c82adb6662d74ef7234.jpeg"></p><p><strong>Third: Scale+Softmax</strong></p><p>将刚得到的相似度除以<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: 0;" xmlns="http://www.w3.org/2000/svg" width="0.036ex" height="0.036ex" role="img" focusable="false" viewBox="0 0 16 16"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"></g></g></svg></mjx-container>，再进行Softmax。经过Softmax的归一化后，每个值都是一个大于0且小于1的权重系数，且总和为1，这个结果可以被理解成一个权重矩阵。</p><p><img src="https://img-blog.csdnimg.cn/61cdd0e854ac45ef9314b962dc266e83.jpeg"></p><p><strong>Fourth：Matmul</strong></p><p>使用刚得到的权重矩阵，与V相乘，计算加权求和。</p><p><img src="https://img-blog.csdnimg.cn/9c6b21bb37334c8bbf1c6ee89d4b5ef9.jpeg"></p><p>以上是对ThinkingMachines这句话进行自注意力的全过程，最终得到z1和z2两个新向量。</p><p>其中z1表示的是thinking这个词向量的新的向量表示（通过thinking这个词向量，去查询和thinkingmachine这句话里面每个单词和thinking之间的相似度）。</p><p>也就是说新的z1依然是 thinking的词向量表示，只不过这个词向量的表示蕴含了 thinking machines 这句话对于thinking 而言哪个更重要的信息。</p><hr><h3 id="自注意力机制的问题">2.3 自注意力机制的问题</h3><p>自注意力机制的原理是筛选重要信息，过滤不重要信息，这就导致其有效信息的抓取能力会比CNN小一点。这是因为自注意力机制相比CNN，无法利用图像本身具有的尺度、平移不变形，以及图像的特征局部性这些先验知识，只能通过大量数据进行学习。<strong>这就导致自注意力机制只能在大数据的基础上才能有效地建立准确的全局关系，而在小数据的情况下，其效果不如CNN。</strong></p><hr><h2 id="三多头注意力机制multi-head-self-attention">三、多头注意力机制：Multi-HeadSelf-Attention</h2><h3 id="为什么用多头注意力机制">3.1为什么用多头注意力机制</h3><p>自注意力机制的缺陷：模型对当前未知的信息进行编码时，会过度将注意力集中于自身的位置，有效信息抓取能力会差一点，会有才有了多头注意力机制。</p><p>在实践中，当给定相同的查询、键和值的集合时，我们希望模型可以基于相同的注意力机制学习到不同的行为，然后将不同的行为作为知识组合起来，补货序列内各种范围的依赖关系（例如：短距离依赖和长距离依赖关系）。因此，<strong>允许注意力机制组合使用查询、键、值的不同子空间表示（representationsubspaces）可能是有益的。</strong></p><p>为此，与其使用单独一个注意力汇聚，我们可以用<strong>独立学习到的h组（一般h=8）不同的线性投影（linearprojections）</strong>来变换查询、键和值。然后，<strong>这h组变换后的查询、键和值将并行地送到注意力汇聚中。最后，将这h个注意力汇聚的输出拼接到一起，并通过另一个可学习的线性投影进行变换，以生成最终输出。</strong>这种设计被称为<font color="red"><strong>多头注意力（multi-headattention）。</strong></font></p><p><img src="https://img-blog.csdnimg.cn/75d93a626a7844a5aac1df5ff9ad4142.png" alt="f" style="zoom:50%;"></p><hr><h3 id="如何运用多头注意力机制">3.2如何运用多头注意力机制</h3><p><strong>First：定义多组W，生成多组Q,K,V</strong></p><p><img src="https://img-blog.csdnimg.cn/6e9d6d0b7a2d4f0c9121d26dedf01b5d.jpeg"></p><p><strong>Second：定义8组参数</strong></p><p>对应8个single head，对应8组<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="12.408ex" height="2.37ex" role="img" focusable="false" viewBox="0 -853.7 5484.6 1047.7"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(1511.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(1956.1,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mi" transform="translate(1136.2,363) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mo" transform="translate(3510.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msup" transform="translate(3955.4,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g></g></g></g></svg></mjx-container></span>,再分别进行self-attention，就得到了Z0-Z7</p><p><img src="https://img-blog.csdnimg.cn/238fda6a68af4151b9cdde8224b4612a.jpeg"></p><p><strong>Third：将多组输出拼接后乘以矩阵W0以降维</strong></p><p>首先在输出到下一层前，我们需要将Z0-Z7concat到一起，乘以矩阵W0做一次线性变换进行降维</p><p><img src="https://img-blog.csdnimg.cn/3d14d6a9722848a186bd336d01524ff3.jpeg"></p><p>完整流程如下：</p><p><img src="https://img-blog.csdnimg.cn/b2ac3cd2adb4403fb1e6c4d8bfe2f780.png"></p><p>【注意】对于上图中的第2）步，当前为第一层时，直接对输入词进行编码，生成词向量X；当前为后续层时，直接使用上一层输出。</p><hr><h3 id="代码实现多头注意力机制">3.3代码实现多头注意力机制</h3><p>在实现过程中，我们选择了缩放的“点－积”注意力作为每一个注意力头。为了避免计算成本和参数数量的显著增长，我们设置了<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="19.91ex" height="2.347ex" role="img" focusable="false" viewBox="0 -750 8800.2 1037.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mo" transform="translate(1189,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2244.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mo" transform="translate(3477,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(4532.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g><g data-mml-node="mo" transform="translate(5739.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(6795.3,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(7724.2,0)"><g data-mml-node="mo"><path data-c="2F" d="M423 750Q432 750 438 744T444 730Q444 725 271 248T92 -240Q85 -250 75 -250Q68 -250 62 -245T56 -231Q56 -221 230 257T407 740Q411 750 423 750Z"></path></g></g><g data-mml-node="mi" transform="translate(8224.2,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g></g></g></svg></mjx-container></span>。值得注意的是，如果我们将查询、键和值的线性变换的输出数量设置为<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.65ex;" xmlns="http://www.w3.org/2000/svg" width="21.385ex" height="2.22ex" role="img" focusable="false" viewBox="0 -694 9452.2 981.2"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45E" d="M33 157Q33 258 109 349T280 441Q340 441 372 389Q373 390 377 395T388 406T404 418Q438 442 450 442Q454 442 457 439T460 434Q460 425 391 149Q320 -135 320 -139Q320 -147 365 -148H390Q396 -156 396 -157T393 -175Q389 -188 383 -194H370Q339 -192 262 -192Q234 -192 211 -192T174 -192T157 -193Q143 -193 143 -185Q143 -182 145 -170Q149 -154 152 -151T172 -148Q220 -148 230 -141Q238 -136 258 -53T279 32Q279 33 272 29Q224 -10 172 -10Q117 -10 75 30T33 157ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g></g><g data-mml-node="mi" transform="translate(911.3,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(1765,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(2820.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z"></path></g></g><g data-mml-node="mi" transform="translate(3775.2,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(4629,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(5684.8,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D463" d="M173 380Q173 405 154 405Q130 405 104 376T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Q21 294 29 316T53 368T97 419T160 441Q202 441 225 417T249 361Q249 344 246 335Q246 329 231 291T200 202T182 113Q182 86 187 69Q200 26 250 26Q287 26 319 60T369 139T398 222T409 277Q409 300 401 317T383 343T365 361T357 383Q357 405 376 424T417 443Q436 443 451 425T467 367Q467 340 455 284T418 159T347 40T241 -11Q177 -11 139 22Q102 54 102 117Q102 148 110 181T151 298Q173 362 173 380Z"></path></g></g><g data-mml-node="mi" transform="translate(6613.7,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(7467.5,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="msub" transform="translate(8523.3,0)"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></g></svg></mjx-container></span>，则可以并行计算h 头。在下面的实现中，<span class="math inline"><mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="2.102ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 928.9 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(536,-150) scale(0.707)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g></g></g></g></svg></mjx-container></span>是通过参数num_hiddens 指定的。</p><pre class="python3"><code>import mathimport torchfrom torch import nnfrom d2l import torch as d2ldef transpose_qkv(X,num_heads):    # 输入 `X` 的形状: (`batch_size`, 查询或者“键－值”对的个数, `num_hiddens`).    # 输出 `X` 的形状: (`batch_size`, 查询或者“键－值”对的个数, `num_heads`,`num_hiddens` / `num_heads`)    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)    # 输出 `X` 的形状: (`batch_size`, `num_heads`, 查询或者“键－值”对的个数,`num_hiddens` / `num_heads`)    X = X.permute(0, 2, 1, 3)    # `output` 的形状: (`batch_size` * `num_heads`, 查询或者“键－值”对的个数,`num_hiddens` / `num_heads`)    return X.reshape(-1, X.shape[2], X.shape[3])def transpose_output(X,num_heads):    """逆转 `transpose_qkv` 函数的操作"""    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])    X = X.permute(0, 2, 1, 3)    return X.reshape(X.shape[0], X.shape[1], -1)class MultiHeadAttention(nn.Module):    def __init__(self,key_size,query_size,value_size,num_hiddens,                num_heads,dropout,bias=False,**kwargs):        super(MultiHeadAttention,self).__init__(**kwargs)        self.num_heads = num_heads        self.attention = d2l.DotProductAttention(dropout)        self.W_q = nn.Linear(query_size,num_hiddens,bias=bias) # 将输入映射为（batch_size,query_size/k-v size,num_hidden）大小的输出        self.W_k = nn.Linear(key_size,num_hiddens,bias=bias)        self.W_v = nn.Linear(value_size,num_hiddens,bias=bias)        self.W_o = nn.Linear(num_hiddens,num_hiddens,bias=bias)        def forward(self,queries,keys,values,valid_lens):        # `queries`, `keys`, or `values` 的形状:            # (`batch_size`, 查询或者“键－值”对的个数, `num_hiddens`)        # `valid_lens`　的形状:            # (`batch_size`,) or (`batch_size`, 查询的个数)        # 经过变换后，输出的 `queries`, `keys`, or `values`　的形状:            # (`batch_size` * `num_heads`, 查询或者“键－值”对的个数,`num_hiddens` / `num_heads`)        queries = transpose_qkv(self.W_q(queries), self.num_heads)         keys = transpose_qkv(self.W_k(keys), self.num_heads)        values = transpose_qkv(self.W_v(values), self.num_heads) # 将多个头的数据堆叠在一起，然后进行计算，从而不用多次计算        if valid_lens is not None:            valid_lens = torch.repeat_interleave(valid_lens,                                                repeats=self.num_heads,                                                dim=0)        output = self.attention(queries,keys,values,valid_lens) # output-&gt;(10,4,20)#         return output        output_concat = transpose_output(output,self.num_heads) # output_concat -&gt; (2,4,100)        return self.W_o(output_concat)</code></pre><p>让我们使用键和值相同的小栗子来测试我们编写的<code>MultiHeadAttention</code>类。多头注意力输出的形状是（batch_size、num_queries、num_hiddens）。</p><pre class="python3"><code># 线性变换的输出为100个，5个头num_hiddens, num_heads = 100, 5attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens,num_hiddens, num_heads, 0.5)attention.eval()</code></pre><pre class="pyt"><code>MultiHeadAttention(  (attention): DotProductAttention(    (dropout): Dropout(p=0.5, inplace=False)  )  (W_q): Linear(in_features=100, out_features=100, bias=False)  (W_k): Linear(in_features=100, out_features=100, bias=False)  (W_v): Linear(in_features=100, out_features=100, bias=False)  (W_o): Linear(in_features=100, out_features=100, bias=False))</code></pre><div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>batch_size, num_queries, num_kvpairs, valid_lens <span class="op">=</span> <span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, torch.tensor([<span class="dv">3</span>, <span class="dv">2</span>])</span><span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> torch.ones((batch_size, num_queries, num_hiddens)) <span class="co"># query（2，4，100）</span></span><span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>Y <span class="op">=</span> torch.ones((batch_size, num_kvpairs, num_hiddens)) <span class="co"># key和value （2，6，100）</span></span><span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> attention(X, Y, Y, valid_lens) <span class="co"># 输出大小与输入的query的大小相同</span></span><span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>output.shape</span></code></pre></div><pre class="pytho"><code>torch.Size([2, 4, 100])</code></pre>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -Attention </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>BEVFormer</title>
      <link href="/2023/11/07/BEVFormer/"/>
      <url>/2023/11/07/BEVFormer/</url>
      
        <content type="html"><![CDATA[<p>BEVFormer是一个一个采用纯视觉做感知任务的算法模型，其通过提取环视相机采集到的图像特征，并将提取的环视特征通过模型学习的方式转换到BEV空间（模型去学习如何将特征从图像坐标系转化到BEV坐标系），从而实现3D目标检测和地图分割任务。</p><hr><p><strong>BEVFormer的Pipline</strong></p><p>BEVFormer的pipline分为下面几个部分：</p><ul><li>Backbone + Neck （ResNet-101-DCN+FPN）提取环视图像的多尺度特征；</li><li>Encoder模块（包括Temporal Self-Attention模块和SpatialCross-Attion模块）完成环视图像特征向BEV特征的建模；</li><li>Decoder模块完成3D目标检测的分类和定位任务；</li><li>正负样本的定义（采用Transformer 中常用的匈牙利匹配算法，Foacal Loss+ L1 loss的总损失最小）；</li><li>损失的计算（Focal Loss分类损失 + L1 Loss回归损失）；</li><li>反向传播，更新网络模型参数</li></ul><hr><p><strong>输入数据格式</strong></p><p>BEVFormer网络模型的输入是一个6维的张量：</p><p>（bs，queue，cam，C，H，W）</p><ul><li>bs：batch size大小；</li><li>queue：连续帧的个数；由于BEVFormer采用了时序信息的思想，可以从一定程度上缓解遮挡问题，所以输入到网络模型中的数据包含当前帧及之前几帧数据；</li><li>cam：每帧中包含的图像数量，对于nuScenes数据集而言，由于一辆车带有6个环视相机传感器，可以实现360°全场景的覆盖，所以一帧会包含6个环视相机拍摄到的6张环视图片；</li><li>C,H,W:图片的通道数、高度及宽度。</li></ul><p><img src="https://pic4.zhimg.com/80/v2-b2c6629cfc100aea30b58f676af2992f_720w.webp"></p><p>网络特征提取的目的是将每一帧对应的六张环视图像的特征提取出来，便于后续转换到BEV 特征空间，生成 BEV特征，在特征提取过程中，张量流的变换情况如下：</p><pre class="python3"><code># 输入图片信息 tensor: (bs, queue, cam, c, h, w)# 通过 for loop 方式一次获取单帧对应的六张环视图像# 送入到 Backbone + Neck 网络提取多尺度的图像特征for idx in range(tensor.size(1) - 1):  # 利用除当前帧之外的所有帧迭代计算 `prev_bev` 特征    single_frame = tensor[:, idx, :]   # (bs, cam, c, h, w)    # 将 bs * cam 看作是 batch size，将原张量 reshape 成 4 维的张量    # 待 Backbone + Neck 网络提取多尺度特征后，再把 bs * cam 的维度再拆成 bs，cam    single_frame = single_frame.reshape(bs * cam, c, h, w)    feats = Backbone(FPN(single_frame))     """ feats 是一个多尺度的特征列表 """    [0]: (bs, cam, 256, h / 8, w / 8)    [1]: (bs, cam, 256, h / 16, w / 16)    [2]: (bs, cam, 256, h / 32, w / 32)    [3]: (bs, cam, 256, h / 64, w / 64)</code></pre><hr><p><strong>Encoder模块</strong></p><p>Encoder模块是为了生成BEV特征，其网络结构如下：</p><p><img src="https://pic2.zhimg.com/v2-65a11a98d73c1111bcc05e1f10848195_r.jpg"></p><p>Encoder模块包含了两个子模块：Temporal Self-Attention模块和SpatialCross-Attention模块。</p><p>这两个模块都用到了一个组件------多尺度的可变性注意力模块，该模块是将Transformer的全局注意力变为局部注意力的一个非常关键的组件，用来减少训练时间，提高Transformer的收敛速度。</p><p>多尺度可变形注意力模块与Transformer中常见的先生成AttentionMap，再计算加权和的方式不同；常规而言Attention Map = Query和Key做内积运算，将AttentionMap再和Value做加权；但是由于这种方式计算量开销会比较大，所以在DeformableDETR中用局部注意力机制代替了全局注意力机制，只对几个采样点进行采样，<strong>而采样点的位置对于参考点的偏移量和每个采样点在加权时的比重均是靠Query经过Linear层学习得到的。</strong></p><p><strong>Temporal Self-Attention模块</strong></p><p><strong>功能：</strong>通过引入时序信息（History BEV）与当前时刻的BEVQuery进行融合，提高BEV Query的建模能力。</p><p><img src="/home/haseka/Pictures/Spatial-Att.png"></p><p>对于TemporalSelf-Attention模块而言，需要bev_query、bev_pos、prev_bev、ref_point、value等参数。</p><ul><li><p><strong>bev_query：</strong>一个完全<strong>learnableparameter</strong>，通过nn.Embedding()函数得到，形状shape =（200*200，256）；200，200分别代表BEV特征平面的长和宽；</p><ul><li>History BEV <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.471ex;" xmlns="http://www.w3.org/2000/svg" width="4.527ex" height="2.016ex" role="img" focusable="false" viewBox="0 -683 2000.9 891"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g><g data-mml-node="mo" transform="translate(361,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(1139,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g></g></g></g></g></svg></mjx-container> 与当前BEV Queries <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="2.483ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1097.3 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path></g></g></g></g></g></svg></mjx-container>会首先进行Self-Attention，前者为后者BEV Queries提供先验，提前优化了该BEVQueries，方便之后与图像空间上的多尺度特征进行Cross-Attention，这样既融合了时序特征又融合了空间特征，并最终生产BEV特征。</li></ul></li><li><p><strong>bev_pose：</strong>一个完全<strong>learnableparameter</strong>，与2D检测中常见的正余弦编码方式不同，是把不同的grid位置映射到一个高维的向量空间，shape=（bs，256，200，200），代码如下：</p><pre class="python3"><code>""" bev_pose 的生成过程 """# w, h 分别代表 bev 特征的空间尺寸 200 * 200x = torch.arange(w, device=mask.device)y = torch.arange(h, device=mask.device)# self.col_embed 和 self.row_embed 分别是两个 Linear 层，将(200, )的坐标向高维空间做映射x_embed = self.col_embed(x)  # (200, 128)y_embed = self.row_embed(y)  # (200, 128)# pos shape: (bs, 256, 200, 200)pos = torch.cat((x_embed.unsqueeze(0).repeat(h, 1, 1), y_embed.unsqueeze(1).repeat(1, w, 1)), dim=-1).permute(2, 0, 1).unsqueeze(0).repeat(mask.shape[0], 1, 1, 1)</code></pre></li><li><p><strong>ref_point：</strong>该参数根据当前TemporalSelf-Attention模块是否有pre_bev特征输入而言，会对应不同的情况，之所以会出现不同，是考虑到了前后时刻BEV特征存在不对齐的问题，BEV特征不对齐主要表现在以下两个方面：</p><ul><li><p>车自身是不断运动的</p><p>上一刻和当前时刻，由于车身的不断运动，两个时刻的BEV特征在空间上是不对齐的；针对这一问题，为了实现两个特征的空间对齐，需要用到can_bus数据中有关车身自身旋转角度和偏移的信息，从而对上一时刻的BEV特征与当前时刻的BEV特征在空间上实现特征对齐；</p></li><li><p>车周围的物体也在一定范围内运动</p><p>针对车周围的物体可能在不同时刻也有移动，这部分的特征对齐就是靠网络自身的注意力模块去学习实现修正了。</p></li></ul><p>综上，对于TemporalSelf-Attention模块没有输入pre_bev（第一帧没有前一时刻的BEV特征）的情况，其<code>ref_point = ref_2d</code>；对于存在输入pre_bev的情况，其<code>ref_point = ref_2d +shift</code>;</p><p>涉及到的<code>ref_2d</code>、<code>shift</code>参数，核心代码如下：</p><pre class="text"><code>"""shift 参数的生成""" # obtain rotation angle and shift with ego motion delta_x = kwargs['img_metas'][0]['can_bus'][0] delta_y = kwargs['img_metas'][0]['can_bus'][1] ego_angle = kwargs['img_metas'][0]['can_bus'][-2] / np.pi * 180 rotation_angle = kwargs['img_metas'][0]['can_bus'][-1] grid_length_y = grid_length[0] grid_length_x = grid_length[1] translation_length = np.sqrt(delta_x ** 2 + delta_y ** 2) translation_angle = np.arctan2(delta_y, delta_x) / np.pi * 180 if translation_angle &lt; 0:     translation_angle += 360 bev_angle = ego_angle - translation_angle shift_y = translation_length * \     np.cos(bev_angle / 180 * np.pi) / grid_length_y / bev_h shift_x = translation_length * \     np.sin(bev_angle / 180 * np.pi) / grid_length_x / bev_w shift_y = shift_y * self.use_shift shift_x = shift_x * self.use_shift shift = bev_queries.new_tensor([shift_x, shift_y])  # shape (2,) # 通过`旋转`和`平移`变换实现 BEV 特征的对齐，对于平移部分是通过对参考点加上偏移量`shift`体现的if prev_bev is not None:    if prev_bev.shape[1] == bev_h * bev_w:        prev_bev = prev_bev.permute(1, 0, 2)    if self.rotate_prev_bev:        num_prev_bev = prev_bev.size(1)        prev_bev = prev_bev.reshape(bev_h, bev_w, -1).permute(2, 0, 1)  # sequence -&gt; grid        prev_bev = rotate(prev_bev, rotation_angle, center=self.rotate_center)        prev_bev = prev_bev.permute(1, 2, 0).reshape(bev_h * bev_w, num_prev_bev, -1)"""ref_2d 参数的生成，常规的 2D 网格生成的规则坐标点"""ref_y, ref_x = torch.meshgrid(torch.linspace(0.5, H - 0.5, H, dtype=dtype, device=device),                              torch.linspace(0.5, W - 0.5, W, dtype=dtype, device=device))ref_y = ref_y.reshape(-1)[None] / Href_x = ref_x.reshape(-1)[None] / Wref_2d = torch.stack((ref_x, ref_y), -1)ref_2d = ref_2d.repeat(bs, 1, 1).unsqueeze(2)</code></pre></li><li><p><strong>value:</strong>该参数就是对应着bev_query去查询的特征；</p><p>对于 Temporal Self-Attention 模块输入包含<code>prev_bev</code>时，<code>value = [prev_bev，bev_query]</code>，对应的参考点<code>ref_point = [ref_2d + shift，ref_2d]</code>；如果输入不包含<code>prev_bev</code>时，<code>value =  [bev_query，bev_query]</code>，对应的参考点<code>ref_point = [ref_2d，ref_2d]</code>。</p><p>内部参数：Offset、weights、Sample Location。</p><p>参数<code>Offset</code>的计算是同时考虑了<code>value[0]</code>和<code>bev_query</code>的信息，在映射空间的维度上进行了concat，并基于concat 后的特征，去计算<code>Offset</code>以及<code>attention weights</code>，涉及到的核心代码如下：</p><pre class="python3"><code>""" bev_query 按照通道维度进行 concat """query = torch.cat([value[0:1], query], -1)  # (bs, 40000, 512)""" value 经过 Linear 做映射 """value = self.value_proj(value)""" offsets 以及 attention weights 的生成过程 """# sampling_offsets: shape = (bs, num_query, 8, 1, 4, 2)# 对 query 进行维度映射得到采样点的偏移量sampling_offsets = self.sampling_offsets(query).view(bs, num_query, self.num_heads, self.num_levels, self.num_points, 2)# 对 query 进行维度映射得到注意力权重attention_weights = self.attention_weights(query).view(bs, num_query, self.num_heads, self.num_levels * self.num_points)  attention_weights = attention_weights.softmax(-1)# attention_weights: shape = (bs, num_query, 8, 1, 4)attention_weights = attention_weights.view(bs, num_query, self.num_heads, self.num_levels, self.num_points) """ sample location 的生成过程 通过代码可以观察到两点：1. 通过 query 学到的 sampling_offsets 偏移量是一个绝对量，不是相对量，所以需要做 normalize；2. 最终生成的 sampling_locations 是一个相对量；"""offset_normalizer = torch.stack([spatial_shapes[..., 1], spatial_shapes[..., 0]], -1)sampling_locations = reference_points[:, :, None, :, None, :] \                + sampling_offsets / offset_normalizer[None, None, None, :, None, :] </code></pre></li><li><p>输出bev_query</p><p>至此，Temporal Self-Attention 模块的逻辑到此结束，将生成的 bev_query送入到后面的 Spatial Cross-Attention 模块中。</p><pre class="python3"><code>""" 各个参数的 shape 情况 1. value: (2，40000，8，32） # 2: 代表前一时刻的 BEV 特征和后一时刻的 BEV 特征，两个特征在计算的过程中是互不干扰的，                             # 40000: 代表 bev_query 200 * 200 空间大小的每个位置                             # 8: 代表8个头，# 32: 每个头表示为 32 维的特征2. spatial_shapes: (200, 200) # 方便将归一化的 sampling_locations 反归一化3. level_start_index: 0 # BEV 特征只有一层4. sampling_locations: (2, 40000, 8, 1, 4, 2)5. attention_weights: (2, 40000, 8, 1, 4)6. output: (2, 40000, 8, 32)"""output = MultiScaleDeformableAttnFunction.apply(value,                                                 spatial_shapes,                                                 level_start_index,                                                 sampling_locations,                                                attention_weights,                                                 self.im2col_step)""" 最后将前一时刻的 bev_query 与当前时刻的 bev_query 做平均output = output.permute(1, 2, 0)output = (output[..., :bs] + output[..., bs:])/self.num_bev_queue</code></pre></li></ul><p><strong>Spatial Cross-Attention模块</strong></p><ul><li><p>功能</p><p>利用TemporalSelf-Attention模块输出的<code>bev_query</code>，对主干网和Neck网络提取到的多尺度环视图像特征进行查询，生成BEV空间下的BEVEmbedding特征；</p></li><li><p>代码实现</p><p>对于Spatial Cross-Attention模块而言，与TemporalSelf-Attention模块需要的参数很类似，但是不需要bev_pos参数，只需要bev_query、ref_point、value（就是concat到一起的多尺度特征），不需要bev_pose；</p></li><li><p>参数bev_query</p><p>bev_query参数来自于Temporal Self-Attention模块的输出</p></li><li><p>参数value</p><p>对于Transformer而言，由于其本身是处理文本序列的模型，而文本序列都是一组组一维的数据，所以将前面提取到的多尺度特征做flatten()处理，将所有层的特征汇聚到一起，方便之后做查询，相应代码如下：</p><pre class="python3"><code>""" 首先将多尺度的特征每一层都进行 flatten() """for lvl, feat in enumerate(mlvl_feats):    bs, num_cam, c, h, w = feat.shape    spatial_shape = (h, w)    feat = feat.flatten(3).permute(1, 0, 3, 2)      if self.use_cams_embeds:        feat = feat + self.cams_embeds[:, None, None, :].to(feat.dtype)        feat = feat + self.level_embeds[None, None, lvl:lvl + 1, :].to(feat.dtype)        spatial_shapes.append(spatial_shape)        feat_flatten.append(feat)""" 对每个 camera 的所有层级特征进行汇聚 """feat_flatten = torch.cat(feat_flatten, 2)  # (cam, bs, sum(h*w), 256)spatial_shapes = torch.as_tensor(spatial_shapes, dtype=torch.long, device=bev_pos.device)# 计算每层特征的起始索引位置level_start_index = torch.cat((spatial_shapes.new_zeros((1,)), spatial_shapes.prod(1).cumsum(0)[:-1]))# 维度变换feat_flatten = feat_flatten.permute(0, 2, 1, 3)  # (num_cam, sum(H*W), bs, embed_dims)</code></pre></li><li><p>ref_point</p><p>ref_3d是基于BEV空间产生的三维空间规则网格点，同时在z轴方向上人为的选择了4个坐标点。这里使用z轴，并在z轴上采样的物体意义可能是为了提取每个BEV位置处不同高度的特征，为了更好的获取在BEV空间下的（x,y）处的特征，将（x,y）的坐标进行lift，从而将BEV坐标系下的三维点映射回图像平面后可以去查询并融合更加准确的特征。</p><p>而在映射过程中，由于每个参考点映射回图像坐标系后，不会落到6个图像上，只可能落在其中的某些图像的某些位置上，所以只对这些参考点附近的位置进行采样，可以提高模型的收敛速度。</p><p><img src="https://pic1.zhimg.com/80/v2-503ed0236461349bf35fef572f4dc70c_720w.webp"></p><p>ref_3d参数生成、3D坐标向图像平面转换等过程的核心代码如下，真正用在SpatialCross-Attention模块的参考点事下面代码中的reference_points_cam：</p><pre class="text"><code>""" ref_3d 坐标生成 """zs = torch.linspace(0.5, Z - 0.5, num_points_in_pillar, dtype=dtype, device=device).view(-1, 1, 1).expand(num_points_in_pillar, H, W) / Zxs = torch.linspace(0.5, W - 0.5, W, dtype=dtype, device=device).view(1, 1, W).expand(num_points_in_pillar, H, W) / Wys = torch.linspace(0.5, H - 0.5, H, dtype=dtype, device=device).view(1, H, 1).expand(num_points_in_pillar, H, W) / Href_3d = torch.stack((xs, ys, zs), -1)  # (4, 200, 200, 3)  (level, bev_h, bev_w, 3) 3代表 x,y,z 坐标值ref_3d = ref_3d.permute(0, 3, 1, 2).flatten(2).permute(0, 2, 1)  # (4, 200 * 200, 3)ref_3d = ref_3d[None].repeat(bs, 1, 1, 1)  # (1, 4, 200 * 200, 3)""" BEV 空间下的三维坐标点向图像空间转换的过程代码中的`lidar2img`需要有两点需要注意1. BEV 坐标系 这里指 lidar 坐标系2. 这里提到的`lidar2img`是经过坐标变换的，一般分成三步   第一步：lidar 坐标系 -&gt; ego vehicle 坐标系   第二步：ego vehicle 坐标系 -&gt; camera 坐标系   第三部：camera 坐标系 通过相机内参 得到像素坐标系   以上这三步用到的所有平移和旋转矩阵都合并到了一起，形成了 `lidar2img` 旋转平移矩阵同时需要注意：再与`lidar2img`矩阵乘完，还需要经过下面两步坐标系转换，才是得到了三维坐标点在二维图像平面上的点"""# (level, bs, cam, num_query, 4)坐标系转换第一步：reference_points_cam = torch.matmul(lidar2img.to(torch.float32), reference_points.to(torch.float32)).squeeze(-1)  eps = 1e-5bev_mask = (reference_points_cam[..., 2:3] &gt; eps)  # (level, bs, cam, num_query, 1)坐标系转换第二步：reference_points_cam = reference_points_cam[..., 0:2] / torch.maximum(reference_points_cam[..., 2:3], torch.ones_like(reference_points_cam[..., 2:3]) * eps)# reference_points_cam = (bs, cam = 6, 40000, level = 4, xy = 2)reference_points_cam[..., 0] /= img_metas[0]['img_shape'][0][1]  # 坐标归一化reference_points_cam[..., 1] /= img_metas[0]['img_shape'][0][0]  # 坐标归一化# bev_mask 用于评判某一 三维坐标点 是否落在了 二维坐标平面上# bev_mask = (bs, cam = 6, 40000, level = 4)bev_mask = (bev_mask &amp; (reference_points_cam[..., 1:2] &gt; 0.0)                     &amp; (reference_points_cam[..., 1:2] &lt; 1.0)                     &amp; (reference_points_cam[..., 0:1] &lt; 1.0)                     &amp; (reference_points_cam[..., 0:1] &gt; 0.0))</code></pre><p><strong>注意：</strong>上述得到的bev_query和reference_points_cam并不是直接用在SpatialCross-Attention模块中，而是选择有用部分进行使用（减少模型的计算量，提高训练过程的收敛速度）</p><p>之前也有提到，并不是 BEV坐标系下的每个三维坐标都会映射到环视相机的所有图像上，而只会映射到其中的某几张图片上，所以使用所有来自Temporal Self-Attention模块的所有<code>bev_query</code>会消耗很大的计算量，所以这里是对<code>bev_query</code>进行了重新的整合，涉及的核心代码如下：</p><pre class="python3"><code>indexes = []# 根据每张图片对应的`bev_mask`结果，获取有效query的indexfor i, mask_per_img in enumerate(bev_mask):    index_query_per_img = mask_per_img[0].sum(-1).nonzero().squeeze(-1)    indexes.append(index_query_per_img)queries_rebatch = query.new_zeros([bs * self.num_cams, max_len, self.embed_dims])reference_points_rebatch = reference_points_cam.new_zeros([bs * self.num_cams, max_len, D, 2]) for i, reference_points_per_img in enumerate(reference_points_cam):    for j in range(bs):        index_query_per_img = indexes[i]        # 重新整合 `bev_query` 特征，记作 `query_rebatch        queries_rebatch[j * self.num_cams + i, :len(index_query_per_img)] = query[j, index_query_per_img]        # 重新整合 `reference_point`采样位置，记作`reference_points_rebatch`        reference_points_rebatch[j * self.num_cams + i, :len(index_query_per_img)] = reference_points_per_img[j, index_query_per_img]</code></pre><p>与产生query_rebatch原因相同，获取映射到二维图像后的有效位置，对原有的reference_points进行重新整合reference_points_rebatch。</p><pre class="python3"><code>""" 获取 sampling_offsets，依旧是对 query 做 Linear 做维度的映射，但是需要注意的是这里的 query 指代的是上面提到的 `quries_rebatch` """ # sample 8 points for single ref point in each level.# sampling_offsets: shape = (bs, max_len, 8, 4, 8, 2)sampling_offsets = self.sampling_offsets(query).view(bs, num_query, self.num_heads, self.num_levels, self.num_points, 2)attention_weights = self.attention_weights(query).view(bs, num_query, self.num_heads, self.num_levels * self.num_points)attention_weights = attention_weights.softmax(-1)# attention_weights: shape = (bs, max_len, 8, 4, 8)attention_weights = attention_weights.view(bs, num_query,                                           self.num_heads,                                           self.num_levels,                                           self.num_points)""" 生成 sampling location """offset_normalizer = torch.stack([spatial_shapes[..., 1], spatial_shapes[..., 0]], -1)reference_points = reference_points[:, :, None, None, None, :, :]sampling_offsets = sampling_offsets / offset_normalizer[None, None, None, :, None, :]sampling_locations = reference_points + sampling_offsets</code></pre></li><li><p>输出bev_embedding</p><p>将上述处理好的参数，送入多尺度可变形注意力模块中生成bev_embedding特征：</p><pre class="python3"><code>"""1. value: shape = (cam = 6, sum(h_i * w_i) = 30825, head = 8, dim = 32)2. spatial_shapes = ([[116, 200], [58, 100], [29,  50], [15,  25]])3. level_start_index= [0, 23200, 29000, 30450]4. sampling_locations = (cam, max_len, 8, 4, 8, 2)5. attention_weights = (cam, max_len, 8, 4, 8)6. output = (cam, max_len, 8, 32)"""output = MultiScaleDeformableAttnFunction.apply(value, spatial_shapes, level_start_index, sampling_locations,                attention_weights, self.im2col_step)"""最后再将六个环视相机查询到的特征整合到一起，再求一个平均值 """for i, index_query_per_img in enumerate(indexes):    for j in range(bs):  # slots: (bs, 40000, 256)        slots[j, index_query_per_img] += queries[j * self.num_cams + i, :len(index_query_per_img)]count = bev_mask.sum(-1) &gt; 0count = count.permute(1, 2, 0).sum(-1)count = torch.clamp(count, min=1.0)slots = slots / count[..., None]  # maybe normalize.slots = self.output_proj(slots)</code></pre><p>以上就是 Spatial Cross-Attention 模块的整体逻辑。</p><p>将 Temporal Self-Attetion 模块和 Spatial Cross-Attention模块堆叠在一起，并重复六次，最终得到的 <code>BEV Embedding</code>特征作为下游 3D 目标检测和道路分割任务的 BEV 空间特征。</p></li></ul><hr><p>Decoder模块</p><p>上述产生BEV特征的过程是用了当前输入到网络模型中除当前帧外，之前所有帧特征去迭代修正去获得pre_bev的特征；所以在利用decoder模块进行解码之前，需要对当前时刻环视的6张图片同样利用Backbone+Neck提取多尺度特征，再利用上述的Temporal Self-Attention 模块和 Spatial Cross-Attention模块的逻辑生成当前时刻的<code>bev_embedding</code>，然后将这部分特征送入到Decoder 中进行 3D 目标检测。</p><p>如何获取预测框和分类得分</p><ul><li><p>query、query_pos</p><p>query和query_pos都是可学习的。模型直接用 nn.Embedding()生成一组（900，512）维的张量。然后将 512维的张量分成两组，分别构成了<code>query = (900，256)</code>和<code>query_pos = (900，256)</code>。</p></li><li><p>reference_points</p><p>对于多尺度可变形注意力模块需要参考点，但在预测过程中无参考点，这需要网络学习出来，网络靠query_pos学习到的，代码如下：</p><pre class="text"><code>reference_points = self.reference_points(query_pos)  # (bs, 900, 3)  3 代表 (x, y, z) 坐标reference_points = reference_points.sigmoid()  # absolute -&gt; relativeinit_reference_out = reference_points </code></pre></li><li><p>Decoder逻辑</p><p>在获取到需要用到的<code>query</code>、<code>query_pos</code>、<code>reference_points</code>参数后，后面的逻辑有些类似Deformabe DETR 的 Decoder 过程，简单概括如下几点：</p><p>利用<code>query</code>和<code>query_pos</code>去做常规的Self-Attention 运算更新<code>query</code>；</p><p>利用 Self-Attention 得到的 query，之前获得的<code>bev_embedding</code>作为value，<code>query_pos</code>，由query生成的<code>reference_points</code>（虽然生成的x，y，z参考点位置，但是BEV Embedding 是二维的，所以参考点只选择了前两维）仿照 DeformableAttention Module 的 pipeline 做可变形注意力；</p><p>可变形注意力核心代码如下：</p><pre class="text"><code>""" 由 query 生成 sampling_offsets 和 attention_weights """sampling_offsets = self.sampling_offsets(query).view(            bs, num_query, self.num_heads, self.num_levels, self.num_points, 2)  # (bs, 900, 8, 1, 4, 2)attention_weights = self.attention_weights(query).view(            bs, num_query, self.num_heads, self.num_levels * self.num_points)  # (bs, 900, 8, 4)attention_weights = attention_weights.softmax(-1)attention_weights = attention_weights.view(bs, num_query,                                                   self.num_heads,                                                   self.num_levels,                                                   self.num_points)  # (bs, 900, 8, 1, 4)""" sampling_offsets 和 reference_points 得到 sampling_locations """offset_normalizer = torch.stack(                [spatial_shapes[..., 1], spatial_shapes[..., 0]], -1)sampling_locations = reference_points[:, :, None, :, None, :] \                + sampling_offsets \                / offset_normalizer[None, None, None, :, None, :]""" 多尺度可变形注意力模块 """# value: shape = (bs, 40000, 8, 32)# spatial_shapes = (200, 200)# level_start_index = 0# sampling_locations = (bs, 900, 8, 1, 4, 2)# attention_weights = (bs, 900, 8, 1, 4)# output = (bs, 900, 256)output = MultiScaleDeformableAttnFunction.apply(value, spatial_shapes, level_start_index, sampling_locations,                attention_weights, self.im2col_step)</code></pre><p>在获得查询到的特征后，会利用回归分支（FFN网络）对提取的特征计算回归结果，预测 10 个输出；</p><p>我的理解这 10个维度的含义为：[xc，yc，w，l，zc，h，rot.sin()，rot.cos()，vx，vy]；[预测框中心位置的x方向偏移，预测框中心位置的y方向偏移，预测框的宽，预测框的长，预测框中心位置的z方向偏移，预测框的高，旋转角的正弦值，旋转角的余弦值，x方向速度，y方向速度]；</p><p>然后根据预测的偏移量，对参考点的位置进行更新，为级联的下一个 Decoder提高精修过的参考点位置，核心代码如下：</p><pre class="python3"><code>if reg_branches is not None:  # update the reference point.    tmp = reg_branches[lid](output)  # (bs, 900, 256) -&gt; (bs, 900, 10) 回归分支的预测输出    assert reference_points.shape[-1] == 3    new_reference_points = torch.zeros_like(reference_points)    # 预测出来的偏移量是绝对量    new_reference_points[..., :2] = tmp[..., :2] + inverse_sigmoid(reference_points[..., :2])  # 框中心处的 x, y 坐标    new_reference_points[..., 2:3] = tmp[..., 4:5] + inverse_sigmoid(reference_points[..., 2:3])  # 框中心处的 z 坐标    # 参考点坐标是一个归一化的坐标    new_reference_points = new_reference_points.sigmoid()    reference_points = new_reference_points.detach()""" 最后将每层 Decoder 产生的特征 = (bs, 900, 256)，以及参考点坐标 = (bs, 900, 3) 保存下来。"""if self.return_intermediate:    intermediate.append(output)    intermediate_reference_points.append(reference_points)</code></pre><p>然后将层级的 <code>bev_embedding</code>特征以及参考点通过 for loop的形式，一次计算每个 Decoder 层的分类和回归结果：</p><pre class="text"><code>bev_embed, hs, init_reference, inter_references = outputshs = hs.permute(0, 2, 1, 3)  # (decoder_level, bs, 900, 256)outputs_classes = []outputs_coords = []for lvl in range(hs.shape[0]):    if lvl == 0:        reference = init_reference    else:        reference = inter_references[lvl - 1]    reference = inverse_sigmoid(reference)    outputs_class = self.cls_branches[lvl](hs[lvl])  # (bs, 900, num_classes)    tmp = self.reg_branches[lvl](hs[lvl])  # (bs, 900, 10)    assert reference.shape[-1] == 3    tmp[..., 0:2] += reference[..., 0:2]  # (x, y)    tmp[..., 0:2] = tmp[..., 0:2].sigmoid()    tmp[..., 4:5] += reference[..., 2:3]    tmp[..., 4:5] = tmp[..., 4:5].sigmoid()    tmp[..., 0:1] = (tmp[..., 0:1] * (self.pc_range[3] - self.pc_range[0]) + self.pc_range[0])    tmp[..., 1:2] = (tmp[..., 1:2] * (self.pc_range[4] - self.pc_range[1]) + self.pc_range[1])    tmp[..., 4:5] = (tmp[..., 4:5] * (self.pc_range[5] - self.pc_range[2]) + self.pc_range[2])    outputs_coord = tmp    outputs_classes.append(outputs_class)    outputs_coords.append(outputs_coord) </code></pre></li></ul><hr><p><strong>正负样本的定义</strong></p><p>正负样本的定义用到的就是匈牙利匹配算法，分类损失和类似回归损失的总损失和最小；</p><p>分类损失的计算代码如下：</p><pre class="text"><code>cls_pred = cls_pred.sigmoid()  # calculate the neg_cost and pos_cost by focal loss.neg_cost = -(1 - cls_pred + self.eps).log() * (1 - self.alpha) * cls_pred.pow(self.gamma)pos_cost = -(cls_pred + self.eps).log() * self.alpha * (1 - cls_pred).pow(self.gamma)cls_cost = pos_cost[:, gt_labels] - neg_cost[:, gt_labels]cls_cost = cls_cost * self.weight</code></pre><p>类回归损失的计算代码如下：</p><p>这里介绍一下，gt_box 的表示方式，gt_box 的维度是九维的，分别是[xc，yc，zc，w，l，h，rot，vx，vy]；而预测结果框的维度是十维的，所以要对gt_box 的维度进行转换，转换为的维度表示为[xc，yc，w，l，cz，h，rot.sin()，rot.cos()，vx，vy]</p><p>对应代码如下：</p><pre class="text"><code>cx = bboxes[..., 0:1]cy = bboxes[..., 1:2]cz = bboxes[..., 2:3]w = bboxes[..., 3:4].log()l = bboxes[..., 4:5].log()h = bboxes[..., 5:6].log()rot = bboxes[..., 6:7]vx = bboxes[..., 7:8] vy = bboxes[..., 8:9]normalized_bboxes = torch.cat((cx, cy, w, l, cz, h, rot.sin(), rot.cos(), vx, vy), dim=-1)</code></pre><p>计算类回归损失（L1 Loss）</p><p>这里有一点需要注意的是，在正负样本定义中计算 L1 Loss的时候，只对前预测框和真值框的前 8 维计算损失</p><pre class="text"><code>self.reg_cost(bbox_pred[:, :8], normalized_gt_bboxes[:, :8])</code></pre>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -BEVFormer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>视觉BEV综述</title>
      <link href="/2023/11/06/%E8%A7%86%E8%A7%89BEV%E7%BB%BC%E8%BF%B0/"/>
      <url>/2023/11/06/%E8%A7%86%E8%A7%89BEV%E7%BB%BC%E8%BF%B0/</url>
      
        <content type="html"><![CDATA[<h1 id="感知bev综述">感知BEV综述</h1><h3 id="什么是bev">什么是BEV</h3><p>BEV的意思是鸟瞰图，也就是我们会将环视摄像机，激光雷达，甚至是毫米波雷达的数据，经过特征提取之后，统统通过视角变换，转换到鸟瞰图这种场景下，然后会在这些场景下，做一些多传感器数据融合就很方便了，之后我们就可以接各种任务头，做3D目标检测，车道线检测，语义分割，障碍物检测等等，都是可以的。</p><p>对于低成本的自动驾驶系统，以视觉为中心的BEV感知是一个长期的挑战，因为摄像头通常放置在自车上，与地面平行，面向外部。图像在与BEV正交的透视图（PV）中获取，并且两个视图之间的变换是不适定问题。最早工作[用单应矩阵以物理和数学方式将平坦地面从PV转换为BEV。多年来，这种方法一直占据主导地位，直到平地硬约束无法满足复杂真实场景的自主驾驶要求。随着计算机视觉中数据驱动方法的发展，近年来出现了许多基于深度学习的方法，通过求解PV-BEV变换来促进以视觉为中心的BEV感知。</p><h3 id="bev方法">BEV方法</h3><p>基于视图变换，当前BEV视觉感知工作可分为两大类：基于几何的变换和基于网络的变换。如图1所示：</p><p><imgsrc="https://pic1.zhimg.com/v2-1bccea29938448e33a091e958698199c_r.jpg" /></p><p>前者充分利用摄像头的物理原理以可解释的方式迁移视图。除了经典的基于homograph的方法外，通过显式或隐式深度估计将2-D特征提升到3-D空间是主要的解决方案。对于图像的每个像素，都存在一条来自摄影机的光线，该光线会遇到现实世界中的目标。不直接将像素映射到BEV，另一种方法是计算每个像素的深度分布，利用该分布将2D特征提升到3D，然后通过降维从3D获得BEV表示。</p><p>这些方法对深度采用不同的假设，例如精确值、射线上的均匀分布或射线上的类分布。深度监督来自于最终的显示深度值或任务监督。对于后者，其方法采用神经网络作为PV到BEV的视图投影。深度神经网络充当一个负责的映射函数，以不同的模式、维度、表示等将输入转换为输出。简单的想法是使用编码器-解码器（VE-D）或MLP将PV特征投影到BEV。上述方法在某种程度上采用了自下而上（bottom-up）的策略，以前向的凡是处理转换。另一种方法是采用自顶向下（top-down）的策略，通过交叉注意力机制直接构造BEVquery并搜索前视图像上的相应特征。为了匹配不同的下游任务，各种方法提出稀疏、密集或混合query。</p><p>3-D目标检测是3-D感知的核心任务之一。根据不同的输入数据模式，该任务可以分为：基于图像、基于激光雷达和基于多模态的3-D检测。</p><p>基于图像的3D检测设置需要模型预测仅给定多个图像的目标类别和3-D边框。以前的工作通常直接从透视图特征进行预测，这个过程虽然简单，但在实践中对多视图摄像头数据进行复杂的后处理，难以利用来自多个视图和时间连续帧的立体视觉线索。因此，最近基于BEV的方法进入视野。</p><p>将透视图转化为BEV的一个传统而直接的解决方案是，利用二者之间的自然集合投影关系，称之为几何方法。根据如何弥合这两个视图间的差距，以前的工作可分为两组：基于homograpgh的方法和基于深度的方法。</p><h4 id="基于homograph的方法">基于homograph的方法</h4><p>3-D空间中的点可以通过透视映射变换到图像空间，而将图像像素投影到3-D空间的逆问题是病态的。逆透视映射（IPM），基于逆映射点位于水平面的夫君爱约束，解决数学上不可能的映射问题。单应矩阵可以从相机的内外参物理地导出。一些方法用CNN提取PV图形的语义特征，并估计图像中的垂直消失点和地平面消失线，以确定单应矩阵。</p><p>由于IPM严重依赖于平坦地面假设，这些给予IPM的方法通常无法准确检测地平面上方的目标，如建筑物、车辆和行人。</p><p><strong>总结：</strong>基于homograph方法主要基于PV和BEV之间平地面的物理映射，具有良好的可解释性。IPM在下游感知任务的图像投影或特征投影中起作用。为了减少地平面以上区域的失真，充分探索语义信息，并广泛使用GAN来提高BEV特征的质量。由于从PV到BEV的实际转换是不适定的，IPM的硬假设解决来部分问题。PV整个特征图的有效BEV映射仍有待解决。</p><h4 id="基于深度预测的方法">基于深度预测的方法</h4><p>基于深度的PV-BEV方法自然建立在显示3D表示上。基于所使用的表示，这些方法可以分为两种类型：基于点的方法和基于体素的方法。</p><ul><li>基于点的视图转换</li></ul><p>基于点的方法直接使用深度估计将像素转换为点云，在连续3-D空间中散播。其更直接，更容易集成单目深度估计和基于激光雷达的3D检测成熟经验。</p><ul><li>基于体素的视图变换</li></ul><p>与基于激光雷达的3-D检测方法类似，纯摄像头方法也有两种常见的选择来表示变换后的3-D特征和几何。与分布在连续3-D空间中的点云相比，体素通过离散3-D空间来构造用于特征变换的均匀结构，为3-D场景理解提供来更有效的表示。</p><p>具体而言，该方案通常使用深度引导直接在相应位置的3D位置散射2D特征（而不是点）。先前的工作将2D特征图与相应的预测深度分布进行外积（outerproduct）来实现这一目标。早期的工作假设分布是均匀的，即沿射线的所有特征都相同，如OFT。这项工作建立了一个内部表示，以确定图像中哪些特征与正交BEV上的位置相关。在定义的均匀间隔3-D格上，它构建3-D体素特征图，并在投影的相应图像特征图区域累积特征来填充体素。然后，沿垂直轴对体素特征求和获得正交特征图，然后深度卷积神经网络提取BEV特征用于3-D目标检测。<strong>对于图像的每个像素，网络对分配的3D点预测相同的表示，即预测沿深度的均匀表示。</strong>这类方法通常不需要深度监督，并且可以在视图转换之后以端到端方式学习网络中的深度或3D位置信息。</p><p>相反，另一种范式会明确预测深度分布，并以此仔细构建3D特征，LSS代表了这种方法。其预测深度上的类分布（categoricaldistribution）和上下文向量，其外积确定透视光线每个点的特征，更好地接近真实深度分布。此外，它将来自所有摄像头的预测融合到场景的一个结合表征中，对标定误差更有鲁棒性。BEVDet遵循这一LSS范式，提出了一种从BEV进行全摄像头多视图的3D检测框架。而新版本BEVDet4D展示了基于多摄像头3D检测的时域线索。具体而言，保留前一帧的中间BEV特征，并将其与前帧生产的特征连接。</p><ul><li>深度监督</li></ul><p>当使用预测深度分布来提升2-D特征时，该分布精度非常重要。CaDDN用经典方法对激光雷达点投影的稀疏深度图进行插值，并以此监督深度分布的预测。其他不用深度标签的方法，只能从稀疏实例标注中学习此类3D位置或深度信息，仅靠网络学习，要困难得多。除了将深度监督纳入检测框架之外，DD3D和MV-FCOS3D++指出，深度估计和单目3D检测的预训练可以显著增强2D主干的表征学习。</p><ul><li>与基于IPM的方法相结合</li></ul><p>PanopticSeg利用这两个方法的优点，提出一种用于全景分割的densetransformer模块，其包括一个用IPM的flattransformer，然后误差校正，生成平面BEV特征，还有一个用3-D体格（volumetrilattice）建模中间3D空间的vertical transformer。</p><ul><li>多视图聚合做立体匹配</li></ul><p>除了单目深度估计外，立体匹配还可以在纯摄像头感知中预测更精确的深度信息。它依赖于适当多视图设置自然形成的基线。相比之下，在双目情况下的深度估计中具有更重要的优点。</p><p>基于深度的视图变换方法通常基于显式3-D表示、量化体素或连续3-D空间的点云散射。基于体素的方法使用均匀的深度向量或明确预测的深度分布将2D特征提升到3D体素空间，并执行几乎BEV的感知。相反，基于点的方法将深度预测转化为伪激光雷达表示，然后用定义网络进行3-D检测。如下表显式了3-D检测的结果：</p><p><imgsrc="https://pic4.zhimg.com/80/v2-1a79417fd7b3a648bc32a239516a4a9b_720w.webp" /></p><p>下图是基于深度的方法时间顺序概述：</p><p><imgsrc="https://pic4.zhimg.com/80/v2-dc857d960de7bb1eb157a672367a9c1b_720w.webp" /></p><p><strong>总而言之：</strong></p><p>1.早期的方法通常第一步用伪激光雷达表示，在第二步直接用3D检测器；然而，由于难以进行可推广的端到端训练，而面临着模型复杂度和性能低的问题。</p><p>2.由于计算效率和灵活性，最近的方法更加关注基于体素的方法。这种表示已广泛应用于不同任务的纯摄像头方法中。</p><p>3.深度监督对于这种基于深度的方法很重要，因为准确的深度分布可以为特征PV转换为BEV时提供基本线索。</p><p>4.如DfM、BEVDet4D和MV-FCOS3D++所分析的，在时域建模中此类方法是一个有希望的方向。</p><p>基于几何的方法明确建立在摄像头投影过程的物理原理上，将视图pV转换为BEV，这是一种可解释的解决方案。另一种选择是以<strong>数据驱动</strong>的方式对视图进行建模，有效地利用摄像头几何结构，其中神经网络充当PV和BEV之间的映射函数。为了涵盖单应性等复杂变幻，<strong>MLP</strong>和<strong>transformer</strong>是基于<strong>网络方法</strong>的两个合适选择。</p><h4 id="基于mlp的视图转换">基于MLP的视图转换</h4><p>多层感知器（MLP）在某种程度上可以看为一个复杂的映射函数，其将输入映射到具有不同模态、维度或表示的输出。摆脱标定摄像机设置包含的继承感应偏差，一些方法倾向于利用MLP学习摄像机标定的隐式表示，实现在两个不同视图（PV和BEV）之间转换。</p><p>基于MLP的方法忽略了标定摄像机的几何先验，并利用MLP作为通用映射函数来建模从PV到BEV的转换。虽然MLP在理论上是一种通用的近似器，但由于缺乏深度信息、遮挡等原因，这使得基于MLP的方法无法利用重叠区域带来的几何潜力。</p><p>总之，基于MLP的方法更多地关注单个图像的情况，而多视图融合还没有得到充分的研究。</p><h4 id="基于transformer的视图转换">基于Transformer的视图转换</h4><p>Transformer解决方案，无需明确利用摄像头模型。基于MLP和基于Transformer的张量映射之间有三个主要区别：</p><p>1）由于加权矩阵在推理过程中是固定的，因此MLP学习的映射不依赖于数据，相反，Transformer中的交叉注意与数据相关，其中加权矩阵与输入数据相关。此数据相关属性使Transformer更有表现力。</p><p>2）交叉注意是置换不变的，需要位置编码来区分输入顺序；MLP对排列自然敏感。</p><p>3）基于Transformer的方法采用自顶向下的策略，通过构造query并通过注意机制搜索相应的图像特征，而不是像基于MLP的方法那样以前向方式处理视图变换。</p><p>根据Transformer解码器中可学习slots（称为query）的粒度，将这些方法分为三类：基于稀疏query的方法、基于密集query的方法和基于混合query的方法。</p><h5 id="基于稀疏query的方法">基于稀疏query的方法</h5><p>对于基于稀疏查询的方法，查询嵌入使网络能够直接产生稀疏感知结果，而无需显式执行图像特征的密集变换。</p><p>DETR3D侧重与多摄像机输入的3D检测，并用基于几何的特征采样过程代替交叉注意。它首先从可学习的稀疏查询中预测3-D参考点，然后使用标定矩阵将参考点投影到图像平面上，最后对相应的多视图多尺度图像特征进行采样，进行端到端的3-D边框预测。为了缓解DETR3D中复杂的特征采样过程，PETR将摄像机参数导出的3-D位置嵌入编码到2-D多视图特征中，这样稀疏查询可以直接与交叉注意中位置-觉察图像特征进行交互，实现更简单、更优雅的框架。下图为PETR3D与PETR比较：</p><p><imgsrc="https://pic3.zhimg.com/80/v2-69dfa7b7a47ab07cda1888787f838006_720w.webp" /></p><p>PETRv2将3D位置嵌入扩展到时域来利用时域信息。</p><h5 id="基于密集query的方法">基于密集query的方法</h5><p>对于基于密集查询的方法，每个查询都预先分配3D空间或BEV空间的空间位置。查询数目有光栅化空间的空间分辨率决定，通常大于基于稀疏查询的方法。密集BEV表示可以密集查询与多个下游任务图像特征之间的交互来实现。</p><h5 id="基于混合query的方法">基于混合query的方法</h5><p>基于稀疏查询的方法适用于以目标为中心的任务，但无法导出显示密集BEV表示，不适用于密集感知任务，如BEV分割。因此，PETRv2中设计了一种混合查询策略，其中处理稀疏目标查询外，还提出了一种密集分割查询，每个分割查询分割特定的patch。</p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 -综述 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -综述 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DETR代码解读</title>
      <link href="/2023/11/02/DETR%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/"/>
      <url>/2023/11/02/DETR%E4%BB%A3%E7%A0%81%E8%A7%A3%E8%AF%BB/</url>
      
        <content type="html"><![CDATA[<h1 id="detr代码解析">DETR代码解析</h1><h2 id="一源代码">一、源代码</h2><p><code>https://link.zhihu.com/?target=https%3A//github.com/facebookresearch/detr</code></p><h2 id="二代码解析">二、代码解析</h2><h3 id="前言">1.前言</h3><ul><li><p><strong>二维位置编码：</strong></p><p>构造位置矩阵x_embed、y_embed，这里用python函数cumsum，对一个矩阵的元素进行累加，那么累加以后最后一个元素就是对所以累加元素的和，省去了求和的步骤，直接用这个和做归一化，对应x_embed[:,:,-1:]和y_embed[:,-1:,:]。</p></li><li><p><strong>代码中一些变量的shape：</strong></p><p>tensor_list的类型是NestedTensor,内部自动附加mask，用于表示动态shape，是pytorch新特性，全是false。</p><p>x:(b,c,H,W)</p><p>mask: (b,H,W)，全是False。</p><p>not_mask：(b,H,W)，全是True。</p><p>首先出现的y_embed：(b,H,W)，具体是1,1,1,1,......,2,2,2,2,......,3,3,3,3,......</p><p>首先出现的x_embed：(b,H,W)，具体是1,2,3,4,......,1,2,3,4,......,1,2,3,4,......</p><p>self.num_pos_feats = 128</p><p>首先出现的dim_t = [0,1,2,3,......,127]</p><p>pos_x：(b,H,W,128)</p><p>pos_y：(b,H,W,128)</p><p>flatten后面的数字是指：flatten()方法应从哪个轴开始展开操作。</p><p>torch.stack((pos_y[:,:,:,0::2].sin(),pos_y[:,:,:,0::2].cos()),dim=4)</p><p>这一步执行完后变成(b,H,W,2,64)通过flatten()方法从第3个轴开始展平，变为：(b,H,W,128)</p><p>toch.cat((pos_y,pos_x),dim=3)之后变为(b,H,W,256)，最后permute为(b,256,H,W)。</p><p>PositionEmbeddingSine类继承nn.Module类。</p></li></ul><h3 id="位置编码">2.位置编码</h3><pre class="python3"><code>class PositionEmbeddingSine(nn.Module):    def forward(self, tensor_list: NestedTensor):#输入是b,c,h,w#tensor_list的类型是NestedTensor，内部自动附加了mask，#用于表示动态shape，是pytorch中tensor新特性https://github.com/pytorch/nestedtensor        x = tensor_list.tensors# 附加的mask，shape是b,h,w 全是false        mask = tensor_list.mask        assert mask is not None        not_mask = ~mask# 因为图像是2d的，所以位置编码也分为x,y方向# 1 1 1 1 ..  2 2 2 2... 3 3 3...        y_embed = not_mask.cumsum(1, dtype=torch.float32)# 1 2 3 4 ... 1 2 3 4...        x_embed = not_mask.cumsum(2, dtype=torch.float32)        if self.normalize:            eps = 1e-6            y_embed = y_embed / (y_embed[:, -1:, :] + eps) * self.scale            x_embed = x_embed / (x_embed[:, :, -1:] + eps) * self.scale# num_pos_feats = 128# 0~127 self.num_pos_feats=128,因为前面输入向量是256，编码是一半sin，一半cos        dim_t = torch.arange(self.num_pos_feats, dtype=torch.float32, device=x.device)        dim_t = self.temperature ** (2 * (dim_t // 2) / self.num_pos_feats)# 输出shape=b,h,w,128        pos_x = x_embed[:, :, :, None] / dim_t        pos_y = y_embed[:, :, :, None] / dim_t        pos_x = torch.stack((pos_x[:, :, :, 0::2].sin(), pos_x[:, :, :, 1::2].cos()), dim=4).flatten(3)        pos_y = torch.stack((pos_y[:, :, :, 0::2].sin(), pos_y[:, :, :, 1::2].cos()), dim=4).flatten(3)        pos = torch.cat((pos_y, pos_x), dim=3).permute(0, 3, 1, 2)# 每个特征图的xy位置都编码成256的向量，其中前128是y方向编码，而128是x方向编码        return pos# b,n=256,h,w</code></pre><p>作者定义了一种数据结构：NestedTensor，里面打包存放了两个变量：x和mask。x是张量数据，mask是x数据是否是padding填充的。mask数据如下图所示：</p><p><imgsrc="/home/haseka/Documents/hexo_blog/themes/butterfly/source/img/detr_code/mask.png" /></p><p>而not_mask则是对mask取反说明featuremap某个(x,y)是否是真实值，未用padding，如下：</p><p><img src="/home/haseka/Pictures/not_mask.png" /></p><p>之后对图像进行编码，因为不是一维编码，是二维编码，需要考虑x，y方向上的编码，这里使用cumsum()求累加和的方法来进行编码，x和y经cumsum()后的结果如下：</p><p><imgsrc="/home/haseka/Documents/hexo_blog/source/img/detr_code/y_embed.png" /><img src="/home/haseka/Pictures/x_embed.png" /></p><p>并进行归一化后，得到对应的x、y编码，最终通过cat()操作将两个128维向量合成256维向量，作为最终编码pos返回。</p><h3 id="backbone">3.backbone</h3><pre class="python3"><code>class BackboneBase(nn.Module):    def __init__(self, backbone: nn.Module, train_backbone: bool, num_channels: int, return_interm_layers: bool):        super().__init__()        for name, parameter in backbone.named_parameters():            if not train_backbone or &#39;layer2&#39; not in name and &#39;layer3&#39; not in name and &#39;layer4&#39; not in name:                parameter.requires_grad_(False)        if return_interm_layers:            return_layers = &#123;&quot;layer1&quot;: &quot;0&quot;, &quot;layer2&quot;: &quot;1&quot;, &quot;layer3&quot;: &quot;2&quot;, &quot;layer4&quot;: &quot;3&quot;&#125;        else:            return_layers = &#123;&#39;layer4&#39;: &quot;0&quot;&#125;#作用的模型：定义BackboneBase时传入的nn.Moduleclass的backbone，返回的layer：来自bool变量return_interm_layers        self.body = IntermediateLayerGetter(backbone, return_layers=return_layers)        self.num_channels = num_channels    def forward(self, tensor_list: NestedTensor):#BackboneBase的输入是一个NestedTensor#xs中间层的输出，        xs = self.body(tensor_list.tensors)        out: Dict[str, NestedTensor] = &#123;&#125;        for name, x in xs.items():            m = tensor_list.mask            assert m is not None#F.interpolate上下采样，调整mask的size#to(torch.bool)  把mask转化为Bool型变量            mask = F.interpolate(m[None].float(), size=x.shape[-2:]).to(torch.bool)[0]            out[name] = NestedTensor(x, mask)        return outclass Backbone(BackboneBase):    &quot;&quot;&quot;ResNet backbone with frozen BatchNorm.&quot;&quot;&quot;    def __init__(self, name: str,                 train_backbone: bool,                 return_interm_layers: bool,                 dilation: bool):#根据name选择backbone, num_channels, return_interm_layers等，传入BackboneBase初始化        backbone = getattr(torchvision.models, name)(            replace_stride_with_dilation=[False, False, dilation],            pretrained=is_main_process(), norm_layer=FrozenBatchNorm2d)        num_channels = 512 if name in (&#39;resnet18&#39;, &#39;resnet34&#39;) else 2048        super().__init__(backbone, train_backbone, num_channels, return_interm_layers)</code></pre><p>本文采取Resnt作为backbone。</p><pre class="python3"><code>class Joiner(nn.Sequential):    def __init__(self, backbone, position_embedding):        super().__init__(backbone, position_embedding)    def forward(self, tensor_list: NestedTensor):        xs = self[0](tensor_list)        out: List[NestedTensor] = []        pos = []        for name, x in xs.items():            out.append(x)            # position encoding            pos.append(self[1](x).to(x.tensors.dtype))        return out, posdef build_backbone(args):#position_embedding是个nn.module    position_embedding = build_position_encoding(args)    train_backbone = args.lr_backbone &gt; 0    return_interm_layers = args.masks#backbone是个nn.module    backbone = Backbone(args.backbone, train_backbone, return_interm_layers, args.dilation)#nn.Sequential在一起    model = Joiner(backbone, position_embedding)    model.num_channels = backbone.num_channels    return model</code></pre><p><strong>把Backbone和之前的PositionEmbeddingSine连在一起：</strong>Backbone完以后输出(b,c,h,w)，再经过PositionEmbeddingSine输出(b,H,W,256)。</p><h3 id="transformer">4.Transformer</h3><h4 id="encoder">encoder</h4><pre class="python3"><code>class TransformerEncoderLayer(nn.Module):    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,                 activation=&quot;relu&quot;, normalize_before=False):        super().__init__()        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)        # Implementation of Feedforward model        self.linear1 = nn.Linear(d_model, dim_feedforward)        self.dropout = nn.Dropout(dropout)        self.linear2 = nn.Linear(dim_feedforward, d_model)        self.norm1 = nn.LayerNorm(d_model)        self.norm2 = nn.LayerNorm(d_model)        self.dropout1 = nn.Dropout(dropout)        self.dropout2 = nn.Dropout(dropout)        self.activation = _get_activation_fn(activation)        self.normalize_before = normalize_before    def with_pos_embed(self, tensor, pos: Optional[Tensor]):        return tensor if pos is None else tensor + pos    def forward_post(self,                     src,                     src_mask: Optional[Tensor] = None,                     src_key_padding_mask: Optional[Tensor] = None,                     pos: Optional[Tensor] = None):    # 和标准做法有点不一样，src加上位置编码得到q和k，但是v依然还是src，    # 也就是v和qk不一样        q = k = self.with_pos_embed(src, pos)        src2 = self.self_attn(q, k, value=src, attn_mask=src_mask,                              key_padding_mask=src_key_padding_mask)[0]#Add and Norm        src = src + self.dropout1(src2)        src = self.norm1(src)#FFN        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))#Add and Norm        src = src + self.dropout2(src2)        src = self.norm2(src)        return src    def forward_pre(self, src,                    src_mask: Optional[Tensor] = None,                    src_key_padding_mask: Optional[Tensor] = None,                    pos: Optional[Tensor] = None):        src2 = self.norm1(src)        q = k = self.with_pos_embed(src2, pos)        src2 = self.self_attn(q, k, value=src2, attn_mask=src_mask,                              key_padding_mask=src_key_padding_mask)[0]        src = src + self.dropout1(src2)        src2 = self.norm2(src)        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))        src = src + self.dropout2(src2)        return src    def forward(self, src,                src_mask: Optional[Tensor] = None,                src_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None):        if self.normalize_before:            return self.forward_pre(src, src_mask, src_key_padding_mask, pos)        return self.forward_post(src, src_mask, src_key_padding_mask, pos)</code></pre><p><strong>有了一个EncoderLayer的定义，再看Transformer的整个Encoder：</strong></p><pre class="python3"><code>class TransformerEncoder(nn.Module):    def __init__(self, encoder_layer, num_layers, norm=None):        super().__init__()        # 编码器copy6份        self.layers = _get_clones(encoder_layer, num_layers)        self.num_layers = num_layers        self.norm = norm    def forward(self, src,                mask: Optional[Tensor] = None,                src_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None):        # 内部包括6个编码器，顺序运行        # src是图像特征输入，shape=hxw,b,256        output = src        for layer in self.layers:            # 第一个编码器输入来自图像特征，后面的编码器输入来自前一个编码器输出            output = layer(output, src_mask=mask,                           src_key_padding_mask=src_key_padding_mask, pos=pos)        return output</code></pre><h4 id="decoder">Decoder</h4><pre class="python3"><code>class TransformerDecoderLayer(nn.Module):    def __init__(self, d_model, nhead, dim_feedforward=2048, dropout=0.1,                 activation=&quot;relu&quot;, normalize_before=False):        super().__init__()        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)        self.multihead_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)        # Implementation of Feedforward model        self.linear1 = nn.Linear(d_model, dim_feedforward)        self.dropout = nn.Dropout(dropout)        self.linear2 = nn.Linear(dim_feedforward, d_model)        self.norm1 = nn.LayerNorm(d_model)        self.norm2 = nn.LayerNorm(d_model)        self.norm3 = nn.LayerNorm(d_model)        self.dropout1 = nn.Dropout(dropout)        self.dropout2 = nn.Dropout(dropout)        self.dropout3 = nn.Dropout(dropout)        self.activation = _get_activation_fn(activation)        self.normalize_before = normalize_before    def with_pos_embed(self, tensor, pos: Optional[Tensor]):        return tensor if pos is None else tensor + pos            def forward_post(self, tgt, memory,                     tgt_mask: Optional[Tensor] = None,                     memory_mask: Optional[Tensor] = None,                     tgt_key_padding_mask: Optional[Tensor] = None,                     memory_key_padding_mask: Optional[Tensor] = None,                     pos: Optional[Tensor] = None,                     query_pos: Optional[Tensor] = None):                     #query,key的输入是object queries(query_pos) + Decoder的输入(tgt),shape都是(100,b,256)#value的输入是Decoder的输入(tgt),shape = (100,b,256)        q = k = self.with_pos_embed(tgt, query_pos)#Multi-head self-attention        tgt2 = self.self_attn(q, k, value=tgt, attn_mask=tgt_mask,                              key_padding_mask=tgt_key_padding_mask)[0]#Add and Norm        tgt = tgt + self.dropout1(tgt2)        tgt = self.norm1(tgt)#query的输入是上一个attention的输出(tgt) + object queries(query_pos)#key的输入是Encoder的位置编码(pos) + Encoder的输出(memory)#value的输入是Encoder的输出(memory)        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),                                   key=self.with_pos_embed(memory, pos),                                   value=memory, attn_mask=memory_mask,                                   key_padding_mask=memory_key_padding_mask)[0]#Add and Norm        tgt = tgt + self.dropout2(tgt2)        tgt = self.norm2(tgt)#FFN        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))        tgt = tgt + self.dropout3(tgt2)        tgt = self.norm3(tgt)        return tgt    def forward_pre(self, tgt, memory,                    tgt_mask: Optional[Tensor] = None,                    memory_mask: Optional[Tensor] = None,                    tgt_key_padding_mask: Optional[Tensor] = None,                    memory_key_padding_mask: Optional[Tensor] = None,                    pos: Optional[Tensor] = None,                    query_pos: Optional[Tensor] = None):        tgt2 = self.norm1(tgt)        q = k = self.with_pos_embed(tgt2, query_pos)        tgt2 = self.self_attn(q, k, value=tgt2, attn_mask=tgt_mask,                              key_padding_mask=tgt_key_padding_mask)[0]        tgt = tgt + self.dropout1(tgt2)        tgt2 = self.norm2(tgt)        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),                                   key=self.with_pos_embed(memory, pos),                                   value=memory, attn_mask=memory_mask,                                   key_padding_mask=memory_key_padding_mask)[0]        tgt = tgt + self.dropout2(tgt2)        tgt2 = self.norm3(tgt)        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))        tgt = tgt + self.dropout3(tgt2)        return tgt    def forward(self, tgt, memory,                tgt_mask: Optional[Tensor] = None,                memory_mask: Optional[Tensor] = None,                tgt_key_padding_mask: Optional[Tensor] = None,                memory_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None,                query_pos: Optional[Tensor] = None):        if self.normalize_before:            return self.forward_pre(tgt, memory, tgt_mask, memory_mask,                                    tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)        return self.forward_post(tgt, memory, tgt_mask, memory_mask,                                 tgt_key_padding_mask, memory_key_padding_mask, pos, query_pos)</code></pre><p><strong>有了一个Decoder def with_pos_embed(self, tensor, pos:Optional[Tensor]): return tensor if pos is None else tensor + posLayer的定义，再看Transformer的整个Decoder：</strong></p><pre class="python3"><code>class TransformerDecoder(nn.Module):#值得注意的是：在使用TransformerDecoder时需要传入的参数有：# tgt：Decoder的输入，memory：Encoder的输出，pos：Encoder的位置编码的输出，query_pos：Object Queries，一堆mask    def forward(self, tgt, memory,                tgt_mask: Optional[Tensor] = None,                memory_mask: Optional[Tensor] = None,                tgt_key_padding_mask: Optional[Tensor] = None,                memory_key_padding_mask: Optional[Tensor] = None,                pos: Optional[Tensor] = None,                query_pos: Optional[Tensor] = None):        output = tgt# Decoder输入的tgt:(100, b, 256)        intermediate = []        for layer in self.layers:            output = layer(output, memory, tgt_mask=tgt_mask,                           memory_mask=memory_mask,                           tgt_key_padding_mask=tgt_key_padding_mask,                           memory_key_padding_mask=memory_key_padding_mask,                           pos=pos, query_pos=query_pos)            if self.return_intermediate:                intermediate.append(self.norm(output))        if self.norm is not None:            output = self.norm(output)            if self.return_intermediate:                intermediate.pop()                intermediate.append(output)        if self.return_intermediate:            return torch.stack(intermediate)        return output.unsqueeze(0)</code></pre><h3 id="ffn">5.FFN</h3><pre class="python3"><code>class MLP(nn.Module):    &quot;&quot;&quot; Very simple multi-layer perceptron (also called FFN)&quot;&quot;&quot;    def __init__(self, input_dim, hidden_dim, output_dim, num_layers):        super().__init__()        self.num_layers = num_layers        h = [hidden_dim] * (num_layers - 1)        self.layers = nn.ModuleList(nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim]))    def forward(self, x):        for i, layer in enumerate(self.layers):            x = F.relu(layer(x)) if i &lt; self.num_layers - 1 else layer(x)        return x</code></pre><p><strong>匈牙利匹配HungarianMatcher类：</strong><strong>这个类的目的是计算从targets到predictions的一种最优排列。</strong>predictions比targets的数量多，但我们要进行1-to-1matching，所以多的predictions将与 匹配。这个函数整体在构建(13)式，cost_class，cost_bbox，cost_giou，对应的就是(13)式中的几个损失函数，它们的维度都是(b,100,m)。m包含了这个batch内部所有的GT Bounding Box。</p><pre class="python3"><code># pred_logits:[b,100,92]# pred_boxes:[b,100,4]# targets是个长度为b的list，其中的每个元素是个字典，共包含：labels-长度为(m,)的Tensor，元素是标签；boxes-长度为(m,4)的Tensor，元素是Bounding Box。# detr分类输出，num_queries=100，shape是(b,100,92)        bs, num_queries = outputs[&quot;pred_logits&quot;].shape[:2]        # We flatten to compute the cost matrices in a batch        out_prob = outputs[&quot;pred_logits&quot;].flatten(0, 1).softmax(-1)  # [batch_size * num_queries, num_classes] = [100b, 92]        out_bbox = outputs[&quot;pred_boxes&quot;].flatten(0, 1)  # [batch_size * num_queries, 4] = [100b, 4]# 准备分类target shape=(m,)里面存储的是类别索引，m包括了整个batch内部的所有gt bbox        # Also concat the target labels and boxes        tgt_ids = torch.cat([v[&quot;labels&quot;] for v in targets])# (m,)[3,6,7,9,5,9,3]# 准备bbox target shape=(m,4)，已经归一化了        tgt_bbox = torch.cat([v[&quot;boxes&quot;] for v in targets])# (m,4)#(100b,92)-&gt;(100b, m)，对于每个预测结果，把目前gt里面有的所有类别值提取出来，其余值不需要参与匹配#对应上述公式，类似于nll loss，但是更加简单        # Compute the classification cost. Contrary to the loss, we don&#39;t use the NLL,        # but approximate it in 1 - proba[target class].        # The 1 is a constant that doesn&#39;t change the matching, it can be ommitted.#行：取每一行；列：只取tgt_ids对应的m列        cost_class = -out_prob[:, tgt_ids]# (100b, m)        # Compute the L1 cost between boxes, 计算out_bbox和tgt_bbox两两之间的l1距离 (100b, m)        cost_bbox = torch.cdist(out_bbox, tgt_bbox, p=1)# (100b, m)        # Compute the giou cost betwen boxes, 额外多计算一个giou loss (100b, m)        cost_giou = -generalized_box_iou(box_cxcywh_to_xyxy(out_bbox), box_cxcywh_to_xyxy(tgt_bbox))#得到最终的广义距离(100b, m)，距离越小越可能是最优匹配        # Final cost matrix        C = self.cost_bbox * cost_bbox + self.cost_class * cost_class + self.cost_giou * cost_giou#(100b, m)--&gt; (b, 100, m)        C = C.view(bs, num_queries, -1).cpu()#计算每个batch内部有多少物体，后续计算时候按照单张图片进行匹配，没必要batch级别匹配,徒增计算        sizes = [len(v[&quot;boxes&quot;]) for v in targets]#匈牙利最优匹配，返回匹配索引#enumerate(C.split(sizes, -1))]：(b,100,image1,image2,image3,...)        indices = [linear_sum_assignment(c[i]) for i, c in enumerate(C.split(sizes, -1))]           return [(torch.as_tensor(i, dtype=torch.int64), torch.as_tensor(j, dtype=torch.int64)) for i, j in indices]</code></pre><p>在得到匹配关系后算loss就水到渠成了。loss_labels计算分类损失，loss_boxes计算回归损失，包含L_1 loss,iou_loss。</p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -DETR -code </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DETR_Start</title>
      <link href="/2023/11/01/DETR%E5%AD%A6%E4%B9%A0/"/>
      <url>/2023/11/01/DETR%E5%AD%A6%E4%B9%A0/</url>
      
        <content type="html"><![CDATA[<center><head>    DETR原理解读    </head> </center><h6 id="原理解读"><a href="#原理解读" class="headerlink" title="原理解读"></a>原理解读</h6><hr><p> DETR任务是Object detection，用到的工具是transformers，特点是End-to-end。而目标检测的任务是要预测一系列的Bounding Box的坐标及Label，当下大多数检测器通过定义一些proposal或者anchor，将问题构建成一个分类及回归问题来间接完成这个任务。DETR的工作则是将transfoemers运用到目标检测领域，取代了现在模型需要手工设计的工作，并且取得了不错的结果。    DETR是第一个使用端到端的方法解决检测问题，解决的方法是检测问题视为一个set prediction 问题，如下图所示：</p><p>​    <img src="https://pic1.zhimg.com/v2-772984ccd82a0e0a279ea6a09c3c34c0_r.jpg" alt=""></p><h6 id=""><a href="#" class="headerlink" title=" "></a> </h6><p>     网络的主要组成：CNN和Transformer。</p><p>DETR工作两个关键部分：</p><ul><li>用transformer的encoder-decoder架构一次性生成N个box prediction。(N是一个事先设定的、远远大于image中object个数的一个整数)</li><li>设计了bipartite matching loss，基于预测的box和ground truthboxes的二分图匹配计算loss大小，从而使得预测的box位置和类别更接近于ground truth。</li></ul><p>DETR整体结构可以分为4个部分：(如下图所示)</p><ul><li><p>backbone</p></li><li><p>encoder</p></li><li><p>decoder</p></li><li><p>FFN</p><p><img src="https://pic4.zhimg.com/80/v2-3d43474df51c545ad6bafc19b3c8ccc3_720w.webp" alt=""></p></li></ul><ol><li><p><strong>backbone:</strong> CNN backbone处理 <script type="math/tex">x_i \in B \times 3 \times H_0 \times W_0</script>维的图像，把它转换为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="12.511ex" height="2.413ex" role="img" focusable="false" viewBox="0 -861.5 5530 1066.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(827.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1772.6,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(2297,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(3075,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container>维的feature map。</p></li><li><p><strong>encoder：</strong> encoder的输入是<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="12.511ex" height="2.413ex" role="img" focusable="false" viewBox="0 -861.5 5530 1066.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D453" d="M118 -162Q120 -162 124 -164T135 -167T147 -168Q160 -168 171 -155T187 -126Q197 -99 221 27T267 267T289 382V385H242Q195 385 192 387Q188 390 188 397L195 425Q197 430 203 430T250 431Q298 431 298 432Q298 434 307 482T319 540Q356 705 465 705Q502 703 526 683T550 630Q550 594 529 578T487 561Q443 561 443 603Q443 622 454 636T478 657L487 662Q471 668 457 668Q445 668 434 658T419 630Q412 601 403 552T387 469T380 433Q380 431 435 431Q480 431 487 430T498 424Q499 420 496 407T491 391Q489 386 482 386T428 385H372L349 263Q301 15 282 -47Q255 -132 212 -173Q175 -205 139 -205Q107 -205 81 -186T55 -132Q55 -95 76 -78T118 -61Q162 -61 162 -103Q162 -122 151 -136T127 -157L118 -162Z"></path></g><g data-mml-node="mo" transform="translate(827.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(1772.6,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mo" transform="translate(2297,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(3075,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的feature map，接下来一次进行下面过程：</p><ul><li><strong>通道数压缩:</strong> 通过1*1卷积处理，将channels数量从C压缩到d，即得到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="12.923ex" height="2.306ex" role="img" focusable="false" viewBox="0 -853.7 5711.8 1019.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mn" transform="translate(498,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1179.3,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2124.1,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2057,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2835,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的新feature map。</li><li><strong>转化为序列化数据：</strong> 将空间的维度（高和宽）压缩为一个维度，即把<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="12.923ex" height="2.306ex" role="img" focusable="false" viewBox="0 -853.7 5711.8 1019.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mn" transform="translate(498,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1179.3,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2124.1,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2057,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2835,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的新feature map通过reshape成（HW，B，256）维的feature map。</li><li><strong>位置编码：</strong> 在得到$z<em>0 \in R^{B\times d \times W}$ 维的feature map后，正式输入encoder之前，需要进行<strong>Positional Encoding</strong>。因为在<em>_self-attention中需要有表示位置的信息，但是transformer encoder这个结构本身无法体现出位置信息</em></em>。所以我们需要对<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex;" xmlns="http://www.w3.org/2000/svg" width="12.923ex" height="2.306ex" role="img" focusable="false" viewBox="0 -853.7 5711.8 1019.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D467" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path></g><g data-mml-node="mn" transform="translate(498,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g><g data-mml-node="mo" transform="translate(1179.3,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="msup" transform="translate(2124.1,0)"><g data-mml-node="mi"><path data-c="1D445" d="M230 637Q203 637 198 638T193 649Q193 676 204 682Q206 683 378 683Q550 682 564 680Q620 672 658 652T712 606T733 563T739 529Q739 484 710 445T643 385T576 351T538 338L545 333Q612 295 612 223Q612 212 607 162T602 80V71Q602 53 603 43T614 25T640 16Q668 16 686 38T712 85Q717 99 720 102T735 105Q755 105 755 93Q755 75 731 36Q693 -21 641 -21H632Q571 -21 531 4T487 82Q487 109 502 166T517 239Q517 290 474 313Q459 320 449 321T378 323H309L277 193Q244 61 244 59Q244 55 245 54T252 50T269 48T302 46H333Q339 38 339 37T336 19Q332 6 326 0H311Q275 2 180 2Q146 2 117 2T71 2T50 1Q33 1 33 10Q33 12 36 24Q41 43 46 45Q50 46 61 46H67Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628Q287 635 230 637ZM630 554Q630 586 609 608T523 636Q521 636 500 636T462 637H440Q393 637 386 627Q385 624 352 494T319 361Q319 360 388 360Q466 361 492 367Q556 377 592 426Q608 449 619 486T630 554Z"></path></g><g data-mml-node="TeXAtom" transform="translate(792,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mo" transform="translate(759,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(1537,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mo" transform="translate(2057,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mi" transform="translate(2835,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g></g></g></g></g></svg></mjx-container> 维的feature map做positional encoding。</li></ul><p>原版本Transformer与Vision Transformer中Positional Encoding表达式为：</p><script type="math/tex; mode=display">PE_{(pos,2i)} = sin(pos / 10000^{2i/d}),  PE_{(pos,2i+1)} = cos(pos / 10000^{2i/d})</script><p>其中，d就是d*HW维的feature map的第一维，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="13.838ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 6116.2 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(988,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mo" transform="translate(1734.8,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(2679.6,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(2957.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3457.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3902.2,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(4790.2,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(5838.2,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container>。表示token在sequence中的位置，sequence的长度是HW，例如第一个token的pos=0。</p><p>2i和2i+1表示了Positional Encoding的维度，i的取值范围为[0,…,d/2）。所以当pos为1时，Positional Encoding可以写为：</p><script type="math/tex; mode=display">PE(1) = [sin(1/10000^{(0/256)}),cos(1/10000^{(0/256)}),sin(1/10000^{(2/256)}),cos(1/10000^{(2/256)}),...]</script><p>式子中，d=256。</p><p><strong>不同点1：因为Transformer原版中只需要考虑x方向的位置编码，而DETR需要考虑xy方向的位置编码（图像特征是2-D特征），考虑xy方向进行同时编码</strong>Positional Enconding的输出张量：(B,d,H,W),d = 256,其中d代表位置编码长度，H,W代表张量位置。意思为，这个特征图上的任意一个点(H1,W1)有个位置编码，这个编码的长度为256，其中，前128维代表H1的位置编码，后128维代表W1的位置编码。</p><script type="math/tex; mode=display">PE_{(pos_x,2i) = sin(pos_x/10000^{2i/128})}</script><script type="math/tex; mode=display">PE_{(pos_x,2i+1) = cos(pos_x/10000^{2i/128})}</script><script type="math/tex; mode=display">PE_{(pos_y,2i) = sin(pos_y/10000^{2i/128})}</script><script type="math/tex; mode=display">PE_{(pos_y,2i+1) = cos(pos_y/10000^{2i/128})}</script><p>任意一个位置<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="43.195ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 19092.3 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(1377,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(2333.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2778.1,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(3281.1,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(3766.1,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4664.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(5053.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(5498.3,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(6001.3,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(6486.3,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(7720.5,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(8665.3,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(8943.3,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(9443.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(9888,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(10776,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(11824,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g><g data-mml-node="mo" transform="translate(12102,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(12546.6,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(13049.6,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(13534.6,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(14710.9,0)"><path data-c="2208" d="M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z"></path></g><g data-mml-node="mo" transform="translate(15655.7,0)"><path data-c="5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path></g><g data-mml-node="mn" transform="translate(15933.7,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(16433.7,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(16878.3,0)"><path data-c="1D43B" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 219 683Q260 681 355 681Q389 681 418 681T463 682T483 682Q499 682 499 672Q499 670 497 658Q492 641 487 638H485Q483 638 480 638T473 638T464 637T455 637Q416 636 405 634T387 623Q384 619 355 500Q348 474 340 442T328 395L324 380Q324 378 469 378H614L615 381Q615 384 646 504Q674 619 674 627T617 637Q594 637 587 639T580 648Q580 650 582 660Q586 677 588 679T604 682Q609 682 646 681T740 680Q802 680 835 681T871 682Q888 682 888 672Q888 645 876 638H874Q872 638 869 638T862 638T853 637T844 637Q805 636 794 634T776 623Q773 618 704 340T634 58Q634 51 638 51Q646 48 692 46H723Q729 38 729 37T726 19Q722 6 716 0H701Q664 2 567 2Q533 2 504 2T458 2T437 1Q420 1 420 10Q420 15 423 24Q428 43 433 45Q437 46 448 46H454Q481 46 514 49Q520 50 522 50T528 55T534 64T540 82T547 110T558 153Q565 181 569 198Q602 330 602 331T457 332H312L279 197Q245 63 245 58Q245 51 253 49T303 46H334Q340 38 340 37T337 19Q333 6 327 0H312Q275 2 178 2Q144 2 115 2T69 2T48 1Q31 1 31 10Q31 12 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="mi" transform="translate(17766.3,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="mo" transform="translate(18814.3,0)"><path data-c="5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path></g></g></g></svg></mjx-container> 的Positional Encoding，通过公式(3)(4)可以得到128维向量，代表 <mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.439ex;" xmlns="http://www.w3.org/2000/svg" width="4.399ex" height="1.439ex" role="img" focusable="false" viewBox="0 -442 1944.5 636"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(988,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></svg></mjx-container> 的位置编码，通过带入<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="4.268ex" height="1.667ex" role="img" focusable="false" viewBox="0 -442 1886.5 737"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(988,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>带入公式(5)(6)可以得到一个128维向量，代表<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="4.268ex" height="1.667ex" role="img" focusable="false" viewBox="0 -442 1886.5 737"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(503,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(988,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>的位置编码，将这两个128维的向量拼接起来，可以得到一个256维的向量，代表<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="11.434ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 5053.6 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(1377,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(2333.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(2778.1,0)"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z"></path></g><g data-mml-node="mi" transform="translate(3281.1,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="msub" transform="translate(3766.1,0)"><g data-mml-node="mi"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(502,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(4664.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>的位置编码。</p></li></ol><p>   计算所有位置的编码后就可以得到(256,H,W)的张量，代表这个batch的位置编码。编码矩阵的维度是(B,256,H,W)，也把其序列化为维度为(HW,B,256)维的张量。准备与<strong>(HW,B,256)维的feature map相加输入Encoder</strong>。</p><p>   <img src="https://pic1.zhimg.com/80/v2-89d23b461169c6ab25ea64389fe8d86c_720w.webp" alt=""></p><p>   <strong>不同点2：原版Transformer只在Encoder之前使用了Positional Encoding，并且只在输入上进行Positional Encoding，再把输入经过transformation matrix变为Query，Key和Value这几个张量。但DETR在Encoder的每一个Multi-head Self-attention之前都使用了Positional Encoding，且只对Query和Key使用，即：只把维度维(HW,B,256)维的位置编码与维度为(HW,B,256)维的Query和Key相加，而不与Value相加</strong>。</p><p>   下图为DETR的transformer的结构详解：</p><p>   <img src="https://pic3.zhimg.com/v2-c158521c7a602382dfa4d85243672df2_r.jpg" alt=""></p><p>   <img src="https://pic4.zhimg.com/v2-1719966a223d98ad48f98c2e4d71add7_r.jpg" alt=""></p><p>   除了Positonal Encoding设置不一样之外，Encoder其他结构一致。每个Encoder Layer包含一个multi-head self-attention的module和一个前馈网络。</p><p>   Encoder最终输出的是(HW,b,256)维的编码矩阵Embedding，并将其输入Decoder。</p><p>   <strong>与原始transformer编码器不同之处：</strong></p><ul><li><p>输入编码器的位置需要考虑2-D空间位置。</p></li><li><p>位置编码向量需要加入每个Encoder Layer中。</p></li><li><p>在编码器内部位置编码仅作用于Query和Key，即只与Query和Key相加，Value不做处理。</p></li></ul><ol><li><p>decoder：</p><p>DETR的Decoder与原版Transformer的也不太一样：原版的decoder最后一个框output probability，代表一次只产生一个单词的softmax，并由此得到这个单词的预测结果。即：<strong>predicts the output sequence one element at a time</strong>。</p></li></ol><p>   不同的是，DETR的transformer decoder是一次性处理全部的object queries，即一次性输出全部的predictions，即：<strong>decodes the N objects in parallel at each decoder layer</strong>。</p><p>   DETR的Decoder主要有两个输入：</p><ol><li>Transformer Encoder 输入的Embedding与position encoding之和。</li><li><p>Object queries。</p><p>其中，Embedding即使上文提到的(HW,b,256)的编码矩阵。</p></li></ol><p>   <strong>Object queries</strong>是一个维度维(100,b,256)的张量，数据类型是nn.Embedding，该张量可学习。<strong>Object queries</strong>矩阵内部通过学习建模了100个物体之间的全局关系（例如：房间里桌子旁一般放椅子），推理时可以利用该全局注意力更好的进行解码预测输出。</p><p>   Decoder的输入初始被初始为维度为(100,b,256)维的全部元素为0的张量，和<strong>Object queries</strong>相加后一起充当<strong>multi-head self-attention的Query和Key。multi-head self-attention的Value为Decoder的输入(全0张量)</strong>。</p><p>   而到了Decoder的multi-head attention时，它的Key和Value来自Encoder的输出张量，维度为(hw,b,256)，    其中Key值还进行位置编码。Query值一部分来自第一个Add and Norm的输出，维度为(100,b,256)的张量，另一部分来自Object queries，充当可学习的位置编码。所以，multi-head attention的Key和Value的维度为(hw,b,256)，而Query的维度为(100,b,256)。</p><p>   每个Decoder的输出维度为(1,b,100,256)，送入后面的前馈网络。</p><p>   故而：Object queries充当的其实是位置编码的作用，只不过它是可学习的位置编码。所以，归纳得：</p><p>   <img src="https://pic1.zhimg.com/v2-6b9de32f5e1174eb3ecfecc2f0335d48_r.jpg" alt=""></p><p>   <strong>损失函数部分解读：</strong></p><p>   Decoder输出维度(b,100,256)的张量，送到2个前馈网络FFN得到class和Bounding Box。他们会得到N=100个预测目标，包括类别和Bounding Box(100远大于图中目标总数)。计算loss时回归分支仅计算物体位置，背景集合忽略。所以DETR输出张量的维度为<strong>分类分支(b,100,class+1)</strong>和<strong>回归分支(b,100,4)</strong>。其中，4是指每个预测目标归一化的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.667ex;" xmlns="http://www.w3.org/2000/svg" width="11.735ex" height="2.364ex" role="img" focusable="false" viewBox="0 -750 5186.9 1045"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msub" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g><g data-mml-node="mo" transform="translate(1309.5,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="msub" transform="translate(1754.1,0)"><g data-mml-node="mi"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(466,-150) scale(0.707)"><path data-c="1D466" d="M21 287Q21 301 36 335T84 406T158 442Q199 442 224 419T250 355Q248 336 247 334Q247 331 231 288T198 191T182 105Q182 62 196 45T238 27Q261 27 281 38T312 61T339 94Q339 95 344 114T358 173T377 247Q415 397 419 404Q432 431 462 431Q475 431 483 424T494 412T496 403Q496 390 447 193T391 -23Q363 -106 294 -155T156 -205Q111 -205 77 -183T43 -117Q43 -95 50 -80T69 -58T89 -48T106 -45Q150 -45 150 -87Q150 -107 138 -122T115 -142T102 -147L99 -148Q101 -153 118 -160T152 -167H160Q177 -167 186 -165Q219 -156 247 -127T290 -65T313 -9T321 21L315 17Q309 13 296 6T270 -6Q250 -11 231 -11Q185 -11 150 11T104 82Q103 89 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g><g data-mml-node="mo" transform="translate(2616.6,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(3061.3,0)"><path data-c="1D464" d="M580 385Q580 406 599 424T641 443Q659 443 674 425T690 368Q690 339 671 253Q656 197 644 161T609 80T554 12T482 -11Q438 -11 404 5T355 48Q354 47 352 44Q311 -11 252 -11Q226 -11 202 -5T155 14T118 53T104 116Q104 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Q21 293 29 315T52 366T96 418T161 441Q204 441 227 416T250 358Q250 340 217 250T184 111Q184 65 205 46T258 26Q301 26 334 87L339 96V119Q339 122 339 128T340 136T341 143T342 152T345 165T348 182T354 206T362 238T373 281Q402 395 406 404Q419 431 449 431Q468 431 475 421T483 402Q483 389 454 274T422 142Q420 131 420 107V100Q420 85 423 71T442 42T487 26Q558 26 600 148Q609 171 620 213T632 273Q632 306 619 325T593 357T580 385Z"></path></g><g data-mml-node="mo" transform="translate(3777.3,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(4221.9,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(4797.9,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>。归一化就是出一图片宽高进行归一化。</p><p>   <strong>question: 预测框和真值如何一一对应————-如何知道第47个预测框对应图片里的狗的?</strong></p><p>   DETR: 目标检测任务就是输出无序集合，如何将GT Bounding Box计算loss？</p><p>   一幅图，若第i个物体的真值表达为$y<em>i = (c_i,b_i)<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="9.05ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 4000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">其</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">中</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>c_i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="16.285ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 7198 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">表</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">示</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">它</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(4000,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mi" transform="translate(4433,0)"><path data-c="1D459" d="M117 59Q117 26 142 26Q179 26 205 131Q211 151 215 152Q217 153 225 153H229Q238 153 241 153T246 151T248 144Q247 138 245 128T234 90T214 43T183 6T137 -11Q101 -11 70 11T38 85Q38 97 39 102L104 360Q167 615 167 623Q167 626 166 628T162 632T157 634T149 635T141 636T132 637T122 637Q112 637 109 637T101 638T95 641T94 647Q94 649 96 661Q101 680 107 682T179 688Q194 689 213 690T243 693T254 694Q266 694 266 686Q266 675 193 386T118 83Q118 81 118 75T117 65V59Z"></path></g><g data-mml-node="mi" transform="translate(4731,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z"></path></g><g data-mml-node="mi" transform="translate(5260,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(5729,0)"><path data-c="1D460" d="M131 289Q131 321 147 354T203 415T300 442Q362 442 390 415T419 355Q419 323 402 308T364 292Q351 292 340 300T328 326Q328 342 337 354T354 372T367 378Q368 378 368 379Q368 382 361 388T336 399T297 405Q249 405 227 379T204 326Q204 301 223 291T278 274T330 259Q396 230 396 163Q396 135 385 107T352 51T289 7T195 -10Q118 -10 86 19T53 87Q53 126 74 143T118 160Q133 160 146 151T160 120Q160 94 142 76T111 58Q109 57 108 57T107 55Q108 52 115 47T146 34T201 27Q237 27 263 38T301 66T318 97T323 122Q323 150 302 164T254 181T195 196T148 231Q131 256 131 289Z"></path></g><g data-mml-node="mi" transform="translate(6198,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g></g></g></svg></mjx-container>b_i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="29.805ex" height="2.161ex" role="img" focusable="false" viewBox="0 -750 13174 955"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">表</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">示</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">它</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(4000,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(4759,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(5244,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5816,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6416,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(6936,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7281,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7881,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(8358,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(9117,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(9602,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(10174,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">。</text></g></g><g data-mml-node="mi" transform="translate(11174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">定</text></g><g data-mml-node="mi" transform="translate(12174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">义</text></g></g></g></svg></mjx-container>\hat{y} = {\hat{y_i}}^N</em>{i=1}$ 为网络输出的N个预测值。</p><p>   由匈牙利算法，可以找到每个真指对应的预测值：</p><script type="math/tex; mode=display">   \hat{\sigma} = arg \underset{\sigma\in\textstyle \sum_{N}^{}}{min}  \sum_{i}^{N}L_{match}(y_i,\hat{y_{\sigma(i)}}),</script><p>   对于某一个真值$y<em>i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="40.724ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 18000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">假</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">设</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">已</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">经</text></g><g data-mml-node="mi" transform="translate(5000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">找</text></g><g data-mml-node="mi" transform="translate(6000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">到</text></g><g data-mml-node="mi" transform="translate(7000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">了</text></g><g data-mml-node="mi" transform="translate(8000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">这</text></g><g data-mml-node="mi" transform="translate(9000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">个</text></g><g data-mml-node="mi" transform="translate(10000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text></g><g data-mml-node="mi" transform="translate(11000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">值</text></g><g data-mml-node="mi" transform="translate(12000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">对</text></g><g data-mml-node="mi" transform="translate(13000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">应</text></g><g data-mml-node="mi" transform="translate(14000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(15000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">预</text></g><g data-mml-node="mi" transform="translate(16000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">测</text></g><g data-mml-node="mi" transform="translate(17000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">值</text></g></g></g></svg></mjx-container>\hat{y</em>{\sigma(i)}}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="6.787ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 3000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">这</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">里</text></g></g></g></svg></mjx-container>\textstyle \sum<em>{N}^{}$表示所有可能的排列，代表<strong>从真值索引到预测值索引的所有的映射</strong>，然后用$L</em>{match}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="6.787ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 3000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">小</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">化</text></g></g></g></svg></mjx-container>y<em>i<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="2.262ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 1000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">和</text></g></g></g></svg></mjx-container>\hat{y</em>{\sigma(i)}}$的距离。</p><script type="math/tex; mode=display">   L_{match} = -l_{\{c_i\ne\emptyset \}}\hat{p}_{\sigma(i)}(c_i) + l_{\{c_i\ne\emptyset \}}L_{box}(b_i,\hat{b}_{\sigma{(i)}})</script><p>   意思为：假设当前从真值索引到预测值索引的所有映射为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1ex" role="img" focusable="false" viewBox="0 -431 571 442"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g></g></g></svg></mjx-container>，对于图片中的每个真值ℹ，先找到对应的预测值<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.833ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 1694 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(571,0)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(389,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(734,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></svg></mjx-container>,再看分类网络的结果$\hat{p}<em>{\sigma(i)}(c_i)<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="10.056ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 4444.7 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mo"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mi" transform="translate(444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">取</text></g><g data-mml-node="mi" transform="translate(1444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">反</text></g><g data-mml-node="mi" transform="translate(2444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">作</text></g><g data-mml-node="mi" transform="translate(3444.7,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">为</text></g></g></g></svg></mjx-container>L</em>{match}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="35.068ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 15500 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">第</text></g><g data-mml-node="mn" transform="translate(2000,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mi" transform="translate(2500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">部</text></g><g data-mml-node="mi" transform="translate(3500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">分</text></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(4500,0)"><g data-mml-node="mo"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">。</text></g></g><g data-mml-node="mi" transform="translate(5500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">再</text></g><g data-mml-node="mi" transform="translate(6500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">计</text></g><g data-mml-node="mi" transform="translate(7500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">算</text></g><g data-mml-node="mi" transform="translate(8500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">回</text></g><g data-mml-node="mi" transform="translate(9500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">归</text></g><g data-mml-node="mi" transform="translate(10500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">网</text></g><g data-mml-node="mi" transform="translate(11500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">络</text></g><g data-mml-node="mi" transform="translate(12500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(13500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">结</text></g><g data-mml-node="mi" transform="translate(14500,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">果</text></g></g></g></svg></mjx-container>\hat{b}<em>{\sigma{(i)}}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.464ex;" xmlns="http://www.w3.org/2000/svg" width="34.33ex" height="2.161ex" role="img" focusable="false" viewBox="0 -750 15174 955"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">与</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">直</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">值</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(4000,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(4759,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(5244,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5816,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(6416,0)"><path data-c="1D451" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path></g><g data-mml-node="mi" transform="translate(6936,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7281,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(7881,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z"></path></g><g data-mml-node="mi" transform="translate(8358,0)"><path data-c="1D435" d="M231 637Q204 637 199 638T194 649Q194 676 205 682Q206 683 335 683Q594 683 608 681Q671 671 713 636T756 544Q756 480 698 429T565 360L555 357Q619 348 660 311T702 219Q702 146 630 78T453 1Q446 0 242 0Q42 0 39 2Q35 5 35 10Q35 17 37 24Q42 43 47 45Q51 46 62 46H68Q95 46 128 49Q142 52 147 61Q150 65 219 339T288 628Q288 635 231 637ZM649 544Q649 574 634 600T585 634Q578 636 493 637Q473 637 451 637T416 636H403Q388 635 384 626Q382 622 352 506Q352 503 351 500L320 374H401Q482 374 494 376Q554 386 601 434T649 544ZM595 229Q595 273 572 302T512 336Q506 337 429 337Q311 337 310 336Q310 334 293 263T258 122L240 52Q240 48 252 48T333 46Q422 46 429 47Q491 54 543 105T595 229Z"></path></g><g data-mml-node="mi" transform="translate(9117,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(9602,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(10174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(11174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">差</text></g><g data-mml-node="mi" transform="translate(12174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">异</text></g><g data-mml-node="mi" transform="translate(13174,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">，</text></g><g data-mml-node="mi" transform="translate(14174,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">即</text></g></g></g></svg></mjx-container>L</em>{box}(b<em>i,\hat{b}</em>{\sigma{(i)}})<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="4.525ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 2000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">作</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">为</text></g></g></g></svg></mjx-container>L_{match}$的第2部分。</p><p>   所以，可使$L<em>{match}<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex;" xmlns="http://www.w3.org/2000/svg" width="11.312ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 5000 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">最</text></g><g data-mml-node="mi" transform="translate(1000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">小</text></g><g data-mml-node="mi" transform="translate(2000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">的</text></g><g data-mml-node="mi" transform="translate(3000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">排</text></g><g data-mml-node="mi" transform="translate(4000,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">列</text></g></g></g></svg></mjx-container>\hat{\sigma}$就是我们要找的排列，即：<em>_对于每个真值ℹ来说，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="3.833ex" height="2.398ex" role="img" focusable="false" viewBox="0 -810 1694 1060"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(285.5,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g><g data-mml-node="mo" transform="translate(571,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(960,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(1305,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container>就是这个真值所对应的预测值的索引</em></em>。</p><p>   接下来，使用上步得到的排列<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.025ex;" xmlns="http://www.w3.org/2000/svg" width="1.292ex" height="1.857ex" role="img" focusable="false" viewBox="0 -810 571 821"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mover"><g data-mml-node="mi"><path data-c="1D70E" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path></g><g data-mml-node="mo" transform="translate(285.5,16) translate(-250 0)"><path data-c="5E" d="M112 560L249 694L257 686Q387 562 387 560L361 531Q359 532 303 581L250 627L195 580Q182 569 169 557T148 538L140 532Q138 530 125 546L112 560Z"></path></g></g></g></g></g></svg></mjx-container>，计算匈牙利损失：</p><script type="math/tex; mode=display">   L_{Hungarian}(y,\hat{y}) = \sum_{i=1}^{N}[-log\hat{p}_{\hat{\sigma}(i)}(c_i) + L_{box}(b_i,\hat{b}_{\sigma{(i)}})]</script><p>   其中，<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="4.106ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1814.8 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D44F" d="M73 647Q73 657 77 670T89 683Q90 683 161 688T234 694Q246 694 246 685T212 542Q204 508 195 472T180 418L176 399Q176 396 182 402Q231 442 283 442Q345 442 383 396T422 280Q422 169 343 79T173 -11Q123 -11 82 27T40 150V159Q40 180 48 217T97 414Q147 611 147 623T109 637Q104 637 101 637H96Q86 637 83 637T76 640T73 647ZM336 325V331Q336 405 275 405Q258 405 240 397T207 376T181 352T163 330L157 322L136 236Q114 150 114 114Q114 66 138 42Q154 26 178 26Q211 26 245 58Q270 81 285 114T318 219Q336 291 336 325Z"></path></g><g data-mml-node="mi" transform="translate(429,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(914,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g></g></g></g></g></svg></mjx-container>具体为：</p><script type="math/tex; mode=display">   L_{box}(b_i,\hat{b}_{\sigma{(i)}}) = \lambda_{iou}(b_i,\hat{b}_{\sigma(i)}) + \lambda_{L1}\left \| b_i - \hat{b}_{\sigma(i)}) \right \|_1, where    \lambda_{iou},\lambda_{L1} \in R</script><p>   常用的L1 loss对于大小Bounding  Box会有不同的标度，即使它们的相对误差相似。为缓解该问题，这里使用L1 loss和广义loU损耗<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex;" xmlns="http://www.w3.org/2000/svg" width="3.971ex" height="1.902ex" role="img" focusable="false" viewBox="0 -683 1755.4 840.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D43F" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path></g><g data-mml-node="TeXAtom" transform="translate(714,-150) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(345,0)"><path data-c="1D45C" d="M201 -11Q126 -11 80 38T34 156Q34 221 64 279T146 380Q222 441 301 441Q333 441 341 440Q354 437 367 433T402 417T438 387T464 338T476 268Q476 161 390 75T201 -11ZM121 120Q121 70 147 48T206 26Q250 26 289 58T351 142Q360 163 374 216T388 308Q388 352 370 375Q346 405 306 405Q243 405 195 347Q158 303 140 230T121 120Z"></path></g><g data-mml-node="mi" transform="translate(830,0)"><path data-c="1D462" d="M21 287Q21 295 30 318T55 370T99 420T158 442Q204 442 227 417T250 358Q250 340 216 246T182 105Q182 62 196 45T238 27T291 44T328 78L339 95Q341 99 377 247Q407 367 413 387T427 416Q444 431 463 431Q480 431 488 421T496 402L420 84Q419 79 419 68Q419 43 426 35T447 26Q469 29 482 57T512 145Q514 153 532 153Q551 153 551 144Q550 139 549 130T540 98T523 55T498 17T462 -8Q454 -10 438 -10Q372 -10 347 46Q345 45 336 36T318 21T296 6T267 -6T233 -11Q189 -11 155 7Q103 38 103 113Q103 170 138 262T173 379Q173 380 173 381Q173 390 173 393T169 400T158 404H154Q131 404 112 385T82 344T65 302T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></g></svg></mjx-container>的线性组合，它是比列不变的。</p><p>   <strong>DETR的End-to-End的原理概括</strong></p><ul><li><p><strong>DETR如何训练?</strong></p><p>训练集李的任意一张图片，假设第1张图片，通过模型产生100个预测框Predict Bounding Box，假设这张图片有3个GT Bounding Box，它们分别是Cat,Monkey,Pig。</p><p>​                               <script type="math/tex">(label_{Cat} = 1,label_{Monkey} = 19,label_{Pig} = 80)</script></p><p>问题是：如何知道这100个预测框哪个对应Cat，哪个对应Monkey，哪个对应Pig？</p><p>首先建立一个(100,3)的矩阵，矩阵元素即为公式(7)所得结果。举个例子：比如左上角(1,1)号元素的含义是：第1个预测框对应Cat(label = 1)的情况下的$L<em>{match}$值。我们用<strong>scipy.optimize</strong>这个库中的<strong>linear_sum_assignment</strong>函数找到最优匹配，这个过程称之为：<em>_”匈牙利算法(Hungarian Algorithm)”</em></em>。</p><p>假设<strong>linear_sum_assignment</strong>结果是：第16个预测框对应Cat，第39个预测框对应Monkey，第88个预测框对应Pig。接下来，会将第16、39、88个预测框挑出来安装公式(9)计算这个图片的Loss。最后，将所有的图片都按照这个模式去训练模型。</p></li></ul><ul><li><p><strong>训练完如何用?</strong></p><p>训练完，你的模型学习到了一种能力，即：<strong>模型产生的100个预测框，它指导某个预测框该对应什么Object</strong>，例如，模型学习到：第1个预测框对应Cat(label=1)，第2个预测框对应Dog(label=11)，第3个预测框对应Mouse(label=32)，第4-100个预测框对应……</p></li></ul><ul><li><p><strong>为什么训练完后，模型学习到了一种能力，即：模型产生的100个预测框，它指导某个预测框该对应什么Object？</strong></p><p>前文提到Object queries，它是一个维度为(100,b,256)维的张量，初始化元素维全0。实现方式是<strong>nn.Embedding(num_queries,hidden_dim)</strong>，这里num<em>queries=100，hidden<em>dim=256，它是可以训练的。这里的b指batch size，对于但章图片而言，假设Object queries是一个维度为(100,256)维的张量。在训练完模型后，这个张量也训练完成了，那</em></em>此时的Object queries代表什么呢?</p><p>可以把此时的<strong>Object queries看成100个格子，每个格子都是256维的向量</strong>。训练完成后，这100个格子里<strong>注入了不同Object的位置信息和类别信息</strong>。例如：第一个格子里的这256维的向量代表着Cat这种Object的位置信息，这种信息是通过训练，考虑所有图片的某个位置附近的Cat编码特征，属于和位置有关的全局Car统计信息。</p><p>测试时，倘若图片中有Cat，Monkey，Pig三种物体，该图片会输入到编码器中进行特征编码，假设特征没有丢失，Decoder的<strong>Key</strong>和 <strong>Value</strong>就是编码器输出的编码向量，而<strong>Query</strong>就是Object queries，就是我们的100个格子。</p><p><strong>Query可以看作代表不同Object的信息，而Key和Value可以看作代表图像的全局信息</strong>。</p><p>通过注意力模块，将<strong>Query</strong>和<strong>Key</strong>计算，然后加权<strong>Value</strong>得到解码器输出。对于第1个格子的<strong>Query</strong>会和<strong>Key</strong>中的所有向量进行计算，目的是查找某个位置附近有没有Cat,如果有那么该特征就会加权输出，若没有，输出信息就不会有Cat。</p><p>整个过程计算完成后就可以把编码向量中的Cat，Monkey，Pig的编码嵌入信息提取出来，容纳后后面接上FFN进行分类和回归就比较容易，因为特征已经对齐了。</p><p>总而言之，Object queries在训练过程中，对于N个格子会压缩入对应的位置和类别相关统计信息，在测试阶段就可以利用<strong>Query区和某个图像的编码特征Key，Value</strong>计算，<strong>若图片中刚好有Query想找的特征，比如Cat，则这个特征就能提取出来，最后通过2个FFN进行分类和回归</strong>。Object queries作用非常类似Faster R-CNN中的anchor，这个anchor是可学习的，由于维度比较高，故可以表征的东西丰富，训练时间相应也会越长。</p></li></ul><p><strong>Experiments：</strong></p><p><strong>1.性能对比：</strong></p><p>​       <img src="https://pic4.zhimg.com/80/v2-a82446719e7ebd58ac2b3680bd096b6b_720w.webp" alt=""></p><p><strong>2.编码器层数对比:</strong></p><p><img src="https://pic2.zhimg.com/80/v2-35d68162e148aa1457e7f91d135cfdf1_720w.webp" alt=""></p><p>实验发现，编码器层数越多越好，最后选择6层。</p><p>下图为最后一个Encoder Layer的attention可视化，Encoder已经分离了instances，简化了Decoder的对象提取和定位。</p><p><img src="https://pic3.zhimg.com/80/v2-dffe148c6e78f7b67cf6aa5c8bbbc316_720w.webp" alt=""></p><p><strong>3.解码器层数对比:</strong></p><p><img src="https://pic4.zhimg.com/80/v2-87f7c11d6b088af0d0351e3e4808e4b7_720w.webp" alt=""></p><p>可以发现，性能随着解码器层数的增加而提升。下图为Decoder Layer的attention可视化：</p><p><img src="https://pic1.zhimg.com/80/v2-6b80634bf88e496f035945ec25c40764_720w.webp" alt=""></p><p>类似于可视化编码器注意力，作者用不同颜色给每个预测对象的注意力图着色。</p><p><strong>Final: Question:</strong></p><p><strong>Q:</strong> 如果他的N个object query在训练完之后，每个都有了自己对应的目标，比如cat\monkey\pig等，但是如果测试图中，有好多同一目标该怎么办？这时候的输出(N，class+1)与(N,4)该怎么输出多个同一目标？</p><p><strong>A:</strong> N个object query在训练完之后，每个都有了自己对应的目标”只是一种便于理解的方式，实际上也可能是多个query都能找到同样类型的object。比如第49,65个query都可以对应Cat。但anyway，还是query个数多一点比较好，像Deformable DETR就用了N=300。</p><p><strong>Q</strong>:<strong>残差链接用途</strong></p><p><strong>A：</strong>残差链接减小了梯度消失的影响，加入残差链接，就能保证层次很深的模型不会出现梯度消失的现象。</p><p><strong>Q:encoder的输出如何作为decoder的输入</strong></p><p><strong>A：</strong>根据transformer的整体架构图可以看出，decoder的第二层是一个多头注意力（Multi-Head Attention）。既然是多头注意力了，那么一定会涉及到Q、K、V三个矩阵。从上图中还可以看出，K、V矩阵是由encoder部分的输出作为decoder的输入的。刚才提到，encoder最后一层的输出是Zn。那么如何把Zn这一个矩阵变成K、V两个矩阵呢？很简单，和注意力机制内部一样，初始化一个新的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="4.106ex" height="1.964ex" role="img" focusable="false" viewBox="0 -846 1814.8 868"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D43E" d="M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z"></path></g></g></g></g></g></svg></mjx-container>和<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.05ex;" xmlns="http://www.w3.org/2000/svg" width="3.914ex" height="1.964ex" role="img" focusable="false" viewBox="0 -846 1730 868"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z"></path></g><g data-mml-node="TeXAtom" transform="translate(1136.2,363) scale(0.707)" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="1D449" d="M52 648Q52 670 65 683H76Q118 680 181 680Q299 680 320 683H330Q336 677 336 674T334 656Q329 641 325 637H304Q282 635 274 635Q245 630 242 620Q242 618 271 369T301 118L374 235Q447 352 520 471T595 594Q599 601 599 609Q599 633 555 637Q537 637 537 648Q537 649 539 661Q542 675 545 679T558 683Q560 683 570 683T604 682T668 681Q737 681 755 683H762Q769 676 769 672Q769 655 760 640Q757 637 743 637Q730 636 719 635T698 630T682 623T670 615T660 608T652 599T645 592L452 282Q272 -9 266 -16Q263 -18 259 -21L241 -22H234Q216 -22 216 -15Q213 -9 177 305Q139 623 138 626Q133 637 76 637H59Q52 642 52 648Z"></path></g></g></g></g></g></svg></mjx-container>​权重矩阵，用Zn去乘这两个矩阵就可以了。总结一下，假如该transformer的编码部分有6层encoder，每层encoder有8个“头”，那么编码部分一共初始化了多少个<img src="https://latex.csdn.net/eq?W%5E%7BQ%7D" alt="W^{Q}">、<img src="https://latex.csdn.net/eq?W%5E%7BK%7D" alt="W^{K}">、<img src="https://latex.csdn.net/eq?W%5E%7BV%7D" alt="W^{V}">权重矩阵？</p><blockquote><p><img src="https://latex.csdn.net/eq?W%5E%7BK%7D" alt="W^{K}">、<img src="https://latex.csdn.net/eq?W%5E%7BV%7D" alt="W^{V}">都是6×8+1个，<img src="https://latex.csdn.net/eq?W%5E%7BQ%7D" alt="W^{Q}">有6×8个。</p></blockquote><p><strong>DETR模型弊端</strong></p><p>如果用10*10的特征图表示一张图片，即一张图片划分成100个Patch，那么就有100个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要100*100=10000次。</p><p>如果用100*100的特征图表示一张图片，即一张图片划分成10000个Patch，那么就有10000个特征向量，每一个特征向量要和所有的特征向量计算注意力机制，所以计算一次注意力机制要10000*100000=1亿次。由此可见，每一个Patch的边长缩小10倍，计算量要增加一万倍。因为识别小物体有恰恰需要划分更小的Patch，因此DETR的小物体识别能力有限。<br>                                                      <img src="https://img-blog.csdnimg.cn/img_convert/065259c3a0e98a8e500c6f59db05fbab.png" style="zoom:36%;"></p>]]></content>
      
      
      <categories>
          
          <category> -技术 -笔记 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> -BEV -DETR </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
